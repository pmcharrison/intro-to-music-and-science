@ARTICLE{Chi2005-er,
  title     = "Multiresolution spectrotemporal analysis of complex sounds",
  author    = "Chi, Taishih and Ru, Powen and Shamma, Shihab A",
  abstract  = "A computational model of auditory analysis is described that is
               inspired by psychoacoustical and neurophysiological findings in
               early and central stages of the auditory system. The model
               provides a unified multiresolution representation of the
               spectral and temporal features likely critical in the perception
               of sound. Simplified, more specifically tailored versions of
               this model have already been validated by successful application
               in the assessment of speech intelligibility [Elhilali et al.,
               Speech Commun. 41(2-3), 331-348 (2003); Chi et al., J. Acoust.
               Soc. Am. 106, 2719-2732 (1999)] and in explaining the perception
               of monaural phase sensitivity [R. Carlyon and S. Shamma, J.
               Acoust. Soc. Am. 114, 333-348 (2003)]. Here we provide a more
               complete mathematical formulation of the model, illustrating how
               complex signals are transformed through various stages of the
               model, and relating it to comparable existing models of auditory
               processing. Furthermore, we outline several reconstruction
               algorithms to resynthesize the sound from the model output so as
               to evaluate the fidelity of the representation and contribution
               of different features and cues to the sound percept.",
  journal   = "The journal of the Acoustical Society of America",
  publisher = "Acoustical Society of America (ASA)",
  volume    =  118,
  number    =  2,
  pages     = "887--906",
  month     =  aug,
  year      =  2005,
  keywords  = "To read",
  language  = "en",
  issn      = "0001-4966, 1520-8524",
  pmid      = "16158645",
  doi       = "10.1121/1.1945807"
}

@ARTICLE{Tomasevic2021-zp,
  title     = "Exploring annotations for musical pattern discovery gathered
               with digital annotation tools",
  author    = "Toma{\v s}evi{\'c}, Darian and Wells, Stephan and Ren, Iris
               Yuping and Volk, Anja and Pesek, Matev{\v z}",
  abstract  = "The study of inter-annotator agreement in musical pattern
               annotations has gained increased attention over the past few
               years. While expert annotations are often taken as the reference
               for evaluating pattern discovery algorithms, relying on just one
               reference is not usually sufficient to capture the complex
               musical relations between patterns. In this paper, we address
               the potential of digital annotation tools to enable large-scale
               annotations of musical patterns, by comparing datasets gathered
               with two recently developed digital tools. We investigate the
               influence of the tools and different annotator backgrounds on
               the annotation process by performing inter-annotator agreement
               analysis and feature-based analysis on the annotated patterns.
               We discuss implications for further adaptation of annotation
               tools, and the potential for deriving reference data from such
               rich annotation datasets for the evaluation of automatic pattern
               discovery algorithms in the future.",
  journal   = "Journal of Mathematics \& Music. Mathematical and Computational
               Approaches to Music Theory, Analysis, Composition and
               Performance",
  publisher = "Taylor \& Francis",
  volume    =  15,
  number    =  2,
  pages     = "194--207",
  month     =  may,
  year      =  2021,
  issn      = "1745-9737",
  doi       = "10.1080/17459737.2021.1943026"
}

@ARTICLE{Knoferle2012-vj,
  title    = "Crossmodal correspondences between sounds and tastes",
  author   = "Kn{\"o}ferle, Klemens and Spence, Charles",
  abstract = "In this article, the rapidly growing body of research that has
              been published recently on the topic of crossmodal
              correspondences that involve auditory and gustatory/flavor
              stimuli is critically reviewed. The evidence demonstrates that
              people reliably match different tastes/flavors to auditory
              stimuli varying in both their psychoacoustic (e.g., pitch) and
              musical (e.g., timbre) properties. In order to stimulate further
              progress in this relatively young research field, the present
              article aims at consolidating prior findings concerning specific
              auditory-gustatory mappings, whereby special attention is given
              to highlighting (1) any conflicts in the existing experimental
              evidence and (2) any potential caveats with regard to the most
              appropriate interpretation of prior studies. Next, potential
              mechanisms underlying auditory-gustatory crossmodal
              correspondences are discussed. Finally, a number of potentially
              fruitful avenues for future research are outlined.",
  journal  = "Psychonomic bulletin \& review",
  month    =  oct,
  year     =  2012,
  language = "en",
  issn     = "1069-9384, 1531-5320",
  pmid     = "23055144",
  doi      = "10.3758/s13423-012-0321-z"
}

@INCOLLECTION{Balzano1982-za,
  title     = "The Pitch Set as a Level of Description for Studying Musical
               Pitch Perception",
  booktitle = "Music, Mind, and Brain: The Neuropsychology of Music",
  author    = "Balzano, Gerald J",
  editor    = "Clynes, Manfred",
  abstract  = "How shall we define the musical stimulus? Traditionally, music
               theorists interested in pitch phenomena have sought the
               definition in terms of ratios of whole numbers. Such ratios can
               provide a description of most, if not all, of the musical
               intervals in use today, and can be translated readily into
               ratios of physically realizable tone frequencies.
               Psychoacousticians, following the dictates of reductionism, have
               sought a finer grain of analysis than this, pointing out that
               the essential constituent of an interval is a tone, and that the
               study of music perception must ultimately refer to the
               perception of single tones and their frequency components.
               Accordingly, a great deal of scientific effort has gone into
               studying the perception of isolated tones.",
  publisher = "Springer US",
  pages     = "321--351",
  year      =  1982,
  address   = "Boston, MA",
  isbn      = "9781468489170",
  doi       = "10.1007/978-1-4684-8917-0\_17"
}

@ARTICLE{Harrison2017-me,
  title    = "Applying modern psychometric techniques to melodic discrimination
              testing: Item response theory, computerised adaptive testing, and
              automatic item generation",
  author   = "Harrison, Peter M C and Collins, Tom and M{\"u}llensiefen, Daniel",
  abstract = "Modern psychometric theory provides many useful tools for ability
              testing, such as item response theory, computerised adaptive
              testing, and automatic item generation. However, these techniques
              have yet to be integrated into mainstream psychological practice.
              This is unfortunate, because modern psychometric techniques can
              bring many benefits, including sophisticated reliability
              measures, improved construct validity, avoidance of exposure
              effects, and improved efficiency. In the present research we
              therefore use these techniques to develop a new test of a
              well-studied psychological capacity: melodic discrimination, the
              ability to detect differences between melodies. We calibrate and
              validate this test in a series of studies. Studies 1 and 2
              respectively calibrate and validate an initial test version,
              while Studies 3 and 4 calibrate and validate an updated test
              version incorporating additional easy items. The results support
              the new test's viability, with evidence for strong reliability
              and construct validity. We discuss how these modern psychometric
              techniques may also be profitably applied to other areas of music
              psychology and psychological science in general.",
  journal  = "Scientific reports",
  volume   =  7,
  number   =  1,
  pages    = "3618",
  month    =  jun,
  year     =  2017,
  keywords = "My publications",
  language = "en",
  issn     = "2045-2322",
  pmid     = "28620165",
  doi      = "10.1038/s41598-017-03586-z",
  pmc      = "PMC5472621"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@UNPUBLISHED{Gotz2021-os,
  title    = "Let the Algorithm Speak: How to Use Neural Networks for Automatic
              Item Generation in Psychological Scale Development",
  author   = "G{\"o}tz, Friedrich M and Maertens, Rakoen and Linden, Sander van
              der",
  abstract = "Measurement is at the heart of scientific research. As
              many---perhaps most---psychological constructs cannot be directly
              observed, there is a steady demand for sound self-report scales
              to assess such latent constructs. However, scale development is a
              tedious process that requires researchers to produce good items
              in large quantities. In the current tutorial, we introduce,
              explain, and apply the Psychometric Item Generator (PIG), an
              open-source, free-to-use, self-sufficient natural language
              processing algorithm that produces large-scale, human-like,
              customised text output within a few mouse clicks. The PIG is
              based on the GPT-2, a powerful generative language model, and
              runs on Google Colaboratory---an interactive virtual notebook
              environment that executes code on state-of-the-art virtual
              machines at no cost. We demonstrate that based on an input of
              three sentences, the PIG produces 65 items that pass initial face
              validity checks within a single iteration of code and a runtime
              of less than one minute. The PIG does not require any prior
              coding skills or access to computational resources and can be
              easily tailored to any desired context by simply switching out
              short linguistic prompts in a single line of code. Additionally,
              the PIG can also be used as a bottom-up tool to expand and
              diversify the conceptual understanding of a construct or derive
              hypotheses about its relationships to other, existing constructs.
              In short, we present an effective, novel machine learning
              solution to an old psychological challenge. As such, the PIG will
              not only not require you to learn a new language---but speak
              yours.",
  journal  = "https://psyarxiv.com › ...https://psyarxiv.com › ...",
  month    =  jun,
  year     =  2021,
  keywords = "artificial intelligence; automated item generation; neural
              networks; psychometric item generator; psychometrics; scale
              development",
  doi      = "10.31234/osf.io/m6s28"
}

@ARTICLE{Harrison2020-gu,
  title    = "{PPM-Decay}: A computational model of auditory prediction with
              memory decay",
  author   = "Harrison, Peter M C and Bianco, Roberta and Chait, Maria and
              Pearce, Marcus T",
  abstract = "Statistical learning and probabilistic prediction are fundamental
              processes in auditory cognition. A prominent computational model
              of these processes is Prediction by Partial Matching (PPM), a
              variable-order Markov model that learns by internalizing n-grams
              from training sequences. However, PPM has limitations as a
              cognitive model: in particular, it has a perfect memory that
              weights all historic observations equally, which is inconsistent
              with memory capacity constraints and recency effects observed in
              human cognition. We address these limitations with PPM-Decay, a
              new variant of PPM that introduces a customizable memory decay
              kernel. In three studies-one with artificially generated
              sequences, one with chord sequences from Western music, and one
              with new behavioral data from an auditory pattern detection
              experiment-we show how this decay kernel improves the model's
              predictive performance for sequences whose underlying statistics
              change over time, and enables the model to capture effects of
              memory constraints on auditory pattern detection. The resulting
              model is available in our new open-source R package, ppm
              (https://github.com/pmcharrison/ppm).",
  journal  = "PLoS computational biology",
  volume   =  16,
  number   =  11,
  pages    = "e1008304",
  month    =  nov,
  year     =  2020,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "33147209",
  doi      = "10.1371/journal.pcbi.1008304",
  pmc      = "PMC7668605"
}

@ARTICLE{Chen2021-jy,
  title         = "{SurpriseNet}: Melody Harmonization Conditioning on
                   User-controlled Surprise Contours",
  author        = "Chen, Yi-Wei and Lee, Hung-Shin and Chen, Yen-Hsing and
                   Wang, Hsin-Min",
  abstract      = "The surprisingness of a song is an essential and seemingly
                   subjective factor in determining whether the listener likes
                   it. With the help of information theory, it can be described
                   as the transition probability of a music sequence modeled as
                   a Markov chain. In this study, we introduce the concept of
                   deriving entropy variations over time, so that the surprise
                   contour of each chord sequence can be extracted. Based on
                   this, we propose a user-controllable framework that uses a
                   conditional variational autoencoder (CVAE) to harmonize the
                   melody based on the given chord surprise indication. Through
                   explicit conditions, the model can randomly generate various
                   and harmonic chord progressions for a melody, and the
                   Spearman's correlation and p-value significance show that
                   the resulting chord progressions match the given surprise
                   contour quite well. The vanilla CVAE model was evaluated in
                   a basic melody harmonization task (no surprise control) in
                   terms of six objective metrics. The results of experiments
                   on the Hooktheory Lead Sheet Dataset show that our model
                   achieves performance comparable to the state-of-the-art
                   melody harmonization model.",
  month         =  aug,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2108.00378",
  primaryClass  = "cs.SD",
  arxivid       = "2108.00378"
}

@ARTICLE{Conklin2021-ry,
  title     = "Mining contour sequences for significant closed patterns",
  author    = "Conklin, Darrell",
  abstract  = "Sequential pattern mining in music is a central part of
               automated music analysis and music generation. This paper
               evaluates sequential pattern mining on a corpus of Mozarabic
               chant neume sequences that have been annotated by a musicologist
               with intra-opus patterns. Significant patterns are discovered in
               three settings: all closed patterns, maximal closed patterns,
               and minimal closed patterns. Each setting is evaluated against
               the annotated patterns using the measures of recall and
               precision. The results indicate that it is possible to retrieve
               all known patterns with an acceptable precision using
               significant closed pattern discovery.",
  journal   = "Journal of Mathematics \& Music. Mathematical and Computational
               Approaches to Music Theory, Analysis, Composition and
               Performance",
  publisher = "Taylor \& Francis",
  volume    =  15,
  number    =  2,
  pages     = "112--124",
  month     =  may,
  year      =  2021,
  keywords  = "To read",
  issn      = "1745-9737",
  doi       = "10.1080/17459737.2021.1903591"
}

@ARTICLE{Laaksonen2021-kp,
  title     = "Discovering distorted repeating patterns in polyphonic music
               through longest increasing subsequences",
  author    = "Laaksonen, Antti and Lemstr{\"o}m, Kjell",
  abstract  = "We study the problem of identifying repetitions under
               transposition and time-warp invariances in polyphonic symbolic
               music. Using a novel onset-time-pair representation, we reduce
               the repeating pattern discovery problem to instances of the
               classical problem of finding the longest increasing
               subsequences. The resulting algorithm works in O(n2log?n) time
               where n is the number of notes in a musical work. We also study
               windowed variants of the problem where onset-time differences
               between notes are restricted, and show that they can also be
               solved in O(n2log?n) time using the algorithm.",
  journal   = "Journal of Mathematics \& Music. Mathematical and Computational
               Approaches to Music Theory, Analysis, Composition and
               Performance",
  publisher = "Taylor \& Francis",
  volume    =  15,
  number    =  2,
  pages     = "99--111",
  month     =  may,
  year      =  2021,
  issn      = "1745-9737",
  doi       = "10.1080/17459737.2021.1896811"
}

@ARTICLE{Neubarth2021-ks,
  title     = "Modelling pattern interestingness in comparative music corpus
               analysis",
  author    = "Neubarth, Kerstin and Conklin, Darrell",
  abstract  = "In computational pattern discovery, pattern evaluation measures
               select or rank patterns according to their potential
               interestingness in a given analysis task. Many measures have
               been proposed to accommodate different pattern types and
               properties. This paper presents a method and case study
               employing measures for frequent, characteristic, associative,
               contrasting, dependent, and significant patterns to model
               pattern interestingness in a reference analysis, Frances
               Densmore's study of Teton Sioux songs. Results suggest that
               interesting changes from older to more recent Sioux songs
               according to Densmore's analysis are best captured by contrast,
               dependency, and significance measures.",
  journal   = "Journal of Mathematics \& Music. Mathematical and Computational
               Approaches to Music Theory, Analysis, Composition and
               Performance",
  publisher = "Taylor \& Francis",
  volume    =  15,
  number    =  2,
  pages     = "154--167",
  month     =  may,
  year      =  2021,
  issn      = "1745-9737",
  doi       = "10.1080/17459737.2021.1900436"
}

@ARTICLE{White2021-bt,
  title     = "Some observations on autocorrelated patterns within
               computational meter identification",
  author    = "White, Christopher Wm",
  abstract  = "The computational approach of autocorrelation relies on
               recurrent patterns within a musical signal to identify and
               analyze the meter of musical passages. This paper suggests that
               the autocorrelation process can act as a computational proxy for
               the act of period extraction, a crucial aspect of the cognition
               of musical meter, by identifying periodicities with which
               similar events tend to occur within a musical signal. Three
               analytical vignettes highlight three aspects of the identified
               patterns: (1) that the similarities between manifestations of
               the same patterns are often inexact, (2) that these patterns
               have ambiguous boundaries, and (3) that many more patterns exist
               on the musical surface than contribute to the passage's
               notated/felt meter, each of which overlaps with observations
               from music theory and behavioral research. An Online Supplement
               at chriswmwhite.com/autocorrelation contains accompanying data.",
  journal   = "Journal of Mathematics \& Music. Mathematical and Computational
               Approaches to Music Theory, Analysis, Composition and
               Performance",
  publisher = "Taylor \& Francis",
  volume    =  15,
  number    =  2,
  pages     = "181--193",
  month     =  may,
  year      =  2021,
  issn      = "1745-9737",
  doi       = "10.1080/17459737.2021.1923843"
}

@ARTICLE{Verosky2021-vo,
  title    = "Interpreting the tonal hierarchy through corpus analysis",
  author   = "Verosky, Niels J",
  abstract = "Research in tonality perception commonly references the
              correlation between scale-degree occurrence frequencies and
              probe-tone ratings of tonal stability. This corpus study compares
              frequency of occurrence with 3 other statistical cues of tonal
              emphasis: average scale-degree duration, percentage of
              scale-degree instances appearing on downbeats, and percentage of
              scale-degree instances appearing in phrase-final positions. Using
              a mixed linear model that accounts for membership in the diatonic
              scale and random effects at the melody level, Experiment 1 finds
              that all frequency- and non-frequency-based measures of tonal
              emphasis except duration are highly significant predictors of the
              tonal hierarchy, with scale membership explaining the most unique
              variance, followed by phrase-final position and frequency of
              occurrence, then metric placement. Experiment 2 demonstrates that
              controlling for scale membership greatly attenuates the
              relationship between occurrence frequencies and probe-tone
              ratings, with frequencies explaining only 7\% of variance in the
              tonal hierarchy beyond scale membership. Experiment 3 shows that
              phrase-final position, metric placement, and frequency best
              differentiate the tonic from other scale degrees, with all other
              predictors failing to reach significance. Together, these results
              suggest that higher frequency counts correspond to a more general
              tendency for tonally stable scale degrees to be emphasized across
              multiple musical dimensions and that frequency of occurrence is
              not a uniquely informative cue of tonal emphasis. (PsycInfo
              Database Record (c) 2021 APA, all rights reserved)",
  journal  = "Psychomusicology: Music, Mind, and Brain",
  month    =  aug,
  year     =  2021,
  keywords = "To read",
  issn     = "0275-3987, 2162-1535",
  doi      = "10.1037/pmu0000276"
}

@ARTICLE{Zacharakis2014-iz,
  title     = "An interlanguage study of musical timbre semantic dimensions and
               their acoustic correlates",
  author    = "Zacharakis, Asterios and Pastiadis, Konstantinos and Reiss,
               Joshua D",
  abstract  = "A study of musical timbre semantics was conducted with listeners
               from two different linguistic groups. In two separate
               experiments, native Greek and English speaking participants were
               asked to describe 23 musical instrument tones of variable pitch
               using a predefined vocabulary of 30 adjectives. The common
               experimental protocol facilitated the investigation of the
               influence of language on musical timbre semantics by allowing
               for direct comparisons between linguistic groups. Data reduction
               techniques applied to the data of each group revealed three
               salient semantic dimensions that shared common conceptual
               properties between linguistic groups namely: luminance, texture,
               and mass. The results supported universality of timbre
               semantics. A correlation analysis between physical
               characteristics and semantic dimensions associated: i) texture
               with the energy distribution of harmonic partials, ii) thickness
               (a term related to either mass or luminance) and brilliance with
               inharmonicity and spectral centroid variation, and iii) F0 with
               mass or luminance depending on the linguistic group.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  31,
  number    =  4,
  pages     = "339--358",
  month     =  apr,
  year      =  2014,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2014.31.4.339"
}

@ARTICLE{Lahdelma2020-eb,
  title     = "Cultural familiarity and musical expertise impact the
               pleasantness of consonance/dissonance but not its perceived
               tension",
  author    = "Lahdelma, Imre and Eerola, Tuomas",
  abstract  = "The contrast between consonance and dissonance is vital in
               making music emotionally meaningful. Consonance typically
               denotes perceived agreeableness and stability, while dissonance
               disagreeableness and a need of resolution. This study addresses
               the perception of consonance/dissonance in single intervals and
               chords with two empirical experiments conducted online.
               Experiment 1 explored the perception of a representative sample
               of intervals and chords to investigate the overlap between the
               seven most used concepts (Consonance, Smoothness, Purity,
               Harmoniousness, Tension, Pleasantness, Preference) denoting
               consonance/dissonance in all the available (60) empirical
               studies published since 1883. The results show that the concepts
               exhibit high correlations, albeit these are somewhat lower for
               non-musicians compared to musicians. In Experiment 2 the
               stimuli's cultural familiarity was divided into three levels,
               and the correlations between the key concepts of Consonance,
               Tension, Harmoniousness, Pleasantness, and Preference were
               further examined. Cultural familiarity affected the correlations
               drastically across both musicians and non-musicians, but in
               different ways. Tension maintained relatively high correlations
               with Consonance across musical expertise and cultural
               familiarity levels, making it a useful concept for studies
               addressing both musicians and non-musicians. On the basis of the
               results a control for cultural familiarity and musical expertise
               is recommended for all studies investigating
               consonance/dissonance perception.",
  journal   = "Scientific reports",
  publisher = "nature.com",
  volume    =  10,
  number    =  1,
  pages     = "8693",
  month     =  may,
  year      =  2020,
  language  = "en",
  issn      = "2045-2322",
  pmid      = "32457382",
  doi       = "10.1038/s41598-020-65615-8",
  pmc       = "PMC7250829"
}

@BOOK{Long2014-fo,
  title     = "Architectural Acoustics",
  author    = "Long, Marshall",
  publisher = "Elsevier Academic Press",
  edition   = "Second edition",
  year      =  2014,
  address   = "Cambridge, MA"
}

@BOOK{Raf_Orlowski2021-vj,
  title     = "Acoustics in Architectural Design",
  author    = "{Raf Orlowski}",
  abstract  = "It was not until the beginning of the twentieth century that the
               physicist Wallace Clement Sabine developed his theory of
               reverberation, which has remained fundamental to architectural
               acoustics to this day, and has subsequently been applied to many
               building types, especially those for the performing arts. Yet
               the practice of architectural acoustics goes back much further
               with the impressive designs of the Greeks proving highly
               influential. This comprehensive book explores the development of
               acoustics in architectural design from the theatres of Classical
               Greece, through the early development of opera houses, concert
               halls and theatres, to the research work of Sabine and his
               successors and its influence on twentieth- and
               twenty-first-century buildings. Topics covered include: the
               fundamentals of acoustics; the influential legacy of the Greeks
               and Romans; the evolving design of opera houses, theatres and
               concert halls and, finally, the acoustics of schools, music
               schools and recital halls.",
  publisher = "The Crowood Press",
  year      =  2021,
  address   = "Ramsbury",
  keywords  = "ARCHITECTURE / Design, Drafting, Drawing \& Presentation;
               TECHNOLOGY \& ENGINEERING / Acoustics \& Sound;To read",
  isbn      = "9781785008788, 9781785008795"
}

@ARTICLE{Lynn2021-ez,
  title     = "Dark tone quality and vocal tract shaping in soprano song
               production: Insights from real-time {MRI}",
  author    = "Lynn, Elisabeth and Narayanan, Shrikanth S and Lammert, Adam C",
  abstract  = "Tone quality termed ?dark? is an aesthetically important
               property of Western classical voice performance and has been
               associated with lowered formant frequencies, lowered larynx, and
               widened pharynx. The present study uses real-time magnetic
               resonance imaging with synchronous audio recordings to
               investigate dark tone quality in four professionally trained
               sopranos with enhanced ecological validity and a relatively
               complete view of the vocal tract. Findings differ from
               traditional accounts, indicating that labial narrowing may be
               the primary driver of dark tone quality across performers, while
               many other aspects of vocal tract shaping are shown to differ
               significantly in a performer-specific way.",
  journal   = "JASA Express Letters",
  publisher = "Acoustical Society of America",
  volume    =  1,
  number    =  7,
  pages     = "075202",
  month     =  jul,
  year      =  2021,
  keywords  = "To read",
  doi       = "10.1121/10.0005109"
}

@ARTICLE{Lahdelma2021-qy,
  title     = "Sweetness is in the ear of the beholder: Chord preference across
               United Kingdom and Pakistani listeners",
  author    = "Lahdelma, Imre and Athanasopoulos, George and Eerola, Tuomas",
  abstract  = "The majority of research in the field of music perception has
               been conducted with Western participants, and it has remained
               unclear which aspects of music perception are culture dependent,
               and which are universal. The current study compared how
               participants unfamiliar with Western music (people from the
               Khowar and Kalash tribes native to Northwest Pakistan with
               minimal exposure to Western music) perceive affect (positive
               versus negative) in musical chords compared with United Kingdom
               (UK) listeners, as well as the overall preference for these
               chords. The stimuli consisted of four distinct chord types
               (major, minor, augmented, and chromatic) and were played as both
               vertical blocks (pitches presented concurrently) and arpeggios
               (pitches presented successively). The results suggest that the
               Western listener major-positive minor-negative affective
               distinction is opposite for Northwest Pakistani listeners,
               arguably because of the reversed prevalence of these chords in
               the two music cultures. The aversion to the harsh dissonance of
               the chromatic cluster is present cross-culturally, but the
               preference for the consonance of the major triad varies between
               UK and Northwest Pakistani listeners, depending on cultural
               familiarity. Our findings imply not only notable cultural
               variation but also commonalities in chord perception across
               Western and non-Western listeners.",
  journal   = "Annals of the New York Academy of Sciences",
  publisher = "Wiley",
  volume    =  1502,
  number    =  1,
  pages     = "72--84",
  month     =  jul,
  year      =  2021,
  keywords  = "chord; consonance; cross-cultural; dissonance; harmony; music;To
               read",
  copyright = "http://creativecommons.org/licenses/by/4.0/",
  language  = "en",
  issn      = "0077-8923, 1749-6632",
  pmid      = "34240419",
  doi       = "10.1111/nyas.14655"
}

@INPROCEEDINGS{Cambouropoulos2021-au,
  title     = "Symbolic Representation and Processing of Musical Structure:
               Stream Segments, Pitch Interval Patterns, General Chord Types",
  booktitle = "Culture and Computing. Interactive Cultural Heritage and Arts",
  author    = "Cambouropoulos, Emilios",
  abstract  = "The difficulty of modelling musical structure in a general and
               cognitively plausible manner is due primarily to music's
               inter-dependent multi-parametric and multi-level nature that
               allows multiple structural interpretations to emerge.
               Traditional AI symbolic processing methods, however, can be used
               effectively for modelling particular analytic and creative
               aspects of musical structure. In this paper three specific
               problems of music structure, namely, segmentation and streaming,
               pattern extraction, harmonic abstraction and generation, will be
               addressed with a view to highlighting the importance of problem
               definitions, music representation and multi-parametric
               hierarchical cognitively-inspired processing methodologies.
               Existing proof-of-concept models are used as a basis for a
               theoretical discussion.",
  publisher = "Springer International Publishing",
  pages     = "201--212",
  year      =  2021,
  keywords  = "To read",
  doi       = "10.1007/978-3-030-77411-0\_14"
}

@ARTICLE{Mauch2015-bc,
  title    = "The evolution of popular music: {USA} 1960-2010",
  author   = "Mauch, Matthias and MacCallum, Robert M and Levy, Mark and Leroi,
              Armand M",
  abstract = "In modern societies, cultural change seems ceaseless. The flux of
              fashion is especially obvious for popular music. While much has
              been written about the origin and evolution of pop, most claims
              about its history are anecdotal rather than scientific in nature.
              To rectify this, we investigate the US Billboard Hot 100 between
              1960 and 2010. Using music information retrieval and text-mining
              tools, we analyse the musical properties of approximately 17 000
              recordings that appeared in the charts and demonstrate
              quantitative trends in their harmonic and timbral properties. We
              then use these properties to produce an audio-based
              classification of musical styles and study the evolution of
              musical diversity and disparity, testing, and rejecting, several
              classical theories of cultural change. Finally, we investigate
              whether pop musical evolution has been gradual or punctuated. We
              show that, although pop music has evolved continuously, it did so
              with particular rapidity during three stylistic 'revolutions'
              around 1964, 1983 and 1991. We conclude by discussing how our
              study points the way to a quantitative science of cultural
              change.",
  journal  = "Royal Society open science",
  volume   =  2,
  number   =  5,
  pages    = "150081",
  month    =  may,
  year     =  2015,
  keywords = "cultural evolution; diversity; popular music; stylistic
              revolutions",
  language = "en",
  issn     = "2054-5703",
  pmid     = "26064663",
  doi      = "10.1098/rsos.150081",
  pmc      = "PMC4453253"
}

@ARTICLE{Fleurian2019-ov,
  title   = "Reward prediction tells us less than expected about musical
             pleasure",
  author  = "Fleurian, De and Harrison, Peter M C and Pearce, Marcus T and
             Quiroga-martinez, David R",
  journal = "Proceedings of the National Academy of Sciences",
  year    =  2019,
  doi     = "10.1073/pnas.1913244116"
}

@ARTICLE{Samuel1981-an,
  title    = "Phonemic restoration: insights from a new methodology",
  author   = "Samuel, Arthur G",
  abstract = "Phonemic restoration is a powerful auditory illusion in which
              listeners ``hear'' parts of words that are not really there. In
              earlier studies of the illusion, segments of words (phonemes)
              were replaced by an extraneous sound; listeners were asked
              whether anything was missing and where the extraneous noise had
              occurred. Most listeners reported that the utterance was intact
              and mislocalized the noise, suggesting that they had restored the
              missing phoneme. In the present study, a second type of stimulus
              was also presented: items in which the extraneous sound was
              merely superimposed on the critical phoneme. On each trial,
              listeners were asked to report whether they thought a stimulus
              utterance was intact (noise superimposed) or not (noise
              replacing). Since this procedure yields both a miss rate
              P(intact/replaced), and a false alarm rate P(replaced/intact),
              signal detection parameters of discriminability and bias can be
              calculated. The discriminability parameter reflects how similar
              the two types of stimuli sound; perceptual restoration of
              replaced items should make them sound intact, producing low
              discriminability scores. The bias parameter measures the tendency
              of listeners to report utterances as intact; it reflects
              postperceptual decision processes. This improved methodology was
              used to test the hypothesis that restoration (and more generally,
              speech perception) depends upon the bottom-up confirmation of
              expectations generated at higher levels. Perceptual restoration
              varied greatly wih the phone class of the replaced segment and
              its acoustic similarity to the replacement sound, supporting a
              bottom-up component to the illusion. Increasing listeners'
              expectations of a phoneme increased perceptual restoration:
              missing segments in words were better restored than corresponding
              pieces in phonologically legal pseudowords; priming the words
              produced even more restoration. In contrast, sentential context
              affected the postperceptual decision stage, biasing listeners to
              report utterances as intact. A limited interactive model of
              speech perception, with both bottom-up and top-down components,
              is used to explain the results.",
  journal  = "Journal of experimental psychology. General",
  volume   =  110,
  number   =  4,
  pages    = "474--494",
  year     =  1981,
  issn     = "0096-3445",
  pmid     = "6459403",
  doi      = "10.1037/0096-3445.110.4.474"
}

@ARTICLE{Deutsch1980-ma,
  title   = "The processing of structured and unstructured tonal sequences",
  author  = "Deutsch, Diana",
  journal = "Perception \& psychophysics",
  volume  =  28,
  number  =  5,
  pages   = "381--389",
  year    =  1980,
  issn    = "0031-5117",
  doi     = "10.3758/BF03204881"
}

@BOOK{Gordon1989-ut,
  title     = "Advanced measures of music audiation",
  author    = "Gordon, Edwin E",
  publisher = "GIA Publications",
  year      =  1989,
  address   = "Chicago, IL"
}

@ARTICLE{Edworthy1985-ms,
  title   = "Interval and contour in melody processing",
  author  = "Edworthy, Judy",
  journal = "Music perception",
  volume  =  2,
  number  =  3,
  pages   = "375--388",
  year    =  1985,
  issn    = "0730-7829"
}

@BOOK{Riemann1893-yi,
  title     = "Vereinfachte Harmonielehre",
  author    = "Riemann, Hugo",
  publisher = "Augener",
  year      =  1893,
  address   = "London, England"
}

@ARTICLE{Capuzzo2003-dd,
  title   = "{Neo-Riemannian} theory and the analysis of pop-rock music",
  author  = "Capuzzo, Guy",
  journal = "Music Theory Spectrum",
  volume  =  26,
  number  =  2,
  pages   = "177--200",
  year    =  2003,
  issn    = "0195-6167"
}

@ARTICLE{Byrd1995-cp,
  title   = "A limited memory algorithm for bound constrained optimization",
  author  = "Byrd, R H and Lu, P and Nocedal, J and Zhu, C",
  journal = "SIAM journal on scientific computing: a publication of the Society
             for Industrial and Applied Mathematics",
  volume  =  6,
  number  =  5,
  pages   = "1190--1208",
  year    =  1995,
  issn    = "1064-8275"
}

@ARTICLE{Blood2001-cq,
  title   = "Intensely pleasurable responses to music correlate with activity
             in brain regions implicated in reward and emotion",
  author  = "Blood, Anne J and Zatorre, Robert J",
  journal = "Proceedings of the National Academy of Sciences",
  volume  =  98,
  number  =  20,
  pages   = "11818--11823",
  year    =  2001
}

@ARTICLE{Charles2005-cp,
  title    = "The correction for attenuation due to measurment error:
              Clarifying concepts and creating confidence sets",
  author   = "Charles, Eric Phillip",
  journal  = "Psychological methods",
  volume   =  10,
  number   =  2,
  pages    = "206--226",
  year     =  2005,
  keywords = "attenuation; confidence interval; correction for measurement
              error; correlation",
  issn     = "1082-989X",
  doi      = "10.1037/1082-989X.10.2.206"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cheung2020-cm,
  title     = "Distinct roles of cognitive and sensory information in musical
               expectancy",
  author    = "Cheung, V K M and Harrison, P and Koelsch, S and Pearce, M and
               {others}",
  abstract  = "Expectation is crucial for our enjoyment of music , yet the
               underlying generative mechanism remains contested. While sensory
               --acoustic models derive predictions based on the short- term
               auditory input alone, cognitive models assume the use of
               abstract knowledge of music …",
  publisher = "psyarxiv.com",
  year      =  2020,
  keywords  = "My publications"
}

@ARTICLE{Cheung2019-yo,
  title    = "Uncertainty and surprise jointly predict musical pleasure and
              amygdala, hippocampus, and auditory cortex activity",
  author   = "Cheung, Vincent K M and Harrison, Peter M C and Meyer, Lars and
              Pearce, Marcus T and Haynes, John-Dylan and Koelsch, Stefan",
  abstract = "Listening to music often evokes intense emotions [1, 2]. Recent
              research suggests that musical pleasure comes from positive
              reward prediction errors, which arise when what is heard proves
              to be better than expected [3]. Central to this view is the
              engagement of the nucleus accumbens-a brain region that processes
              reward expectations-to pleasurable music and surprising musical
              events [4-8]. However, expectancy violations along multiple
              musical dimensions (e.g., harmony and melody) have failed to
              implicate the nucleus accumbens [9-11], and it is unknown how
              music reward value is assigned [12]. Whether changes in musical
              expectancy elicit pleasure has thus remained elusive [11]. Here,
              we demonstrate that pleasure varies nonlinearly as a function of
              the listener's uncertainty when anticipating a musical event, and
              the surprise it evokes when it deviates from expectations. Taking
              Western tonal harmony as a model of musical syntax, we used a
              machine-learning model [13] to mathematically quantify the
              uncertainty and surprise of 80,000 chords in US Billboard pop
              songs. Behaviorally, we found that chords elicited high pleasure
              ratings when they deviated substantially from what the listener
              had expected (low uncertainty, high surprise) or, conversely,
              when they conformed to expectations in an uninformative context
              (high uncertainty, low surprise). Neurally, we found using fMRI
              that activity in the amygdala, hippocampus, and auditory cortex
              reflected this interaction, while the nucleus accumbens only
              reflected uncertainty. These findings challenge current
              neurocognitive models of music-evoked pleasure and highlight the
              synergistic interplay between prospective and retrospective
              states of expectation in the musical experience. VIDEO ABSTRACT.",
  journal  = "Current biology",
  volume   =  29,
  number   =  23,
  pages    = "4084--4092.e4",
  month    =  dec,
  year     =  2019,
  keywords = "aesthetics; amygdala; emotions; fMRI; information theory; nucleus
              accumbens; prediction; predictive coding; reward; syntax;My
              publications",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "31708393",
  doi      = "10.1016/j.cub.2019.09.067"
}

@ARTICLE{Mullensiefen2015-sr,
  title    = "Investigating the importance of self-theories of intelligence and
              musicality for students' academic and musical achievement",
  author   = "M{\"u}llensiefen, Daniel and Harrison, Peter and Caprini,
              Francesco and Fancourt, Amy",
  abstract = "Musical abilities and active engagement with music have been
              shown to be positively associated with many cognitive abilities
              as well as social skills and academic performance in secondary
              school students. While there is evidence from intervention
              studies that musical training can be a cause of these positive
              relationships, recent findings in the literature have suggested
              that other factors, such as genetics, family background or
              personality traits, might also be contributing factors. In
              addition, there is mounting evidence that self-concepts and
              beliefs can affect academic performance independently of
              intellectual ability. Students who believe that intelligence is
              malleable are more likely to attribute poor academic performances
              to effort rather than ability, and are more likely to take
              remedial action to improve their performance. However, it is
              currently not known whether student's beliefs about the nature of
              musical talent also influence the development of musical
              abilities in a similar fashion. Therefore, this study introduces
              a short self-report measure termed ``Musical Self-Theories and
              Goals,'' closely modeled on validated measures for self-theories
              in academic scenarios. Using this measure the study investigates
              whether musical self-theories are related to students' musical
              development as indexed by their concurrent musical activities and
              their performance on a battery of listening tests. We use data
              from a cross-sectional sample of 313 secondary school students to
              construct a network model describing the relationships between
              self-theories and academic as well as musical outcome measures,
              while also assessing potential effects of intelligence and the
              Big Five personality dimensions. Results from the network model
              indicate that self-theories of intelligence and musicality are
              closely related. In addition, both kinds of self-theories are
              connected to the students' academic achievement through the
              personality dimension conscientiousness and academic effort.
              Finally, applying the do-calculus method to the network model we
              estimate that the size of the assumed causal effects between
              musical self-theories and academic achievement lie between 0.07
              and 0.15 standard deviations.",
  journal  = "Frontiers in psychology",
  volume   =  6,
  pages    = "1702",
  month    =  nov,
  year     =  2015,
  keywords = "academic performance; musical ability; personality;
              self-concepts; theory of intelligence; theory of musicality;My
              publications",
  language = "en",
  issn     = "1664-1078",
  pmid     = "26594189",
  doi      = "10.3389/fpsyg.2015.01702",
  pmc      = "PMC4633492"
}

@ARTICLE{Harrison2020-gx,
  title    = "Simultaneous consonance in music perception and composition",
  author   = "Harrison, P M C and Pearce, Marcus T",
  abstract = "Simultaneous consonance is a salient perceptual phenomenon
              corresponding to the perceived pleasantness of simultaneously
              sounding musical tones. Various competing theories of consonance
              have been proposed over the centuries, but recently a consensus
              has developed that simultaneous consonance is primarily driven by
              harmonicity perception. Here we question this view,
              substantiating our argument by critically reviewing historic
              consonance research from a broad variety of disciplines,
              reanalyzing consonance perception data from 4 previous behavioral
              studies representing more than 500 participants, and modeling
              three Western musical corpora representing more than 100,000
              compositions. We conclude that simultaneous consonance is a
              composite phenomenon that derives in large part from three
              phenomena: interference, periodicity/harmonicity, and cultural
              familiarity. We formalize this conclusion with a computational
              model that predicts a musical chord's simultaneous consonance
              from these three features, and release this model in an
              open-source R package, incon, alongside 15 other computational
              models also evaluated in this paper. We hope that this package
              will facilitate further psychological and musicological research
              into simultaneous consonance. (PsycINFO Database Record (c) 2020
              APA, all rights reserved).",
  journal  = "Psychological review",
  volume   =  127,
  number   =  2,
  pages    = "216--244",
  month    =  mar,
  year     =  2020,
  keywords = "My publications",
  language = "en",
  issn     = "0033-295X, 1939-1471",
  pmid     = "31868392",
  doi      = "10.1037/rev0000169",
  pmc      = "PMC7032667"
}

@ARTICLE{Harrison2017-fv,
  title    = "Applying modern psychometric techniques to melodic discrimination
              testing: Item response theory, computerised adaptive testing, and
              automatic item generation",
  author   = "Harrison, Peter M C and Collins, Tom and M{\"u}llensiefen, Daniel",
  abstract = "Modern psychometric theory provides many useful tools for ability
              testing, such as item response theory, computerised adaptive
              testing, and automatic item generation. However, these techniques
              have yet to be integrated into mainstream psychological practice.
              This is unfortunate, because modern psychometric techniques can
              bring many benefits, including sophisticated reliability
              measures, improved construct validity, avoidance of exposure
              effects, and improved efficiency. In the present research we
              therefore use these techniques to develop a new test of a
              well-studied psychological capacity: melodic discrimination, the
              ability to detect differences between melodies. We calibrate and
              validate this test in a series of studies. Studies 1 and 2
              respectively calibrate and validate an initial test version,
              while Studies 3 and 4 calibrate and validate an updated test
              version incorporating additional easy items. The results support
              the new test's viability, with evidence for strong reliability
              and construct validity. We discuss how these modern psychometric
              techniques may also be profitably applied to other areas of music
              psychology and psychological science in general.",
  journal  = "Scientific reports",
  volume   =  7,
  number   =  1,
  pages    = "3618",
  month    =  jun,
  year     =  2017,
  language = "en",
  issn     = "2045-2322",
  pmid     = "28620165",
  doi      = "10.1038/s41598-017-03586-z",
  pmc      = "PMC5472621"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Harrison2016-ro,
  title     = "Modelling melodic discrimination tests: Descriptive and
               explanatory approaches",
  author    = "Harrison, P M C and Musil, J J and {others}",
  abstract  = "Melodic discrimination tests have been used for many years to
               assess individual differences in musical abilities. These tests
               are usually analysed using classical test theory. However,
               classical test theory is not well suited for optimizing test
               efficiency or for investigating …",
  journal   = "Journal of New Music",
  publisher = "Taylor \& Francis",
  year      =  2016,
  keywords  = "My publications"
}

@ARTICLE{Harrison2018-ur,
  title    = "Development and Validation of the Computerised Adaptive Beat
              Alignment Test ({CA-BAT})",
  author   = "Harrison, Peter M C and M{\"u}llensiefen, Daniel",
  abstract = "Beat perception is increasingly being recognised as a fundamental
              musical ability. A number of psychometric instruments have been
              developed to assess this ability, but these tests do not take
              advantage of modern psychometric techniques, and rarely receive
              systematic validation. The present research addresses this gap in
              the literature by developing and validating a new test, the
              Computerised Adaptive Beat Alignment Test (CA-BAT), a variant of
              the Beat Alignment Test (BAT) that leverages recent advances in
              psychometric theory, including item response theory, adaptive
              testing, and automatic item generation. The test is constructed
              and validated in four empirical studies. The results support the
              reliability and validity of the CA-BAT for laboratory testing,
              but suggest that the test is not well-suited to online testing,
              owing to its reliance on fine perceptual discrimination.",
  journal  = "Scientific reports",
  volume   =  8,
  number   =  1,
  pages    = "12395",
  month    =  aug,
  year     =  2018,
  keywords = "My publications",
  language = "en",
  issn     = "2045-2322",
  pmid     = "30120265",
  doi      = "10.1038/s41598-018-30318-8",
  pmc      = "PMC6097996"
}

@ARTICLE{Larrouy-Maestri2019-pm,
  title    = "The mistuning perception test: A new measurement instrument",
  author   = "Larrouy-Maestri, Pauline and Harrison, Peter M C and
              M{\"u}llensiefen, Daniel",
  abstract = "An important aspect of the perceived quality of vocal music is
              the degree to which the vocalist sings in tune. Although most
              listeners seem sensitive to vocal mistuning, little is known
              about the development of this perceptual ability or how it
              differs between listeners. Motivated by a lack of suitable
              preexisting measures, we introduce in this article an adaptive
              and ecologically valid test of mistuning perception ability. The
              stimulus material consisted of short excerpts (6 to 12 s in
              length) from pop music performances (obtained from MedleyDB;
              Bittner et al., 2014) for which the vocal track was pitch-shifted
              relative to the instrumental tracks. In a first experiment, 333
              listeners were tested on a two-alternative forced choice task
              that tested discrimination between a pitch-shifted and an
              unaltered version of the same audio clip. Explanatory item
              response modeling was then used to calibrate an adaptive version
              of the test. A subsequent validation experiment applied this
              adaptive test to 66 participants with a broad range of musical
              expertise, producing evidence of the test's reliability,
              convergent validity, and divergent validity. The test is ready to
              be deployed as an experimental tool and should make an important
              contribution to our understanding of the human ability to judge
              mistuning.",
  journal  = "Behavior research methods",
  volume   =  51,
  number   =  2,
  pages    = "663--675",
  month    =  apr,
  year     =  2019,
  keywords = "Gold-MSI; Musical abilities; Pitch accuracy; Pitch perception;My
              publications",
  language = "en",
  issn     = "1554-351X, 1554-3528",
  pmid     = "30924106",
  doi      = "10.3758/s13428-019-01225-1",
  pmc      = "PMC6478636"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Harrison_undated-sj,
  title    = "Dissociating sensory and cognitive theories of harmony perception
              through computational modeling",
  author   = "Harrison, P and Pearce, M",
  abstract = "Two approaches exist for explaining harmonic expectation. The
              sensory approach claims that harmonic expectation is a low-level
              process driven by sensory responses to acoustic properties of
              musical sounds. Conversely, the cognitive approach describes
              harmonic …",
  journal  = "psyarxiv.com",
  keywords = "My publications"
}

@ARTICLE{Zioga2020-ih,
  title    = "From learning to creativity: Identifying the behavioural and
              neural correlates of learning to predict human judgements of
              musical creativity",
  author   = "Zioga, Ioanna and Harrison, Peter M C and Pearce, Marcus T and
              Bhattacharya, Joydeep and Di Bernardi Luft, Caroline",
  abstract = "Human creativity is intricately linked to acquired knowledge.
              However, to date learning a new musical style and subsequent
              musical creativity have largely been studied in isolation. We
              introduced a novel experimental paradigm combining behavioural,
              electrophysiological, and computational methods, to examine the
              neural correlates of unfamiliar music learning, and to
              investigate how neural and computational measures can predict
              human creativity. We investigated music learning by training
              non-musicians (N = 40) on an artificial music grammar.
              Participants' knowledge of the grammar was tested before and
              after three training sessions on separate days by assessing
              explicit recognition of the notes of the grammar, while
              additionally recording their EEG. After each training session,
              participants created their own musical compositions, which were
              later evaluated by human experts. A computational model of
              auditory expectation was used to quantify the statistical
              properties of both the grammar and the compositions. Results
              showed that participants successfully learned the new grammar.
              This was also reflected in the N100, P200, and P3a components,
              which were higher in response to incorrect than correct notes.
              The delta band (2.5-4.5 Hz) power in response to grammatical
              notes during first exposure to the grammar positively correlated
              with learning, suggesting a potential neural mechanism of
              encoding. On the other hand, better learning was associated with
              lower alpha and higher beta band power after training,
              potentially reflecting neural mechanisms of retrieval.
              Importantly, learning was a significant predictor of creativity,
              as judged by experts. There was also an inverted U-shaped
              relationship between percentage of correct intervals and
              creativity, as compositions with an intermediate proportion of
              correct intervals were associated with the highest creativity.
              Finally, the P200 in response to incorrect notes was predictive
              of creativity, suggesting a link between the neural correlates of
              learning, and creativity. Overall, our findings shed light on the
              neural mechanisms of learning an unfamiliar music grammar, and
              offer novel contributions to the associations between learning
              measures and creative compositions based on learned materials.",
  journal  = "NeuroImage",
  volume   =  206,
  pages    = "116311",
  month    =  feb,
  year     =  2020,
  keywords = "Artificial music grammar; Creativity; EEG; IDyOM; Statistical
              learning; Training;My publications",
  language = "en",
  issn     = "1053-8119, 1095-9572",
  pmid     = "31669411",
  doi      = "10.1016/j.neuroimage.2019.116311"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Harrison2020-sp,
  title     = "A computational cognitive model for the analysis and generation
               of voice leadings",
  author    = "Harrison, P M C and Pearce, M T",
  abstract  = "Voice leading is a common task in Western music composition
               whose conventions are consistent with fundamental principles of
               auditory perception. Here we introduce a computational cognitive
               model of voice leading, intended both for analyzing
               voice-leading …",
  journal   = "Music perception",
  publisher = "online.ucpress.edu",
  volume    =  37,
  number    =  3,
  pages     = "208--224",
  year      =  2020,
  keywords  = "My publications",
  issn      = "0730-7829",
  doi       = "10.1525/mp.2020.37.3.208"
}

@ARTICLE{Harrison2021-bz,
  title    = "Correction: {PPM-Decay}: A computational model of auditory
              prediction with memory decay",
  author   = "Harrison, Peter M C and Bianco, Roberta and Chait, Maria and
              Pearce, Marcus T",
  abstract = "[This corrects the article DOI: 10.1371/journal.pcbi.1008304.].",
  journal  = "PLoS computational biology",
  volume   =  17,
  number   =  5,
  pages    = "e1008995",
  month    =  may,
  year     =  2021,
  keywords = "My publications",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "34038404",
  doi      = "10.1371/journal.pcbi.1008995"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Harrison2020-iy,
  title     = "Gibbs Sampling with People",
  booktitle = "Advances in Neural Information Processing Systems",
  author    = "Harrison, P M C and Marjieh, R and Adolfi, F and van Rijn, P and
               Anglada-Tort, M and Tchernichovski, O and Larrouy-Maestri, P and
               Jacoby, N",
  abstract  = "Abstract A core problem in cognitive science and machine
               learning is to understand how humans derive semantic
               representations from perceptual objects, such as color from an
               apple, pleasantness from a musical chord, or seriousness from a
               face. Markov Chain Monte …",
  year      =  2020,
  address   = "Vancouver, Canada",
  keywords  = "My publications",
  doi       = "10.48550/arXiv.2008.02595"
}

@ARTICLE{De_Fleurian2019-py,
  title    = "Reward prediction tells us less than expected about musical
              pleasure",
  author   = "de Fleurian, R{\'e}mi and Harrison, Peter M C and Pearce, Marcus
              T and Quiroga-Martinez, David R",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  116,
  number   =  42,
  pages    = "20813--20814",
  month    =  oct,
  year     =  2019,
  keywords = "My publications",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "31537748",
  doi      = "10.1073/pnas.1913244116",
  pmc      = "PMC6800363"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Harrison2017-nq,
  title     = "A statistical-learning model of harmony perception",
  author    = "Harrison, P M C and Pearce, M T",
  abstract  = "DMRN+ 12: DIGITAL MUSIC RESEARCH NETWORK ONE-DAY WORKSHOP 2017
               QUEEN MARY UNIVERSITY OF LONDON TUE 19 DECEMBER 2017 DMRN+ 12:
               DIGITAL MUSIC RESEARCH NETWORK ONE-DAY WORKSHOP 2017, QUEEN MARY
               UNIVERSITY OF LONDON, TUE 19 …",
  journal   = "DMRN+ 12: Digital Music Research",
  publisher = "researchgate.net",
  year      =  2017,
  keywords  = "My publications"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Anglada-Tort2021-gx,
  title     = "{REPP}: A robust cross-platform solution for online sensorimotor
               synchronization experiments",
  author    = "Anglada-Tort, M and Harrison, P M C and Jacoby, N",
  abstract  = "Sensorimotor synchronization (SMS), the rhythmic coordination of
               perception and action, is a fundamental human skill that
               supports many behaviors, from daily repetitive routines to the
               most complex behavioural coordination, including music and dance
               (Repp 2005; Repp \& …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2021,
  keywords  = "My publications",
  doi       = "10.1101/2021.01.15.426897"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Harrison_undated-bt,
  title    = "Representing harmony in computational music cognition",
  author   = "Harrison, P and Pearce, M",
  abstract = "Cognitive theories of harmony require unambiguous formal models
              of how listeners internally represent chords and chord
              progressions. Previous modeling work often uses representation
              schemes heavily reliant on Western music theory, such as
              Roman-numeral …",
  journal  = "psyarxiv.com",
  keywords = "My publications"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Harrison2020-ds,
  title    = "{psychTestR}: An {R} package for designing and conducting
              behavioural psychological experiments",
  author   = "Harrison, P M C",
  abstract = "Today's psychologists can choose from many different software
              packages for developing and administering psychological
              experiments, with the most appropriate package typically varying
              from task to task. For simple experiments based on short
              questionnaires …",
  journal  = "The Journal of Open Source Software",
  year     =  2020,
  keywords = "My publications",
  doi      = "10.21105/joss.02088"
}

@ARTICLE{Gelding2021-wq,
  title    = "An efficient and adaptive test of auditory mental imagery",
  author   = "Gelding, Rebecca W and Harrison, Peter M C and Silas, Sebastian
              and Johnson, Blake W and Thompson, William F and
              M{\"u}llensiefen, Daniel",
  abstract = "The ability to silently hear music in the mind has been argued to
              be fundamental to musicality. Objective measurements of this
              subjective imagery experience are needed if this link between
              imagery ability and musicality is to be investigated. However,
              previous tests of musical imagery either rely on self-report,
              rely on melodic memory, or do not cater in range of abilities.
              The Pitch Imagery Arrow Task (PIAT) was designed to address these
              shortcomings; however, it is impractically long. In this paper,
              we shorten the PIAT using adaptive testing and automatic item
              generation. We interrogate the cognitive processes underlying the
              PIAT through item response modelling. The result is an efficient
              online test of auditory mental imagery ability (adaptive Pitch
              Imagery Arrow Task: aPIAT) that takes 8 min to complete, is
              adaptive to participant's individual ability, and so can be used
              to test participants with a range of musical backgrounds.
              Performance on the aPIAT showed positive moderate-to-strong
              correlations with measures of non-musical and musical working
              memory, self-reported musical training, and general musical
              sophistication. Ability on the task was best predicted by the
              ability to maintain and manipulate tones in mental imagery, as
              well as to resist perceptual biases that can lead to incorrect
              responses. As such, the aPIAT is the ideal tool in which to
              investigate the relationship between pitch imagery ability and
              musicality.",
  journal  = "Psychological research",
  volume   =  85,
  number   =  3,
  pages    = "1201--1220",
  month    =  apr,
  year     =  2021,
  keywords = "My publications",
  language = "en",
  issn     = "0340-0727, 1430-2772",
  pmid     = "32356009",
  doi      = "10.1007/s00426-020-01322-3",
  pmc      = "PMC8049941"
}

@ARTICLE{Harrison2021-ip,
  title     = "Three questions concerning consonance perception",
  author    = "Harrison, Peter M C",
  abstract  = "I discuss three fundamental questions underpinning the study of
               consonance: 1) What features cause a particular chord to be
               perceived as consonant? 2) How did humans evolve the ability to
               perceive these features? 3) Why did humans evolve to attribute
               particular aesthetic valences to these features (if they did at
               all)? The first question has been addressed by several recent
               articles, including Friedman, Kowalewski, Vuvan, and Neill
               (2021), with the common conclusion that consonance in Western
               listeners is driven by multiple features such as harmonicity,
               interference between partials, and familiarity. On this basis,
               it seems relatively straightforward to answer the second
               question: each of these consonance features seems to be grounded
               in fundamental aspects of human auditory perception, such as
               auditory scene analysis and auditory long-term memory. However,
               the third question is harder to resolve. I describe several
               potential answers, and argue that the present evidence is
               insufficient to distinguish between them, despite what has been
               claimed in the literature. I conclude by discussing what kinds
               of future studies might be able to shed light on this problem.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  38,
  number    =  3,
  pages     = "337--339",
  month     =  feb,
  year      =  2021,
  keywords  = "My publications",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2021.38.3.337"
}

@ARTICLE{Van_Rijn2021-ri,
  title         = "Exploring emotional prototypes in a high dimensional {TTS}
                   latent space",
  author        = "van Rijn, Pol and Mertes, Silvan and Schiller, Dominik and
                   Harrison, Peter M C and Larrouy-Maestri, Pauline and
                   Andr{\'e}, Elisabeth and Jacoby, Nori",
  abstract      = "Recent TTS systems are able to generate prosodically varied
                   and realistic speech. However, it is unclear how this
                   prosodic variation contributes to the perception of
                   speakers' emotional states. Here we use the recent
                   psychological paradigm 'Gibbs Sampling with People' to
                   search the prosodic latent space in a trained GST Tacotron
                   model to explore prototypes of emotional prosody.
                   Participants are recruited online and collectively
                   manipulate the latent space of the generative speech model
                   in a sequentially adaptive way so that the stimulus
                   presented to one group of participants is determined by the
                   response of the previous groups. We demonstrate that (1)
                   particular regions of the model's latent space are reliably
                   associated with particular emotions, (2) the resulting
                   emotional prototypes are well-recognized by a separate group
                   of human raters, and (3) these emotional prototypes can be
                   effectively transferred to new sentences. Collectively,
                   these experiments demonstrate a novel approach to the
                   understanding of emotional speech by providing a tool to
                   explore the relation between the latent space of generative
                   models and human semantics.",
  month         =  may,
  year          =  2021,
  keywords      = "My publications",
  archivePrefix = "arXiv",
  eprint        = "2105.01891",
  primaryClass  = "cs.HC",
  arxivid       = "2105.01891"
}

@ARTICLE{Zioga2020-gt,
  title    = "Auditory but not audiovisual cues lead to higher neural
              sensitivity to the statistical regularities of an unfamiliar
              musical style",
  author   = "Zioga, Ioanna and Harrison, Peter M C and Pearce, Marcus T and
              Bhattacharya, Joydeep and Luft, Caroline Di Bernardi",
  abstract = "It is still a matter of debate whether visual aids improve
              learning of music. In a multisession study, we investigated the
              neural signatures of novel music sequence learning with or
              without aids (auditory-only: AO, audiovisual: AV). During three
              training sessions on three separate days, participants
              (nonmusicians) reproduced (note by note on a keyboard) melodic
              sequences generated by an artificial musical grammar. The AV
              group (n = 20) had each note color-coded on screen, whereas the
              AO group (n = 20) had no color indication. We evaluated learning
              of the statistical regularities of the novel music grammar before
              and after training by presenting melodies ending on correct or
              incorrect notes and by asking participants to judge the
              correctness and surprisal of the final note, while EEG was
              recorded. We found that participants successfully learned the new
              grammar. Although the AV group, as compared to the AO group,
              reproduced longer sequences during training, there was no
              significant difference in learning between groups. At the neural
              level, after training, the AO group showed a larger N100 response
              to low-probability compared with high-probability notes,
              suggesting an increased neural sensitivity to statistical
              properties of the grammar; this effect was not observed in the AV
              group. Our findings indicate that visual aids might improve
              sequence reproduction while not necessarily promoting better
              learning, indicating a potential dissociation between sequence
              reproduction and learning. We suggest that the difficulty induced
              by auditory-only input during music training might enhance
              cognitive engagement, thereby improving neural sensitivity to the
              underlying statistical properties of the learned material.",
  journal  = "Journal of cognitive neuroscience",
  volume   =  32,
  number   =  12,
  pages    = "2241--2259",
  month    =  dec,
  year     =  2020,
  keywords = "My publications",
  language = "en",
  issn     = "0898-929X, 1530-8898",
  pmid     = "32762519",
  doi      = "10.1162/jocn\_a\_01614"
}

@PHDTHESIS{Harrison2020-tu,
  title    = "Modelling the perception and composition of Western musical
              harmony",
  author   = "Harrison, Peter Michael Combes",
  year     =  2020,
  school   = "Queen Mary University of London",
  keywords = "My publications"
}

@ARTICLE{Zioga2020-gc,
  title    = "From learning to creativity: Identifying the behavioural and
              neural correlates of learning to predict human judgements of
              musical creativity",
  author   = "Zioga, I and Harrison, P M C and Pearce, M T and Bhattacharya, J
              and Di Bernardi Luft, C",
  abstract = "\copyright{} 2019 Human creativity is intricately linked to
              acquired knowledge. However, to date learning a new musical style
              and subsequent musical creativity have largely been studied in
              isolation. We introduced a novel experimental paradigm combining
              behavioural, electrophysiological, and computational methods, to
              examine the neural correlates of unfamiliar music learning, and
              to investigate how neural and computational measures can predict
              human creativity. We investigated music learning by training
              non-musicians (N = 40) on an artificial music grammar.
              Participants' knowledge of the grammar was tested before and
              after three training sessions on separate days by assessing
              explicit recognition of the notes of the grammar, while
              additionally recording their EEG. After each training session,
              participants created their own musical compositions, which were
              later evaluated by human experts. A computational model of
              auditory expectation was used to quantify the statistical
              properties of both the grammar and the compositions. Results
              showed that participants successfully learned the new grammar.
              This was also reflected in the N100, P200, and P3a components,
              which were higher in response to incorrect than correct notes.
              The delta band (2.5--4.5 Hz) power in response to grammatical
              notes during first exposure to the grammar positively correlated
              with learning, suggesting a potential neural mechanism of
              encoding. On the other hand, better learning was associated with
              lower alpha and higher beta band power after training,
              potentially reflecting neural mechanisms of retrieval.
              Importantly, learning was a significant predictor of creativity,
              as judged by experts. There was also an inverted U-shaped
              relationship between percentage of correct intervals and
              creativity, as compositions with an intermediate proportion of
              correct intervals were associated with the highest creativity.
              Finally, the P200 in response to incorrect notes was predictive
              of creativity, suggesting a link between the neural correlates of
              learning, and creativity. Overall, our findings shed light on the
              neural mechanisms of learning an unfamiliar music grammar, and
              offer novel contributions to the associations between learning
              measures and creative compositions based on learned materials.",
  journal  = "NeuroImage",
  volume   =  206,
  year     =  2020,
  keywords = "Artificial music grammar; Creativity; EEG; IDyOM; Statistical
              learning; Training",
  issn     = "1053-8119, 1095-9572",
  doi      = "10.1016/j.neuroimage.2019.116311"
}

@ARTICLE{Zioga2020-xr,
  title    = "Auditory but not audiovisual cues lead to higher neural
              sensitivity to the statistical regularities of an unfamiliar
              musical style",
  author   = "Zioga, I and Harrison, P M C and Pearce, M T and Bhattacharya, J
              and Luft, C D B",
  abstract = "\copyright{} 2020 Massachusetts Institute of Technology. It is
              still a matter of debate whether visual aids improve learning of
              music. In a multisession study, we investigated the neural
              signatures of novel music sequence learning with or without aids
              (auditory-only: AO, audiovisual: AV). During three training
              sessions on three separate days, participants (nonmu-sicians)
              reproduced (note by note on a keyboard) melodic sequences
              generated by an artificial musical grammar. The AV group (n = 20)
              had each note color-coded on screen, whereas the AO group (n =
              20) had no color indication. We evaluated learning of the
              statistical regularities of the novel music grammar before and
              after training by presenting melodies ending on correct or
              incorrect notes and by asking participants to judge the
              correctness and surprisal of the final note, while EEG was
              recorded. We found that participants successfully learned the new
              grammar. Although the AV group, as compared to the AO group,
              reproduced longer sequences during training, there was no
              significant difference in learning between groups. At the neural
              level, after training, the AO group showed a larger N100 response
              to low-probability compared with high-probability notes,
              suggesting an increased neural sensitivity to statistical
              properties of the grammar; this effect was not observed in the AV
              group. Our findings indicate that visual aids might improve
              sequence reproduction while not necessarily promoting better
              learning, indicating a potential dissociation between sequence
              reproduction and learning. We suggest that the difficulty induced
              by auditory-only input during music training might enhance
              cognitive engagement, thereby improving neural sensitivity to the
              underlying statistical properties of the learned material.",
  journal  = "Journal of cognitive neuroscience",
  volume   =  32,
  number   =  12,
  year     =  2020,
  issn     = "0898-929X, 1530-8898",
  doi      = "10.1162/jocn\_a\_01614"
}

@ARTICLE{Gold2019-wl,
  title   = "Reply to de Fleurian et al.: Toward a fuller understanding of
             reward prediction errors and their role in musical pleasure",
  author  = "Gold, Benjamin P and Mas-herrero, Ernest and Dagher, Alain and
             Zatorre, Robert J",
  journal = "Proceedings of the National Academy of Sciences",
  year    =  2019,
  doi     = "10.1073/pnas.1913835116"
}

@ARTICLE{Brysbaert2018-rd,
  title    = "Power Analysis and Effect Size in Mixed Effects Models : A
              Tutorial",
  author   = "Brysbaert, Marc and Stevens, Micha{\"e}l",
  journal  = "Journal of Cognition",
  volume   =  1,
  number   =  1,
  year     =  2018,
  keywords = "effect size; f1 analysis; mixed effects models; power analysis;
              random factors",
  doi      = "10.5334/joc.10"
}

@ARTICLE{Weiss2019-ob,
  title    = "Development of consonance preferences in Western listeners",
  author   = "Weiss, Michael W and Cirelli, Laura K and Mcdermott, Josh H and
              Trehub, Sandra E",
  journal  = "Journal of experimental psychology. General",
  year     =  2019,
  keywords = "10; 1037; aesthetic preferences; consistent; consonance;
              development; doi; dx; evaluative judgments of simultaneously;
              http; ing tones are relatively; music; org; sound-; supp;
              supplemental materials; they prefer tone combinations; western
              adults; xge0000680",
  issn     = "0096-3445",
  doi      = "10.1037/xge0000680"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{PagesPortabella2019-qz,
  title    = "Dissonant endings of chord progressions elicit a larger {ERAN}
              than ambiguous endings in musicians",
  author   = "Pag{\`e}s‐Portabella, Carlota and Toro, Juan M",
  journal  = "Psychophysiology",
  year     =  2019,
  keywords = "dissonance; eran; erps; harmonic expectations; musical training",
  issn     = "0048-5772",
  doi      = "10.1111/psyp.13476"
}

@MISC{Johnson2019-sr,
  title  = "The {NLopt} nonlinear-optimization package",
  author = "Johnson, Steven G",
  year   =  2019
}

@PHDTHESIS{Rowan1990-jg,
  title   = "Functional stability analysis of numerical algorithms",
  author  = "Rowan, T",
  year    =  1990,
  address = "Austin, TX",
  school  = "University of Texas at Austin"
}

@INCOLLECTION{Thagard2019-vo,
  title     = "Cognitive science",
  booktitle = "The Stanford Encyclopedia of Philosophy",
  author    = "Thagard, Paul",
  editor    = "Zalta, Edward N",
  publisher = "Metaphysics Research Lab, Stanford University",
  edition   = "Spring 201",
  year      =  2019,
  address   = "Stanford, CA"
}

@ARTICLE{Frieler2013-ji,
  title    = "Absolute memory for pitch: A comparative replication of Levitin's
              1994 study in six European labs",
  author   = "Frieler, Klaus and Fischinger, Timo and Schlemmer, Kathrin and
              Lothwesen, Kai and Jakubowski, Kelly and M{\"u}llensiefen, Daniel",
  abstract = "In a widely cited study, Levitin (1994) suggested the existence
              of absolute pitch memory for music in the general population
              beyond the rare trait of genuine absolute pitch (AP). In his
              sample, a significant proportion of non-AP possessors were able
              to reproduce absolute pitch levels when asked to sing very
              familiar pop songs from memory. Forty-four percent of
              participants sang the correct pitch on at least one of two
              trials, and 12\% were correct on both trials. However, until now,
              no replication of this study has ever been published. The current
              paper presents the results of a large replication endeavour
              across six different labs in Germany and the UK. All labs used
              the same methodology, carefully replicating Levitin's original
              experiment. In each lab, between 40 and 50 participants were
              tested (N = 277). Participants were asked to sing two different
              pop songs of their choice. All sung productions were compared to
              the original songs. Twenty-five percent of the participants sang
              the exact pitch of at least one of the two chosen songs and 4\%
              hit the right pitches for both songs. Our results generally
              confirm the findings of Levitin (1994). However, the results
              differ considerably across laboratories, and the estimated
              overall effect using meta-analysis techniques was significantly
              smaller than Levitin's original result. This illustrates the
              variability of empirical findings derived from small sample sizes
              and corroborates the need for replication and meta-analytical
              studies in music psychology in general. \copyright{} The
              Author(s) 2013.",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  volume   =  17,
  number   =  3,
  pages    = "334--349",
  year     =  2013,
  keywords = "absolute pitch; collaborative research; music listening; music
              memory; replication",
  issn     = "1029-8649",
  doi      = "10.1177/1029864913493802"
}

@BOOK{Jackendoff1987-kg,
  title     = "Consciousness and the Computational Mind",
  author    = "Jackendoff, R",
  publisher = "MIT Press",
  year      =  1987,
  address   = "Cambridge, MA"
}

@INPROCEEDINGS{Chew2002-gf,
  title     = "The Spiral Array: An algorithm for determining key boundaries",
  booktitle = "Music and Artificial Intelligence. {ICMAI} 2002. Lecture Notes
               in Computer Science, vol 2445",
  author    = "Chew, Elaine",
  editor    = "Anagnostopoulou, C and Ferrand, M and Smaill, A",
  publisher = "Springer",
  year      =  2002,
  address   = "Berlin, Germany",
  doi       = "10.1007/3-540-45722-4"
}

@ARTICLE{Neuwirth2018-im,
  title    = "The Annotated Beethoven Corpus ({ABC)}: A dataset of harmonic
              analyses of all Beethoven string quartets",
  author   = "Neuwirth, Markus and Harasim, Daniel and Moss, Fabian C and
              Rohrmeier, Martin",
  journal  = "Frontiers in Digital Humanities",
  volume   =  5,
  year     =  2018,
  keywords = "Beethoven; beethoven; corpus research; digital musicology; ground
              truth; harmony; music; symbolic music data",
  doi      = "10.3389/fdigh.2018.00016"
}

@ARTICLE{Arthur2018-ww,
  title    = "A perceptual study of scale-degree qualia in context",
  author   = "Arthur, Claire",
  abstract = "A PERCEPTUAL STUDY INVESTIGATED THE ABILITY of scale degrees to
              evoke qualia, and the impact of har- monic context in shaping a
              scale degree's qualia. In addition, the following questions were
              addressed: What role does music training have in shaping qualia?
              Are listeners consistent in their descriptions? Are experi- ences
              similar across participants, or are they individual and
              subjective? Listeners with or without music- theoretic training
              were asked to rate the qualia of scale degrees following various
              chord progressions, each end- ing with a different final harmony.
              Scale degrees were found to exhibit relatively consistent musical
              qualia; however, the local chord context was found to signifi-
              cantly influence qualia ratings. In general, both groups of
              listeners were found to be fairly consistent in their ratings of
              scale-degree qualia; however, as expected, musician listeners
              were more consistent than nonmusi- cian listeners. Finally, a
              subset of the musical qualia ratings were compared against
              Krumhansl and Kessler's (1982) scale-degree ``profiles.'' While
              profiles created from the present data, overall, were correlated
              with the K\&K profiles, their claim that tonal stability accounts
              for the high ratings ascribed to tonic triad members was found to
              be better explained by the effect of the local chord context.",
  journal  = "Music perception",
  volume   =  35,
  number   =  3,
  pages    = "295--314",
  year     =  2018,
  keywords = "Key profiles; Melodic-harmonic interaction; Phenomenology; Pitch
              perception; Scale degree",
  issn     = "0730-7829, 1533-8312",
  doi      = "10.1525/MP.2018.35.3.295"
}

@ARTICLE{Cambouropoulos2010-yf,
  title    = "The musical surface: Challenging basic assumptions",
  author   = "Cambouropoulos, Emilios",
  abstract = "This paper addresses problems and misconceptions pertaining to
              the notion of the musical surface, a notion that is commonly
              thought to be relatively straight-forward and is often taken as a
              given in computational and cognitive research. It is suggested
              that the musical surface is comprised of (complex) musical events
              perceived as wholes within coherent musical streams - the musical
              surface is not merely an unstructured sequence of atomic note
              events, such as score notes or a piano-roll representation.
              Additionally, it is maintained that the emergence of the musical
              surface involves rather complex mechanisms that require, not only
              multi-pitch extraction from the acoustic signal, but, the
              employment of cognitive processes such as beat-tracking, metre
              induction, chord identification and stream/voice separation. Such
              processes do not come into play after the surface has been
              formed, but are, rather, an integral part of the formation of the
              musical surface per se.",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  volume   =  14,
  number   = "2\_suppl",
  pages    = "131--147",
  year     =  2010,
  keywords = "automatic transcription; beat-tracking; musical surface; stream
              separation",
  issn     = "1029-8649",
  doi      = "10.1177/10298649100140S209"
}

@ARTICLE{Jaynes1968-rh,
  title    = "Prior probabilities",
  author   = "Jaynes, Edwin T",
  abstract = "In decision theory, mathematical analysis shows that once the
              sampling distribution, loss function, and sample are specified,
              the only remaining basis for a choice among different admissible
              decisions lies in the prior probabilities. Therefore, the logical
              foundations of decision theory cannot be put in fully
              satisfactory form until the old problem of arbitrariness
              (sometimes called ``subjectiveness'') in assigning prior
              probabilities is resolved. The principle of maximum entropy
              represents one step in this direction. Its use is illustrated,
              and a correspondence property between maximum-entropy
              probabilities and frequencies is demonstrated. The consistency of
              this principle with the principles of conventional ``direct
              probability'' analysis is illustrated by showing that many known
              results may be derived by either method. However, an ambiguity
              remains in setting up a prior on a continuous parameter space
              because the results lack invariance under a change of parameters;
              thus a further principle is needed. It is shown that in many
              problems, including some of the most important in practice, this
              ambiguity can be removed by applying methods of group theoretical
              reasoning which have long been used in theoretical physics. By
              finding the group of transformations on the parameter space which
              convert the problem into an equivalent one, a basic desideratum
              of consistency can be stated in the form of functional equations
              which impose conditions on, and in some cases fully determine, an
              ``invariant measure'' on the parameter space.",
  journal  = "IEEE Transactions on Systems Science and Cybernetics",
  volume   =  4,
  number   =  3,
  pages    = "227--241",
  year     =  1968,
  issn     = "2168-2887",
  doi      = "10.1109/TSSC.1968.300117"
}

@ARTICLE{Sainburg2019-rk,
  title     = "Parallels in the sequential organization of birdsong and human
               speech",
  author    = "Sainburg, Tim and Theilman, Brad and Thielk, Marvin and Gentner,
               Timothy Q",
  journal   = "Nature communications",
  publisher = "Springer US",
  volume    =  10,
  pages     = "3636",
  year      =  2019,
  issn      = "2041-1723",
  doi       = "10.1038/s41467-019-11605-y"
}

@ARTICLE{Zador2019-ws,
  title   = "A critique of pure learning: What artificial neural networks can
             learn from animal brains",
  author  = "Zador, Anthony M",
  journal = "Nature communications",
  volume  =  10,
  year    =  2019,
  doi     = "10.1038/s41467-019-11786-6"
}

@ARTICLE{Sears2019-tj,
  title    = "Expectations for tonal cadences: Sensory and cognitive priming
              effects",
  author   = "Sears, David R W and Pearce, Marcus T and Spitzer, Jacob and
              Caplin, William E and McAdams, Stephen",
  journal  = "The Quarterly journal of experimental psychology",
  volume   =  72,
  number   =  6,
  pages    = "1422--1438",
  year     =  2019,
  keywords = "Musical priming; cognitive; sensory; tonal cadence; tonal
              expectations",
  issn     = "0033-555X, 1747-0226",
  doi      = "10.1177/1747021818814472"
}

@BOOK{Silverman1986-de,
  title     = "Density estimation",
  author    = "Silverman, B W",
  publisher = "Chapman \& Hall",
  year      =  1986,
  address   = "London, England"
}

@BOOK{Hastie1990-pt,
  title     = "Generalized additive models",
  author    = "Hastie, T J and Tibshirani, R J",
  publisher = "Chapman \& Hall",
  year      =  1990,
  address   = "London, England"
}

@ARTICLE{Kneib2007-ri,
  title    = "Semiparametric multinomial logit models for analysing consumer
              choice behaviour",
  author   = "Kneib, Thomas and Baumgartner, Bernhard and Steiner, Winfried J",
  journal  = "AStA. Advances in Statistical Analysis. A Journal of the German
              Statistical Society",
  volume   =  91,
  pages    = "225--244",
  year     =  2007,
  keywords = "brand choice; conditional logit model; logit model; mixed models;
              multinomial; penalised splines; proper scoring rules;
              semiparametric regression",
  issn     = "1863-8171",
  doi      = "10.1007/s10182-007-0033-2"
}

@ARTICLE{Vuvan2019-gs,
  title    = "Musical style affects the strength of harmonic expectancy",
  author   = "Vuvan, Dominique T and Hughes, Bryn",
  abstract = "Research in music perception has typically focused on
              common-practice music (tonal music from the Western European
              tradition, ca. 1750--1900) as a model of Western musical
              structure. However, recent research indicates that different
              styles within Western tonal music may follow distinct harmonic
              syntaxes. The current study investigated whether listeners can
              adapt their harmonic expectations when listening to different
              musical styles. In two experiments, listeners were presented with
              short musical excerpts that primed either rock or classical
              music, followed by a timbre-matched cadence. Results from both
              experiments indicated that listeners prefer V-I cadences over
              bVII-I cadences within a classical context, but that this
              preference is significantly diminished in a rock context. Our
              findings provide empirical support for the idea that different
              musical styles do employ different harmonic syntaxes.
              Furthermore, listeners are not only sensitive to these
              differences, but are able to adapt their expectations dep...",
  journal  = "Music \& Science",
  volume   =  2,
  year     =  2019,
  keywords = "2 july 2018; 8 november 2018; acceptance date; cadence;
              common-practice music; expectation; like language; perception;
              popular music; style; submission date; tonal music from; tonality",
  issn     = "2059-2043",
  doi      = "10.1177/2059204318816066"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Eitan2017-yl,
  title    = "Implicit absolute pitch representation affects basic tonal
              perception",
  author   = "Eitan, Zohar and Ben-Haim, Moshe Shay and Margulis, Elizabeth
              Hellmuth",
  abstract = "It is undisputed that the cognition of tonal music is primarily
              established by pitch relationships set within a tonal scheme such
              as a major or minor key. The corresponding notion---that absolute
              pitch and absolute key are largely inconsequential for tonal
              cognition---thus seems inevitable. Here, we challenge the latter
              notion, presenting data suggesting that absolute pitch and
              absolute key significantly modify listeners' judgments of tonal
              fit and tonal tension. In two experiments extending the probe
              tone technique (as applied in Krumhansl \& Kessler, 1982)
              participants heard a brief tonal context (a major triad in
              Experiment 1, a harmonic progression in Experiment 2) followed by
              individual probe tones, and rated how well each probe fitted the
              preceding context, as well as the musical tension conveyed by
              each probe. Two maximally distant key contexts, G major and D♭
              major, were used in both experiments and in both tasks. Ratings
              revealed significant absolute pitch effects in both tasks, though
              in different ways. In the tonal fit task, diatonic pitches in G
              major were rated higher than those in D♭ major; in contrast,
              chromatic pitches were rated higher in D♭ major, compared to G.
              In the tension task, overall ratings were significantly higher
              for D♭ major contexts than for G major context (Experiment 1).
              Importantly, these effects reflect the occurrence frequency of
              pitch classes and keys in the tonal repertory: frequent pitch
              classes were rated as better fits than rarer ones, and a rarer
              key (D♭) rated tenser than a frequently-occurring key (G).
              Absolute pitch effects were most strongly manifested by
              participants without formal training, for whom the relative pitch
              effects of the tonal hierarchy were weak, and were stronger when
              tonal context was weaker (Experiment 1 as compared to Experiment
              2). Results suggest that implicit absolute pitch perception,
              reflecting key and pitch class occurrence frequency,
              significantly affects tonal music processing; such absolute pitch
              effects may be activated principally when tonal perception or
              tonal cues are lacking.",
  journal  = "Music perception",
  volume   =  34,
  number   =  5,
  pages    = "569--584",
  year     =  2017,
  keywords = "Absolute key; Absolute pitch; Music training; Musical tension;
              Tonal perception",
  issn     = "0730-7829, 1533-8312",
  doi      = "10.1525/MP.2017.34.5.569"
}

@ARTICLE{Miyazaki1988-kl,
  title    = "Musical pitch identification by absolute pitch possessors",
  author   = "Miyazaki, Ken'ichi",
  abstract = "Musical pitch identification was investigated in two experiments
              in which absolute pitch (AP) possessors and nonpossessors
              categorized tones presented in isolation into predetermined pitch
              classes. Stimuli consisted of 60 different tones per octave (at
              intervals of 20 cents). The experi-ments were designed to
              minimize the possibility that subjects could use strategies other
              than AP in perfi~rming the task. The results clearly
              differentiated AP possessors from nonpossessors in accurac.v and
              speed of responding. Those subjects who had AP could categorize
              the tones quite consistently by using musical qualities of the
              tones (tone chroma). However, they did not respond uniformly to
              all stimuli; they responded more accurately and quickly to some
              musically impor-tant tones in a C-major mode (C, E, or G). On the
              other hand, those who had no AP showed almost random response
              patterns. In the absence of a tonal context, they could not use
              tone chroma, but only tone height. It is argued that tone chroma
              should be defined as the musical characteris-tics of tones in a
              tonal context, and that AP possessors are unique in that they can
              perceive it absolutely in the absence of any musical context.
              Although AP was believed to be very rare, it was proved here that
              a phenomenally large proportion of the subjects tested had AP.
              The corre-lation was observed between AP possession and early
              musical training that started at the age of 3 to 5.",
  journal  = "Perception \& psychophysics",
  volume   =  44,
  number   =  6,
  pages    = "501--512",
  year     =  1988,
  issn     = "0031-5117",
  doi      = "10.3758/BF03207484"
}

@INCOLLECTION{Schneider2018-bb,
  title     = "Pitch and pitch perception",
  booktitle = "Springer Handbook of Systematic Musicology",
  author    = "Schneider, Albert",
  editor    = "Bader, R",
  publisher = "Springer",
  pages     = "605--685",
  year      =  2018,
  address   = "Berlin, Germany",
  doi       = "10.1007/978-3-662-55004-5\_31"
}

@ARTICLE{Sloboda1991-ld,
  title    = "Music structure and emotional response: Some empirical findings",
  author   = "Sloboda, John A",
  abstract = "83 music listeners completed a questionnaire in which they
              provided information about the occurrence of a range of physical
              reactions while listening to music. Shivers down the spine,
              laughter, tears, and lump in the throat were reported by over
              80\% of Ss. Ss were asked to locate specific musical passages
              that reliably evoked such responses. Structural analysis of these
              passages shows that tears were most reliably evoked by melodic
              appogiaturas and, to a lesser extent, by sequences and harmonic
              movements through the cycle of 5ths to the tonic. Shivers were
              most reliably provoked by relatively sudden changes in harmony.
              Racing heart was provoked by acceleration and syncopation. Data
              generally support theoretical approaches to emotion based on
              confirmations and violations of expectancy. (PsycINFO Database
              Record (c) 2004 APA, all rights reserved)",
  journal  = "Psychology of Music",
  volume   =  19,
  pages    = "110--120",
  year     =  1991,
  issn     = "1741-3087",
  doi      = "10.1177/0305735691192002"
}

@INCOLLECTION{Harnard2003-em,
  title     = "Categorical perception",
  booktitle = "Encyclopedia of Cognitive Science",
  author    = "Harnard, S",
  editor    = "Nadel, Lynn",
  publisher = "Nature Publishing Group",
  year      =  2003,
  address   = "New York, NY"
}

@ARTICLE{Spyra2019-lw,
  title    = "Events versus time in the perception of nonadjacent key
              relationships",
  author   = "Spyra, Joanna and Stodolak, Matthew and Woolhouse, Matthew",
  abstract = "Increasing the duration of an intervening key has a negative
              effect on memory for the original, nonadjacent key. Evidence
              suggests the recollection of a key only remains for 20 seconds
              after modulation to a new key section. But factors other than
              time might influence the perception of nonadjacent key
              relationships. By using a probe-cadence paradigm, this study
              tested whether time or the number of musical events (chords)
              determined the deterioration in memory of the global effect of
              nonadjacent keys. Stimuli were constructed in three parts: (a) a
              major key was established through a standard chord progression;
              (b) an intervening section, either 6 or 9 seconds in duration and
              formed from either four or six chords, was introduced in 12
              possible keys; and (c) a short pause was followed by the probe
              cadence in the original key---that is, the key at (a). Fifty-one
              participants were asked to estimate the amount of harmonic
              closure they perceived at the probe cadence. Results confirmed
              previous findings of significant negative effects of time on the
              residual influence of the nonadjacent key. However, there were no
              significant effects of number of events. This provides evidence
              that it is the length of time, not the number of musical events
              in an intervening modulation that determines the recollection of
              the original key.",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  year     =  2019,
  keywords = "Harmony; memory; music; nonadjacency; perception",
  issn     = "1029-8649",
  doi      = "10.1177/1029864919867463"
}

@ARTICLE{Patel2003-pb,
  title   = "Language, music, syntax and the brain",
  author  = "Patel, Aniruddh D",
  journal = "Nature neuroscience",
  volume  =  6,
  number  =  7,
  pages   = "674--681",
  year    =  2003,
  issn    = "1097-6256",
  doi     = "10.1038/nn1082"
}

@ARTICLE{Sauve2018-ge,
  title   = "Effects of pitch and timing expectancy on musical emotion",
  author  = "Sauv{\'e}, Sarah A and Sayed, A and Dean, Roger T and Pearce,
             Marcus T",
  journal = "Psychomusicology: Music, Mind, and Brain",
  volume  =  28,
  number  =  1,
  pages   = "17--39",
  year    =  2018,
  doi     = "10.1037/pmu0000203"
}

@ARTICLE{Gebhardt2016-dd,
  title    = "Psychoacoustic approaches for harmonic music mixing",
  author   = "Gebhardt, Roman B and Davies, Matthew E P and Seeber, Bernhard U",
  abstract = "The practice of harmonic mixing is a technique used by DJs for
              the beat-synchronous and harmonic alignment of two or more pieces
              of music. In this paper, we present a new harmonic mixing method
              based on psychoacoustic principles. Unlike existing commercial
              DJ-mixing software, which determines compatible matches between
              songs via key estimation and harmonic relationships in the circle
              of fifths, our approach is built around the measurement of
              musical consonance. Given two tracks, we first extract a set of
              partials using a sinusoidal model and average this information
              over sixteenth note temporal frames. By scaling the partials of
              one track over 6 semitones (in 1/8th semitone steps), we
              determine the pitch-shift that maximizes the consonance of the
              resulting mix. For this, we measure the consonance between all
              combinations of dyads within each frame according to
              psychoacoustic models of roughness and pitch commonality. To
              evaluate our method, we conducted a listening test where short m",
  journal  = "NATO Advanced Science Institutes series E: Applied sciences",
  volume   =  6,
  year     =  2016,
  keywords = "Audio content analysis; Audio signal processing; Digital DJ
              interfaces; Music information retrieval; Music technology;
              Musical consonance; Psychoacoustics; Sound and music computing;
              Spectral analysis",
  issn     = "0168-132X, 1454-5101",
  doi      = "10.3390/app6050123"
}

@ARTICLE{Wang2013-xw,
  title    = "The harmonic organization of auditory cortex",
  author   = "Wang, Xiaoqin",
  abstract = "A fundamental structure of sounds encountered in the natural
              environment is the harmonicity. Harmonicity is an essential
              component of music found in all cultures. It is also a unique
              feature of vocal communication sounds such as human speech and
              animal vocalizations. Harmonics in sounds are produced by a
              variety of acoustic generators and reflectors in the natural
              environment, including vocal apparatuses of humans and animal
              species as well as music instruments of many types. We live in an
              acoustic world full of harmonicity. Given the widespread
              existence of the harmonicity in many aspects of the hearing
              environment, it is natural to expect that it be reflected in the
              evolution and development of the auditory systems of both humans
              and animals, in particular the auditory cortex. Recent
              neuroimaging and neurophysiology experiments have identified
              regions of non-primary auditory cortex in humans and non-human
              primates that have selective responses to harmonic pitches.
              Accumulating evidence has also shown that neurons in many regions
              of the auditory cortex exhibit characteristic responses to
              harmonically related frequencies beyond the range of pitch.
              Together, these findings suggest that a fundamental
              organizational principle of auditory cortex is based on the
              harmonicity. Such an organization likely plays an important role
              in music processing by the brain. It may also form the basis of
              the preference for particular classes of music and voice sounds.",
  journal  = "Frontiers in systems neuroscience",
  volume   =  7,
  year     =  2013,
  keywords = "Auditory cortex; Harmonicity; Marmoset; Music; Pitch",
  issn     = "1662-5137",
  doi      = "10.3389/fnsys.2013.00114"
}

@ARTICLE{Wang2019-ci,
  title    = "Statistical Learning of Unfamiliar Sounds as Trajectories Through
              a Perceptual Similarity Space",
  author   = "Wang, Felix Hao and Hutton, Elizabeth A and Zevin, Jason D",
  journal  = "Cognitive science",
  volume   =  43,
  number   =  8,
  year     =  2019,
  keywords = "correspondence should be sent; department of psychology; levels
              of representation; similarity spaces; statistical learning; to
              felix hao wang; university of nevada las",
  issn     = "0364-0213",
  doi      = "10.1111/cogs.12740"
}

@ARTICLE{Mirand2007-jy,
  title   = "Double dissociation between rules and memory in music: An
             event-related potential study",
  author  = "Mirand, Robbin A and Ullman, Michael T",
  journal = "NeuroImage",
  volume  =  38,
  number  =  2,
  pages   = "331--345",
  year    =  2007,
  issn    = "1053-8119, 1537-8276"
}

@PHDTHESIS{Mauch2010-wg,
  title    = "Automatic chord transcription from audio using computational
              models of musical context",
  author   = "Mauch, Matthias",
  abstract = "This thesis is concerned with the automatic transcription of
              chords from audio, with an emphasis on modern popular music.
              Musical context such as the key and the structural segmentation
              aid the interpretation of chords in human beings. In this thesis
              we propose computational models that integrate such musical
              context into the automatic chord estimation process. We present a
              novel dynamic Bayesian network (DBN) which integrates models of
              metric position, key, chord, bass note and two beat-synchronous
              audio features (bass and treble chroma) into a single high-level
              musical context model. We simultaneously infer the most probable
              sequence of metric positions, keys, chords and bass notes via
              Viterbi inference. Several experiments with real world data show
              that adding context parameters results in a significant increase
              in chord recognition accuracy and faithfulness of chord
              segmentation. The proposed, most complex method transcribes
              chords with a state-of-the-art accuracy of 73\% on the song
              collection used for the 2009 MIREX Chord Detection tasks. This
              method is used as a baseline method for two further enhancements.
              Firstly, we aim to improve chord confusion behaviour by modifying
              the audio front end processing. We compare the effect of learning
              chord profiles as Gaussian mixtures to the effect of using
              chromagrams generated from an approximate pitch transcription
              method. We show that using chromagrams from approximate
              transcription results in the most substantial increase in
              accuracy. The best method achieves 79\% accuracy and
              significantly outperforms the state of the art.Secondly, we
              propose a method by which chromagram information is shared
              between repeated structural segments (such as verses) in a song.
              This can be done fully automatically using a novel structural
              segmentation algorithm tailored to this task. We show that the
              technique leads to a significant increase in accuracy and
              readability. The segmentation algorithm itself also obtains
              state-of-the-art results. A method that combines both of the
              above enhancements reaches an accuracy of 81\%, a statistically
              significant improvement over the best result (74\%) in the 2009
              MIREX Chord Detection tasks.",
  year     =  2010,
  address  = "London, UK",
  school   = "Queen Mary University of London"
}

@ARTICLE{Lee2008-kl,
  title    = "Acoustic chord transcription and key extraction from audio using
              key-dependent {HMMs} trained on synthesized audio",
  author   = "Lee, Kyogu and Slaney, Malcolm",
  abstract = "We describe an acoustic chord transcription system that uses
              symbolic data to train hidden Markov models and gives
              best-of-class frame-level recognition results. We avoid the
              extremely laborious task of human annotation of chord names and
              boundaries-which must be done to provide machine learning models
              with ground truth-by performing automatic harmony analysis on
              symbolic music files. In parallel, we synthesize audio from the
              same symbolic files and extract acoustic feature vectors which
              are in perfect alignment with the labels. We, therefore, generate
              a large set of labeled training data with a minimal amount of
              human labor. This allows for richer models. Thus, we build 24
              key-dependent HMMs, one for each key, using the key information
              derived from symbolic data. Each key model defines a unique
              state-transition characteristic and helps avoid confusions seen
              in the observation vector. Given acoustic input, we identify a
              musical key by choosing a key model with the maximum likelihood,
              and we obtain the chord sequence from the optimal state path of
              the corresponding key model, both of which are returned by a
              Viterbi decoder. This not only increases the chord recognition
              accuracy, but also gives key information. Experimental results
              show the models trained on synthesized data perform very well on
              real recordings, even though the labels automatically generated
              from symbolic data are not 100\% accurate. We also demonstrate
              the robustness of the tonal centroid feature, which outperforms
              the conventional chroma feature.",
  journal  = "IEEE transactions on audio, speech, and language processing",
  volume   =  16,
  number   =  2,
  pages    = "291--301",
  year     =  2008,
  keywords = "Acoustic chord transcription; Hidden Markov model (HMM); Key
              extraction; Key-dependent models; Symbolic music files",
  issn     = "1558-7916",
  doi      = "10.1109/TASL.2007.914399"
}

@ARTICLE{Benetos2013-rp,
  title    = "Multiple-instrument polyphonic music transcription using a
              temporally constrained shift-invariant model",
  author   = "Benetos, Emmanouil and Dixon, Simon",
  abstract = "A method for automatic transcription of polyphonic music is
              proposed in this work that models the temporal evolution of
              musical tones. The model extends the shift-invariant
              probabilistic latent component analysis method by supporting the
              use of spectral templates that correspond to sound states such as
              attack, sustain, and decay. The order of these templates is
              controlled using hidden Markov model-based temporal constraints.
              In addition, the model can exploit multiple templates per pitch
              and instrument source. The shift-invariant aspect of the model
              makes it suitable for music signals that exhibit frequency
              modulations or tuning changes. Pitch-wise hidden Markov models
              are also utilized in a postprocessing step for note tracking. For
              training, sound state templates were extracted for various
              orchestral instruments using isolated note samples. The proposed
              transcription system was tested on multiple-instrument recordings
              from various datasets. Experimental results show that the
              proposed model is superior to a non-temporally constrained model
              and also outperforms various state-of-the-art transcription
              systems for the same experiment.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  133,
  number   =  3,
  pages    = "1727--1741",
  year     =  2013,
  issn     = "0001-4966",
  doi      = "10.1121/1.4790351"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Bharucha1987-mv,
  title    = "Priming of chords: Spreading activation or overlapping frequency
              spectra?",
  author   = "Bharucha, Jamshed J and Stoeckig, Keiko",
  abstract = "A chord generates expectancies for related chords to follow.
              Expectancies can be studied by measuring the time to discriminate
              between a target chord and a mistuned foil as a function of the
              target‚{\"A}{\^o}s relatedness to a preceding prime chord. This
              priming paradigm has been employed to demonstrate that related
              targets are processed more quickly and are perceived to be more
              consonant than are unrelated targets (Bharucha \& Stoeckig,
              1986). The priming experiments in the present paper were designed
              to determine whether expectancies are generated at a cognitive
              level, by activation spreading through a network that represents
              harmonic relationships, or solely at a sensory level, by the
              activation of frequency-specific units. In Experiment 1,
              prime-target pairs shared no component tones, but related pairs
              had overlapping frequency spectra. In Experiment 2, all
              overlapping frequency components were eliminated. Priming was
              equally strong in both experiments. We conclude that
              frequency-specific repetition priming cannot account for
              expectancies in harmony, suggesting that activation spreads at a
              cognitive level of representation.",
  journal  = "Perception \& psychophysics",
  volume   =  41,
  number   =  6,
  pages    = "519--524",
  year     =  1987,
  issn     = "0031-5117",
  doi      = "10.3758/BF03210486"
}

@ARTICLE{Kunert2016-qp,
  title    = "Language influences music harmony perception: Effects of shared
              syntactic integration resources beyond attention",
  author   = "Kunert, Richard and Willems, Roel M and Hagoort, Peter",
  abstract = "Many studies have revealed shared music--language processing
              resources by finding an influence of music harmony manipulations
              on concurrent language processing. However, the nature of the
              shared resources has remained ambiguous. They have been argued to
              be syntax specific and thus due to shared syntactic integration
              resources. An alternative view regards them as related to general
              attention and, thus, not specific to syntax. The present
              experiments evaluated these accounts by investigating the
              influence of language on music. Participants were asked to
              provide closure judgements on harmonic sequences in order to
              assess the appropriateness of sequence endings. At the same time
              participants read syntactic garden-path sentences. Closure
              judgements revealed a change in harmonic processing as the result
              of reading a syntactically challenging word. We found no
              influence of an arithmetic control manipulation (experiment 1) or
              semantic garden-path sentences (experiment 2). Our results
              provide behavioural evidence for a specific influence of
              linguistic syntax processing on musical harmony judgements. A
              closer look reveals that the shared resources appear to be needed
              to hold a harmonic key online in some form of syntactic working
              memory or unification workspace related to the integration of
              chords and words. Overall, our results support the syntax
              specificity of shared music--language processing resources.",
  journal  = "Royal Society Open Science",
  volume   =  3,
  year     =  2016,
  keywords = "Closure ratings; Dynamic attending theory; Harmony perception;
              Music cognition; Semantic processing; Syntactic processing",
  issn     = "2054-5703",
  doi      = "10.1098/rsos.150685"
}

@ARTICLE{Tillmann2001-dt,
  title   = "Global context effect in normal and scrambled musical sequences",
  author  = "Tillmann, B and Bigand, E",
  journal = "Journal of experimental psychology. Human perception and
             performance",
  volume  =  27,
  number  =  5,
  pages   = "1185--1196",
  year    =  2001,
  issn    = "0096-1523"
}

@ARTICLE{Slevc2015-yg,
  title    = "Processing structure in language and music: a case for shared
              reliance on cognitive control",
  author   = "Slevc, L Robert and Okada, Brooke M",
  abstract = "\copyright{} 2014, Psychonomic Society, Inc.The relationship
              between structural processing in music and language has received
              increasing interest in the past several years, spurred by the
              influential Shared Syntactic Integration Resource Hypothesis
              (SSIRH; Patel, Nature Neuroscience, 6, 674--681, 2003). According
              to this resource-sharing framework, music and language rely on
              separable syntactic representations but recruit shared cognitive
              resources to integrate these representations into evolving
              structures. The SSIRH is supported by findings of interactions
              between structural manipulations in music and language. However,
              other recent evidence suggests that such interactions also can
              arise with nonstructural manipulations, and some recent
              neuroimaging studies report largely nonoverlapping neural regions
              involved in processing musical and linguistic structure. These
              conflicting results raise the question of exactly what shared
              (and distinct) resources underlie musical and linguistic
              structural processing. This paper suggests that one shared
              resource is prefrontal cortical mechanisms of cognitive control,
              which are recruited to detect and resolve conflict that occurs
              when expectations are violated and interpretations must be
              revised. By this account, musical processing involves not just
              the incremental processing and integration of musical elements as
              they occur, but also the incremental generation of musical
              predictions and expectations, which must sometimes be overridden
              and revised in light of evolving musical input.",
  journal  = "Psychonomic bulletin \& review",
  volume   =  22,
  number   =  3,
  pages    = "637--652",
  year     =  2015,
  keywords = "Cognitive control; Language; Music; Musical ambiguity; Syntax",
  issn     = "1069-9384, 1531-5320",
  doi      = "10.3758/s13423-014-0712-4"
}

@ARTICLE{Tekman1992-ad,
  title    = "Time course of chord priming",
  author   = "Tekman, Hasan G{\"u}rkan and Bharucha, Jamshed J",
  abstract = "The time course of chord priming was explored in four
              experiments. In chord priming, a chord (a typical combination of
              simultaneously sounded tones) primes other chords that are
              musically related. In the present study, the prime duration and
              the stimulus onset asynchrony (SOA) between the prime chord and
              the chord to be judged were varied. Priming occurred at an SOA
              and prime duration as short as 50 msec, the shortest tested. When
              the prime duration was held constant at 50 msec, priming occurred
              at an SOA as long as 2,500 msec, the longest tested, and the
              magnitude of the priming effect did not diminish. To eliminate a
              possible role of sensory memory in maintaining the priming effect
              during the silence following the prime, a 250-msec noise mask was
              presented immediately following the 50-msec prime. The
              interpolated noise mask did not eliminate priming, thereby
              supporting the view that chord priming is the consequence of
              associative activation.",
  journal  = "Perception \& psychophysics",
  volume   =  51,
  number   =  1,
  pages    = "33--39",
  year     =  1992,
  issn     = "0031-5117",
  doi      = "10.3758/BF03205071"
}

@ARTICLE{Bigand1999-fe,
  title    = "Effect of global structure and temporal organization on chord
              processing",
  author   = "Bigand, Emmanuel and Madurell, Fran{\c c}ois and Tillmann,
              Barbara and Pineau, Marion",
  abstract = "This study further explores the effect of global context on chord
              processing reported by E. Bigand and M. Pineau (1997).
              Expectations of a target chord were varied by manipulating the
              preliminary harmonic context while holding constant the chord(s)
              prior to the target. In Experiment 1, previously observed priming
              effects were replicated with an on-line paradigm. Experiment 2
              was an attempt to identify the point in chord sequences that is
              responsible for the occurrence of the priming effect. In
              Experiment 3, Bigand and Pineau's findings were extended to wider
              harmonic contexts (i.e., defined at three hierarchical levels),
              and new evidence was provided that chord processing also depends
              on the temporal organization of the musical sequence. Neural net
              simulations globally support J. J. Bharucha's (1987, 1994) view
              that priming effects result from activations spreading via a
              schematic knowledge of Western harmony.",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  25,
  number   =  1,
  pages    = "184--197",
  year     =  1999,
  issn     = "0096-1523",
  doi      = "10.1037/0096-1523.25.1.184"
}

@ARTICLE{Patel1998-ej,
  title   = "Processing syntactic relations in language and music: An
             event-related potential study",
  author  = "Patel, Aniruddh D and Gibson, Edward and Ratner, Jennifer and
             Besson, Mireille and Holcomb, Phillip J",
  journal = "Journal of cognitive neuroscience",
  volume  =  10,
  number  =  6,
  pages   = "717--733",
  year    =  1998,
  issn    = "0898-929X"
}

@ARTICLE{Hoch2011-ac,
  title    = "The influence of task-irrelevant music on language processing:
              Syntactic and semantic structures",
  author   = "Hoch, Lisianne and Poulin-Charronnat, Benedicte and Tillmann,
              Barbara",
  abstract = "Recent research has suggested that music and language processing
              share neural resources, leading to new hypotheses about
              interference in the simultaneous processing of these two
              structures. The present study investigated the effect of a
              musical chord's tonal function on syntactic processing
              (Experiment 1) and semantic processing (Experiment 2) using a
              cross-modal paradigm and controlling for acoustic differences.
              Participants read sentences and performed a lexical decision task
              on the last word, which was, syntactically or semantically,
              expected or unexpected. The simultaneously presented
              (task-irrelevant) musical sequences ended on either an expected
              tonic or a less-expected subdominant chord. Experiment 1 revealed
              interactive effects between music-syntactic and
              linguistic-syntactic processing. Experiment 2 showed only main
              effects of both music-syntactic and linguistic-semantic
              expectations. An additional analysis over the two experiments
              revealed that linguistic violations interacted with musical
              violations, though not differently as a function of the type of
              linguistic violations. The present findings were discussed in
              light of currently available data on the processing of music as
              well as of syntax and semantics in language, leading to the
              hypothesis that resources might be shared for structural
              integration processes and sequencing. \copyright{} 2011 Hoch,
              Poulin-Charronnat and Tillmann.",
  journal  = "Frontiers in psychology",
  volume   =  2,
  year     =  2011,
  keywords = "Cross-modal interactions; Musical expectancy; Semantic
              expectancy; Structural integration; Syntactic expectancy",
  issn     = "1664-1078",
  doi      = "10.3389/fpsyg.2011.00112"
}

@ARTICLE{Perruchet2013-tg,
  title    = "Challenging prior evidence for a shared syntactic processor for
              language and music",
  author   = "Perruchet, Pierre and Poulin-Charronnat, B{\'e}n{\'e}dicte",
  abstract = "A theoretical landmark in the growing literature comparing
              language and music is the shared syntactic integration resource
              hypothesis (SSIRH; e.g., Patel, 2008), which posits that the
              successful processing of linguistic and musical materials relies,
              at least partially, on the mastery of a common syntactic
              processor. Supporting the SSIRH, Slevc, Rosenberg, and Patel
              (Psychonomic Bulletin \& Review 16(2):374-381, 2009) recently
              reported data showing enhanced syntactic garden path effects when
              the sentences were paired with syntactically unexpected chords,
              whereas the musical manipulation had no reliable effect on the
              processing of semantic violations. The present experiment
              replicated Slevc et al.'s (2009) procedure, except that syntactic
              garden paths were replaced with semantic garden paths. We
              observed the very same interactive pattern of results. These
              findings suggest that the element underpinning interactions is
              the garden path configuration, rather than the implication of an
              alleged syntactic module. We suggest that a different amount of
              attentional resources is recruited to process each type of
              linguistic manipulations, hence modulating the resources left
              available for the processing of music and, consequently, the
              effects of musical violations.",
  journal  = "Psychonomic bulletin \& review",
  volume   =  20,
  number   =  2,
  pages    = "310--317",
  year     =  2013,
  keywords = "Attention; Language comprehension; Modularity; Music cognition",
  issn     = "1069-9384",
  doi      = "10.3758/s13423-012-0344-5"
}

@ARTICLE{Koelsch2001-vm,
  title    = "Differentiating {ERAN} and {MMN}: An {ERP} study",
  author   = "Koelsch, Stefan and Gunter, Thomas C and Schr{\"o}ger, Erich and
              Tervaniemi, Mari and Sammler, Daniela and Friederici, Angela D",
  abstract = "In the present study, the early right-anterior negativity (ERAN)
              elicited by harmonically inappropriate chords during listening to
              music was compared to the frequency mismatch negativity (MMN) and
              the abstract-feature MMN. Results revealed that the amplitude of
              the ERAN, in contrast to the MMN, is speci\textregistered{}cally
              dependent on the degree of harmonic appropriate-ness. Thus, the
              ERAN is correlated with the cognitive processing of complex
              rule-based information, i.e. with the application of
              music$\pm$syntactic rules. Moreover, results showed that the
              ERAN, compared to the abstract-feature MMN, had both a longer
              latency, and a larger amplitude. The combined
              \textregistered{}ndings indicate that ERAN and MMN
              re\textasciimacron{}ect different mechan-isms of pre-attentive
              irregularity detection, and that, although both components have
              several features in common, the ERAN does not easily
              \textregistered{}t into the classical MMN framework. The present
              ERPs thus provide evidence for a differentiation of cognitive
              processes underlying the fast and pre-attentive processing of
              auditory information. NeuroReport 12:1385$\pm$1389 \& 2001
              Lippincott Williams \& Wilkins.",
  journal  = "Neuroreport",
  volume   =  12,
  number   =  7,
  pages    = "1385--1389",
  year     =  2001,
  keywords = "although; and a larger amplitude; and mmn re; and that; auditory
              processing; both a longer latency; detection; ect different
              mechan-; eeg; eran; erp; isms of pre-attentive irregularity; mmn;
              music; ndings indicate that eran; the combined",
  issn     = "0959-4965, 0003-6951",
  doi      = "10.1063/1.4973814"
}

@ARTICLE{Koelsch2000-ru,
  title    = "Brain indices of music processing: ''Nonmusicians'' are musical",
  author   = "Koelsch, Stefan and Gunter, Tomas and Friederici, Angela D and
              Schr{\"o}ger, Erich",
  abstract = "Only little systematic research has examined event-related brain
              potentials (ERPs) elicited by the cognitive processing of music.
              The present study investigated how music processing is influenced
              by a preceding musical context, affected by the task relevance of
              unexpected chords, and influenced by the degree and the
              probability of violation. Four experiments were conducted in
              which 'nonmusicians' listened to chord sequences, which
              infrequently contained a chord violating the sound expectancy of
              listeners. Integration of in-key chords into the musical context
              was reflected as a late negative-frontal deflection in the ERPs.
              This negative deflection declined towards the end of a chord
              sequence, reflecting normal buildup of musical context. Brain
              waves elicited by chords with unexpected notes revealed two ERP
              effects: an early right-hemispheric preponderant-anterior
              negativity, which was taken to reflect the violation of sound
              expectancy; and a late bilateral-frontal negativity. The late
              negativity was larger compared to in-key chords and taken to
              reflect the higher degree of integration needed for unexpected
              chords. The early right-anterior negativity (ERAN) was unaffected
              by the task relevance of unexpected chords. The amplitudes of
              both early and late negativities were found to be sensitive to
              the degree of musical expectancy induced by the preceding
              harmonic context, and to the probability for deviant acoustic
              events. The employed experimental design opens a new field for
              the investigation of music processing. Results strengthen the
              hypothesis of an implicit musical ability of the human brain.",
  journal  = "Journal of cognitive neuroscience",
  volume   =  12,
  number   =  3,
  pages    = "520--541",
  year     =  2000,
  issn     = "0898-929X",
  doi      = "10.1162/089892900562183"
}

@ARTICLE{Koelsch2005-rk,
  title    = "Interaction between syntax processing in language and in music:
              An {ERP} study",
  author   = "Koelsch, Stefan and Gunter, Thomas C and Wittfoth, Matthias and
              Sammler, Daniela",
  abstract = "The present study investigated simultaneous processing of
              language and music using visually presented sentences and
              auditorily presented chord sequences. Music-syntactically regular
              and irregular chord functions were presented synchronously with
              syntactically correct or incorrect words, or with words that had
              either a high or a low semantic cloze probability.
              Music-syntactically irregular chords elicited an early right
              anterior negativity (ERAN). Syntactically incorrect words
              elicited a left anterior negativity (LAN). The LAN was clearly
              reduced when words were presented simultaneously with
              music-syntactically irregular chord functions. Processing of high
              and low cloze-probability words as indexed by the N400 was not
              affected by the presentation of irregular chord functions. In a
              control experiment, the LAN was not affected by physically
              deviant tones that elicited a mismatch negativity (MMN). Results
              demonstrate that processing of musical syntax (as reflected in
              the ERAN) interacts with the processing of linguistic syntax (as
              reflected in the LAN), and that this interaction is not due to a
              general effect of deviance-related negativities that precede an
              IAN. Findings thus indicate a strong overlap of neural resources
              involved in the processing of syntax in language and music.
              \copyright{} 2005 Massachusetts Institute of Technology.",
  journal  = "Journal of cognitive neuroscience",
  volume   =  17,
  number   =  10,
  pages    = "1565--1577",
  year     =  2005,
  issn     = "0898-929X",
  doi      = "10.1162/089892905774597290"
}

@ARTICLE{Koelsch2002-bg,
  title    = "Music matters: Preattentive musicality of the human brain",
  author   = "Koelsch, Stefan and Schroger, Erich and Gunter, Thomas C",
  abstract = "During listening to a musical piece, unexpected harmonies may
              evoke brain responses that are reflected electrically as an early
              right anterior negativity (ERAN) and a late frontal negativity
              (N5). In the present study we demonstrate that these components
              of the event-related potential can be evoked preattentively, that
              is, even when a musical stimulus is ignored. Both ERAN and N5
              differed in amplitude as a function of music-theoretical
              principles. Participants had no special musical expertise;
              results thus provide evidence for an automatic processing of
              musical information in ``nonmusicians''.",
  journal  = "Psychophysiology",
  volume   =  39,
  pages    = "38--48",
  year     =  2002,
  issn     = "0048-5772",
  doi      = "10.1111/1469-8986.3910038"
}

@BOOK{Rahn1980-uf,
  title     = "Basic atonal theory",
  author    = "Rahn, J",
  publisher = "Schirmer",
  year      =  1980,
  address   = "New York, NY"
}

@ARTICLE{Morgan2019-fe,
  title    = "Statistical learning and Gestalt-like principles predict melodic
              expectations",
  author   = "Morgan, Emily and Fogel, Allison and Nair, Anjali and Patel,
              Aniruddh D",
  abstract = "Expectation, or prediction, has become a major theme in cognitive
              science. Music offers a powerful system for studying how
              expectations are formed and deployed in the processing of richly
              structured sequences that unfold rapidly in time. We ask to what
              extent expectations about an upcoming note in a melody are driven
              by two distinct factors: Gestalt-like principles grounded in the
              auditory system (e.g. a preference for subsequent notes to move
              in small intervals), and statistical learning of melodic
              structure. We use multinomial regression modeling to evaluate the
              predictions of computationally implemented models of melodic
              expectation against behavioral data from a musical cloze task, in
              which participants hear a novel melodic opening and are asked to
              sing the note they expect to come next. We demonstrate that both
              Gestalt-like principles and statistical learning contribute to
              listeners' online expectations. In conjunction with results in
              the domain of language, our results point to a
              larger-than-previously-assumed role for statistical learning in
              predictive processing across cognitive domains, even in cases
              that seem potentially governed by a smaller set of theoretically
              motivated rules. However, we also find that both of the models
              tested here leave much variance in the human data unexplained,
              pointing to a need for models of melodic expectation that
              incorporate underlying hierarchical and/or harmonic structure. We
              propose that our combined behavioral (melodic cloze) and modeling
              (multinomial regression) approach provides a powerful method for
              further testing and development of models of melodic expectation.",
  journal  = "Cognition",
  volume   =  189,
  pages    = "23--34",
  year     =  2019,
  keywords = "Expectation; Melody; Music; Probabilistic modeling; Statistical
              learning",
  issn     = "0010-0277, 1873-7838",
  doi      = "10.1016/j.cognition.2018.12.015"
}

@ARTICLE{Bharucha1987-nk,
  title    = "Music cognition and perceptual facilitation: A connectionist
              framework",
  author   = "Bharucha, Jamshed J",
  abstract = "The mind internalizes persistent structural regularities in music
              and recruits these internalized representations to facilitate
              subsequent perception. Facilitation underlies the generation of
              musical expectations and implications and the influence of a
              musical context on consonance and memory. Facilitation is
              demonstrated in experiments showing prim- ing of chords: chords
              that are harmonically closely related to a preceding context are
              processed more quickly than chords that are harmonically distant
              from the context. A tonal context enhances intonational sensitiv-
              ity for related chords and heightens their consonance.
              Facilitation occurs even when related chords don't share
              component tones with the context, and even when overlapping
              harmonics are eliminated. These results point to the indirect
              activation of representational units at a cognitive level. In a
              parallel study conducted in India, tones considered to play an
              important role in a r{\^a}g but absent from the experimental
              rendition of that r{\^a}g were facilitated in the same way. In a
              connectionist framework, facili- tation is a consequence of
              activation spreading through a network of rep- resentational
              units whose pattern of connectivity encodes musical rela-
              tionships. In a proposed connectionist model of harmony, each
              event in a musical sequence activates tone units, and activation
              spreads via con- necting links to parent chord units and then to
              parent key units. Activa- tion reverberates bidirectionally until
              the network settles into a state of equilibrium. The initial
              stages of the activation process constitute the bottom-up
              influence of the sounded tones, while the later, reverberatory
              stages constitute the top-down influence of learned, schematic
              structures internalized at the cognitive level. Computer
              simulations of the model show the same pattern of data as human
              subjects in experiments on relat- edness judgments of chords and
              memory for chord sequences.",
  journal  = "Music perception",
  volume   =  5,
  number   =  1,
  pages    = "1--30",
  year     =  1987,
  issn     = "0730-7829",
  doi      = "10.2307/40285384"
}

@ARTICLE{Temperley2008-tj,
  title    = "A probabilistic model of melody perception",
  author   = "Temperley, David",
  abstract = "This study presents a probabilistic model of melody perception,
              which infers the key of a melody and also judges the probability
              of the melody itself. The model uses Bayesian reasoning: For any
              ``surface'' pattern and underlying ``structure,'' we can infer
              the structure maximizing P(structure|surface) based on knowledge
              of P(surface, structure). The probability of the surface can then
              be calculated as $\sum$ P(surface, structure), summed over all
              structures. In this case, the surface is a pattern of notes; the
              structure is a key. A generative model is proposed, based on
              three principles: (a) melodies tend to remain within a narrow
              pitch range; (b) note-to-note intervals within a melody tend to
              be small; and (c) notes tend to conform to a distribution (or key
              profile) that depends on the key. The model is tested in three
              ways. First, it is tested on its ability to identify the keys of
              a set of folksong melodies. Second, it is tested on a melodic
              expectation task in which it must judge the probability of
              different notes occurring given a prior context; these judgments
              are compared with perception data from a melodic expectation
              experiment. Finally, the model is tested on its ability to detect
              incorrect notes in melodies by assigning them lower probabilities
              than the original versions.",
  journal  = "Cognitive science",
  volume   =  32,
  number   =  2,
  pages    = "418--444",
  year     =  2008,
  keywords = "Expectation; Key perception; Music cognition; Probabilistic
              modeling",
  issn     = "0364-0213",
  doi      = "10.1080/03640210701864089"
}

@ARTICLE{Woolhouse2016-xp,
  title    = "Perception of nonadjacent tonic-key relationships",
  author   = "Woolhouse, Matthew and Cross, Ian and Horton, Timothy",
  abstract = "The issue of structural nonadjacency in music and language was
              explored from a musical perspective in an experiment employing a
              stimulus-matching paradigm. The experiment measured the
              perceptual effect of a temporally nonadjacent key on the closure
              of a musical phrase; participants rated a stimulus-ending
              two-chord probe cadence for its closural properties. The temporal
              rate of decay of the nonadjacent key in memory was observed by
              varying the length of the intervening key area; that is, the key
              temporally adjacent to the probe cadence. Evidence emerged that
              listeners were able to hold the nonadjacent key in memory for
              over 10 seconds, indicating ``global'' nonadjacent harmonic
              perceptions. The study provides qualified evidence to support the
              notion that there are syntactic parallelisms between language and
              music, particularly in respect of nonadjacent key relationships.",
  journal  = "Psychology of Music",
  volume   =  44,
  number   =  4,
  pages    = "802--815",
  year     =  2016,
  keywords = "harmony; language; memory; music; nonadjacency",
  issn     = "1741-3087",
  doi      = "10.1177/0305735615593409"
}

@PHDTHESIS{Sauve2017-dm,
  title   = "Prediction in polyphony: modelling musical auditory scene analysis",
  author  = "Sauv{\'e}, Sarah A",
  year    =  2017,
  address = "London, UK",
  school  = "Quen Mary University of London"
}

@BOOK{Huron2016-zu,
  title     = "Voice leading: The science behind a musical art",
  author    = "Huron, David",
  publisher = "MIT Press",
  year      =  2016,
  address   = "Cambridge, MA"
}

@ARTICLE{Arthur2016-mu,
  title    = "The direct octaves rule: Testing a scene-analysis interpretation",
  author   = "Arthur, Claire and Huron, David",
  abstract = "A venerable rule of traditional Western part writing is the
              so-called Direct Octaves Rule (also known as Hidden or Exposed
              octaves), whereby similar pitch motion (i.e., two or more voices
              moving in the same direction) to a perfect octave should be
              avoided unless step motion is used. A number of interpretations
              have been offered as to why musicians might follow this rule. A
              traditional account (Fux, 1725/1966) exhibits several
              inconsistencies. A modern interpretation based on auditory scene
              analysis appears to have merit. However, this interpretation has
              yet to be tested empirically. Three experiments test the
              scene-analysis account using numerosity judgments for complex
              chords as the dependent measure. In Experiment 1, musician
              listeners show decreasing accuracy in numerosity judgments when
              an octave is present in the sonority -- as predicted. In
              experiments 2 and 3, chords were preceded by a single neighboring
              or distant tone. It was hypothesized that neighboring primes
              would increase the accuracy of nume...",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  volume   =  20,
  number   =  4,
  pages    = "495--511",
  year     =  2016,
  keywords = "auditory scene analysis; counterpoint; octave perception; voice
              leading",
  issn     = "1029-8649",
  doi      = "10.1177/1029864915623093"
}

@ARTICLE{Jacoby2017-kh,
  title     = "Integer Ratio Priors on Musical Rhythm Revealed Cross-culturally
               by Iterated Reproduction",
  author    = "Jacoby, Nori and McDermott, Josh H",
  abstract  = "Probability distributions over external states (priors) are
               essential to the interpretation of sensory signals. Priors for
               cultural artifacts such as music and language remain largely
               uncharacterized, but likely constrain cultural transmission,
               because only those signals with high probability under the prior
               can be reliably reproduced and communicated. We developed a
               method to estimate priors for simple rhythms via iterated
               reproduction of random temporal sequences. Listeners were asked
               to reproduce random ``seed'' rhythms; their reproductions were
               fed back as the stimulus and over time became dominated by
               internal biases, such that the prior could be estimated by
               applying the procedure multiple times. We validated that the
               measured prior was consistent across the modality of
               reproduction and that it correctly predicted perceptual
               discrimination. We then measured listeners' priors over the
               entire space of two- and three-interval rhythms. Priors in US
               participants showed peaks at rhythms with simple integer ratios
               and were similar for musicians and non-musicians. An analogous
               procedure produced qualitatively different results for spoken
               phrases, indicating some specificity to music. Priors measured
               in members of a native Amazonian society were distinct from
               those in US participants but also featured integer ratio peaks.
               The results do not preclude biological constraints favoring
               integer ratios, but they suggest that priors on musical rhythm
               are substantially modulated by experience and may simply reflect
               the empirical distribution of rhythm that listeners encounter.
               The proposed method can efficiently map out a high-resolution
               view of biases that shape transmission and stability of simple
               reproducible patterns within a culture.",
  journal   = "Current biology: CB",
  publisher = "Elsevier Ltd.",
  volume    =  27,
  number    =  3,
  pages     = "359--370",
  year      =  2017,
  keywords  = "Bayesian models of perception; cross-cultural psychophysics;
               finger tapping; iterated learning; music cognition; music
               universals; musical meter; rhythm entertainment; serial
               reproduction; speech rhythm",
  issn      = "0960-9822",
  doi       = "10.1016/j.cub.2016.12.031"
}

@INPROCEEDINGS{Hild1984-uq,
  title     = "{HARMONET}: A neural net for harmonizing chorales in the style
               of J. S. Bach",
  booktitle = "Advances in Neural Information Processing Systems",
  author    = "Hild, Hermann and Feulner, Johannes and Menzel, Wolfram",
  publisher = "Morgan Kaufmann",
  pages     = "267--274",
  year      =  1984,
  address   = "Los Altos, CA"
}

@INPROCEEDINGS{McIntyre1994-lp,
  title     = "Bach in a box: The evolution of four part Baroque harmony using
               the genetic algorithm",
  booktitle = "Proceedings of the 1994 {IEEE} Conference on Evolutionary
               Computation",
  author    = "McIntyre, R A",
  pages     = "852--857",
  year      =  1994,
  address   = "Orlando, FL",
  doi       = "10.1109/icec.1994.349943"
}

@INPROCEEDINGS{Landsnes2019-zx,
  title     = "A model comparison for chord prediction on the Annotated
               Beethoven Corpus",
  booktitle = "Proceedings of the 16th Sound \& Music Computing Conference",
  author    = "Landsnes, Kristoffer and Mehrabyan, Liana and Wiklund, Victor
               and Lieck, Robert and Moss, Fabian C and Rohrmeier, Martin",
  year      =  2019,
  address   = "M{\'a}laga, Spain"
}

@PHDTHESIS{Hedges2017-ce,
  title   = "Advances in Multiple Viewpoint Systems and Applications in
             Modelling by Higher Order Musical Structure",
  author  = "Hedges, Thomas",
  year    =  2017,
  address = "London, UK",
  school  = "Queen Mary University of London"
}

@ARTICLE{Bachem1950-eb,
  title   = "Tone height and tone chroma as two different pitch qualities",
  author  = "Bachem, A",
  journal = "Acta psychologica",
  volume  =  7,
  pages   = "80--88",
  year    =  1950,
  issn    = "0001-6918",
  doi     = "10.1016/0001-6918(50)90004-7"
}

@ARTICLE{Leman1995-oo,
  title   = "A model of retroactive tone-center perception",
  author  = "Leman, Marc",
  journal = "Music Perception1",
  volume  =  12,
  number  =  4,
  pages   = "439--471",
  year    =  1995
}

@ARTICLE{White2018-it,
  title    = "Feedback and feedforward models of musical key",
  author   = "White, Christopher Wm",
  abstract = "This study begins by drawing a distinction between two ways of
              framing the concept of musical key. Feedforward models understand
              key as arising from immediately apparent surface characteristics
              like the distribution of pitch classes or a melody's intervallic
              content. Feedback models, on the other hand, understand key as
              being determined in tandem with other domains. Here, key arises
              from the surface being organized into other more complicated
              musical groupings or schemata---harmonic progressions, cadences,
              prolongations, meter, etc.---that themselves are informed by the
              music's tonal center. While much music theory and theory pedagogy
              have acknowledged that feedback occurs in various approaches to
              tonality, formal modeling in the fields of music cognition and
              computation has focused primarily on feedforward systems. This
              article attempts to right this imbalance by presenting a
              corpus-based feedback computational model that can be tested
              against human behavior. My model will identify a passage's key by
              organizing a surface into its constituent harmonies. Here,
              harmonic organization and key will be integrated into a feedback
              system with the ideal key being that which produces the ideal
              harmonic analysis, and vice versa. To validate the resulting
              model, its behavior is compared to that of other published tonal
              models, to the behaviors of undergraduate music students, and to
              the intuitions of professional music theorists.",
  journal  = "Music Theory Online",
  volume   =  24,
  number   =  2,
  year     =  2018,
  keywords = "a melody; abstract; apparent surface; as arising from
              immediately; characteristics like the distribution; corpus
              analysis; drawing a distinction between; feedback models;
              feedforward models understand key; harmony; key; modeling; of
              musical key; of pitch classes or; s intervallic content; scale
              degrees; the concept; this study begins by; tonality; two ways of
              framing",
  doi      = "10.30535/mto.24.2.4"
}

@INPROCEEDINGS{Barthelemy2001-xs,
  title     = "Figured bass and tonality recognition",
  booktitle = "Proceedings of the Second International Symposium on Music
               Information Retrieval",
  author    = "Barth{\'e}lemy, Jerome and Bonardi, Alain",
  abstract  = "[First paragraph] In the course of the WedelMusic project [15],
               we are currently implementing retrieval engines based on musical
               content automatically extracted from a musical score. By musical
               content, we mean not only main melodic motives, but also
               harmony, or tonality. In this paper, we first review previous
               research in the domain of harmonic analysis of tonal music. We
               then present a method for automated harmonic analysis of a music
               score based on the extraction of a figured bass. The figured
               bass is determined by means of a template-matching algorithm,
               where templates for chords can be entirely and easily redefined
               by the end-user. We also address the problem of tonality
               recognition with a simple algorithm based on the figured bass.
               Limitations of the method are discussed. Results are shown and
               compared to previous research. Finally, potential uses for Music
               Information Retrieval are discussed.",
  pages     = "129--136",
  year      =  2001,
  address   = "Bloomington, IN",
  keywords  = "automatic extraction of musical; bass and tonality recognition;
               features; figured; music analysis"
}

@INPROCEEDINGS{Kroger2008-ri,
  title     = "Rameau: A system for automatic harmonic analysis",
  booktitle = "Proceedings of the 2008 International Computer Music Conference",
  author    = "Kr{\"o}ger, Pedro and Passos, Alexandre and Sampaio, Marcos da
               Silva and de Cidra, Givaldo",
  abstract  = "Automated harmonic analysis is an important and interest- ing
               music research topic. Although many researchers have studied
               solutions to this problem, there is no comprehensive and
               systematic comparison of the many techniques proposed. In this
               paper we present Rameau, a framework for automatic harmonic
               analysis we are developing. With Rameau we are able to
               reimplement and analyze previous techniques, and develop new
               ones as well. We present a performance evaluation of ten
               algorithms on a corpus of 140 Bach chorales. We also evaluate
               four of them using precision and recall and discuss possible
               improvements. We also present a numeric codification for tonal
               music with interesting properties, such as easy transposition,
               preservation of enharmonic information and easy conversion to
               standard pitch-class notation.",
  pages     = "273--281",
  year      =  2008,
  address   = "Belfast, Northern Ireland",
  keywords  = "computational musicology"
}

@PHDTHESIS{Mearns2013-wh,
  title    = "The computational analysis of harmony in Western art music",
  author   = "Mearns, Lesley",
  abstract = "This thesis describes research in the computational analysis of
              harmony in western art music, focussing particularly on improving
              the accuracy and information-richness of key and chord extraction
              from digital score data. It is argued that a greater
              sophistication in automatic harmony analysis is an important
              contribution to the field of computational musicology. Initial
              experiments use hiddenMarkov models to predict key and mod-
              ulation from automatically labelled chord sequences. Model
              parameters are based on heuristically formulated chord and key
              weightings derived from Schonberg's harmonic theory and the key
              and chord ratings resulting from perceptual experiments with
              listeners. The music theory models are shown to outperform the
              perceptual models both in terms of key accuracy and modelling the
              precise moment of key change. All of the models perform well
              enough to generate descriptive data about modulatory frequency,
              modulatory type and key distance. A robust method of classifying
              underlying chord types from elaborated keyboard music is then
              detailed. The method successfully distinguishes between essential
              and inessential notes, for example, passing notes and neighbour
              notes, and combines note classification information with tertian
              chord potential to measure the harmonic importance of a note.
              Existing approaches to automatic chord classification are
              unsuitable for use with complex textures and are restricted to
              triads and simple sevenths. An important goal is therefore to
              recognise a much broader set of chords, including complex chord
              types such as 9ths, 11ths and 13ths. This level of detail is
              necessary if the methods are to supply sophisticated information
              about the harmonic techniques of composers. Testing on the first
              twenty-four preludes of J. S. Bach's Well Tempered Clavier, hand
              annotated by the author, a state of the art approach achieves
              22.1\% accuracy; our method achieves 55\% accuracy.",
  year     =  2013,
  address  = "London, UK",
  school   = "Queen Mary University of London"
}

@INPROCEEDINGS{Ju2017-cu,
  title     = "Non-chord tone identification using deep neural networks",
  booktitle = "Proceedings of the 4th International Workshop on Digital
               Libraries for Musicology",
  author    = "Ju, Yaolong and Condit-Schultz, Nathaniel and Arthur, Claire and
               Fujinaga, Ichiro",
  abstract  = "\copyright{} 2017 Association for Computing Machinery. This
               paper addresses the problem of harmonic analysis by proposing a
               non-chord tone identification model using deep neural network
               (DNN). By identifying non-chord tones, the task of harmonic
               analysis is much simplified. Trained and tested on a dataset of
               140 Bach chorales, an initial DNN was able to identify non-chord
               tones with F1-measure of 57.00\%, using pitch-class information
               alone. By adding metric information, a small size contextual
               window, and fine-tuning DNN, the model's accuracy increased to a
               F1-measure of 72.19\%. These results suggest that DNNs offer an
               innovative and promising approach to tackling the problem of
               non-chord tone identification, as well as harmonic analysis.",
  pages     = "13--16",
  year      =  2017,
  address   = "Shanghai, China",
  keywords  = "acm reference format; bach chorales; deep neural; harmonic
               analysis; machine learning; networks; non-chord tone
               identification",
  doi       = "10.1145/3144749.3144753"
}

@INPROCEEDINGS{Oudre2009-qf,
  title     = "Template-based chord recognition: Influence of the chord types",
  booktitle = "Proceedings of the 10th International Society for Music
               Information Retrieval Conference",
  author    = "Oudre, Laurent and Grenier, Yves and F{\'e}votte, C{\'e}dric",
  abstract  = "This paper describes a fast and efficient template-based chord
               recognition method. We introduce three chord mod- els taking
               into account one ormore harmonics for the notes of the chord.
               The use of pre-determined chord models enables to consider
               several types of chords (major, mi- nor, dominant seventh, minor
               seventh, augmented, dimin- ished...). After extracting a
               chromagram from the signal, the detected chord over a frame is
               the one minimizing a measure of fit between the chromagramframe
               and the chord templates. Several popularmeasures in the
               probability and signal processing field are considered for our
               task. In or- der to take into account the time persistence, we
               perform a post-processing filtering over the recognition
               criteria. The transcription tool is evaluated on the 13 Beatles
               albums with different chord types and compared to state-of-the-
               art chord recognition methods. We particularly focus on the
               influence of the chord types considered over the per- formances
               of the system. Experimental results show that our method
               outperforms the state-of-the-art and more im- portantly is less
               computationally demanding than the other evaluated systems.",
  pages     = "153--158",
  year      =  2009,
  address   = "Kobe, Japan"
}

@INPROCEEDINGS{Chen2018-cz,
  title     = "Functional harmony recognition of symbolic music data with
               multi-task recurrent neural networks",
  booktitle = "Proceedings of the 19th International Society for Music
               Information Retrieval Conference",
  author    = "Chen, Tsung-Ping and Su, Li",
  abstract  = "Previous works on chord recognition mainly focus on chord
               symbols but overlook other essential features that matter in
               musical harmony. To tackle the functional harmony recognition
               problem, we compile a new professionally annotated dataset of
               symbolic music encompassing not only chord symbols, but also
               various interrelated chord functions such as key modulation,
               chord inversion, secondary chords, and chord quality. We further
               present a novel holistic system in functional harmony
               recognition; a multi-task learning (MTL) architecture is
               implemented with the recurrent neural network (RNN) to jointly
               model chord functions in an end-to-end scenario. Experimental
               results highlight the capability of the proposed recognition
               system, and a promising improvement of the system by employing
               multi-task learning instead of single-task learning. This is one
               attempt to challenge the end-to-end chord recognition task from
               the perspective of functional harmony so as to uncover the grand
               structure ruling the flow of musical sound. The dataset and the
               source code of the proposed system is announced at
               https://github.com/ Tsung-Ping/functional-harmony.",
  pages     = "90--97",
  year      =  2018,
  address   = "Paris, France"
}

@INPROCEEDINGS{Zhou2015-gq,
  title     = "Chord detection using deep learning",
  booktitle = "Proceedings of the 16th International Society for Music
               Information Retrieval Conference",
  author    = "Zhou, Xinquan and Lerch, Alexander",
  abstract  = "In this paper, we utilize deep learning to learn high-level
               features for audio chord detection. The learned features,
               obtained by a deep network in bottleneck architecture, give
               promising results and outperform state-of-the-art systems. We
               present and evaluate the results for various methods and
               configurations, including input pre-processing, a bottleneck
               architecture, and SVMs vs. HMMs for chord classification.",
  pages     = "52--58",
  year      =  2015,
  address   = "M{\'a}laga, Spain"
}

@ARTICLE{Deng2017-mt,
  title    = "Large vocabulary automatic chord estimation using deep neural
              nets: Design framework, system variations and limitations",
  author   = "Deng, Junqi and Kwok, Yu-Kwong",
  abstract = "In this paper, we propose a new system design framework for large
              vocabulary automatic chord estimation. Our approach is based on
              an integration of traditional sequence segmentation processes and
              deep learning chord classification techniques. We systematically
              explore the design space of the proposed framework for a range of
              parameters, namely deep neural nets, network configurations,
              input feature representations, segment tiling schemes, and
              training data sizes. Experimental results show that among the
              three proposed deep neural nets and a baseline model, the
              recurrent neural network based system has the best average chord
              quality accuracy that significantly outperforms the other
              considered models. Furthermore, our bias-variance analysis has
              identified a glass ceiling as a potential hindrance to future
              improvements of large vocabulary automatic chord estimation
              systems.",
  journal  = "arXiv",
  year     =  2017,
  arxivid  = "1709.07153v2"
}

@INPROCEEDINGS{Mauch2010-gm,
  title     = "Approximate note transcription for the improved identification
               of difficult chords",
  booktitle = "Proceedings of the 11th International Society for Music
               Information Retrieval Conference",
  author    = "Mauch, Matthias and Dixon, Simon",
  abstract  = "The automatic detection and transcription of musical chords from
               audio is an established music computing task. The choice of
               chord profiles and higher-level time-series modelling have
               received a lot of attention, resulting in methods with an
               overall performance of more than 70\% in the MIREX Chord
               Detection task 2009. Research on the front end of chord
               transcription algorithms has often concentrated on finding good
               chord templates to fit the chroma features. In this paper we
               reverse this approach and seek to find chroma features that are
               more suitable for usage in a musically-motivated model. We do so
               by performing a prior approximate transcription using an
               existing technique to solve non-negative least squares problems
               (NNLS). The resulting NNLS chroma features are tested by using
               them as an input to an existing state-of-the-art high-level
               model for chord transcription. We achieve very good results of
               80\% accuracy using the song collection and metric of the 2009
               MIREX Chord Detection tasks. This is a significant increase over
               the top result (74\%) inMIREX2009. The nature of some chords
               makes their identification particularly susceptible to confusion
               between fundamental frequency and partials. We show that the
               recognition of these diffcult chords in particular is
               substantially improved by the prior approximate transcription
               using NNLS.",
  pages     = "135--140",
  year      =  2010,
  address   = "Utrecht, The Netherlands",
  keywords  = "chord detection; chord extraction; chromagram; nnls;
               non-negative least squares; tection; transcription"
}

@INPROCEEDINGS{Khadkevich2009-kf,
  title     = "Use of Hidden Markov Models and factored language models for
               automatic chord recognition",
  booktitle = "Proceedings of the 10th International Society for Music
               Information Retrieval Conference",
  author    = "Khadkevich, Maksim and Omologo, Maurizio",
  abstract  = "This paper focuses on automatic extraction of acoustic chord
               sequences from a musical piece. Standard and factored language
               models are analyzed in terms of applicability to the chord
               recognition task. Pitch class profile vectors that represent
               harmonic information are extracted from the given audio signal.
               The resulting chord sequence is obtained by running a Viterbi
               decoder on trained hidden Markov models and subsequent lattice
               rescoring, applying the language model weight. We performed
               several experiments using the proposed technique. Results
               obtained on 175 manually-labeled songs provided an increase in
               accuracy of about 2\%. \copyright{} 2009 International Society
               for Music Information Retrieval.",
  pages     = "561--566",
  year      =  2009,
  address   = "Kobe, Japan"
}

@INPROCEEDINGS{Mcfee2017-bx,
  title     = "Structure training for large-vocabulary chord recognition",
  booktitle = "Proceedings of the 18th International Society for Music
               Information Retrieval Conference",
  author    = "Mcfee, Brian and Bello, Juan Pablo",
  abstract  = "Automatic chord recognition systems operating in the
               large-vocabulary regime must overcome data scarcity: certain
               classes occur much less frequently than others, and this
               presents a significant challenge when estimating model
               parameters. While most systems model the chord recognition task
               as a (multi-class) classification problem, few attempts have
               been made to directly exploit the intrinsic structural
               similarities between chord classes. In this work, we develop a
               deep convolutional-recurrent model for automatic chord
               recognition over a vocabulary of 170 classes. To exploit
               structural relationships between chord classes, the model is
               trained to produce both the time-varying chord label sequence as
               well as binary en-codings of chord roots and qualities. This
               binary encoding directly exposes similarities between related
               classes, allowing the model to learn a more coherent
               representation of simultaneous pitch content. Evaluations on a
               corpus of 1217 annotated recordings demonstrate substantial
               improvements compared to previous models.",
  pages     = "188--194",
  year      =  2017,
  address   = "Suzhou, China"
}

@INPROCEEDINGS{Rocher2010-qc,
  title     = "Concurrent estimation of chords and keys from audio",
  booktitle = "Proceedings of the 11th International Society for Music
               Information Retrieval Conference",
  author    = "Rocher, Thomas and Robine, Matthias and Hanna, Pierre and
               Conklin, Darrell",
  abstract  = "This paper proposes a new method for local key and chord
               estimation from audio signals. A harmonic content of the musical
               piece is first extracted by computing a set of chroma vectors.
               Correlation with fixed chord and key templates then selects a
               set of key/chord pairs for every frame. A weighted acyclic
               harmonic graph is then built with these pairs as vertices, and
               the use of a musical distance to weigh its edges. Finally, the
               output sequences of chords and keys are obtained by finding the
               best path in the graph. The proposed system allows a mutual and
               beneficial chord and key estimation. It is evaluated on a corpus
               composed of Beatles songs for both the local key estimation and
               chord recognition tasks. Results show that it performs better
               than state-of-the art chord analysis algorithms while providing
               a more complete harmonic analysis. \copyright{} 2010
               International Society for Music Information Retrieval.",
  pages     = "141--146",
  year      =  2010,
  address   = "Utrecht, The Netherlands",
  issn      = "0031-4005",
  isbn      = "9789039353813"
}

@INPROCEEDINGS{Boulanger-Lewandowski2013-dn,
  title     = "Audio chord recognition with recurrent neural networks",
  booktitle = "Proceedings of the 14th International Society for Music
               Information Retrieval Conference",
  author    = "Boulanger-Lewandowski, Nicolas and Bengio, Yoshua and Vincent,
               Pascal",
  abstract  = "In this paper, we present an audio chord recognition system
               based on a recurrent neural network. The audio features are
               obtained from a deep neural network optimized with a combination
               of chromagram targets and chord informa-tion, and aggregated
               over different time scales. Contrar-ily to other existing
               approaches, our system incorporates acoustic and musicological
               models under a single train-ing objective. We devise an
               efficient algorithm to search for the global mode of the output
               distribution while tak-ing long-term dependencies into account.
               The resulting method is competitive with state-of-the-art
               approaches on the MIREX dataset in the major/minor prediction
               task.",
  pages     = "335--340",
  year      =  2013,
  address   = "Curitiba, Brazil"
}

@INPROCEEDINGS{Hori2017-dl,
  title     = "Music chord recognition from audio data using bidirectional
               encoder-decoder {LSTMs}",
  booktitle = "Proceedings of 2017 {APSIPA} Annual Summit and Conference",
  author    = "Hori, Takeshi and Nakamura, Kazuyuki and Sagayama, Shigeki",
  pages     = "1312--1315",
  year      =  2017,
  address   = "Aloft Kuala Lumpur Sentral, Malaysia"
}

@INPROCEEDINGS{Haas2012-tb,
  title     = "Improving audio chord transcription by exploiting harmonic and
               metric knowledge",
  booktitle = "Proceedings of the 13th International Society for Music
               Information Retrieval Conference",
  author    = "Haas, B de and Magalh{\~a}es, Jos{\'e} Pedro and Wiering, Frans",
  abstract  = "We present a new system for chord transcription from polyphonic
               musical audio that uses domain-specific knowledge about tonal
               harmony and metrical position to improve chord transcription
               performance. Low-level pulse and spectral features are extracted
               from an audio source using the Vamp plugin architecture.
               Subsequently, for each beat-synchronised chromagram we compute a
               list of chord candidates matching that chromagram, together with
               the confidence in each candidate. When one particular chord
               candidate matches the chromagram significantly bet- ter than all
               others, this chord is selected to represent the segment.
               However, when multiple chords match the chro- magram similarly
               well, we use a formal music theoreti- cal model of tonal harmony
               to select the chord candidate that best matches the sequence
               based on the surrounding chords. In an experiment we show that
               exploiting metri- cal and harmonic knowledge yields
               statistically significant chord transcription improvements on a
               corpus of 217 Bea- tles, Queen, and Zweieck songs.",
  publisher = "Porto, Portugal",
  pages     = "295--300",
  year      =  2012
}

@INPROCEEDINGS{Mauch2009-fu,
  title     = "Using musical structure to enhance automatic chord transcription",
  booktitle = "Proceedings of the 10th International Society for Music
               Information Retrieval Conference",
  author    = "Mauch, Matthias and Noland, Katy and Dixon, Simon",
  abstract  = "Chord extraction from audio is a well-established music
               computing task, and many valid approaches have been pre- sented
               in recent years that use different chord templates, smoothing
               techniques and musical context models. The present work shows
               that additional exploitation of the repet- itive structure of
               songs can enhance chord extraction, by combining chroma
               information from multiple occurrences of the same segment type.
               To justify this claim we mod- ify an existing chord labelling
               method, providing it with manual or automatic segment labels,
               and compare chord extraction results on a collection of 125
               songs to baseline methods without segmentation information. Our
               method results in consistent and more readily readable chord la-
               bels and provides a statistically significant boost in label
               accuracy. 1.",
  pages     = "231--236",
  year      =  2009,
  address   = "Kobe, Japan"
}

@ARTICLE{Ni2012-bx,
  title    = "An end-to-end machine learning system for harmonic analysis of
              music",
  author   = "Ni, Yizhao and McVicar, Matt and Santos-Rodriguez, Ral and De
              Bie, Tijl",
  abstract = "We present a new system for simultaneous estimation of keys,
              chords, and bass notes from music audio. It makes use of a novel
              chromagram representation of audio that takes perception of
              loudness into account. Furthermore, it is fully based on machine
              learning (instead of expert knowledge), such that it is
              potentially applicable to a wider range of genres as long as
              training data is available. As compared to other models, the
              proposed system is fast and memory efficient, while achieving
              state-of-the-art performance.",
  journal  = "IEEE transactions on audio, speech, and language processing",
  volume   =  20,
  number   =  6,
  pages    = "1771--1783",
  year     =  2012,
  keywords = "Audio chord estimation; harmony progression analyzer (HPA);
              loudness-based chromagram; machine learning; meta-song evaluation",
  issn     = "1558-7916",
  doi      = "10.1109/TASL.2012.2188516"
}

@INPROCEEDINGS{Yoshioka2004-hp,
  title     = "Automatic chord transcription with concurrent recognition of
               chord symbols and boundaries",
  booktitle = "Proceedings of the 5th International Conference on Music
               Information Retrieval",
  author    = "Yoshioka, Takuya and Kitahara, Tetsuro and Komatani, Kazunori
               and Ogata, Tetsuya and Okuno, Hiroshi G",
  abstract  = "This paper describes a method that recognizes musical chords
               from real-world audio signals in compact-disc recordings. The
               automatic recognition of musical chords is necessary for music
               information retrieval (MIR) sys- tems, since the chord sequences
               of musical pieces cap- ture the characteristics of their
               accompaniments. None of the previous methods can accurately
               recognize musi- cal chords from complex audio signals that
               contain vocal and drum sounds. The main problem is that the
               chord- boundary-detection and chord-symbol-identification pro-
               cesses are inseparable because of their mutual depen- dency. In
               order to solve this mutual dependency problem, our method
               generates hypotheses about tuples of chord symbols and chord
               boundaries, and outputs the most plau- sible one as the
               recognition result. The certainty of a hy- pothesis is evaluated
               based on three cues: acoustic fea- tures, chord progression
               patterns, and bass sounds. Ex- perimental results show that our
               method successfully rec- ognized chords in seven popular music
               songs; the average accuracy of the results was around 77\%.",
  pages     = "100--105",
  year      =  2004,
  address   = "Barcelona, Spain",
  keywords  = "audio signal; hy-; musical chord; musical key"
}

@ARTICLE{De_Valk2015-rm,
  title    = "Bringing `Musicque into the tableture': machine-learning models
              for polyphonic transcription of 16th-century lute tablature",
  author   = "de Valk, Reinier and Weyde, Tillman",
  abstract = "A large corpus of music written in lute tablature, spanning some
              three-and-a-half centuries, has survived. This music has so far
              escaped systematic musicological research because of its
              notational format. Being a practical instruction for the player,
              tablature reveals very little of the polyphonic structure of the
              music it encodes--and is therefore relatively inaccessible to
              non-specialists. Automatic polyphonic transcription into modern
              music notation can help unlock the corpus to a larger audience,
              and thus facilitate musicological research. In this study we
              present four variants of a machinelearning model for voice
              separation and duration reconstruction in 16th-century lute
              tablature. These models are intended to form the heart of an
              interactive system for automatic polyphonic transcription that
              can assist users in making editions tailored to their own
              preferences. Additionally, such models can provide new methods
              for analysing different aspects of polyphonic structure. We have
              experimented with modelling only voice and modelling voice and
              duration simultaneously, applying each in a forward- and in a
              backward-processing approach. The models are evaluated on a
              dataset containing 15 three- and four-voice intabulations. Each
              processing approach has its advantages, and the results vary
              between the models. With accuracy rates between approximately 80
              and 90 per cent, both for voice prediction and for duration
              prediction, the best models' performance is promising. Even in
              this early stage of the research, such models yield a useful
              initial transcription system. [ABSTRACT FROM AUTHOR]",
  journal  = "Early Music",
  volume   =  43,
  number   =  4,
  pages    = "563--576",
  year     =  2015,
  issn     = "0306-1078",
  doi      = "10.1093/em/cau102"
}

@INPROCEEDINGS{Nakamura2018-hn,
  title     = "Towards complete polyphonic music transcription: Integrating
               multi-pitch detection and rhythm quantization",
  booktitle = "2018 {IEEE} International Conference on Acoustics, Speech and
               Signal Processing ({ICASSP})",
  author    = "Nakamura, Eita and Benetos, Emmanouil and Yoshii, Kazuyoshi and
               Dixon, Simon",
  abstract  = "Most work on automatic transcription produces `` piano roll ''
               data with no musical interpretation of the rhythm or pitches. We
               present a polyphonic transcription method that converts a music
               audio signal into a human-readable musical score, by integrating
               multi-pitch de-tection and rhythm quantization methods. This
               integration is made difficult by the fact that the multi-pitch
               detection produces erroneous notes such as extra notes and
               introduces timing errors that are added to temporal deviations
               due to musical expression. Thus, we propose a rhythm
               quantization method that can remove extra notes by extend-ing
               the metrical hidden Markov model and optimize the model
               pa-rameters. We also improve the note-tracking process of
               multi-pitch detection by refining the treatment of repeated
               notes and adjustment of onset times. Finally, we propose
               evaluation measures for tran-scribed scores. Systematic
               evaluations on commonly used classical piano data show that
               these treatments improve the performance of transcription, which
               can be used as benchmarks for further studies.",
  publisher = "IEEE",
  pages     = "101--105",
  year      =  2018,
  keywords  = "Automatic transcription; Multi-pitch detection; Music signal
               analysis; Rhythm quantization; Statistical modelling",
  issn      = "1520-6149",
  isbn      = "9781538646588",
  doi       = "10.1109/ICASSP.2018.8461914"
}

@ARTICLE{OHanlon2016-ni,
  title    = "Non-negative group sparsity with subspace note modelling for
              polyphonic transcription",
  author   = "O'Hanlon, Ken and Nagano, Hidehisa and Keriven, Nicolas and
              Plumbley, Mark D",
  abstract = "\copyright{}2016 IEEE. Automatic music transcription (AMT) can be
              performed by deriving a pitch-time representation through
              decomposition of a spectrogram with a dictionary of
              pitch-labelled atoms. Typically, non-negative matrix
              factorisation (NMF) methods are used to decompose magnitude
              spectrograms. One atom is often used to represent each note.
              However, the spectrum of a note may change over time. Previous
              research considered this variability using different atoms to
              model specific parts of a note, or large dictionaries comprised
              of datapoints from the spectrograms of full notes. In this paper,
              the use of subspace modelling of note spectra is explored, with
              group sparsity employed as a means of coupling activations of
              related atoms into a pitched subspace. Stepwise and
              gradient-based methods for non-negative group sparse
              decompositions are proposed. Finally, a group sparse NMF approach
              is used to tune a generic harmonic subspace dictionary, leading
              to improved NMF-based AMT results.",
  journal  = "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
  volume   =  24,
  number   =  3,
  pages    = "530--542",
  year     =  2016,
  keywords = "Automatic music transcription; Group sparsity; Non-negative
              matrix factorisation; Stepwise optimal",
  issn     = "2329-9290",
  doi      = "10.1109/TASLP.2016.2515514"
}

@INPROCEEDINGS{Kelz2019-wp,
  title     = "Deep polyphonic {ADSR} piano note transcription",
  booktitle = "2019 {IEEE} International Conference on Acoustics, Speech and
               Signal Processing ({ICASSP})",
  author    = "Kelz, Rainer and Bock, Sebastian and Widmer, Gerhard",
  abstract  = "We investigate a late-fusion approach to piano transcription ,
               combined with a strong temporal prior in the form of a
               handcrafted Hidden Markov Model (HMM). The network architecture
               under consideration is compact in terms of its number of
               parameters and easy to train with gradient descent and momentum.
               The network outputs are fused over time in the final stage to
               obtain note segmentations, with an HMM whose transition-and
               observation probabilities are chosen based on a model of attack
               decay sustain release (ADSR) envelope. The note segments are
               then subject to a final binary decision rule to reject too weak
               note segment hypotheses. 1. METHODS We would like to transcribe
               a polyphonic audio recording of a piano into a symbolic score.
               For each note sounding, we expect to obtain a tuple (s, e, n,
               v), denoting start, end, MIDI note number, and optionally,
               volume. 1.1 Deep convolutional neural network We employ a model
               with multiple outputs, predicting different note phases. A
               conceptual drawing is shown in Figure 1. The network input x t
               $\in$ R c$\times$b is a spectro-gram snippet, extending c
               context frames in time, and b bins in frequency. b is the number
               of bins resulting from passing a linear STFT through a
               filterbank with semi-logarithmically spaced, triangular filters,
               resulting in a resolution of approximately two bins per
               semitone. We choose c = 11, b = 144. The temporal resolution of
               the model is 50 [frames/s]. The target matrix y t $\in$ \{0, 1\}
               88$\times$3 decomposes into vectors y on t , y f rm t , and y
               off t respectively, denoting the onset , the intermediate note
               phases, and the offset for each note for the center frame within
               the context window c.",
  pages     = "246--250",
  year      =  2019,
  isbn      = "9781538646588",
  doi       = "10.1109/icassp.2019.8683582"
}

@INPROCEEDINGS{Kelz2019-bn,
  title     = "Multitask learning for polyphonic piano transcription, a case
               study",
  booktitle = "2019 International Workshop on Multilayer Music Representation
               and Processing ({MMRP})",
  author    = "Kelz, Rainer and B{\"o}ck, Sebastian and Widmer, Gerhard",
  abstract  = "Viewing polyphonic piano transcription as a multitask learning
               problem, where we need to simultaneously predict onsets,
               intermediate frames and offsets of notes, we investigate the
               performance impact of additional prediction targets, using a
               variety of suitable convolutional neural network architectures.
               We quantify performance differences of additional objectives on
               the large MAESTRO dataset.",
  pages     = "85--91",
  year      =  2019,
  keywords  = "Multitask learning; Polyphonic transcription",
  isbn      = "9781728116495",
  doi       = "10.1109/MMRP.2019.8665372"
}

@ARTICLE{Martin2008-mp,
  title   = "The Tristan chord resolved",
  author  = "Martin, Nathan",
  journal = "Intersections",
  volume  =  28,
  number  =  2,
  pages   = "6--30",
  year    =  2008,
  issn    = "1911-0146",
  doi     = "10.7202/029953ar"
}

@BOOK{Carter2002-fg,
  title     = "Harmony Book",
  author    = "Carter, Elliott",
  editor    = "Hopkins, Nicholas and Link, John F",
  publisher = "Carl Fischer",
  year      =  2002,
  address   = "New York, NY"
}

@ARTICLE{Martino1961-hf,
  title   = "The source set and its aggregate formations",
  author  = "Martino, Donald",
  journal = "Journal of Mathematics \& Music. Mathematical and Computational
             Approaches to Music Theory, Analysis, Composition and Performance",
  volume  =  5,
  number  =  2,
  pages   = "224--273",
  year    =  1961,
  issn    = "1745-9737"
}

@ARTICLE{Dean2019-ns,
  title   = "Spectral pitch similarity is a predictor of perceived change in
             sound- as well as note-based music",
  author  = "Dean, Roger T and Milne, Andrew J and Bailes, Freya",
  journal = "Music \& Science",
  volume  =  2,
  pages   = "1--14",
  year    =  2019,
  issn    = "2059-2043",
  doi     = "10.1177/2059204319847351"
}

@INPROCEEDINGS{Sears2017-sp,
  title     = "Modeling harmony with skip-grams",
  booktitle = "Proceedings of the 18th International Society for Music
               Information Retrieval Conference",
  author    = "Sears, David R W and Arzt, Andreas and Frostel, Harald and
               Sonnleitner, Reinhard and Widmer, Gerhard",
  abstract  = "String-based (or viewpoint) models of tonal harmony often
               struggle with data sparsity in pattern discovery and prediction
               tasks, particularly when modeling composite events like triads
               and seventh chords, since the number of distinct n-note
               combinations in polyphonic textures is potentially enormous. To
               address this problem, this study examines the efficacy of
               skip-grams in music research, an alternative viewpoint method
               developed in corpus linguistics and natural language processing
               that includes sub-sequences of n events (or n-grams) in a
               frequency distribution if their constituent members occur within
               a certain number of skips. Using a corpus consisting of four
               datasets of Western classical music in symbolic form, we found
               that including skip-grams reduces data sparsity in n-gram
               distributions by (1) minimizing the proportion of n-grams with
               negligible counts, and (2) increasing the coverage of contiguous
               n-grams in a test corpus. What is more, skip-grams significantly
               outperformed contiguous n-grams in discovering conventional
               closing progressions (called cadences).",
  year      =  2017,
  address   = "Suzhou, China"
}

@ARTICLE{Babbitt1965-cw,
  title   = "The use of computers in musicological research",
  author  = "Babbitt, Milton",
  journal = "Perspectives of New Music",
  volume  =  3,
  number  =  2,
  pages   = "74--83",
  year    =  1965
}

@ARTICLE{Straus1991-gy,
  title   = "A primer for atonal set theory",
  author  = "Straus, Joseph N",
  journal = "College Music Symposium",
  volume  =  31,
  pages   = "1--26",
  year    =  1991
}

@ARTICLE{Wiggins2007-uf,
  title   = "A Framework for the Evaluation of Music Representation Systems",
  author  = "Wiggins, Geraint and Miranda, Eduardo and Smaill, Alan and Harris,
             Mitch",
  journal = "Computer Music Journal",
  volume  =  17,
  number  =  3,
  pages   = "31",
  year    =  2007,
  issn    = "0148-9267",
  doi     = "10.2307/3680941"
}

@ARTICLE{Wiggins2000-vs,
  title   = "{Computer-Representation} of Music in the Research Environment",
  author  = "Wiggins, Geraint A",
  journal = "Modern Methods for Musicology: Prospects, Proposals and Realities",
  number  = "January 2007",
  pages   = "1--13",
  year    =  2000
}

@ARTICLE{Karrick1998-ri,
  title   = "An examination of the intonation tendencies of wind
             instrumentalists based on their performance of selected harmonic
             musical intervals",
  author  = "Karrick, Brant",
  journal = "Journal of Research in Music Education",
  volume  =  46,
  number  =  1,
  pages   = "112--127",
  year    =  1998
}

@ARTICLE{Loosen1993-qf,
  title    = "Intonation of solo violin performance with reference to equally
              tempered, Pythagorean, and just intonations",
  author   = "Loosen, Franz",
  abstract = "Determined which musical scale best modeled the solo performances
              of eight 25--33 yr old professional violinists, who played the
              diatonic scale of C major, very slowly, without vibrato, and as
              accurately as possible (i.e., the usual way of playing when a
              string teacher shows a pupil how a scale sounds). When individual
              scales were analyzed as a whole, violin performances fit
              Pythagorean and equally tempered intonations more precisely than
              the just intonation; performances fit the Pythagorean and the
              equally tempered model almost equally well. Interval size
              (analyzed not considering the context of the individual scales)
              was halfway between the interval sizes in Pythagorean and equally
              tempered intonations. (PsycINFO Database Record (c) 2012 APA, all
              rights reserved)",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  93,
  number   =  1,
  pages    = "525--539",
  year     =  1993,
  issn     = "0001-4966",
  doi      = "10.1121/1.405632"
}

@ARTICLE{Kopiez2003-nu,
  title    = "Intonation of harmonic intervals: Adaptability of expert
              musicians to equal temperament and just intonation",
  author   = "Kopiez, Reinhard",
  abstract = "This study examines the deviation in the intonation of
              simultaneously sounding tones under the condition of an embedded
              melody task. Two professional musicians (trumpet players) were
              chosen as subjects to play the missing upper voice of a four-part
              audio example, while listening via headphones to the remaining
              three parts in adaptive five-limit just intonation and equal
              temperament. The experimental paradigm was that of a controlled
              varied condition with a 2 (tuning systems)x5 (interval
              categories)x5 (renditions)x2 (players) factorial design. An
              analysis of variance showed a nonsignificant difference between
              the average deviation of harmonic intonation in the two systems
              used. Mean deviations of 4.9 cents (SD=6.5 cents) in the
              equal-temperament condition and of 6.7 cents (SD=8.1 cents) in
              the just-intonation condition were found. Thus, we assume that
              the musicians employed the same intonation for equal-temperament
              and just-intonation versions (an unconscious ``always the same''
              strategy) and could not successfully adapt their performances to
              the just-intonation tuning system. Fewer deviations could be
              observed in the equal-temperament condition. This overall
              tendency can be interpreted as a ``burn in'' effect... (PsycINFO
              Database Record (c) 2012 APA, all rights reserved) (journal
              abstract)",
  journal  = "Music perception",
  volume   =  20,
  number   =  4,
  pages    = "383--410",
  year     =  2003,
  issn     = "0730-7829",
  doi      = "10.1525/mp.2003.20.4.383"
}

@ARTICLE{Zimmerman2011-id,
  title  = "A simple and effective decision rule for choosing a non-normality",
  author = "Zimmerman, Donald W",
  volume =  6,
  pages  = "388--409",
  year   =  2011,
  doi    = "10.1348/000711010X524739"
}

@ARTICLE{Zimmerman2004-kk,
  title  = "A note on preliminary tests of equality of variances",
  author = "Zimmerman, Donald W",
  pages  = "173--181",
  year   =  2004
}

@ARTICLE{Quick_undated-oe,
  title    = "Kulitta : a Framework for Automated Music Composition",
  author   = "Quick, Donya",
  number   =  1,
  keywords = "rule-based"
}

@ARTICLE{Emura2008-dk,
  title    = "A modular system generating Jazz-style arrangement for a given
              set of a melody and its chord name sequence",
  author   = "Emura, N and Miura, M and Yanagida, M",
  abstract = "There are many music systems available on the market, such as
              systems for the automatic arrangement of music pieces given as
              note sequences for solo pianos into a piano score in a specific
              style. These systems, however, are usually designed to generate
              music by concatenation of existing arrangement patterns, so no
              one can expect that these systems will satisfy user requirements.
              We propose a system in which a given melody expressed as a note
              sequence is arranged into a modern Jazz-style score for the piano
              on the basis of the ``Jazz theory,'' a theory of harmony used in
              Jazz and popular music. The performance of the proposed system is
              evaluated by comparing the results obtained with the proposed
              system with those obtained using popular arrangement systems
              available on the market. Experimental results show that
              arrangement using the proposed system is significantly superior
              to arrangement using systems available on the market.
              \copyright{} 2008 The Acoustical Society of Japan.",
  journal  = "Acoustical science and technology / edited by the Acoustical
              Society of Japan",
  volume   =  29,
  number   =  1,
  pages    = "51--57",
  year     =  2008,
  keywords = "jazz;music theory;rule-based",
  issn     = "1346-3969, 1347-5177",
  doi      = "10.1250/ast.29.51"
}

@BOOK{Crowder1976-py,
  title     = "Principles of Learning and Memory",
  author    = "Crowder, Robert G",
  publisher = "Psychology Press",
  edition   = "Classic Ed",
  year      =  1976,
  address   = "London, UK"
}

@ARTICLE{Hornel2004-wm,
  title    = "{CHORDNET}: Learning and producing voice leading with neural
              networks and dynamic programming",
  author   = "H{\"o}rnel, D",
  abstract = "We introduce a novel method for learning voice leading using
              neural networks. Unlike earlier approaches for learning chord
              sequences where chords are predicted from a local context, this
              method uses a multi-layer neural network for learning chord
              assessment from music examples. The network employs a special
              constraint-based topology for transforming the relative
              comparison of chord pairs into an absolute assessment function.
              Using this chord assessment function, globally optimized chord
              sequences can be found in linear time using the dynamic
              programming technique. The CHORDNET implementation of the
              approach learns stylistic aspects of voice leading directly from
              a set of training examples. In combination with the HARMONET
              system, it presents a powerful framework for solving practical
              harmonization tasks.",
  journal  = "Journal of New Music Research",
  volume   =  33,
  number   =  4,
  pages    = "387--397",
  year     =  2004,
  keywords = "dynamic programming;fixed number of voices;hand-crafted features",
  doi      = "10.1080/0929821052000343859"
}

@INPROCEEDINGS{Kitahara2008-ul,
  title     = "Computational Model for Automatic Chord Voicing based on
               Bayesian Network",
  booktitle = "Proceedings of {ICMPC10}",
  author    = "Kitahara, Tetsuro and Katsura, Makiko and Katayose, Haruhiro and
               Nagata, Noriko",
  abstract  = "Title from title screen.",
  volume    =  10,
  pages     = "146",
  year      =  2008,
  keywords  = "Bayesian network;chord symbols;data-driven;jazz;melody",
  issn      = "0027-8424",
  isbn      = "9784990420802",
  pmid      = "10339516",
  doi       = "10.1073/pnas.96.11.5903"
}

@ARTICLE{Miskiewicz2007-vw,
  title    = "Perceived roughness of two simultaneous harmonic complex tones",
  author   = "Mi{\'s}kiewicz, Andrzej and Rogala, Tomira and
              Szczepa{\'n}ska-Antosik, Joanna",
  journal  = "Archives of Acoustics",
  volume   =  32,
  number   =  3,
  pages    = "737--748",
  year     =  2007,
  keywords = "dissonance; roughness; timbre"
}

@ARTICLE{Vencovsky2017-ks,
  title   = "Roughness of two simultaneous harmonic complex tones on
             just-tempered and equal-tempered scales",
  author  = "Vencovsk{\'y}, V{\'a}clav and Rund, Franti{\v s}ek",
  journal = "Music perception",
  volume  =  35,
  number  =  2,
  pages   = "127--143",
  year    =  2017,
  issn    = "0730-7829"
}

@ARTICLE{Popescu2019-mq,
  title     = "The pleasantness of sensory dissonance is mediated by musical
               style and expertise",
  author    = "Popescu, Tudor and Neuser, Monja P and Neuwirth, Markus and
               Bravo, Fernando and Mende, Wolfgang and Boneh, Oren and Moss,
               Fabian C and Rohrmeier, Martin",
  journal   = "Scientific reports",
  publisher = "Springer US",
  volume    =  9,
  year      =  2019,
  issn      = "2045-2322",
  doi       = "10.1038/s41598-018-35873-8"
}

@ARTICLE{Arnon2019-sq,
  title     = "Do current statistical learning tasks capture stable individual
               differences in children ? An investigation of task reliability
               across modality",
  author    = "Arnon, Inbal",
  publisher = "Behavior Research Methods",
  year      =  2019,
  keywords  = "Statistical learning,Individual differences,Reliab; and adults
               are constantly; children; domain generality; environment and
               manage to; exposed to recur-; generalize from them; individual
               differences; infants; learn and; often called statistical;
               reliability; ring patterns in their; statistical learning; this
               ability"
}

@ARTICLE{Skerritt-Davis2019-rq,
  title   = "A model for statistical regularity extraction from dynamic sounds",
  author  = "Skerritt-Davis, Benjamin and Elhilali, Mounya",
  journal = "Acta Acustica united with Acustica",
  volume  =  105,
  year    =  2019,
  doi     = "10.3813/AAA.919279"
}

@ARTICLE{Skerritt-Davis2018-yw,
  title    = "Detecting change in stochastic sound sequences",
  author   = "Skerritt-Davis, Benjamin and Elhilali, Mounya",
  journal  = "PLoS computational biology",
  volume   =  14,
  number   =  5,
  year     =  2018,
  keywords = "Bayesian inference;Gaussian;changepoint;limited capacity",
  issn     = "1553-734X",
  doi      = "10.1371/journal.pcbi.1006162"
}

@INCOLLECTION{McFadden1974-qa,
  title     = "Conditional logit analysis of qualitative choice behaviour",
  booktitle = "Frontiers in Econometrics",
  author    = "McFadden, D",
  editor    = "Zarembka, P",
  publisher = "Academic Press",
  pages     = "105--142",
  year      =  1974,
  address   = "New York, NY"
}

@ARTICLE{Thiessen2017-do,
  title    = "What's statistical about learning? Insights from modelling
              statistical learning as a set of memory processes",
  author   = "Thiessen, Erik D",
  abstract = "One contribution of 13 to a theme issue 'New frontiers for
              statistical learning in the cognitive sciences'. EDT,
              0000-0002-2563-032X Statistical learning has been studied in a
              variety of different tasks, including word segmentation, object
              identification, category learning, artificial grammar learning
              and serial reaction time tasks (e.g. Saffran et al. 1996 Language
              Learning 62, 302-- 331). The difference among these tasks raises
              questions about whether they all depend on the same kinds of
              underlying processes and computations, or whether they are
              tapping into different underlying mechanisms. Prior theoretical
              approaches to statistical learning have often tried to explain or
              model learn-ing in a single task. However, in many cases these
              approaches appear inadequate to explain performance in multiple
              tasks. For example, explain-ing word segmentation via the
              computation of sequential statistics (such as transitional
              probability) provides little insight into the nature of
              sensitivity to regularities among simultaneously presented
              features. In this article, we will present a formal computational
              approach that we believe is a good candi-date to provide a
              unifying framework to explore and explain learning in a wide
              variety of statistical learning tasks. This framework suggests
              that statistical learning arises from a set of processes that are
              inherent in memory systems, including activation, interference,
              integration of information and forgetting (e.g. Perruchet \&
              Vinter 1998 Journal of Memory and Language 39, 246--263; Thiessen
              et al. 2013 Psychological Bulletin 139, 792--814). From this
              perspective, statistical learning does not involve explicit
              computation of statistics, but rather the extraction of elements
              of the input into memory traces, and subsequent integration
              across those memory traces that emphasize consistent information
              (Thiessen and Pavlik 2013 Cognitive Science 37, 310--343). This
              article is part of the themed issue 'New frontiers for
              statistical learning in the cognitive sciences'.",
  journal  = "Philosophical transactions of the Royal Society of London. Series
              B, Biological sciences",
  volume   =  372,
  number   =  1711,
  year     =  2017,
  keywords = "Memory; Modeling; Statistical learning",
  issn     = "0962-8436, 1471-2970",
  pmid     = "27872374",
  doi      = "10.1098/rstb.2016.0056"
}

@INPROCEEDINGS{Langlois2017-lm,
  title    = "Uncovering visual priors in spatial memory using serial
              reproduction",
  author   = "Langlois, Thomas A and Jacoby, Nori and Suchow, Jordan and
              Griffiths, Thomas L",
  year     =  2017,
  keywords = "inductive biases; iterated learning; reproduction; serial;
              spatial memory; vision"
}

@INPROCEEDINGS{Fitsioris2008-uo,
  title     = "Parallel successions of perfect fifths in the Bach chorales",
  booktitle = "Proceedings of the fourth Conference on Interdisciplinary
               Musicology ({CIM08})",
  author    = "Fitsioris, George and Conklin, Darrell",
  year      =  2008,
  address   = "Thessaloniki, Greece"
}

@ARTICLE{Villegas2010-yl,
  title   = "Roughness minimization through automatic intonation adjustments",
  author  = "Villegas, Juli{\'a}n and Cohen, Michael",
  journal = "Journal of New Music Research",
  volume  =  39,
  number  =  1,
  pages   = "75--92",
  year    =  2010,
  doi     = "10.1080/09298211003642480"
}

@ARTICLE{Loosen1994-fq,
  title   = "Tuning of diatonic scales by violinists, pianists, and
             nonmusicians",
  author  = "Loosen, Franz",
  journal = "Perception \& psychophysics",
  volume  =  56,
  number  =  2,
  pages   = "221--226",
  year    =  1994,
  issn    = "0031-5117"
}

@ARTICLE{Schellenberg2002-cs,
  title   = "Asymmetries in the Discrimination of Musical Intervals: Going
             {Out-of-Tune} Is More Noticeable Than Going {In-Tune}",
  author  = "Schellenberg, Glenn",
  journal = "Music perception",
  volume  =  19,
  number  =  2,
  pages   = "223--248",
  year    =  2002,
  issn    = "0730-7829"
}

@ARTICLE{Szczepanska-Antosik2008-qp,
  title    = "Roughness of two simultaneous harmonic complex tones in various
              pitch registers",
  author   = "Szczepa{\'n}ska-Antosik, Joanna",
  journal  = "Archives of Acoustics",
  volume   =  33,
  number   =  1,
  pages    = "73--78",
  year     =  2008,
  keywords = "dissonance; music perception; psychoacoustics; roughness"
}

@ARTICLE{Donald2019-vg,
  title   = "Perception of musical interval tuning",
  author  = "Donald, E and Hess, Joan Taylor",
  journal = "Music perception",
  volume  =  2,
  number  =  2,
  pages   = "166--195",
  year    =  2019,
  issn    = "0730-7829"
}

@ARTICLE{Manzara1992-qg,
  title  = "On the Entropy of Music: An Experiment with Bach Chorale Melodies",
  author = "Manzara, Leonard C and Witten, Ian H and James, Mark and Journal,
            Leonardo Music and Manzara, Leonard C and Witten, Ian H",
  volume =  2,
  pages  = "81--88",
  year   =  1992
}

@ARTICLE{Hsu2019-fo,
  title     = "Identifying category representations for complex stimuli using
               discrete Markov chain Monte Carlo with people",
  author    = "Hsu, Anne S and Martin, Jay B and Sanborn, Adam N and Griffiths,
               Thomas L and Martin, Jay B",
  publisher = "Behavior Research Methods",
  year      =  2019,
  keywords  = "Category representation,Markov chain Monte Carlo,W; and; big
               data is transforming; category representation; image databases;
               images are potentially rich; large databases of text; markov
               chain monte carlo; portunity for psychology research; resources
               for understanding human; significant op-; society and offers a;
               words representations"
}

@BOOK{Neisser1967-yn,
  title     = "Cognitive psychology",
  author    = "Neisser, Ulric",
  publisher = "Appleton-Century-Crofts",
  year      =  1967,
  address   = "New York, NY"
}

@ARTICLE{Sanborn2010-ce,
  title  = "Uncovering Mental Representations with Markov Chain Monte Carlo",
  author = "Sanborn, Adam N and Griffiths, Thomas L and Shiffrin, Richard M",
  volume =  60,
  number =  2,
  pages  = "63--106",
  year   =  2010
}

@INCOLLECTION{Atkinson1968-fx,
  title     = "Human memory: A proposed system and its control processes",
  booktitle = "Psychology of Learning and Motivation",
  author    = "Atkinson, R C and Shiffrin, R M",
  publisher = "Academic Press",
  volume    =  2,
  pages     = "89--195",
  year      =  1968,
  address   = "New York, NY"
}

@ARTICLE{Sanborn_undated-it,
  title  = "Markov Chain Monte Carlo with People",
  author = "Sanborn, Adam N and Griffiths, Thomas L",
  pages  = "1--8"
}

@ARTICLE{Ravignani2016-om,
  title     = "Musical evolution in the lab exhibits rhythmic universals",
  author    = "Ravignani, Andrea and Delgado, Tania",
  journal   = "Nature Publishing Group",
  publisher = "Nature Publishing Group",
  volume    =  1,
  number    = "december",
  pages     = "1--7",
  year      =  2016,
  doi       = "10.1038/s41562-016-0007"
}

@ARTICLE{Tabas2019-ar,
  title   = "Modeling and {MEG} evidence of early consonance processing in
             auditory cortex",
  author  = "Tabas, Alejandro and Andermann, Martin and Schuberth, Valeria and
             Riedel, Helmut and Balaguer-Ballester, Emili and Rupp, Andr{\'e}",
  journal = "PLoS computational biology",
  volume  =  15,
  number  =  2,
  year    =  2019,
  issn    = "1553-734X",
  doi     = "10.1371/journal.pcbi.1006820"
}

@ARTICLE{Deutsch1986-jt,
  title   = "A musical paradox",
  author  = "Deutsch, Diana",
  journal = "1Music Perception",
  volume  =  3,
  number  =  3,
  pages   = "275--280",
  year    =  1986,
  doi     = "10.2307/40285337"
}

@ARTICLE{Shepard1964-tb,
  title   = "Circularity in judgments of relative pitch",
  author  = "Shepard, Roger N",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  36,
  number  =  12,
  pages   = "2346--2353",
  year    =  1964,
  issn    = "0001-4966"
}

@ARTICLE{Deutsch1984-zf,
  title   = "Pitch classes differ with respect to height",
  author  = "Deutsch, Diana and Moore, Richard F and Dolson, Mark",
  journal = "Music perception",
  volume  =  2,
  number  =  2,
  pages   = "265--271",
  year    =  1984,
  issn    = "0730-7829"
}

@ARTICLE{Wilson2018-gz,
  title   = "Non-adjacent dependency learning in humans and other animals",
  author  = "Wilson, Benjamin and Spierings, Michelle and Ravignani, Andrea and
             Mueller, Jutta L and Mintz, Toben H and Wijnen, Frank and Kant,
             Anne Van Der and Smith, Kenny",
  journal = "Topics in cognitive science",
  year    =  2018,
  issn    = "1756-8757",
  doi     = "10.1111/tops.12381"
}

@ARTICLE{Steinley2006-jo,
  title   = "K-means clustering: A half-century synthesis",
  author  = "Steinley, Douglas",
  journal = "The British journal of mathematical and statistical psychology",
  volume  =  59,
  pages   = "1--34",
  year    =  2006,
  issn    = "0007-1102",
  doi     = "10.1348/000711005X48266"
}

@ARTICLE{Craton2019-in,
  title    = "It's only rock 'n roll (but {I} like it): Chord perception and
              rock's liberal harmonic palette",
  author   = "Craton, Lincoln G and Lee, Jane Hyo Jin and Krahe, Peter M",
  abstract = "Both music-theoretic accounts and corpus analyses indicate that
              rock routinely employs chords that deviate from the norms of
              common-practice music. Yet we know little about how listeners
              experience the chords that make up rock's liberal harmonic
              palette. In the present study, participants in two online
              experiments rated major chords that followed a short tonal
              sequence (a major scale + tonic major triad). Liking ratings
              obtained in Experiment 1 replicated earlier work showing that
              listeners prefer rock-typical targets---chords that are common in
              rock, but lie outside the basic diatonic set---to atypical,
              rarely used targets (Craton, Juergens, Michalak, \& Poirier,
              2016). Goodness of fit ratings with the same stimuli in
              Experiment 2 were similar to the liking ratings. High ratings for
              rock-typical target chords across the two experiments were not an
              artifact of their register and the pattern of responses was
              similar across four levels level of music training. In addition,
              the mean fitness ratings were approxima...",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  year     =  2019,
  keywords = "Harmonic hierarchy; harmonic expectancies; harmony perception;
              rock harmony; tonal hierarchy",
  issn     = "1029-8649",
  doi      = "10.1177/1029864919845023"
}

@INCOLLECTION{Repp1984-fz,
  title     = "Categorical perception: Issues, methods, findings",
  booktitle = "Speech and Language",
  author    = "Repp, Bruno H",
  editor    = "Jass, Norman J",
  publisher = "Academic Press",
  volume    =  10,
  pages     = "243--335",
  year      =  1984,
  address   = "Cambridge, MA"
}

@ARTICLE{Scott2016-fu,
  title     = "Auditory short-term memory in the primate auditory cortex",
  author    = "Scott, Brian H and Mishkin, Mortimer",
  journal   = "Brain research",
  publisher = "Elsevier",
  volume    =  1640,
  number    = "B",
  pages     = "264--277",
  year      =  2016,
  keywords  = "Cortex; Hearing; Macaque; Short-term memory; Working memory",
  issn      = "0006-8993",
  doi       = "10.1016/j.brainres.2015.10.048"
}

@ARTICLE{Periodicals2007-mk,
  title  = "Dealing with assumptions underlying statistical tests",
  author = "Periodicals, Wiley",
  volume =  44,
  number =  5,
  pages  = "495--502",
  year   =  2007
}

@ARTICLE{Parncutt2019-oa,
  title    = "Tone profiles of isolated musical chords: Psychoacoustic versus
              cognitive models",
  author   = "Parncutt, Richard and Sattmann, Sabrina and Gaich, Andreas and
              Seither-Preisler, Annemarie",
  journal  = "Music perception",
  volume   =  36,
  number   =  4,
  pages    = "406--430",
  year     =  2019,
  keywords = "harmony; missing funda-; pitch; tonality",
  issn     = "0730-7829"
}

@ARTICLE{Yu2017-gy,
  title     = "Robust linear regression: A review and comparison",
  author    = "Yu, Chun and Yao, Weixin",
  journal   = "Communications in Statistics - Simulation and Computation",
  publisher = "Taylor \& Francis",
  volume    =  46,
  number    =  8,
  pages     = "6261--6282",
  year      =  2017,
  keywords  = "Breakdown point; Linear regression; Outliers; Robustness",
  issn      = "0361-0918",
  doi       = "10.1080/03610918.2016.1202271"
}

@ARTICLE{Freckleton2011-ly,
  title    = "Dealing with collinearity in behavioural and ecological data:
              model averaging and the problems of measurement error",
  author   = "Freckleton, Robert P",
  journal  = "Behavioral ecology and sociobiology",
  volume   =  65,
  pages    = "91--101",
  year     =  2011,
  keywords = "information; model selection; regression",
  issn     = "0340-5443",
  doi      = "10.1007/s00265-010-1045-6"
}

@ARTICLE{Derksen1992-wv,
  title   = "Backward, forward and stepwise automated subset selection
             algorithms: Frequency of obtaining authentic and noise variables",
  author  = "Derksen, Shelley and Keselmanf, J",
  journal = "The British journal of mathematical and statistical psychology",
  volume  =  45,
  pages   = "265--282",
  year    =  1992,
  issn    = "0007-1102",
  doi     = "10.1111/j.2044-8317.1992.tb00992.x"
}

@ARTICLE{Whittingham2006-tj,
  title   = "Why do we still use stepwise modelling in ecology and behaviour ?",
  author  = "Whittingham, Mark J and Stephens, Philip A and Richard, B and
             Freckleton, Robert P",
  journal = "The Journal of animal ecology",
  volume  =  75,
  pages   = "1182--1189",
  year    =  2006,
  issn    = "0021-8790",
  doi     = "10.1111/j.1365-2656.2006.01141.x"
}

@ARTICLE{Rakowski1990-nn,
  title   = "Intonation variants of musical intervals in isolation and in
             musical contexts",
  author  = "Rakowski, Andrzej",
  journal = "Psychology of Music",
  volume  =  18,
  pages   = "60--72",
  year    =  1990
}

@ARTICLE{Moore1983-hr,
  title   = "Suggested formulae for calculating auditory-filter bandwidths and
             excitation patterns",
  author  = "Moore, Brian C J and Glasberg, Brian R",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  74,
  number  =  3,
  pages   = "750--753",
  year    =  1983,
  issn    = "0001-4966"
}

@ARTICLE{White2018-rj,
  title    = "Chord context and harmonic function in tonal music",
  author   = "White, Christopher Wm and Quinn, Ian",
  journal  = "Music Theory Spectrum",
  volume   =  40,
  number   =  2,
  pages    = "314--335O",
  year     =  2018,
  keywords = "bach chorale; computational modeling; corpus analysis; function;
              harmony; hidden markov models; kostka and payne; machine
              learning; mcgill billboard; music cognition; popular music;
              riemann; tonality",
  doi      = "10.1093/mts/mty021"
}

@BOOK{Tenney1988-sp,
  title     = "A history of 'consonance' and 'dissonance'",
  author    = "Tenney, James",
  publisher = "Excelsior Music Publishing Company",
  year      =  1988,
  address   = "New York, NY"
}

@ARTICLE{Parncutt2018-kt,
  title    = "A psychocultural theory of musical interval: Bye bye Pythagoras",
  author   = "Parncutt, Richard and Hair, Graham",
  journal  = "Music perception",
  volume   =  35,
  number   =  4,
  pages    = "475--501",
  year     =  2018,
  keywords = "bce; because it ignores perception; been problematic; in the 4th
              century; interval; intonation; musical intervals has always;
              pitch; pythagoras; ratio; the pythagorean approach to;
              understanding",
  issn     = "0730-7829"
}

@ARTICLE{Moore2012-vn,
  title    = "Frequency difference limens at high frequencies: Evidence for a
              transition from a temporal to a place code",
  author   = "Moore, Brian C J and Ernst, Stephan M A",
  abstract = "It is commonly believed that difference limens for frequency
              (DLFs) for pure tones depend on a temporal mechanism (phase
              locking) for frequencies up to 4-5 kHz and a place mechanism at
              higher frequencies. The DLFs predicted from a place mechanism,
              expressed as a proportion of center frequency ($\Delta$ff),
              should be approximately invariant with frequency at medium to
              high frequencies. If there is a transition from a temporal to a
              place mechanism, $\Delta$ff should increase with increasing
              center frequency until the transition occurs, and then reach a
              plateau. Published data do not show such an effect. In this
              study, DLFs were measured for center frequencies from 2 to 14
              kHz, using earphones designed to produce a flat response at the
              eardrum. The level of every tone was varied over a range of
              $\pm$4 dB, to reduce loudness cues. The value of $\Delta$ff
              increased progressively from 2 to 8 kHz, but did not change
              significantly for frequencies from 8 to 14 kHz. The results are
              consistent with the idea that there is a transition from a
              temporal to a place mechanism at about 8 kHz, rather than at 4-5
              kHz, as is commonly assumed. \copyright{} 2012 Acoustical Society
              of America.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  132,
  number   =  3,
  pages    = "1542--1547",
  year     =  2012,
  issn     = "0001-4966",
  doi      = "10.1121/1.4739444"
}

@ARTICLE{Bendor2012-kf,
  title    = "Dual-pitch processing mechanisms in primate auditory cortex",
  author   = "Bendor, D and Osmanski, M S and Wang, X",
  abstract = "Pitch, our perception of how high or low a sound is on a musical
              scale, is a fundamental perceptual attribute of sounds and is
              important for both music and speech. After more than a century of
              research, the exact mechanisms used by the auditory system to
              extract pitch are still being debated. Theoretically, pitch can
              be computed using either spectral or temporal acoustic features
              of a sound. We have investigated how cues derived from the
              temporal envelope and spectrum of an acoustic signal are used for
              pitch extraction in the common marmoset (Callithrix jacchus), a
              vocal primate species, by measuring pitch discrimination
              behaviorally and examining pitch-selective neuronal responses in
              auditory cortex. Wefind that pitch is extracted by marmosets
              using temporal envelope cues for lower pitch sounds composed of
              higher-order harmonics, whereas spectral cues are used for higher
              pitch sounds with lower-order harmonics. Our data support
              dual-pitch processing mechanisms, originally proposed by
              psychophysicists based on human studies, whereby pitch is
              extracted using a combination of temporal envelope and spectral
              cues. \copyright{} 2012 the authors.",
  journal  = "Journal of Neuroscience",
  volume   =  32,
  number   =  46,
  pages    = "16149--16161",
  year     =  2012,
  issn     = "0270-6474",
  doi      = "10.1523/jneurosci.2563-12.2012"
}

@ARTICLE{Larrouy-Maestri2019-pw,
  title     = "The mistuning perception test: A new measurement instrument",
  author    = "Larrouy-Maestri, Pauline and Harrison, Peter M C and
               M{\"u}llensiefen, Daniel",
  abstract  = "An important aspect of the perceived quality of vocal music is
               the degree to which the vocalist sings in tune. Although most
               listeners seem sensitive to vocal mistuning, little is known
               about the development of this perceptual ability or how it
               differs between listeners. Motivated by a lack of suitable
               preexisting measures, we introduce in this article an adaptive
               and ecologically valid test of mistuning perception ability. The
               stimulus material consisted of short excerpts (6 to 12 s in
               length) from pop music performances (obtained from MedleyDB;
               Bittner et al., 2014) for which the vocal track was
               pitch-shifted relative to the instrumental tracks. In a first
               experiment, 333 listeners were tested on a two-alternative
               forced choice task that tested discrimination between a
               pitch-shifted and an unaltered version of the same audio clip.
               Explanatory item response modeling was then used to calibrate an
               adaptive version of the test. A subsequent validation experiment
               applied this adaptive test to 66 participants with a broad range
               of musical expertise, producing evidence of the test's
               reliability, convergent validity, and divergent validity. The
               test is ready to be deployed as an experimental tool and should
               make an important contribution to our understanding of the human
               ability to judge mistuning.",
  journal   = "Behavior research methods",
  publisher = "Behavior Research Methods",
  volume    =  51,
  number    =  2,
  pages     = "663--675",
  year      =  2019,
  keywords  = "Gold-MSI; Musical abilities; Pitch accuracy; Pitch perception",
  issn      = "1554-351X, 1554-3528",
  doi       = "10.3758/s13428-019-01225-1"
}

@ARTICLE{Gold2019-su,
  title  = "Musical reward prediction errors engage the nucleus accumbens and
            motivate learning",
  author = "Gold, Benjamin P and Mas-herrero, Ernest and Zeighami, Yashar and
            Benovoy, Mitchel and Dagher, Alain",
  pages  = "1--6",
  year   =  2019,
  doi    = "10.1073/pnas.1809855116"
}

@ARTICLE{Ross2011-ln,
  title    = "Nonparametric monitoring of data streams for changes in location
              and scale",
  author   = "Ross, Gordon J and Tasoulis, Dimitris K and Adams, Niall M",
  abstract = "The analysis of data streams requires methods which can cope with
              a very high volume of data points. Under the requirement that
              algorithms must have constant computational complexity and a
              fixed amount of memory, we develop a framework for detecting
              changes in data streams when the distributional form of the
              stream variables is unknown.We consider the general problem of
              detecting a change in the location and/or scale parameter of a
              stream of random variables, and adapt several nonparametric
              hypothesis tests to create a streaming change detection
              algorithm. This algorithm uses a test statistic with a null
              distribution independent of the data. This allows a desired rate
              of false alarms to be maintained for any stream even when its
              distribution is unknown. Our method is based on hypothesis tests
              which involve ranking data points, and we propose a method for
              calculating these ranks online in a manner which respects the
              constraints of data stream analysis.",
  journal  = "Technometrics: a journal of statistics for the physical,
              chemical, and engineering sciences",
  volume   =  53,
  number   =  4,
  pages    = "379--389",
  year     =  2011,
  keywords = "Change detection; Nonparametric tests; Streaming data",
  issn     = "0040-1706",
  doi      = "10.1198/TECH.2011.10069"
}

@ARTICLE{Winkler1996-ut,
  title    = "Interactions between transient and long-term auditory memory as
              reflected by the mismatch negativity",
  author   = "Winkler, Istv{\'a}n and Cowan, Nelson and Cs{\'e}pe, Val{\'e}ria
              and Czigler, Istv{\'a}n and N{\"a}{\"a}t{\"a}nen, Risto",
  abstract = "Abstract The mismatch negativity (MMN) event-related potential
              (ERP) component is elicited by any discriminable change in series
              of repetitive auditory stimuli. MMN is generated by a process
              registering the deviation of the incoming stimulus from the trace
              of the previous repetitive stimulus. Using MMN as a probe into
              auditory sensory memory, the present study addressed the question
              of whether the sensory memory representation is formed strictly
              on the basis of an automatic feature analysis of incoming sensory
              stimuli or information from long-term memory is also
              incorporated. Trains of 6 tone bursts (standards with up to 1
              deviant per train) separated by 9.5-sec intertrain intervals were
              presented to subjects performing a visual tracking task and
              disregarding the auditory stimuli. Trains were grouped into
              stimulus blocks of 20 trains with a 2-min rest period between
              blocks. In the Constant-Standard Condition, both standard and
              deviant stimuli remained fixed across the session, encouraging
              the formation of a long-term memory representation. To eliminate
              the carryover of sensory storage from one train to the next, the
              first 3.6 sec of the intertrain interval was filled with 6 tones
              of random frequencies. In the Roving-Standard Condition, the
              standard changed from train to train and the intervening tones
              were omitted. It was found that MMN was elicited by deviants
              presented in Position 2 of the trains in the Constant-Standard
              Condition revealing that a single reminder of the constant
              standard reactivated the standard-stimulus representation. The
              MMN amplitude increased across trials within each stimulus block
              in the Constant- but not in the Roving-Standard Condition,
              demonstrating long-term learning in that condition (i.e., the
              standard-stimulus trace indexed by the MMN amplitude benefitted
              from the presentations of the constant standard in the previous
              trains). The present results suggest that the transient auditory
              sensory memory representation underlying the MMN is facilitated
              by a longer-term representation of the corresponding stimulus.",
  journal  = "Journal of cognitive neuroscience",
  volume   =  8,
  number   =  5,
  pages    = "403--415",
  year     =  1996,
  issn     = "0898-929X",
  pmid     = "23961944",
  doi      = "10.1162/jocn.1996.8.5.403"
}

@ARTICLE{Krumhansl1999-mk,
  title   = "Melodic expectation in Finnish spiritual folk hymns: Convergence
             of statistical, behavioral, and computational approaches",
  author  = "Krumhansl, Carol L and Louhivuori, Jukka and Toiviainen, Petri and
             J{\"a}rvinen, Topi and Eerola, Tuomas",
  journal = "Music perception",
  volume  =  17,
  number  =  2,
  pages   = "151--195",
  year    =  1999,
  issn    = "0730-7829"
}

@ARTICLE{Cheung2018-lx,
  title     = "The right inferior frontal gyrus processes nested non-local
               dependencies in music",
  author    = "Cheung, Vincent K M and Meyer, Lars and Friederici, Angela D and
               Koelsch, Stefan",
  abstract  = "Complex auditory sequences known as music have often been
               described as hierarchically structured. This permits the
               existence of non-local dependencies, which relate elements of a
               sequence beyond their temporal sequential order. Previous
               studies in music have reported differential activity in the
               inferior frontal gyrus (IFG) when comparing regular and
               irregular chord-transitions based on theories in Western tonal
               harmony. However, it is unclear if the observed activity
               reflects the interpretation of hierarchical structure as the
               effects are confounded by local irregularity. Using functional
               magnetic resonance imaging (fMRI), we found that violations to
               non-local dependencies in nested sequences of three-tone musical
               motifs in musicians elicited increased activity in the right
               IFG. This is in contrast to similar studies in language which
               typically report the left IFG in processing grammatical syntax.
               Effects of increasing auditory working demands are moreover
               reflected by distributed activity in frontal and parietal
               regions. Our study therefore demonstrates the role of the right
               IFG in processing non-local dependencies in music, and suggests
               that hierarchical processing in different cognitive domains
               relies on similar mechanisms that are subserved by
               domain-selective neuronal subpopulations.",
  journal   = "Scientific reports",
  publisher = "Springer US",
  volume    =  8,
  number    =  1,
  pages     = "1--12",
  year      =  2018,
  issn      = "2045-2322",
  pmid      = "29491454",
  doi       = "10.1038/s41598-018-22144-9"
}

@ARTICLE{Huotilainen2001-gy,
  title    = "Long-term memory traces facilitate short-term memory trace
              formation in audition in humans",
  author   = "Huotilainen, Minna and Kujala, Anu and Alku, Paavo",
  abstract = "Long-term memory traces of one's native language have an effect
              on the short-term memory traces formed by phonemes, Nature 385
              (1997) 432. We investigated whether they also affect the number
              of stimulus repetitions needed to form an adequate memory trace
              used in the elicitation of the mismatch negativity (MMN), an
              event-related response to a change in an ongoing sound stream. We
              recorded MMNs to infrequent stimuli occurring in trains of
              prototype and non-prototype phonemes, matched in their physical
              distances, and in trains of sinusoidal tones. We found that the
              number of standards needed to produce a prominent MMN was smaller
              for native-language prototype phonemes than to non-prototype
              phonemes, suggesting a faster trace development. \copyright{}
              2001 Published by Elsevier Science Ireland Ltd.",
  journal  = "Neuroscience letters",
  volume   =  310,
  number   = "2-3",
  pages    = "133--136",
  year     =  2001,
  keywords = "Auditory; Even-related potential; Human; Long-term memory; Memory
              trace; Mismatch negativity; Phoneme; Short-term memory",
  issn     = "0304-3940",
  pmid     = "11585585",
  doi      = "10.1016/S0304-3940(01)02096-1"
}

@ARTICLE{Ulanovsky2004-ga,
  title    = "Multiple time scales of adaptation in auditory cortex neurons",
  author   = "Ulanovsky, N",
  abstract = "Neurons in primary auditory cortex (A1) of cats show strong
              stimulus-specific adaptation (SSA). In probabilistic settings, in
              which one stimulus is common and another is rare, responses to
              common sounds adapt more strongly than responses to rare sounds.
              This SSA could be a correlate of auditory sensory memory at the
              level of single A1 neurons. Here we studied adaptation in A1
              neurons, using three different probabilistic designs. We showed
              that SSA has several time scales concurrently, spanning many
              orders of magnitude, from hundreds of milliseconds to tens of
              seconds. Similar time scales are known for the auditory memory
              span of humans, as measured both psychophysically and using
              evoked potentials. A simple model, with linear dependence on both
              short-term and long-term stimulus history, provided a good fit to
              A1 responses. Auditory thalamus neurons did not show SSA, and
              their responses were poorly fitted by the same model. In
              addition, SSA increased the proportion of failures in the
              responses of A1 neurons to the adapting stimulus. Finally, SSA
              caused a bias in the neuronal responses to unbiased stimuli,
              enhancing the responses to eccentric stimuli. Therefore, we
              propose that a major function of SSA in A1 neurons is to encode
              auditory sensory memory on multiple time scales. This SSA might
              play a role in stream segregation and in binding of auditory
              objects over many time scales, a property that is crucial for
              processing of natural auditory scenes in cats and of speech and
              music in humans.",
  journal  = "Journal of Neuroscience",
  volume   =  24,
  number   =  46,
  pages    = "10440--10453",
  year     =  2004,
  keywords = "adaptation; auditory cortex; auditory thalamus; cat; physiology;
              sensory memory",
  doi      = "10.1523/JNEUROSCI.1905-04.2004"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Agres2018-pl,
  title    = "Information-theoretic properties of auditory sequences
              dynamically influence expectation and memory",
  author   = "Agres, Kat and Abdallah, Samer and Pearce, Marcus",
  abstract = "A basic function of cognition is to detect regularities in
              sensory input to facilitate the prediction and recognition of
              future events. It has been proposed that these implicit
              expectations arise from an internal predictive coding model,
              based on knowledge acquired through processes such as statistical
              learning, but it is unclear how different types of statistical
              information affect listeners' memory for auditory stimuli. We
              used a combination of behavioral and computational methods to
              investigate memory for non‐linguistic auditory sequences.
              Participants repeatedly heard tone sequences varying
              systematically in their information‐theoretic properties.
              Expectedness ratings of tones were collected during three
              listening sessions, and a recognition memory test was given after
              each session. Information‐theoretic measures of sequential
              predictability significantly influenced listeners' expectedness
              ratings, and variations in these properties had a significant
              impact on memory performance. Predictable sequences yielded
              increasingly better memory performance with increasing exposure.
              Computational simulations using a probabilistic model of auditory
              expectation suggest that listeners dynamically formed a new, and
              increasingly accurate, implicit cognitive model of the
              information‐theoretic structure of the sequences throughout the
              experimental session. (PsycINFO Database Record (c) 2017 APA, all
              rights reserved)",
  journal  = "Cognitive science",
  volume   =  42,
  number   =  1,
  pages    = "43--76",
  year     =  2018,
  keywords = "Auditory perception; Computational modeling; Expectation;
              Information theory; Music cognition; Predictive coding;
              Recognition memory",
  issn     = "0364-0213, 1551-6709",
  doi      = "10.1111/cogs.12477"
}

@ARTICLE{Wacongne2011-mp,
  title    = "Evidence for a hierarchy of predictions and prediction errors in
              human cortex",
  author   = "Wacongne, C and Labyt, E and van Wassenhove, V and Bekinschtein,
              T and Naccache, L and Dehaene, S",
  abstract = "According to hierarchical predictive coding models, the cortex
              constantly generates predictions of incoming stimuli at multiple
              levels of processing. Responses to auditory mismatches and
              omissions are interpreted as reflecting the prediction error when
              these predictions are violated. An alternative interpretation,
              however, is that neurons passively adapt to repeated stimuli. We
              separated these alternative interpretations by designing a
              hierarchical auditory novelty paradigm and recording human EEG
              and magnetoencephalographic (MEG) responses to mismatching or
              omitted stimuli. In the crucial condition, participants listened
              to frequent series of four identical tones followed by a fifth
              different tone, which generates a mismatch response. Because this
              response itself is frequent and expected, the hierarchical
              predictive coding hypothesis suggests that it should be cancelled
              out by a higher-order prediction. Three consequences ensue.
              First, the mismatch response should be larger when it is
              unexpected than when it is expected. Second, a perfectly
              monotonic sequence of five identical tones should now elicit a
              higher-order novelty response. Third, omitting the fifth tone
              should reveal the brain's hierarchical predictions. The rationale
              here is that, when a deviant tone is expected, its omission
              represents a violation of two expectations: a local prediction of
              a tone plus a hierarchically higher expectation of its deviancy.
              Thus, such an omission should induce a greater prediction error
              than when a standard tone is expected. Simultaneous EEE-
              magnetoencephalographic recordings verify those predictions and
              thus strongly support the predictive coding hypothesis.
              Higher-order predictions appear to be generated in multiple areas
              of frontal and associative cortices.",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  108,
  number   =  51,
  pages    = "20754--20759",
  year     =  2011,
  issn     = "0027-8424",
  pmid     = "22147913",
  doi      = "10.1073/pnas.1117807108"
}

@ARTICLE{Garrido2013-nd,
  title    = "Outlier responses reflect sensitivity to statistical structure in
              the human brain",
  author   = "Garrido, Marta I and Sahani, Maneesh and Dolan, Raymond J",
  abstract = "We constantly look for patterns in the environment that allow us
              to learn its key regularities. These regularities are fundamental
              in enabling us to make predictions about what is likely to happen
              next. The physiological study of regularity extraction has
              focused primarily on repetitive sequence-based rules within the
              sensory environment, or on stimulus-outcome associations in the
              context of reward-based decision-making. Here we ask whether we
              implicitly encode non-sequential stochastic regularities, and
              detect violations therein. We addressed this question using a
              novel experimental design and both behavioural and
              magnetoencephalographic (MEG) metrics associated with responses
              to pure-tone sounds with frequencies sampled from a Gaussian
              distribution. We observed that sounds in the tail of the
              distribution evoked a larger response than those that fell at the
              centre. This response resembled the mismatch negativity (MMN)
              evoked by surprising or unlikely events in traditional oddball
              paradigms. Crucially, responses to physically identical outliers
              were greater when the distribution was narrower. These results
              show that humans implicitly keep track of the uncertainty induced
              by apparently random distributions of sensory events. Source
              reconstruction suggested that the statistical-context-sensitive
              responses arose in a temporo-parietal network, areas that have
              been associated with attention orientation to unexpected events.
              Our results demonstrate a very early neurophysiological marker of
              the brain's ability to implicitly encode complex statistical
              structure in the environment. We suggest that this sensitivity
              provides a computational basis for our ability to make perceptual
              inferences in noisy environments and to make decisions in an
              uncertain world.",
  journal  = "PLoS computational biology",
  volume   =  9,
  number   =  3,
  year     =  2013,
  issn     = "1553-734X",
  doi      = "10.1371/journal.pcbi.1002999"
}

@ARTICLE{Moffat1998-gf,
  title    = "Arithmetic coding revisited",
  author   = "Moffat, Alistair and Neal, Radford M and Witten, Ian H",
  abstract = "During its long gestation in the 1970s and early 1980s,
              arithmetic coding was widely regarded more as an academic
              curiosity than a practical coding technique. One factor that
              helped it gain the popularity it enjoys today was the publication
              in 1987 of source code for a multi symbol arithmetic coder in
              Communications of the ACM. Now (1995), our understanding of
              arithmetic coding has further matured, and it is timely to review
              the components of that implementation and summarise the
              improvements that we and other authors have developed since then.
              We also describe a novel method for performing the underlying
              calculation needed for arithmetic coding. Accompanying the paper
              is a ``Mark II'' implementation that incorporates the
              improvements we suggest. The areas examined include: changes to
              the coding procedure that reduce the number of multiplications
              and divisions and permit them to be done to low precision; the
              increased range of probability approximations and alphabet sizes
              that can be supported using limited precision calculation; data
              structures for support of arithmetic coding on large alphabets;
              the interface between the modelling and coding subsystems; the
              use of enhanced models to allow high performance compression. For
              each of these areas, we consider how the new implementation
              differs from the CACM package",
  journal  = "ACM Transactions on Information Systems",
  volume   =  16,
  number   =  3,
  pages    = "256--294",
  year     =  1998,
  keywords = "algorithms; approximate coding; arithmetic coding;
              data-compression scheme; huffman codes; performance; redundancy;
              text compression; word-based model",
  issn     = "1068-0314",
  doi      = "10.1109/DCC.1995.515510"
}

@ARTICLE{Anderson1989-wq,
  title  = "``W Copy",
  author = "Anderson, John R",
  year   =  1989
}

@PHDTHESIS{Howard1993-nq,
  title   = "The design and analysis of efficient lossless data compression
             systems",
  author  = "Howard, P G",
  year    =  1993,
  address = "Providence, RI",
  school  = "Brown University"
}

@ARTICLE{Boucher2003-bs,
  title    = "Two ways of learning associations",
  author   = "Boucher, Luke and Dienes, Zolt{\'a}n",
  abstract = "How people learn chunks or associations between adjacent items in
              sequences was modelled. Two previously successful models of how
              people learn artificial grammars were contrasted: the CCN, a
              network version of the competitive chunker of Servan-Schreiber
              and Anderson [J. Exp. Psychol.: Learn. Mem. Cogn. 16 (1990) 592],
              which produces local and compositionally-structured chunk
              representations acquired incrementally; and the simple recurrent
              network (SRN) of Elman [Cogn. Sci. 14 (1990) 179], which acquires
              distributed representations through error correction. The models'
              susceptibility to two types of interference was determined:
              prediction conflicts, in which a given letter can predict two
              other letters that appear next with an unequal frequency; and
              retroactive interference, in which the prediction made by a
              letter changes in the second half of training. The predictions of
              the models were determined by exploring parameter space and
              seeing how densely different regions of the space of possible
              experimental outcomes were populated by model outcomes. For both
              types of interference, human data fell squarely in regions
              characteristic of CCN performance but not characteristic of SRN
              performance. \copyright{} 2003 Cognitive Science Society, Inc.
              All rights reserved.",
  journal  = "Cognitive science",
  volume   =  27,
  number   =  6,
  pages    = "807--842",
  year     =  2003,
  keywords = "Chunks; Learning associations; SRN",
  issn     = "0364-0213",
  pmid     = "5230321",
  doi      = "10.1016/j.cogsci.2003.03.001"
}

@ARTICLE{Turk-Browne2010-jl,
  title   = "Implicit perceptual anticipation triggered by statistical learning",
  author  = "Turk-Browne, Nicholas B and Scholl, Brian J and Johnson, Marcia K
             and Chun, Marvin M",
  journal = "The Journal of neuroscience: the official journal of the Society
             for Neuroscience",
  volume  =  30,
  number  =  33,
  pages   = "11177--11187",
  year    =  2010,
  issn    = "0270-6474",
  doi     = "10.1523/JNEUROSCI.0858-10.2010"
}

@ARTICLE{Perruchet2018-la,
  title   = "What mechanisms underlie implicit statistical learning?
             Transitional probabilities versus chunks in language learning",
  author  = "Perruchet, Pierre",
  journal = "Topics in cognitive science",
  pages   = "1--16",
  year    =  2018,
  issn    = "1756-8757",
  doi     = "10.1111/tops.12403"
}

@ARTICLE{Servan-Schreiber1990-pa,
  title    = "Learning artificial grammars with competitive chunking",
  author   = "Servan-Schreiber, Emile and Anderson, John R",
  abstract = "When exposed to a regular stimulus field, for instance, that
              generated by an artificial grammar, subjects unintentionally
              learn to respond efficiently to the underlying structure (G. A.
              Miller 1958; A. S. Reber see PA, Vol 42:8911). We explored the
              hypothesis that the learning process is chunking and that
              grammatical knowledge is implicitly encoded in a hierarchical
              network of chunks. We trained subjects on exemplar sentences
              while inducing them to form specific chunks. Their knowledge was
              then assessed through judgments of grammaticality. We found that
              subjects were less sensitive to violations that preserved their
              chunks than to violations that did not. We derived the theory of
              competitive chunking (CC) and found that it successfully
              reproduces, via computer simulations, both Miller's experimental
              results and our own. In CC, chunks are hierarchical structures
              strengthened with use by a bottom-up perception process.
              Strength-mediated competitions determine which chunks are created
              and which are used by the perception process.",
  journal  = "Journal of experimental psychology. Learning, memory, and
              cognition",
  volume   =  16,
  number   =  4,
  pages    = "592--608",
  year     =  1990,
  issn     = "0278-7393",
  pmid     = "686",
  doi      = "10.1037/0278-7393.16.4.592"
}

@ARTICLE{Schroger2014-gi,
  title    = "Predictive regularity representations in violation detection and
              auditory stream segregation: From conceptual to computational
              models",
  author   = "Schr{\"o}ger, Erich and Bendixen, Alexandra and Denham, Susan L
              and Mill, Robert W and Bohm, Tam{\'a}s M and Winkler, Istv{\'a}n",
  abstract = "Predictive accounts of perception have received increasing
              attention in the past 20 years. Detecting violations of auditory
              regularities, as reflected by the Mismatch Negativity (MMN)
              auditory event-related potential, is amongst the phenomena
              seamlessly fitting this approach. Largely based on the MMN
              literature, we propose a psychological conceptual framework
              called the Auditory Event Representation System (AERS), which is
              based on the assumption that auditory regularity violation
              detection and the formation of auditory perceptual objects are
              based on the same predictive regularity representations. Based on
              this notion, a computational model of auditory stream
              segregation, called CHAINS, has been developed. In CHAINS, the
              auditory sensory event representation of each incoming sound is
              considered for being the continuation of likely combinations of
              the preceding sounds in the sequence, thus providing alternative
              interpretations of the auditory input. Detecting repeating
              patterns allows predicting upcoming sound events, thus providing
              a test and potential support for the corresponding
              interpretation. Alternative interpretations continuously compete
              for perceptual dominance. In this paper, we briefly describe AERS
              and deduce some general constraints from this conceptual model.
              We then go on to illustrate how these constraints are
              computationally specified in CHAINS.",
  journal  = "Brain topography",
  volume   =  27,
  number   =  4,
  pages    = "565--577",
  year     =  2014,
  keywords = "Auditory object; Auditory scene analysis; Deviance detection;
              Mismatch negativity (MMN); Predictive modelling",
  issn     = "0896-0267, 1573-6792",
  pmid     = "24271978",
  doi      = "10.1007/s10548-013-0334-6"
}

@INCOLLECTION{Watson2016-pm,
  title     = "Uncertainty, informational masking, and the capacity of
               immediate auditory memory",
  booktitle = "Auditory Processing of Complex Sounds",
  author    = "Watson, Charles S",
  editor    = "Yost, William A and Watson, Charles S",
  publisher = "Routledge",
  year      =  2016,
  address   = "Abingdon-on-Thames, UK"
}

@ARTICLE{Maye2008-yp,
  title    = "Statistical phonetic learning in infants: Facilitation and
              feature generalization",
  author   = "Maye, Jessica and Weiss, Daniel J and Aslin, Richard N",
  abstract = "Over the course of the first year of life, infants develop from
              being generalized listeners, capable of discriminating both
              native and non-native speech contrasts, into specialized
              listeners whose discrimination patterns closely reflect the
              phonetic system of the native language(s). Recent work by Maye,
              Werker and Gerken (2002) has proposed a statistical account for
              this phenomenon, showing that infants may lose the ability to
              discriminate some foreign language contrasts on the basis of
              their sensitivity to the statistical distribution of sounds in
              the input language. In this paper we examine the process of
              enhancement in infant speech perception, whereby initially
              difficult phonetic contrasts become better discriminated when
              they define two categories that serve a functional role in the
              native language. In particular, we demonstrate that exposure to a
              bimodal statistical distribution in 8-month-old infants' phonetic
              input can lead to increased discrimination of difficult
              contrasts. In addition, this exposure also facilitates
              discrimination of an unfamiliar contrast sharing the same
              phonetic feature as the contrast presented during
              familiarization, suggesting that infants extract
              acoustic/phonetic information that is invariant across an
              abstract featural representation.",
  journal  = "Developmental science",
  volume   =  11,
  number   =  1,
  pages    = "122--134",
  year     =  2008,
  issn     = "1363-755X",
  doi      = "10.1111/j.1467-7687.2007.00653.x"
}

@ARTICLE{Erickson2015-wb,
  title    = "Statistical learning of language: Theory, validity, and
              predictions of a statistical learning account of language
              acquisition",
  author   = "Erickson, Lucy C and Thiessen, Erik D",
  abstract = "Considerable research indicates that learners are sensitive to
              probabilistic structure in laboratory studies of artificial
              language learning. However, the artificial and simplified nature
              of the stimuli used in the pioneering work on the acquisition of
              statistical regularities has raised doubts about the scalability
              of such learning to the complexity of natural language input. In
              this review, we explore a central prediction of statistical
              learning accounts of language acquisition - that sensitivity to
              statistical structure should be linked to real language processes
              - via an examination of: (1) recent studies that have increased
              the ecological validity of the stimuli; (2) studies that suggest
              statistical segmentation produces representations that share
              properties with real words; (3) correlations between individual
              variability in statistical learning ability and individual
              variability in language outcomes; and (4) atypicalities in
              statistical learning in clinical populations characterized by
              language delays or deficits.",
  journal  = "Developmental review: DR",
  volume   =  37,
  pages    = "66--108",
  year     =  2015,
  keywords = "Developmental disorders; Individual differences; Language
              acquisition; Statistical learning",
  issn     = "0273-2297",
  doi      = "10.1016/j.dr.2015.05.002"
}

@ARTICLE{Watson1985-on,
  title    = "Central factors in the discrimination and identification of
              complex sounds",
  author   = "Watson, C S and Foyle, D C",
  abstract = "The paper by Jesteadt and Norton [J. Acoust. Soc. Am. 78, 365-374
              (1985)] described certain similarities between psychophysical and
              physiological measures of frequency selectivity. Although the
              hearing of naturally occurring sounds is dependent upon these
              peripherally based relationships, recent research has shown that
              other, more central, processes are also strongly involved in the
              perception of complex acoustic events. The present paper
              describes research on the discrimination of complex sounds other
              than those of speech or music. In contrast to the more
              peripherally determined limits on the listener's sensitivity for
              single tones and other simple stimuli, the processing of complex
              sounds requires the interaction of peripheral and central
              mechanisms. These issues are discussed in relation to recent
              studies of the responses of the cochlea to speech stimuli. It is
              suggested that the peripheral processor may be relatively
              transparent to the essential spectral-temporal properties of
              speech, whereas more central processing severely limits the rates
              and amount of information that can be extracted from complex
              sounds.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  78,
  number   =  1,
  pages    = "375--380",
  year     =  1985,
  issn     = "0001-4966",
  doi      = "10.1121/1.392450"
}

@ARTICLE{Zhao2013-pb,
  title    = "Attention is spontaneously biased toward regularities",
  author   = "Zhao, Jiaying and Al-Aidroos, Naseem and Turk-Browne, Nicholas B",
  abstract = "Knowledge about regularities in the environment can be used to
              facilitate perception, memory, and language acquisition. Given
              this usefulness, we hypothesized that statistically structured
              sources of information receive attentional priority over noisier
              sources, independent of their intrinsic salience or goal
              relevance. We report three experiments that support this
              hypothesis. Experiment 1 shows that regularities bias spatial
              attention: Visual search was facilitated at a location containing
              temporal regularities, even though these regularities did not
              predict target location, timing, or identity. Experiments 2 and 3
              show that regularities bias feature attention: Attentional
              capture doubled in magnitude when singletons appeared,
              respectively, in a color or dimension with temporal regularities
              among task-irrelevant stimuli. Prioritization of the locations
              and features of regularities is not easily accounted for in the
              conventional dichotomy between stimulus-driven and goal-directed
              attention. This prioritization may in turn promote further
              statistical learning, helping the mind to acquire knowledge about
              stable aspects of the environment.",
  journal  = "Psychological science",
  volume   =  24,
  number   =  5,
  pages    = "667--677",
  year     =  2013,
  keywords = "attentional capture; cognitive control; feature-based attention;
              spatial attention; statistical learning; visual search",
  issn     = "0956-7976",
  doi      = "10.1177/0956797612460407"
}

@ARTICLE{Winkler2009-ex,
  title    = "Modeling the auditory scene: predictive regularity
              representations and perceptual objects",
  author   = "Winkler, Istv{\'a}n and Denham, Susan L and Nelken, Israel",
  abstract = "Predictive processing of information is essential for
              goal-directed behavior. We offer an account of auditory
              perception suggesting that representations of predictable
              patterns, or 'regularities', extracted from the incoming sounds
              serve as auditory perceptual objects. The auditory system
              continuously searches for regularities within the acoustic
              signal. Primitive regularities may be encoded by neurons adapting
              their response to specific sounds. Such neurons have been
              observed in many parts of the auditory system. Representations of
              the detected regularities produce predictions of upcoming sounds
              as well as alternative solutions for parsing the composite input
              into coherent sequences potentially emitted by putative sound
              sources. Accuracy of the predictions can be utilized for
              selecting the most likely interpretation of the auditory input.
              Thus in our view, perception generates hypotheses about the
              causal structure of the world. \copyright{} 2009 Elsevier Ltd.
              All rights reserved.",
  journal  = "Trends in cognitive sciences",
  volume   =  13,
  number   =  12,
  pages    = "532--540",
  year     =  2009,
  issn     = "1364-6613",
  pmid     = "19828357",
  doi      = "10.1016/j.tics.2009.09.003"
}

@ARTICLE{Yaron2012-la,
  title     = "Sensitivity to complex statistical regularities in rat auditory
               cortex",
  author    = "Yaron, Amit and Hershenhoren, Itai and Nelken, Israel",
  abstract  = "Neurons in auditory cortex are sensitive to the probability of
               stimuli: responses to rare stimuli tend to be stronger than
               responses to common ones. Here, intra- and extracellular
               recordings from the auditory cortex of halothane-anesthetized
               rats revealed the existence of a finer sensitivity to the
               structure of sound sequences. Using oddball sequences in which
               the order of stimulus presentations is periodic, we found that
               tones in periodic sequences evoked smaller responses than the
               same tones in random sequences. Significant reduction in the
               responses to the common tones in periodic relative to random
               sequences occurred even when these tones consisted of 95\% of
               the stimuli in the sequence. The reduction in responses
               paralleled the complexity of the sound sequences and could not
               be explained by short-term effects of clusters of deviants on
               succeeding standards. We conclude that neurons in auditory
               cortex are sensitive to the detailed structure of sound
               sequences over timescales of minutes.",
  journal   = "Neuron",
  publisher = "Elsevier Inc.",
  volume    =  76,
  number    =  3,
  pages     = "603--615",
  year      =  2012,
  issn      = "0896-6273",
  pmid      = "23141071",
  doi       = "10.1016/j.neuron.2012.08.025"
}

@ARTICLE{Garrido2008-sm,
  title    = "Dynamic causal modeling of the response to frequency deviants",
  author   = "Garrido, M I and Kilner, J M and Kiebel, S J and Friston, K J",
  abstract = "This article describes the use of dynamic causal modeling to test
              hypotheses about the genesis of evoked responses. Specifically,
              we consider the mismatch negativity (MMN), a well-characterized
              response to deviant sounds and one of the most widely studied
              evoked responses. There have been several mechanistic accounts of
              how the MMN might arise. It has been suggested that the MMN
              results from a comparison between sensory input and a memory
              trace of previous input, although others have argued that local
              adaptation, due to stimulus repetition, is sufficient to explain
              the MMN. Thus the precise mechanisms underlying the generation of
              the MMN remain unclear. This study tests some biologically
              plausible spatiotemporal dipole models that rest on changes in
              extrinsic top-down connections (that enable comparison) and
              intrinsic changes (that model adaptation). Dynamic causal
              modeling suggested that responses to deviants are best explained
              by changes in effective connectivity both within and between
              cortical sources in a hierarchical network of distributed
              sources. Our model comparison suggests that both adaptation and
              memory comparison operate in concert to produce the early (N1
              enhancement) and late (MMN) parts of the response to frequency
              deviants. We consider these mechanisms in the light of predictive
              coding and hierarchical inference in the brain.",
  journal  = "Journal of neurophysiology",
  volume   =  101,
  number   =  5,
  pages    = "2620--2631",
  year     =  2008,
  issn     = "0022-3077",
  pmid     = "19261714",
  doi      = "10.1152/jn.90291.2008"
}

@ARTICLE{Bendixen2009-dz,
  title    = "{I} heard that coming: Event-related potential evidence for
              stimulus-driven prediction in the auditory system",
  author   = "Bendixen, A and Schroger, E and Winkler, I",
  abstract = "The auditory system has been shown to detect predictability in a
              tone sequence, but does it use the extracted regularities for
              actually predicting the continuation of the sequence? The present
              study sought to find evidence for the generation of such
              predictions. Predictability was manipulated in an isochronous
              series of tones in which every other tone was a repetition of its
              predecessor. The existence of predictions was probed by
              occasionally omitting either the first (unpredictable) or the
              second (predictable) tone of a same-frequency tone pair.
              Event-related electrical brain activity elicited by the omission
              of an unpredictable tone differed from the response to the actual
              tone right from the tone onset. In contrast, early electrical
              brain activity elicited by the omission of a predictable tone was
              quite similar to the response to the actual tone. This suggests
              that the auditory system preactivates the neural circuits for
              expected input, using sequential predictions to specifically
              prepare for future acoustic events.",
  journal  = "Journal of Neuroscience",
  volume   =  29,
  number   =  26,
  pages    = "8447--8451",
  year     =  2009,
  doi      = "10.1523/JNEUROSCI.1493-09.2009"
}

@ARTICLE{Harrison2019-sb,
  title   = "Instantaneous consonance in the perception and composition of
             Western music",
  author  = "Harrison, Peter M C and Pearce, Marcus T",
  journal = "PsyArXiv",
  year    =  2019,
  doi     = "10.31234/osf.io/6jsug"
}

@ARTICLE{Broker2018-iu,
  title    = "Forget-me-some: General versus special purpose models in a
              hierarchical probabilistic task",
  author   = "Br{\"o}ker, Franziska and Bestmann, Sven and Dayan, Peter and
              Marshall, Louise",
  journal  = "PloS one",
  volume   =  13,
  number   =  10,
  pages    = "1--22",
  year     =  2018,
  keywords = "1st-order transition probabilities;exponential filter;forgetful
              observer model;hierarchical Gaussian filter",
  issn     = "1932-6203",
  doi      = "10.1371/journal.pone.0205974"
}

@ARTICLE{Mattar2016-dr,
  title    = "Varying timescales of stimulus integration unite neural
              adaptation and prototype formation",
  author   = "Mattar, Marcelo G and Kahn, David A and Thompson-Schill, Sharon L
              and Aguirre, Geoffrey K",
  abstract = "Human visual perception is both stable and adaptive. Perception
              of complex objects, such as faces, is shaped by the long-term
              average of experience as well as immediate, comparative context.
              Measurements of brain activity have demonstrated corresponding
              neural mechanisms, including norm-based responses reflective of
              stored prototype representations, and adaptation induced by the
              immediately preceding stimulus. Here, we consider the possibility
              that these apparently separate phenomena can arise from a single
              mechanism of sensory integration operating over varying
              timescales. We used fMRI to measure neural responses from the
              fusiform gyrus while subjects observed a rapid stream of face
              stimuli. Neural activity at this cortical site was best explained
              by the integration of sensory experience over multiple sequential
              stimuli, following a decaying-exponential weighting function.
              Although this neural activity could be mistaken for immediate
              neural adaptation or long-term, norm-based responses, it in fact
              reflected a timescale of integration intermediate to both. We
              then examined the timescale of sensory integration across the
              cortex. We found a gradient that ranged from rapid sensory
              integration in early visual areas, to long-term, stable
              representations in higher-level, ventral-temporal cortex. These
              findings were replicated with a new set of face stimuli and
              subjects. Our results suggest that a cascade of visual areas
              integrate sensory experience, transforming highly adaptable
              responses at early stages to stable representations at higher
              levels.",
  journal  = "Current biology: CB",
  volume   =  26,
  number   =  13,
  pages    = "1669--1676",
  year     =  2016,
  keywords = "exponential filter",
  issn     = "0960-9822",
  pmid     = "27321999",
  doi      = "10.1016/j.cub.2016.04.065"
}

@ARTICLE{Norton2017-sl,
  title    = "Suboptimal criterion learning in static and dynamic environments",
  author   = "Norton, Elyse H and Fleming, Stephen M and Daw, Nathaniel D and
              Landy, Michael S",
  abstract = "Humans often make decisions based on uncertain sensory
              information. Signal detection theory (SDT) describes detection
              and discrimination decisions as a comparison of stimulus ``
              strength '' to a fixed decision criterion. However, recent
              research suggests that current responses depend on the recent
              history of stimuli and previous responses, suggesting that the
              decision criterion is updated trial-by-trial. The mechanisms
              underpinning criterion setting remain unknown. Here, we examine
              how observers learn to set a decision criterion in an
              ori-entation-discrimination task under both static and dynamic
              conditions. To investigate mech-anisms underlying trial-by-trial
              criterion placement, we introduce a novel task in which
              participants explicitly set the criterion, and compare it to a
              more traditional discrimination task, allowing us to model this
              explicit indication of criterion dynamics. In each task, stimuli
              were ellipses with principal orientations drawn from two
              categories: Gaussian distributions with different means and equal
              variance. In the covert-criterion task, observers categorized a
              displayed ellipse. In the overt-criterion task, observers
              adjusted the orientation of a line that served as the
              discrimination criterion for a subsequently presented ellipse. We
              com-pared performance to the ideal Bayesian learner and several
              suboptimal models that varied in both computational and memory
              demands. Under static and dynamic conditions, we found that, in
              both tasks, observers used suboptimal learning rules. In most
              conditions, a model in which the recent history of past samples
              determines a belief about category means fit the data best for
              most observers and on average. Our results reveal dynamic
              adjustment of discrimination criterion, even after prolonged
              training, and indicate how decision criteria are updated over
              time.",
  journal  = "PLoS computational biology",
  volume   =  13,
  number   =  1,
  pages    = "1--28",
  year     =  2017,
  keywords = "decision criterion;exponential filter",
  issn     = "1553-734X, 1553-7358",
  pmid     = "28046006",
  doi      = "10.1371/journal.pcbi.1005304"
}

@ARTICLE{Meyniel2016-qa,
  title    = "Human inferences about sequences: A minimal transition
              probability model",
  author   = "Meyniel, Florent and Maheu, Maxime and Dehaene, Stanislas",
  abstract = "The brain constantly infers the causes of the inputs it receives
              and uses these inferences to generate statistical expectations
              about future observations. Experimental evidence for these
              expectations and their violations include explicit reports,
              sequential effects on reaction times, and mismatch or surprise
              signals recorded in electrophysiology and functional MRI. Here,
              we explore the hypothesis that the brain acts as a near-optimal
              inference device that constantly attempts to infer the
              time-varying matrix of transition probabilities between the
              stimuli it receives, even when those stimuli are in fact fully
              unpredictable. This parsimonious Bayesian model, with a single
              free parameter, accounts for a broad range of findings on
              surprise signals, sequential effects and the perception of
              randomness. Notably, it explains the pervasive asymmetry between
              repetitions and alternations encountered in those studies. Our
              analysis suggests that a neural machinery for inferring
              transition probabilities lies at the core of human sequence
              knowledge.",
  journal  = "PLoS computational biology",
  volume   =  12,
  number   =  12,
  pages    = "1--26",
  year     =  2016,
  keywords = "1st-order transition probabilities;Bayesian inference;exponential
              filter;model comparison;switching model",
  issn     = "1553-734X, 1553-7358",
  pmid     = "28030543",
  doi      = "10.1371/journal.pcbi.1005260"
}

@ARTICLE{Harrison2011-ff,
  title    = "Time scales of representation in the human brain: weighing past
              information to predict future events",
  author   = "Harrison, Lee",
  abstract = "The estimates that humans make of statistical dependencies in the
              environment and therefore their representation of uncertainty
              crucially depend on the integration of data over time. As such,
              the extent to which past events are used to represent uncertainty
              has been postulated to vary over the cortex. For example, primary
              visual cortex responds to rapid perturbations in the environment,
              while frontal cortices involved in executive control encode the
              longer term contexts within which these perturbations occur. Here
              we tested whether primary and executive regions can be
              distinguished by the number of past observations they represent.
              This was based on a decay-dependent model that weights past
              observations from a Markov process and Bayesian Model Selection
              to test the prediction that neuronal responses are characterized
              by different decay half-lives depending on location in the brain.
              We show distributions of brain responses for short and long term
              decay functions in primary and secondary visual and frontal
              cortices, respectively. We found that visual and parietal
              responses are released from the burden of the past, enabling an
              agile response to fluctuations in events as they unfold. In
              contrast, frontal regions are more concerned with average trends
              over longer time scales within which local variations are
              embedded. Specifically, we provide evidence for a temporal
              gradient for representing context within the prefrontal cortex
              and possibly beyond to include primary sensory and association
              areas.",
  journal  = "Frontiers in human neuroscience",
  volume   =  5,
  pages    = "1--8",
  year     =  2011,
  keywords = "Bayesian model selection; Bayesian spatial models; bayesian model
              selection; bayesian spatial models; functional MRI; functional
              mri; information theory; surprise; uncertainty;exponential filter",
  issn     = "1662-5161",
  pmid     = "21629858",
  doi      = "10.3389/fnhum.2011.00037"
}

@ARTICLE{Lieder2013-kd,
  title    = "Modelling trial-by-trial changes in the mismatch negativity",
  author   = "Lieder, Falk and Daunizeau, Jean and Garrido, Marta I and
              Friston, Karl J and Stephan, Klaas E",
  abstract = "The mismatch negativity (MMN) is a differential brain response to
              violations of learned regularities. It has been used to
              demonstrate that the brain learns the statistical structure of
              its environment and predicts future sensory inputs. However, the
              algorithmic nature of these computations and the underlying
              neurobiological implementation remain controversial. This article
              introduces a mathematical framework with which competing ideas
              about the computational quantities indexed by MMN responses can
              be formalized and tested against single-trial EEG data. This
              framework was applied to five major theories of the MMN,
              comparing their ability to explain trial-by-trial changes in MMN
              amplitude. Three of these theories (predictive coding, model
              adjustment, and novelty detection) were formalized by linking the
              MMN to different manifestations of the same computational
              mechanism: approximate Bayesian inference according to the
              free-energy principle. We thereby propose a unifying view on
              three distinct theories of the MMN. The relative plausibility of
              each theory was assessed against empirical single-trial MMN
              amplitudes acquired from eight healthy volunteers in a roving
              oddball experiment. Models based on the free-energy principle
              provided more plausible explanations of trial-by-trial changes in
              MMN amplitude than models representing the two more traditional
              theories (change detection and adaptation). Our results suggest
              that the MMN reflects approximate Bayesian learning of sensory
              regularities, and that the MMN-generating process adjusts a
              probabilistic model of the environment according to prediction
              errors.",
  journal  = "PLoS computational biology",
  volume   =  9,
  number   =  2,
  year     =  2013,
  issn     = "1553-734X",
  pmid     = "23436989",
  doi      = "10.1371/journal.pcbi.1002911"
}

@ARTICLE{Yu2008-ar,
  title    = "Sequential effects: Superstition or rational behavior?",
  author   = "Yu, Angela J and Cohen, Jonathan D",
  journal  = "Advances in neural information processing systems",
  volume   =  21,
  pages    = "1873--1880",
  year     =  2008,
  keywords = "approximate Bayes;exponential filter",
  issn     = "1049-5258"
}

@ARTICLE{Squires1976-ms,
  title    = "The effect of stimulus sequence on the waveform of the cortical
              event-related potential",
  author   = "Squires, K C and Wickens, C and Squires, N K and Donchin, E",
  journal  = "Science",
  volume   =  193,
  number   =  4258,
  pages    = "1142--1146",
  year     =  1976,
  keywords = "P300;alternation detection;exponential filter;long-term learning
              rate",
  issn     = "0036-8075",
  doi      = "10.1126/science.959831"
}

@ARTICLE{Jones2013-zx,
  title    = "Sequential effects in response time reveal learning mechanisms
              and event representations",
  author   = "Jones, Matt and Curran, Tim and Mozer, Michael C and Wilder,
              Matthew H",
  abstract = "Binary choice tasks, such as 2-alternative forced choice, show a
              complex yet consistent pattern of sequential effects, whereby
              responses and response times depend on the detailed pattern of
              prior stimuli going back at least 5 trials. We show this pattern
              is well explained by simultaneous incremental learning of 2
              simple statistics of the trial sequence: the base rate and the
              repetition rate. Both statistics are learned by the same basic
              associative mechanism, but they contribute different patterns of
              sequential effects because they entail different representations
              of the trial sequence. Subtler aspects of the data that are not
              explained by these 2 learning processes alone are explained by
              their interaction, via learning from joint error correction.
              Specifically, the cue-competition mechanism that has explained
              classic findings in animal learning (e.g., blocking) appears to
              operate on learning of sequence statistics. We also find that
              learning of the base rate and repetition rate are dissociated
              into response and stimulus processing, respectively, as indicated
              by event-related potentials, manipulations of stimulus
              discriminability, and reanalysis of past experiments that
              eliminated stimuli or prior responses. Thus, sequential effects
              in these tasks appear to be driven by learning the response base
              rate and the stimulus repetition rate. Connections are discussed
              between these findings and previous research attempting to
              separate stimulus- and response-based sequential effects, and
              research using sequential effects to determine mental
              representations. We conclude that sequential effects offer a
              powerful means for uncovering representations and learning
              mechanisms.",
  journal  = "Psychological review",
  volume   =  120,
  number   =  3,
  pages    = "628--666",
  year     =  2013,
  keywords = "event-related potential; incremental learning; sequential
              effects; two-alternative forced choice;binary choice
              task;learning base rate;learning repetition rate",
  issn     = "0033-295X, 1939-1471",
  pmid     = "23915086",
  doi      = "10.1037/a0033180"
}

@ARTICLE{Bendixen2007-lc,
  title    = "Regularity extraction and application in dynamic auditory
              stimulus sequences",
  author   = "Bendixen, Alexandra and Roeber, Urte and Schr{\"o}ger, Erich",
  abstract = "\& Traditional auditory oddball paradigms imply the brain's
              ability to encode regularities, but are not optimal for
              investi-gating the process of regularity establishment. In the
              present study, a dynamic experimental protocol was developed that
              sim-ulates a more realistic auditory environment with changing
              regularities. The dynamic sequences were included in a
              distrac-tion paradigm in order to study regularity extraction and
              ap-plication. Subjects discriminated the duration of sequentially
              presented tones. Without relevance to the task, tones repeated or
              changed in frequency according to a pattern unknown to the
              subject. When frequency repetitions were broken by a deviating
              tone, behavioral distraction (prolonged reaction time in the
              du-ration discrimination task) was elicited. Moreover,
              event-related brain potential components indicated deviance
              detection (mis-match negativity), involuntary attention switches
              (P3a), and at-tentional reorientation. These results suggest that
              regularities were extracted from the dynamic stimulation and were
              used to predict forthcoming stimuli. The effects were already
              observed with deviants occurring after as few as two
              presentations of a standard frequency, that is, violating a just
              emerging rule. Effects of regularity violation strengthened with
              the number of standard repetitions. Control stimuli comprising no
              regularity revealed that the observed effects were due to both
              improvements in stan-dard processing (benefits of regularity
              establishment) and de-teriorations in deviant processing (costs
              of regularity violation). Thus, regularities are exploited in two
              different ways: for an efficient processing of
              regularity-conforming events as well as for the detection of
              nonconforming, presumably important events. The present results
              underline the brain's flexibility in its adaptation to
              environmental demands. \&",
  journal  = "Journal of cognitive neuroscience",
  volume   =  19,
  number   =  10,
  pages    = "1664--1677",
  year     =  2007,
  keywords = "pattern detection",
  issn     = "0898-929X",
  pmid     = "18271740",
  doi      = "10.1162/jocn.2007.19.10.1664"
}

@ARTICLE{Nees2016-ff,
  title    = "Have we forgotten auditory sensory memory? Retention intervals in
              studies of nonverbal auditory working memory",
  author   = "Nees, Michael A",
  abstract = "Researchers have shown increased interest in mechanisms of
              working memory for nonverbal sounds such as music and
              environmental sounds. These studies often have used two-stimulus
              comparison tasks: two sounds separated by a brief retention
              interval (often 3 to 5 s) are compared, and a ``same'' or
              ``different'' judgment is recorded. Researchers seem to have
              assumed that sensory memory has a negligible impact on
              performance in auditory two-stimulus comparison tasks. This
              assumption is examined in detail in this comment. According to
              seminal texts and recent research reports, sensory memory
              persists in parallel with working memory for a period of time
              following hearing a stimulus and can influence behavioral
              responses on memory tasks. Unlike verbal working memory studies
              that use serial recall tasks, research paradigms for exploring
              nonverbal working memory---especially two-stimulus comparison
              tasks---may not be differentiating working memory from sensory
              memory processes in analyses of behavioral responses, because
              retention interval durations have not excluded the possibility
              that the sensory memory trace drives task performance. This
              conflation of different constructs may be one contributor to
              discrepant research findings and the resulting proliferation of
              theoretical conjectures regarding mechanisms of working memory
              for nonverbal sounds.",
  journal  = "Frontiers in psychology",
  volume   =  7,
  pages    = "1--6",
  year     =  2016,
  keywords = "Auditory cognition; Auditory sensory memory; Music cognition;
              Nonverbal sounds; Working memory;echoic memory",
  issn     = "1664-1078",
  pmid     = "27994565",
  doi      = "10.3389/fpsyg.2016.01892"
}

@INCOLLECTION{Lartillot2008-fl,
  title     = "A Matlab toolbox for Music Information Retrieval",
  booktitle = "Data analysis, machine learning and applications",
  author    = "Lartillot, Olivier and Toiviainen, Petri and Eerola, Tuomas",
  editor    = "Preisach, C and Burkhardt, H and Schmidt-Thieme, L and Decker, R",
  publisher = "Springer",
  pages     = "261--268",
  year      =  2008,
  address   = "Berlin, Germany"
}

@ARTICLE{Breiman2001-st,
  title    = "Random forests",
  author   = "Breiman, Leo",
  journal  = "Machine learning",
  volume   =  45,
  number   =  1,
  pages    = "5--32",
  year     =  2001,
  keywords = "classification; ensemble; regression",
  issn     = "0885-6125",
  arxivid  = "10.1023/A:1010933404324"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Arnal2015-dx,
  title    = "Human screams occupy a privileged niche in the communication
              soundscape",
  author   = "Arnal, Luc H and Flinker, Adeen and Kleinschmidt, Andreas and
              Giraud, Anne Lise and Poeppel, David",
  abstract = "Screaming is arguably one of the most relevant communication
              signals for survival in humans. Despite their practical relevance
              and their theoretical significance as innate [1] and virtually
              universal [2, 3] vocalizations, what makes screams a unique
              signal and how they are processed is not known. Here, we use
              acoustic analyses, psychophysical experiments, and neuroimaging
              to isolate those features that confer to screams their alarming
              nature, and we track their processing in the human brain. Using
              the modulation power spectrum (MPS [4, 5]), a recently developed,
              neurally informed characterization of sounds, we demonstrate that
              human screams cluster within restricted portion of the acoustic
              space (between ∼30 and 150 Hz modulation rates) that corresponds
              to a well-known perceptual attribute, roughness. In contrast to
              the received view that roughness is irrelevant for communication
              [6], our data reveal that the acoustic space occupied by the
              rough vocal regime is segregated from other signals, including
              speech, a pre-requisite to avoid false alarms in normal vocal
              communication. We show that roughness is present in natural alarm
              signals as well as in artificial alarms and that the presence of
              roughness in sounds boosts their detection in various tasks.
              Using fMRI, we show that acoustic roughness engages subcortical
              structures critical to rapidly appraise danger. Altogether, these
              data demonstrate that screams occupy a privileged acoustic niche
              that, being separated from other communication signals, ensures
              their biological and ultimately social efficiency.",
  journal  = "Current biology: CB",
  volume   =  25,
  number   =  15,
  pages    = "2051--2056",
  year     =  2015,
  issn     = "0960-9822",
  doi      = "10.1016/j.cub.2015.06.043"
}

@ARTICLE{Padilla2012-mg,
  title    = "Correlation attenuation due to measurement error",
  author   = "Padilla, Miguel A and Veprinsky, Anna",
  abstract = "Issues with correlation attenuation due to measurement error are
              well documented. More than a century ago, Spearman proposed a
              correction for attenuation. However, this correction has seen
              very little use since it can potentially inflate the true
              correlation beyond one. In addition, very little confidence
              interval (CI) research has been done for correction for
              attenuation. In the present study, the authors propose a
              bootstrap procedure for estimating the deattenuated correlation
              and corresponding CIs. The authors use Monte Carlo simulations to
              generate data under certain conditions and assess the performance
              of the bootstrapped deattenuated correlation. The authors
              investigate for bias and 95\% CI coverage. Results indicate that
              the bootstrap deattenuated correlation provided adequate
              percentile CI coverage in all but three conditions. The
              bias-corrected and accelerated CI, however, provided adequate
              coverage under all simulation conditions.",
  journal  = "Educational and psychological measurement",
  volume   =  72,
  number   =  5,
  pages    = "827--846",
  year     =  2012,
  issn     = "0013-1644",
  doi      = "10.1177/0013164412443963"
}

@ARTICLE{Muchinsky1996-zn,
  title   = "The correction for attenuation",
  author  = "Muchinsky, Paul M",
  journal = "Educational and psychological measurement",
  volume  =  56,
  number  =  1,
  pages   = "63--75",
  year    =  1996,
  issn    = "0013-1644",
  doi     = "10.1177/0013164496056001004"
}

@BOOK{Forte1973-dd,
  title     = "The structure of atonal music",
  author    = "Forte, Allen",
  publisher = "Yale University Press",
  year      =  1973,
  address   = "New Haven, CT"
}

@ARTICLE{Frank2010-co,
  title   = "Modeling human performance in statistical word segmentation",
  author  = "Frank, Michael C and Goldwater, Sharon and Griffiths, Thomas L and
             Tenenbaum, Joshua B",
  journal = "Cognition",
  volume  =  117,
  number  =  2,
  pages   = "107--125",
  year    =  2010,
  issn    = "0010-0277",
  doi     = "10.1016/j.cognition.2010.07.005"
}

@ARTICLE{OReilly2013-me,
  title    = "Making predictions in a changing world -inference, uncertainty,
              and learning",
  author   = "O'Reilly, Jill X",
  abstract = "To function effectively, brains need to make predictions about
              their environment based on past experience, i.e., they need to
              learn about their environment. The algorithms by which learning
              occurs are of interest to neuroscientists, both in their own
              right (because they exist in the brain) and as a tool to model
              participants' incomplete knowledge of task parameters and hence,
              to better understand their behavior. This review focusses on a
              particular challenge for learning algorithms-how to match the
              rate at which they learn to the rate of change in the
              environment, so that they use as much observed data as possible
              whilst disregarding irrelevant, old observations. To do this
              algorithms must evaluate whether the environment is changing. We
              discuss the concepts of likelihood, priors and transition
              functions, and how these relate to change detection. We review
              expected and estimation uncertainty, and how these relate to
              change detection and learning rate. Finally, we consider the
              neural correlates of uncertainty and learning. We argue that the
              neural correlates of uncertainty bear a resemblance to neural
              systems that are active when agents actively explore their
              environments, suggesting that the mechanisms by which the rate of
              learning is set may be subject to top down control (in
              circumstances when agents actively seek new information) as well
              as bottom up control (by observations that imply change in the
              environment).",
  journal  = "Frontiers in neuroscience",
  volume   =  7,
  pages    = "1--10",
  year     =  2013,
  keywords = "Bayes theorem; Change detection; Exploratory behavior; Learning;
              Modeling; Uncertainty;Bayesian inference;exponential
              filter;switching model",
  issn     = "1662-4548, 1662-453X",
  pmid     = "23785310",
  doi      = "10.3389/fnins.2013.00105"
}

@ARTICLE{Eerola2018-if,
  title    = "Shared periodic performer movements coordinate interactions in
              duo improvisations",
  author   = "Eerola, Tuomas and Jakubowski, Kelly and Moran, Nikki and Keller,
              Peter E and Clayton, Martin",
  abstract = "\copyright{} 2018 The Authors. Human interaction involves the
              exchange of temporally coordinated, multimodal cues. Our work
              focused on interaction in the visual domain, using music
              performance as a case for analysis due to its temporally diverse
              and hierarchical structures. We made use of two improvising duo
              datasets--- (i) performances of a jazz standard with a regular
              pulse and (ii) non-pulsed, free improvizations---to investigate
              whether human judgements of moments of interaction between
              co-performers are influenced by body movement coordination at
              multiple timescales. Bouts of interaction in the performances
              were manually annotated by experts and the performers' movements
              were quantified using computer vision techniques. The annotated
              interaction bouts were then predicted using several quantitative
              movement and audio features. Over 80\% of the interaction bouts
              were successfully predicted by a broadband measure of the energy
              of the cross-wavelet transform of the co-performers' movements in
              non-pulsed duos. A more complex model, with multiple predictors
              that captured more specific, interacting features of the
              movements, was needed to explain a significant amount of variance
              in the pulsed duos. The methods developed here have key
              implications for future work on measuring visual coordination in
              musical ensemble performances, and can be easily adapted to other
              musical contexts, ensemble types and traditions.",
  journal  = "Royal Society Open Science",
  volume   =  5,
  number   =  2,
  year     =  2018,
  keywords = "Coordination; Entrainment; Interaction; Music; Performance;
              Wavelet;Huw Cheston",
  issn     = "2054-5703",
  doi      = "10.1098/rsos.171520"
}

@ARTICLE{Jakubowski2017-ri,
  title    = "Extracting Coarse Body Movements from Video in Music Performance:
              A Comparison of Automated Computer Vision Techniques with Motion
              Capture Data",
  author   = "Jakubowski, Kelly and Eerola, Tuomas and Alborno, Paolo and
              Volpe, Gualtiero and Camurri, Antonio and Clayton, Martin",
  abstract = "The measurement and tracking of body movement within musical
              performances can provide valuable sources of data for studying
              interpersonal interaction and coordination between musicians. The
              continued development of tools to extract such data from video
              recordings will offer new opportunities to research musical
              movement across a diverse range of settings, including field
              research and other ecological contexts in which the
              implementation of complex motion capture (MoCap) systems is not
              feasible or affordable. Such work might also make use of the
              multitude of video recordings of musical perfor- mances that are
              already available to researchers. This study made use of such
              existing data, specifically, three video datasets of ensemble
              performances from different genres, settings, and instrumentation
              (a pop piano duo, three jazz duos, and a string quartet). Three
              different computer vision techniques were applied to these video
              datasets---frame differencing, optical flow, and kernelized
              correlation filters (KCF)---with the aim of quan- tifying and
              tracking movements of the individual performers. All three
              computer vision techniques exhibited high correlations with MoCap
              data collected from the same musical performances, with median
              correlation (Pearson's r) values of 0.75--0.94. The techniques
              that track movement in two dimensions (optical flow and KCF)
              provided more accu- rate measures of movement than a technique
              that provides a single estimate of overall movement change by
              frame for each performer (frame differencing). Measurements of
              performer's movements were also more accurate when the computer
              vision techniques were applied to more narrowly defined regions
              of interest (head) than when the same techniques were applied to
              larger regions (entire upper body, above the chest, or waist).
              Some",
  journal  = "Frontiers in Digital Humanities",
  volume   =  4,
  number   = "April",
  pages    = "1--10",
  year     =  2017,
  keywords = "computer vision; motion tracking; movement; movement, motion
              tracking, music performance, musi; music performance; musical
              ensemble coordination;Huw Cheston",
  issn     = "2297-2668",
  pmid     = "9216127",
  doi      = "10.3389/fdigh.2017.00009"
}

@ARTICLE{Malmberg1918-ay,
  title   = "The perception of consonance and dissonance",
  author  = "Malmberg, C F",
  journal = "Psychological Monographs: General and Applied",
  volume  =  25,
  number  =  2,
  pages   = "93--133",
  year    =  1918
}

@ARTICLE{Frieler2018-ey,
  title    = "{C} {HA} {L} {L} {E} {N} {G} {E} {S} A {N} {D} {O} {P} {P} {O}
              {RT} {U} {N} {I} {T} {I} {E} {S} {O} {F} {P} {R} {E} {D} {I} {C}
              {T} {I} {N} {G} {M} {U} {S} {I} {C} A {L}",
  author   = "Frieler, Klaus",
  pages    = "217--242",
  year     =  2018,
  keywords = "emotion expression; expert ratings; extraction; feature; mir;
              music information retrieval; predictive"
}

@ARTICLE{Nobili2003-lr,
  title   = "Otoacoustic emissions from residual oscillations of the cochlear
             basilar membrane in a human ear model",
  author  = "Nobili, R and Vete{\v s}n{\'\i}k, A and Turicchia, L and Mammano,
             F",
  journal = "Journal of the Association for Research in Otolaryngology: JARO",
  volume  =  4,
  pages   = "478--494",
  year    =  2003,
  issn    = "1525-3961"
}

@UNPUBLISHED{Meddis2011-mw,
  title  = "Matlab auditory periphery ({MAP}) Model technical description",
  author = "Meddis, Ray",
  year   =  2011
}

@ARTICLE{Koelsch2019-pj,
  title   = "Predictive processes and the peculiar case of music",
  author  = "Koelsch, Stefan and Vuust, Peter and Friston, Karl",
  journal = "Trends in cognitive sciences",
  volume  =  23,
  number  =  1,
  pages   = "63--77",
  year    =  2019,
  issn    = "1364-6613",
  doi     = "10.1016/j.tics.2018.10.006"
}

@ARTICLE{Van_Immerseel1992-rm,
  title   = "Pitch and voiced/unvoiced determination with an auditory model",
  author  = "Van Immerseel, L and Martens, J",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  91,
  number  =  6,
  pages   = "3511--3526",
  year    =  1992,
  issn    = "0001-4966"
}

@ARTICLE{Tabas2017-wc,
  title    = "Early processing of consonance and dissonance in human auditory
              cortex",
  author   = "Tabas, Alejandro and Andermann, Martin and Sebold, Valeria and
              Riedel, Helmut and Balaguer-Ballester, Emili and Rupp, Andr{\'e}",
  abstract = "Pitch is the perceptual correlate of sound's periodicity and a
              fundamental property of the auditory sensation. The interaction
              of two or more pitches gives rise to a sensation that can be
              characterized by its degree of consonance or dissonance. In the
              current study, we investigated the neuromagnetic representations
              of consonant and dissonant musical dyads using a new model of
              cortical activity, in an effort to assess the possible
              involvement of pitch-specific neural mechanisms in consonance
              processing at early cortical stages. In the first step of the
              study, we developed a novel model of cortical pitch processing
              designed to explain the morphology of the pitch onset response
              (POR), a pitch-specific subcomponent of the auditory evoked N100
              component in the human auditory cortex. The model explains the
              neural mechanisms underlying the generation of the POR and
              quantitatively accounts for the relation between its peak latency
              and the perceived pitch. Next, we applied magnetoencephalography
              (MEG) to record the POR as elicited by six consonant and
              dissonant dyads. The peak latency of the POR was strongly
              modulated by the degree of consonance within the stimuli;
              specifically, the most dissonant dyad exhibited a POR with a
              latency that was about 30ms longer than that of the most
              consonant dyad, an effect that greatly exceeds the expected
              latency difference induced by a single pitch sound. Our model was
              able to predict the POR latency pattern observed in the
              neuromagnetic data, and to generalize this prediction to
              additional dyads. These results indicate that the neural
              mechanisms responsible for pitch processing exhibit an intrinsic
              differential response to concurrent consonant and dissonant pitch
              combinations, suggesting that the perception of consonance and
              dissonance might be an emergent property of the pitch processing
              system in human auditory cortex.",
  year     =  2017,
  arxivid  = "1711.10991"
}

@ARTICLE{Camacho2008-ro,
  title    = "A sawtooth waveform inspired pitch estimator for speech and music",
  author   = "Camacho, Arturo and Harris, John G",
  abstract = "A sawtooth waveform inspired pitch estimator (SWIPE) has been
              developed for speech and music. SWIPE estimates the pitch as the
              fundamental frequency of the sawtooth waveform whose spectrum
              best matches the spectrum of the input signal. The comparison of
              the spectra is done by computing a normalized inner product
              between the spectrum of the signal and a modified cosine. The
              size of the analysis window is chosen appropriately to make the
              width of the main lobes of the spectrum match the width of the
              positive lobes of the cosine. SWIPE('), a variation of SWIPE,
              utilizes only the first and prime harmonics of the signal, which
              significantly reduces subharmonic errors commonly found in other
              pitch estimation algorithms. The authors' tests indicate that
              SWIPE and SWIPE(') performed better on two spoken speech and one
              disordered voice database and one musical instrument database
              consisting of single notes performed at a variety of pitches.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  124,
  number   =  3,
  pages    = "1638--1652",
  year     =  2008,
  issn     = "0001-4966",
  doi      = "10.1121/1.2951592"
}

@ARTICLE{Pressnitzer1999-yx,
  title   = "Two phase effects in roughness perception",
  author  = "Pressnitzer, D and McAdams, S",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  105,
  pages   = "2773--2782",
  year    =  1999,
  issn    = "0001-4966"
}

@ARTICLE{Langner1992-mr,
  title    = "Periodicity coding in the auditory system",
  author   = "Langner, Gerald",
  abstract = "Periodic envelope fluctuations are a common feature of acoustic
              communication signals, and as a result of physical constraints,
              many natural, nonliving sound sources also produce periodic
              waveforms. In human speech and music, for example, periodic
              sounds are abundant and reach a high degree of complexity. Under
              noisy conditions these amplitude fluctuations may be reliable
              indicators of a common sound source responsible for the
              activation of different frequency channels of the basilar
              membrane. To make use of this information, a central periodicity
              analysis is necessary in addition to the peripheral frequency
              analysis. The present review summarizes our present knowledge
              about representation and processing of periodic signals, from the
              cochlea to the cortex in mammals, and in homologous or analogous
              anatomical structures as far as these exist and have been
              investigated in other animals. The first sections describe
              important physical and perceptual attributes of periodic signals,
              and the last sections address some theoretical issues.
              \copyright{} 1992.",
  journal  = "Hearing research",
  volume   =  60,
  number   =  2,
  pages    = "115--142",
  year     =  1992,
  keywords = "Acoustic processing; Neuronal mechanisms; Pitch; Temporal
              analysis",
  issn     = "0378-5955",
  pmid     = "1639723",
  doi      = "10.1016/0378-5955(92)90015-F"
}

@ARTICLE{Huang2016-cd,
  title    = "A neuronal network model for pitch selectivity and representation",
  author   = "Huang, Chengcheng and Rinzel, John",
  abstract = "Pitch is a perceptual correlate of periodicity. Sounds with
              distinct spectra can elicit the same pitch. Despite the
              importance of pitch perception, understanding the cellular
              mechanism of pitch perception is still a major challenge and a
              mechanistic model of pitch is lacking. A multi-stage neuronal
              network model is developed for pitch frequency estimation using
              biophysically-based, high-resolution coincidence detector
              neurons. The neuronal units respond only to highly coincident
              input among convergent auditory nerve fibers across frequency
              channels. Their selectivity for only very fast rising slopes of
              convergent input enables these slope-detectors to distinguish the
              most prominent coincidences in multi-peaked input time courses.
              Pitch can then be estimated from the first-order interspike
              intervals of the slope-detectors. The regular firing pattern of
              the slope-detector neurons are similar for sounds sharing the
              same pitch despite the distinct timbres. The decoded pitch
              strengths also correlate well with the salience of pitch
              perception as reported by human listeners. Therefore, our model
              can serve as a neural representation for pitch. Our model
              performs successfully in estimating the pitch of missing
              fundamental complexes and reproducing the pitch variation with
              respect to the frequency shift of inharmonic complexes. It also
              accounts for the phase sensitivity of pitch perception in the
              cases of Schroeder phase, alternating phase and random phase
              relationships. Moreover, our model can also be applied to
              stochastic sound stimuli, iterated-ripple-noise, and account for
              their multiple pitch perceptions.",
  journal  = "Frontiers in computational neuroscience",
  volume   =  10,
  year     =  2016,
  keywords = "Schroeder phase; alternating phase; inharmonics;
              iterated-ripple-noise; missing fundamental; pitch; schroeder
              phase; slope-detector",
  issn     = "1662-5188",
  doi      = "10.3389/fncom.2016.00057"
}

@ARTICLE{Meddis2006-vo,
  title    = "Virtual pitch in a computational physiological model",
  author   = "Meddis, Ray and O'Mard, Lowel P",
  abstract = "A computational model of nervous activity in the auditory nerve,
              cochlear nucleus, and inferior colliculus is presented and
              evaluated in terms of its ability to simulate
              psychophysically-measured pitch perception. The model has a
              similar architecture to previous autocorrelation models except
              that the mathematical operations of autocorrelation are replaced
              by the combined action of thousands of physiologically plausible
              neuronal components. The evaluation employs pitch stimuli
              including complex tones with a missing fundamental frequency,
              tones with alternating phase, inharmonic tones with equally
              spaced frequencies and iterated rippled noise. Particular
              attention is paid to differences in response to resolved and
              unresolved component harmonics. The results indicate that the
              model is able to simulate qualitatively the related
              pitch-perceptions. This physiological model is similar in many
              respects to autocorrelation models of pitch and the success of
              the evaluations suggests that autocorrelation models may, after
              all, be physiologically plausible.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  120,
  number   =  6,
  pages    = "3861--3869",
  year     =  2006,
  issn     = "0001-4966",
  pmid     = "17225413",
  doi      = "10.1121/1.2372595"
}

@ARTICLE{Langner2005-zw,
  title    = "Neuronal mechanisms underlying the perception of pitch and
              harmony",
  author   = "Langner, Gerald",
  abstract = "Temporal processing of periodic acoustic signals in the auditory
              brain stem provides an explanation for pitch perception and the
              natural preference of our hearing system for harmonic
              relationships in music. Experimental evidence is reviewed for a
              corresponding neuronal model of correlation analysis and the
              spatial representation of pitch information along the second
              neural axis of the auditory system.",
  journal  = "Annals of the New York Academy of Sciences",
  volume   =  1060,
  pages    = "50--52",
  year     =  2005,
  issn     = "0077-8923",
  pmid     = "16597748",
  doi      = "10.1196/annals.1360.043"
}

@INPROCEEDINGS{Harma1999-yu,
  title     = "{HUTear} -- a free Matlab toolbox for modeling of human auditory
               system",
  booktitle = "Proceedings of the 1999 {MATLAB} {DSP} Conference",
  author    = "H{\"a}rm{\"a}, Aki and Palom{\"a}ki, Kalle",
  year      =  1999,
  address   = "Espoo, Finland"
}

@ARTICLE{Bonnard2016-kq,
  title    = "Harmonic fusion and pitch affinity: Is there a direct link?",
  author   = "Bonnard, Damien and Dauman, Ren{\'e} and Semal, Catherine and
              Demany, Laurent",
  abstract = "Simultaneous pure tones approximately one octave apart tend to be
              fused perceptually and to evoke a single pitch sensation.
              Besides, sequentially presented pure tones show a subjective
              ``affinity'' or similarity in pitch when their frequency ratio is
              close to one octave. The aim of the study reported here was to
              determine if these two perceptual phenomena are directly related.
              Each stimulus was a triplet of simultaneous or successive pure
              tones forming frequency ratios varying across stimuli between
              0.96 and 1.04 octaves. The tones were presented at a low
              sensation level (15 dB) within broadband threshold-equalizing
              noise, in order to prevent them from interacting in the cochlea
              when they were simultaneous. A large set of stimulus comparisons
              made by 18 listeners indicated that: (1) when the tones were
              simultaneous, maximal fusion was obtained for a mean frequency
              ratio deviating by less than 0.2\% from one octave, and fusion
              decreased less rapidly above this frequency ratio than below it;
              (2) when the tones were presented successively, maximal pitch
              affinity was obtained for a mean frequency ratio significantly
              larger than one octave, and pitch affinity decreased more rapidly
              above this frequency ratio than below it. The differences between
              the results obtained for simultaneous and successive tones
              suggest that harmonic fusion and pitch affinity are unrelated
              phenomena.",
  journal  = "Hearing research",
  volume   =  333,
  pages    = "247--254",
  year     =  2016,
  keywords = "Frequency ratio; Fusion; Harmonicity; Musical interval; Octave;
              Pitch",
  issn     = "0378-5955, 1878-5891",
  pmid     = "26341475",
  doi      = "10.1016/j.heares.2015.08.015"
}

@INCOLLECTION{Terhardt1982-en,
  title     = "Die psychoakustischen Grundlagen der musikalischen
               Akkordgrundt{\"o}ne und deren algorithmische Bestimmung",
  booktitle = "Tiefenstruktur",
  author    = "Terhardt, E",
  editor    = "Dahlhaus, Carl and Krause, M",
  publisher = "Technical University of Berlin",
  year      =  1982,
  address   = "Berlin, Germany"
}

@INPROCEEDINGS{Stolzenburg2012-wl,
  title     = "Harmony perception by periodicity and granularity",
  booktitle = "Proceedings of the 12th International Conference on Music
               Perception and Cognition ({ICMPC}) and 8th Triennial Conference
               of the European Society for the Cognitive Sciences of Music
               ({ESCOM})",
  author    = "Stolzenburg, Frieder",
  pages     = "958--959",
  year      =  2012,
  address   = "Thessaloniki, Greece"
}

@ARTICLE{Olsen2018-kg,
  title    = "Listener expertise enhances intelligibility of vocalizations in
              death metal music",
  author   = "Olsen, Kirk N and Thompson, William Forde and Giblin, Iain",
  journal  = "Music perception",
  volume   =  35,
  number   =  5,
  pages    = "527--539",
  year     =  2018,
  keywords = "auditory perception; emotion; expertise; lyrics; perceptual
              learning",
  issn     = "0730-7829",
  doi      = "10.1525/MP.2018.35.5.527"
}

@ARTICLE{Zajonc2001-rw,
  title    = "Mere exposure: A gateway to the subliminal",
  author   = "Zajonc, R B",
  journal  = "Current directions in psychological science",
  volume   =  10,
  number   =  6,
  pages    = "224--228",
  year     =  2001,
  keywords = "affect; classical conditioning; mere expo-; preference;
              preferences constitute one of; sure; the",
  issn     = "0963-7214"
}

@ARTICLE{Levelt1966-rj,
  title   = "Triadic comparisons of musical intervals",
  author  = "Levelt, W J M and van de Geer, J P and Plomp, R",
  journal = "The British journal of mathematical and statistical psychology",
  volume  =  19,
  number  =  2,
  pages   = "163--179",
  year    =  1966,
  issn    = "0007-1102"
}

@BOOK{Euler1739-vj,
  title     = "Tentamen novae theoria musicae",
  author    = "Euler, Leonhard",
  publisher = "Academiae Scientiarum",
  year      =  1739,
  address   = "Saint Petersburg, Russia"
}

@ARTICLE{Wever1940-wi,
  title   = "The origin of combination tones",
  author  = "Wever, Ernest Glen and Bray, Charles W and Lawrence, Merle",
  journal = "Journal of experimental psychology",
  volume  =  27,
  number  =  3,
  pages   = "217--226",
  year    =  1940,
  issn    = "0022-1015"
}

@ARTICLE{Smoorenburg1972-pa,
  title   = "Combination tones and their origin",
  author  = "Smoorenburg, Guido F",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  52,
  number  =  2,
  pages   = "615--632",
  year    =  1972,
  issn    = "0001-4966",
  doi     = "10.1121/1.1913152"
}

@BOOK{Hindemith1945-cz,
  title     = "The craft of musical composition",
  author    = "Hindemith, Paul",
  abstract  = "English translation by Arthur Mendel",
  publisher = "Associated Music Publishers",
  year      =  1945,
  address   = "New York, NY"
}

@INPROCEEDINGS{Zioga2018-dr,
  title     = "The effect of visual input on the neural signatures of melodic
               sequence learning",
  booktitle = "Neuroscience 2018",
  author    = "Zioga, I and Harrison, P M C and Pearce, M T and Bhattacharya, J
               and Luft, C D B",
  year      =  2018
}

@ARTICLE{Fletcher1924-ke,
  title    = "The physical criterion for determining the pitch of a musical
              tone",
  author   = "Fletcher, Harvey",
  abstract = "Abstract Effects upon pitch and quality of musical sounds of
              eliminating certain component \{frequencies.---A\} high quality
              telephone system was used to reproduce musical sounds from the
              voice, the piano, the violin, the clarinet and the organ without
              any appreciable ...",
  journal  = "Physical Review",
  volume   =  23,
  number   =  3,
  pages    = "427--437",
  year     =  1924,
  issn     = "0031-899X",
  doi      = "10.1103/PhysRev.23.427"
}

@BOOK{Stumpf1890-kt,
  title     = "Tonpsychologie",
  author    = "Stumpf, C",
  publisher = "Verlag S. Hirzel",
  year      =  1890,
  address   = "Leipzig, Germany"
}

@ARTICLE{Stumpf1898-nc,
  title   = "Konsonanz und dissonanz",
  author  = "Stumpf, C",
  journal = "Beitr{\"a}ge zur Akustik und Musikwissenschaft",
  volume  =  1,
  pages   = "1--108",
  year    =  1898
}

@ARTICLE{Press2018-fe,
  title  = "The Petroushka Chord : A Perceptual Investigation Author ( s ):
            Carol {L} . Krumhansl and Mark A . Schmuckler Published by :
            University of California Press Stable {URL} :
            https://www.jstor.org/stable/40285359 The Petroushka Chord : A
            Perceptual In",
  author = "Press, California",
  volume =  4,
  number =  2,
  pages  = "153--184",
  year   =  2018
}

@ARTICLE{Ayotte2002-ax,
  title    = "Congenital amusia: A group study of adults afflicted with a
              music-specific disorder",
  author   = "Ayotte, Julie and Peretz, Isabelle and Hyde, Krista",
  abstract = "The condition of congenital amusia, commonly known as
              tone-deafness, has been described for more than a century, but
              has received little empirical attention. In the present study, a
              research effort has been made to document in detail the
              behavioural manifestations of congenital amusia. A group of 11
              adults, fitting stringent criteria of musical disabilities, were
              examined in a series of tests originally designed to assess the
              presence and specificity of musical disorders in brain-damaged
              patients. The results show that congenital amusia is related to
              severe deficiencies in processing pitch variations. The deficit
              extends to impairments in music memory and recognition as well as
              in singing and the ability to tap in time to music.
              Interestingly, the disorder appears specific to the musical
              domain. Congenital amusical individuals process and recognize
              speech, including speech prosody, common environmental sounds and
              human voices, as well as control subjects. Thus, the present
              study convincingly demonstrates the existence of congenital
              amusia as a new class of learning disabilities that affect
              musical abilities.",
  journal  = "Brain: a journal of neurology",
  volume   =  125,
  number   =  2,
  pages    = "238--251",
  year     =  2002,
  keywords = "auditory disorder; congenital amusia; learning disabilities;
              music; tone-deafness",
  issn     = "0006-8950",
  doi      = "10.1093/brain/awf028"
}

@ARTICLE{Cramer1958-ri,
  title    = "Creation of pitch through binaural interaction",
  author   = "Cramer, Elliot M and Huggins, W H",
  abstract = "This paper is an investigation of the phenomenon which was
              observed by Huggins in 1953. Huggins found that a binaural
              stimulus gives a fairly clear perception of pitch although the
              separate stimuli to the two ears give no such perception. The
              basic stimulus consits of white noise introduced into one ear
              while the same white noise, phase transformed in a narrow band of
              frequencies, is introduced into the other ear. A practiced
              subject listening to theis stimulus reports a faint pitch quality
              which is judged to sound about the same as narrow-band filtered
              noise. A forced-choice technique was used in which six subjects
              were asked to judge the direction of the pitch change when the
              frequency band over which the phase shift occurs was changed. The
              control consisted of the same stimulus presented to the two ears.
              Data are presented indicating the relationship between the
              percent of correct judgments and the three experimental
              variables, frequency, band width, and intensity level.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  30,
  number   =  5,
  pages    = "413--417",
  year     =  1958,
  issn     = "0001-4966",
  doi      = "10.1121/1.1909628"
}

@ARTICLE{Houtsma1972-od,
  title    = "The central origin of the pitch of complex tones: Evidence from
              musical interval recognition",
  author   = "Houtsma, A J M and Goldstein, J L",
  abstract = "Stimuli comprising two randomly chosen successive upper
              harmonics\textbackslashnwere presented both monotically and
              dichotically. Subjects could\textbackslashnrecognise melodies
              equally well with both modes of presentation
              (if\textbackslashnallowance is made for the influence of
              combination tones). The authors\textbackslashnsuggest that all
              monotic stimuli for which identification
              performance\textbackslashnwas better than chance either consisted
              of behaviorally resolveable\textbackslashntones, or generated
              such tones as combination tones. They did
              not,\textbackslashnhowever, measure the ability of their own
              observers in analysing\textbackslashnpartials.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  51,
  number   =  2,
  pages    = "520--529",
  year     =  1972,
  issn     = "0001-4966",
  doi      = "10.1121/1.1912873"
}

@ARTICLE{Vyciniene2002-gy,
  title   = "Lithuanian Schwebungsdiaphonie and its south and east European
             parallels",
  author  = "Vy{\v c}inien{\.e}, Daiva",
  journal = "The World of Music",
  volume  =  44,
  number  =  3,
  pages   = "55--57",
  year    =  2002
}

@ARTICLE{Crowder1991-mz,
  title    = "Perception of the major/minor distinction: V. Preferences among
              infants",
  author   = "Crowder, Robert G and Reznick, J Steven and Rosenkrantz, Stacey L",
  abstract = "Six-month-old infants expressed musical preferences by choosing
              one of two directional targets to look at, one of which produced
              a major chord and the other a minor chord. Over repeated testing
              in this way, no reliable preference for either harmony was
              expressed. However, a comparable choice between consonant and
              dissonant chords produced reliable preference for consonant
              harmonies.",
  journal  = "Bulletin of the Psychonomic Society",
  volume   =  29,
  number   =  3,
  pages    = "187--188",
  year     =  1991,
  issn     = "0090-5054",
  doi      = "10.3758/BF03335230"
}

@ARTICLE{Virtala2013-qd,
  title    = "Newborn infants' auditory system is sensitive to Western music
              chord categories",
  author   = "Virtala, Paula and Huotilainen, Minna and Partanen, Eino and
              Fellman, Vineta and Tervaniemi, Mari",
  abstract = "Neural encoding of abstract rules in the audition of newborn
              infants has been recently demonstrated in several studies using
              event-related potentials (ERPs). In the present study the neural
              encoding of Western music chords was investigated in newborn
              infants. Using ERPs, we examined whether the categorizations of
              major vs. minor and consonance vs. dissonance are present at the
              level of the change-related mismatch response (MMR). Using an
              oddball paradigm, root minor, dissonant and inverted major chords
              were presented in a context of consonant root major chords. The
              chords were transposed to several different frequency levels, so
              that the deviant chords did not include a physically deviant
              frequency that could result in an MMR without categorization. The
              results show that the newborn infants were sensitive to both
              dissonant and minor chords but not to inverted major chords in
              the context of consonant root major chords. While the dissonant
              chords elicited a large positive MMR, the minor chords elicited a
              negative MMR. This indicates that the two categories were
              processed differently. The results suggest newborn infants are
              sensitive to Western music categorizations, which is consistent
              with the authors' previous studies in adults and school-aged
              children.",
  journal  = "Frontiers in psychology",
  volume   =  4,
  year     =  2013,
  keywords = "Auditory processing; Development; Electroencephalography (EEG);
              Enculturation; Event-related potentials (ERP); Mismatch
              negativity (MMN); Music",
  issn     = "1664-1078",
  pmid     = "23966962",
  doi      = "10.3389/fpsyg.2013.00492"
}

@ARTICLE{Butler1968-ks,
  title   = "Musical consonance as musical preference: A cross-cultural study",
  author  = "Butler, Janet Wydom and Daston, Paul G",
  journal = "The Journal of general psychology",
  volume  =  79,
  pages   = "129--142",
  year    =  1968,
  issn    = "0022-1309"
}

@ARTICLE{Maher1976-ct,
  title   = "``Need for resolution'' ratings for harmonic musical intervals: A
             comparison between Indians and Canadians",
  author  = "Maher, Timothy F",
  journal = "Journal of cross-cultural psychology",
  volume  =  7,
  number  =  3,
  pages   = "259--276",
  year    =  1976,
  issn    = "0022-0221, 0091-1674"
}

@ARTICLE{Aures1985-tb,
  title    = "Der sensorische Wohlklang als Funktion psychoakustischer
              Empfindungsgr{\"o}{\ss}en",
  author   = "Aures, W",
  abstract = "It is known from earlier research that the sensory euphony of
              sounds is influenced by the elementary auditory sensations:
              roughness, sharpness, tonalness, and loudness. However, as yet
              there has not been systematic and quantitative exploration of
              these relationships. In the present study, sensory euphony and
              the auditory sensations mentioned above were investigated
              systematically with a great number of test stimuli representing a
              wide variety of the four sensations. The influence of the
              auditory sensations was evaluated and described by mathematical
              expressions. By increasing roughness, sharpness and loudness,
              sensory euphony is reduced, while by increasing tonalness it is
              enhanced.",
  journal  = "Acta Acustica united with Acustica",
  volume   =  58,
  number   =  5,
  pages    = "282--290",
  year     =  1985
}

@ARTICLE{Zwicker1991-jr,
  title   = "Audio engineering and psychoacoustics: Matching signals to the
             final receiver, the human auditory system",
  author  = "Zwicker, Eberhard and Zwicker, U Tilmann",
  journal = "Journal of the Audio Engineering Society. Audio Engineering
             Society",
  volume  =  39,
  number  =  3,
  pages   = "115--126",
  year    =  1991,
  issn    = "0004-7554"
}

@ARTICLE{Sundberg1973-xj,
  title    = "Musical octaves and pitch",
  author   = "Sundberg, J E and Lindqvist, J",
  abstract = "In certain types of musical performances systematic deviations
              from the frequencies of the equally tempered scale have been
              observed. In such scales the octave interval exceeds a 2:1
              frequency ratio slightly. Experiments were carried out in which
              musically trained subjects matched the upper octave of a
              reference tone with a subsequent variable tone. Both signals were
              complex tones. The results show that (1) generally the physical
              size of the perceptually pure musical octave, briefly the
              physical musical octave (PMO), exceeds a 2:1 frequency ratio also
              when complex tones are used, and (2) the PMO is intensity
              dependent. This intensity dependence can be explained as a
              consequence of a pitch-intensity dependence in complex tones. A
              stretched scale derived from the experimentally established
              average PMO at different frequencies shows striking similarities
              with the stretched scales observed in musical performances.
              \copyright{} 1986, American Association of Physics Teachers. All
              rights reserved.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  54,
  number   =  4,
  pages    = "922--929",
  year     =  1973,
  keywords = "Human; Musical; Pitch Discrimination; music; pitch; pressure;
              psychophysics; sound",
  issn     = "0001-4966",
  pmid     = "4757463",
  doi      = "10.1121/1.1914347"
}

@ARTICLE{Aures1985-xn,
  title    = "Der sensorische Wohlklang als Funktion psychoakustischer
              Empfindungsgr{\"o}{\ss}en (Sensory consonance as a function of
              psychoacoustic parameters)",
  author   = "Aures, W",
  abstract = "It is known from earlier research that the sensory euphony of
              sounds is influenced by the elementary auditory sensations:
              roughness, sharpness, tonalness, and loudness. However, as yet
              there has not been systematic and quantitative exploration of
              these relationships. In the present study, sensory euphony and
              the auditory sensations mentioned above were investigated
              systematically with a great number of test stimuli representing a
              wide variety of the four sensations. The influence of the
              auditory sensations was evaluated and described by mathematical
              expressions. By increasing roughness, sharpness and loudness,
              sensory euphony is reduced, while by increasing tonalness it is
              enhanced.",
  journal  = "Acta Acustica united with Acustica",
  volume   =  58,
  number   =  5,
  pages    = "282--290",
  year     =  1985
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ward1954-fs,
  title    = "Subjective musical pitch",
  author   = "Ward, W D",
  abstract = "The subjective relation ``octave of'' is demonstrated to be a
              valid interval for determining scales of musical pitch for pure
              tones presented successively. Octave judgments of trained
              musicians have a standard deviation averaging about 0.6 percent.
              Inter‐observer variability is 2 to 5 times as great, increasing
              with frequency. Judgments vary significantly from day to day, but
              as the direction of shift at different frequencies for a single
              observer is random, the shifts cannot be attributed to changes in
              the octave criterion. Instead, this variability, and also (1)
              differences between right‐ and left‐ear judgments of a given
              observer, (2) the change in difference between subjective and
              physical octaves as a function of frequency, and (3) the high
              inter‐observer variability, all confirm the basic instability of
              pitch‐frequency relations implied by the facts of binaural
              diplacusis. Individual and group scales of musical pitch are
              deduced. In these scales, the average rate of change of musical
              pitch with respect to frequency level is less than unity by a
              small but significant amount. Although this discrepancy not
              explained, tests show that it is not an obvious artifact of
              method. Simultaneous presentation raises variability, but affects
              means only slightly. The relation betwen the peculiarities of
              individual scales and binaural diplacusis discussed.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  26,
  number   =  3,
  pages    = "369--380",
  year     =  1954,
  issn     = "0001-4966",
  doi      = "10.1121/1.1907344"
}

@ARTICLE{Cook2017-xx,
  title    = "Calculation of the acoustical properties of triadic harmonies",
  author   = "Cook, Norman D",
  abstract = "\copyright{} 2017 Author(s). The author reports that the harmonic
              ``tension'' and major/minor ``valence'' of pitch combinations can
              be calculated directly from acoustical properties without relying
              on concepts from traditional harmony theory. The capability to
              compute the well-known types of harmonic triads means that their
              perception is not simply a consequence of learning an arbitrary
              cultural ``idiom'' handed down from the Italian Renaissance. On
              the contrary, for typical listeners familiar with diatonic music,
              attention to certain, definable, acoustical features underlies
              the perception of the valence (modality) and the inherent tension
              (instability) of three-tone harmonies.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  142,
  number   =  6,
  pages    = "3748--3755",
  year     =  2017,
  issn     = "0001-4966",
  doi      = "10.1121/1.5018342"
}

@INCOLLECTION{Vassilakis2005-tm,
  title     = "Auditory roughness as a means of musical expression",
  booktitle = "Selected Reports in Ethnomusicology: Perspectives in Systematic
               Musicology",
  author    = "Vassilakis, P N",
  editor    = "Kendall, Roger A and Savage, Roger H",
  publisher = "Department of Ethnomusicology, University of California",
  volume    =  12,
  pages     = "119--144",
  year      =  2005,
  address   = "Los Angeles, CA"
}

@ARTICLE{Florian1981-mk,
  title   = "The two-part vocal style on Baluan Island Manus Province, Papua
             New Guinea",
  author  = "Florian, Gerald",
  journal = "Ethnomusicology",
  volume  =  25,
  number  =  3,
  pages   = "433--446",
  year    =  1981
}

@ARTICLE{Nikolsky2015-gg,
  title    = "Evolution of tonal organization in music mirrors symbolic
              representation of perceptual reality. Part-1: Prehistoric",
  author   = "Nikolsky, Aleksey",
  abstract = "This paper reveals the way in which musical pitch works as a
              peculiar form of cognition that reflects upon the organization of
              the surrounding world as perceived by majority of music users
              within a socio-cultural formation. The evidence from music
              theory, ethnography, archeology, organology, anthropology,
              psychoacoustics, and evolutionary biology is plotted against
              experimental evidence. Much of the methodology for this
              investigation comes from studies conducted within the territory
              of the former USSR. To date, this methodology has remained solely
              confined to Russian speaking scholars. A brief overview of
              pitch-set theory demonstrates the need to distinguish between
              vertical and horizontal harmony, laying out the framework for
              virtual music space that operates according to the perceptual
              laws of tonal gravity. Brought to life by bifurcation of music
              and speech, tonal gravity passed through eleven discrete stages
              of development until the onset of tonality in the seventeenth
              century. Each stage presents its own method of integration of
              separate musical tones into an auditory-cognitive unity. The
              theory of ``melodic intonation'' is set forth as a counterpart to
              harmonic theory of chords. Notions of tonality, modality, key,
              diatonicity, chromaticism, alteration, and modulation are defined
              in terms of their perception, and categorized according to the
              way in which they have developed historically. Tonal organization
              in music, and perspective organization in fine arts are explained
              as products of the same underlying mental process. Music seems to
              act as a unique medium of symbolic representation of reality
              through the concept of pitch. Tonal organization of pitch
              reflects the culture of thinking, adopted as a standard within a
              community of music users. Tonal organization might be a naturally
              formed system of optimizing individual perception of reality
              within a social group and its immediate environment, setting
              conventional standards of intellectual and emotional
              intelligence.",
  journal  = "Frontiers in psychology",
  volume   =  6,
  year     =  2015,
  keywords = "Diatonic/chromatic music; Evolution of music; Horizontal/vertical
              harmony; Music perception; Musical and verbal intonation; Musical
              mode; Pentatonic/heptatonic music; Tonality",
  issn     = "1664-1078",
  pmid     = "26528193",
  doi      = "10.3389/fpsyg.2015.01405"
}

@ARTICLE{Hulse1995-tf,
  title    = "Auditory discrimination of chord-based spectral structures by
              European starlings (Sturnus vulgaris)",
  author   = "Hulse, Stewart H and Bernard, Daniel J and Braaten, Richard F",
  abstract = "European starlings (Sturnus vulgaris) were trained to
              discriminate two complex harmonic structures modeled after
              musical chords in a 2-alternative choice task. Musical chords
              provide rich acoustic structures with which to study relative
              pitch perception and perceptual invariance in nonhuman animals.
              The starlings learned the chord discrimination and transferred
              the discrimination to chords with different root frequencies,
              thus showing perceptual invariance for the chords. Further
              transfer tests showed that correlates of chord structure were
              indeed controlling discrimination performance. The proposition
              that the starlings were responding primarily to a sensory
              dimension of consonance and dissonance in the acoustic structures
              provides a good account of the data. The harmonic principles that
              govern consonance and dissonance may be important for starling
              auditory communication and, perhaps, auditory communication of
              other songbirds. From the standpoint of human music cognition,
              the data add to previous observations suggesting that the idea of
              musical universals may be extended to species other than humans.",
  journal  = "Journal of experimental psychology. General",
  volume   =  124,
  number   =  4,
  pages    = "409--423",
  year     =  1995,
  issn     = "0096-3445",
  doi      = "10.1037/0096-3445.124.4.409"
}

@ARTICLE{Hoeschele2012-dl,
  title    = "Black-capped chickadee (Poecile atricapillus) and human (Homo
              sapiens) chord discrimination",
  author   = "Hoeschele, Marisa and Cook, Robert G and Guillette, Lauren M and
              Brooks, Daniel I and Sturdy, Christopher B",
  journal  = "Journal of comparative psychology",
  volume   =  126,
  number   =  1,
  pages    = "57--67",
  year     =  2012,
  keywords = "all cultures have some; and musical sys-; and potentially unique
              feature; biomusicology; black-capped chickadee; chord;
              discrimination; form of music; human; isolation from one another;
              music is a universal; of our; share many; species; tems that
              developed in",
  issn     = "0093-4127",
  doi      = "10.1037/a0024627"
}

@ARTICLE{Brooks2010-th,
  title    = "Chord discrimination by pigeons",
  author   = "Brooks, Daniel I and Cook, Robert G",
  journal  = "Music perception",
  volume   =  27,
  number   =  3,
  pages    = "183--196",
  year     =  2010,
  keywords = "auditory; chord; comparative; music; pigeon",
  issn     = "0730-7829",
  doi      = "10.1525/mp.2010.27.3.183"
}

@ARTICLE{McGowan2011-qd,
  title   = "Psychoacoustic foundations of contextual harmonic stability in
             jazz piano voicings",
  author  = "McGowan, J",
  journal = "Journal of Jazz Studies",
  volume  =  7,
  number  =  2,
  pages   = "156--191",
  year    =  2011
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ambrazevicius2017-pi,
  title    = "Dissonance/roughness and tonality perception in Lithuanian
              traditional Schwebungsdiaphonie",
  author   = "Ambrazevi{\v c}ius, Rytis",
  journal  = "Journal of Interdisciplinary Music Studies",
  volume   =  8,
  number   = "1\&2",
  pages    = "39--53",
  year     =  2017,
  keywords = "Schwebungsdiaphonie; Sutartinės; roughness; sensory dissonance;
              tonal hierarchies",
  doi      = "10.4407/jims.2016.12.002"
}

@ARTICLE{Stojanow2016-mb,
  title    = "A review on conventional psychoacoustic evaluation tools, methods
              and algorithms",
  author   = "Stojanow, Alexander and Liebetrau, Judith",
  journal  = "2016 8th International Conference on Quality of Multimedia
              Experience, QoMEX 2016",
  year     =  2016,
  keywords = "(un)pleasantness; acoustical analyzation; annoyance; fluctuation
              strength; harmony; perceptual evaluation; predictive evaluation;
              psychoacoustics; roughness; sharpness; tonality",
  doi      = "10.1109/QoMEX.2016.7498923"
}

@ARTICLE{Krueger1910-yn,
  title   = "Die Theorie der Konsonanz",
  author  = "Krueger, F",
  journal = "Psychologische Studien",
  volume  =  5,
  pages   = "294--411",
  year    =  1910
}

@ARTICLE{Schouten1938-bz,
  title   = "The perception of subjective tones",
  author  = "Schouten, J F",
  journal = "Proceedings of the Koninklijke Nederlandse Akademie van
             Wetenschappen. Series C. Biological and medical sciences",
  volume  =  41,
  pages   = "1086--1093",
  year    =  1938,
  issn    = "0023-3374"
}

@BOOK{Tartini1754-ez,
  title   = "Trattato di musica secondo la vera scienza dell'armonia",
  author  = "Tartini, G",
  year    =  1754,
  address = "Padova, Italy"
}

@ARTICLE{Plomp1967-vs,
  title   = "Pitch of complex tones",
  author  = "Plomp, R",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  41,
  number  =  6,
  pages   = "1526--1533",
  year    =  1967,
  issn    = "0001-4966"
}

@ARTICLE{Koda2013-nl,
  title    = "Validation of an auditory sensory reinforcement paradigm:
              Campbell's monkeys (Cercopithecus campbelli) do not prefer
              consonant over dissonant sounds",
  author   = "Koda, Hiroki and Nagumo, Sumiharu and Basile, Muriel and Olivier,
              Marion and Remeuf, Kevin and Blois-Heulin, Catherine and
              Lemasson, Alban",
  abstract = "The central position and universality of music in human societies
              raises the question of its phylogenetic origin. One of the most
              important properties of music involves harmonic musical
              intervals, in response to which humans show a spontaneous
              preference for consonant over dissonant sounds starting from
              early human infancy. Comparative studies conducted with organisms
              at different levels of the primate lineage are needed to
              understand the evolutionary scenario under which this phenomenon
              emerged. Although previous research found no preference for
              consonance in a New World monkey species, the question remained
              opened for Old World monkeys. We used an experimental paradigm
              based on a sensory reinforcement procedure to test auditory
              preferences for consonant sounds in Campbell's monkeys
              (Cercopithecus campbelli campbelli), an Old World monkey species.
              Although a systematic preference for soft (70 dB) over loud (90
              dB) control white noise was found, Campbell's monkeys showed no
              preference for either consonant or dissonant sounds. The
              preference for soft white noise validates our noninvasive
              experimental paradigm, which can be easily reused in any captive
              facility to test for auditory preferences. This would suggest
              that human preference for consonant sounds is not systematically
              shared with New and Old World monkeys. The sensitivity for
              harmonic musical intervals emerged probably very late in the
              primate lineage.",
  journal  = "Journal of comparative psychology",
  volume   =  127,
  number   =  3,
  pages    = "265--271",
  year     =  2013,
  keywords = "Auditory preference; Consonance; Evolution; Nonhuman primates;
              music",
  issn     = "0093-4127, 0735-7036",
  pmid     = "23566027",
  doi      = "10.1037/a0031237"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Plomp1965-ku,
  title    = "Detectability threshold for combination tones",
  author   = "Plomp, R",
  abstract = "Experiments were performed on the detectability threshold for
              combination tones, defined as the sensation level of primary
              tones for which combination tones become audible. Investigated
              were (1) detectability threshold for h−l with (h−l)<<(h+l), where
              h and l are the frequencies of the higher and lower primary tone,
              respectively; (2) detectability threshold for 200, 400, and 600
              cps with 800+1000 and 800+1400 cps as primary tones; (3)
              audibility of combination tones for l = 1000 cps and h variable
              between 1000 and 3000 cps; (4) detectability threshold for the
              ``missing fundamental'' of $\sum$n−210 cos 2 $\pi$nft, with f
              varying from 125 to 1000 cps. From the experimental data, we may
              conclude that (1) there are large individual differences in the
              minimum sensation level of primary tones for which combination
              tones appear; (2) for usual listening levels of speech and music,
              the ear′s distortion is sufficiently low to avoid audible
              combination tones; (3) the same holds for the ``missing
              fundamental,'' so the fact that the pitch of a complex tone
              without fundamental is equal to the pitch of this tone cannot be
              explained by the assumption that the fundamental tone is
              reintroduced in the listener′s ear; (4) the fact that the
              detectability thresholds for combination tones are significantly
              lower for small than for large tone intervals indicates that, for
              both cases, the ear′s distortion cannot be represented by the
              same nonlinear characteristic and supports the evidence that the
              tones are produced in the inner ear.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  37,
  number   =  6,
  pages    = "1110--1123",
  year     =  1965,
  issn     = "0001-4966",
  pmid     = "14339721",
  doi      = "10.1121/1.1909532"
}

@ARTICLE{Ushakov2010-hj,
  title    = "Spike train statistics for consonant and dissonant musical
              accords in a simple auditory sensory model",
  author   = "Ushakov, Yuriy V and Dubkov, Alexander A and Spagnolo, Bernardo",
  abstract = "The phenomena of dissonance and consonance in a simple auditory
              sensory model composed of three neurons are considered. Two of
              them, here so-called sensory neurons, are driven by noise and
              subthreshold periodic signals with different ratio of
              frequencies, and its outputs plus noise are applied synaptically
              to a third neuron, so-called interneuron. We present a
              theoretical analysis with a probabilistic approach to investigate
              the interspike intervals statistics of the spike train generated
              by the interneuron. We find that tones with frequency ratios that
              are considered consonant by musicians produce at the third neuron
              inter-firing intervals statistics densities that are very
              distinctive from densities obtained using tones with ratios that
              are known to be dissonant. In other words, at the output of the
              interneuron, inharmonious signals give rise to blurry spike
              trains, while the harmonious signals produce more regular, less
              noisy, spike trains. Theoretical results are compared with
              numerical simulations.",
  journal  = "Physical Review E",
  volume   =  81,
  number   =  4,
  year     =  2010,
  issn     = "1539-3755",
  pmid     = "20481757",
  arxivid  = "0911.5243",
  doi      = "10.1103/PhysRevE.81.041911"
}

@ARTICLE{Lee2015-nq,
  title    = "Neural transformation of dissonant intervals in the auditory
              brainstem",
  author   = "Lee, Kyung Myun and Skoe, Erika and Kraus, Nina and Ashley,
              Richard",
  journal  = "Music perception",
  volume   =  32,
  number   =  5,
  pages    = "445--459",
  year     =  2015,
  keywords = "auditory brainstem response; musical inter-; nonlinearity;
              periodicity; sensory consonance; vals",
  issn     = "0730-7829",
  doi      = "10.1525/MP.2015.32.5.445"
}

@INPROCEEDINGS{Spagnolo2013-fp,
  title     = "Harmony perception and regularity of spike trains in a simple
               auditory model",
  booktitle = "{AIP} Conference Proceedings",
  author    = "Spagnolo, B and Ushakov, Y V and Dubkov, A A",
  abstract  = "\copyright{} 2013 American Institute of Physics.A probabilistic
               approach for investigating the phenomena of dissonance and
               consonance in a simple auditory sensory model, composed by two
               sensory neurons and one interneuron, is presented. We calculated
               the interneuron's firing statistics, that is the interspike
               interval statistics of the spike train at the output of the
               interneuron, for consonant and dissonant inputs in the presence
               of additional ``noise'', representing random signals from other,
               nearby neurons and from the environment. We find that blurry
               interspike interval distributions (ISIDs) characterize dissonant
               accords, while quite regular ISIDs characterize consonant
               accords. The informational entropy of the non-Markov spike train
               at the output of the interneuron and its dependence on the
               frequency ratio of input sinusoidal signals is estimated. We
               introduce the regularity of spike train and suggested the high
               or low regularity level of the auditory system's spike trains as
               an indicator of feeling of harmony during sound perception or
               disharmony, respectively.",
  volume    =  1510,
  pages     = "274--289",
  year      =  2013,
  keywords  = "auditory system; consonant and dissonant accords; environmental
               noise; hidden Markov chain; informational entropy; regularity",
  doi       = "10.1063/1.4776512"
}

@ARTICLE{Oxenham2018-fe,
  title    = "How we hear: The perception and neural coding of sound",
  author   = "Oxenham, Andrew J",
  journal  = "Annual review of psychology",
  volume   =  69,
  pages    = "27--50",
  year     =  2018,
  keywords = "auditory perception; auditory scene analysis; frequency
              selectivity; pitch",
  issn     = "0066-4308",
  doi      = "10.1146/annurev-psych-122216-011635"
}

@ARTICLE{Patterson1986-od,
  title   = "Spiral detection of periodicity and the spiral form of musical
             scales",
  author  = "Patterson, Roy D",
  journal = "Psychology of Music",
  volume  =  14,
  pages   = "44--61",
  year    =  1986,
  doi     = "10.1177/0305735686141004"
}

@ARTICLE{Terhardt1982-qd,
  title    = "Algorithm for extraction of pitch and pitch salience from complex
              tonal signals",
  author   = "Terhardt, Ernst and Stoll, Gerhard and Seewann, Manfred",
  abstract = "A procedure is described for the automatic extraction of the
              various pitch percepts which may be simultaneously evoked by
              complex tonal stimuli. The procedure is based on the theory of
              virtual pitch, and in particular on the principle, that the whole
              pitch percept is dependent both on analytic listening (yielding
              spectral pitch) and on holistic perception (yielding virtual
              pitch).The more or less ambiguous pitch percept goverend by these
              two pitch modes is described by two pitch patterns: the
              spectral-pitch pattern, and the virtual-pitch pattern. Each of
              these patterns consists of a number of pitch (height) valies, and
              associated weights, which account for the relative promimence of
              every individual pitch. The spectral-pitch pattern is constructed
              by spectral analysis, extraction of tonal components, evaluation
              of masking effects (masking and pitch shifts), and weighting
              according to the principle of spectral dominance. The
              virtual-pitch patterns is obtained from the spectral-pitch
              pattern by an advanced algorithm of subharmonic coincidence
              assessment. The procedure is based on a previous algorithm for
              calcultating virtual pitch [E. Terhardt, Hear. Res. 1, 155-182
              (1979)], and can be regarded as a generalized and advanced
              version thereof.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  71,
  number   =  3,
  pages    = "679--688",
  year     =  1982,
  issn     = "0001-4966",
  pmid     = "6699300",
  doi      = "10.1121/1.387544"
}

@BOOK{Sorge1747-tz,
  title     = "Vorgemach der musicalischen Composition",
  author    = "Sorge, G A",
  publisher = "Verlag des Autoris",
  year      =  1747,
  address   = "Lobenstein, Germany"
}

@INCOLLECTION{Buus1997-gz,
  title     = "Auditory masking",
  booktitle = "Encyclopedia of Acoustics, Volume Three",
  author    = "Buus, S{\o}ren",
  editor    = "Crocker, Malcolm J",
  publisher = "John Wiley \& Sons",
  pages     = "1427--1445",
  year      =  1997,
  doi       = "10.1002/9780470172537.ch115"
}

@ARTICLE{Aures1985-ya,
  title    = "Berechnungsverfahren f{\"u}r den sensorichen Wohlklang beliebiger
              Schallsignale (A procedure for calculating the sensory consonance
              of any sound)",
  author   = "Aures, W",
  abstract = "A calculation model was developed to achieve assessment of
              sensory euphony from the sound signal. This is done by including
              calculation models of the auditory sensations sharpness,
              roughness, tonalness, and loudness, on which sensory euphony
              depends. To calculate loudness Zwicker's theory was used. The
              calculation of sharpness was done with a modified method by v.
              Bismarck. For calculation of roughness and tonalness new models
              were developed, partly described elsewhere (roughness), partly in
              the present study (tonalness). From the calculated sensations and
              their mathematically expressed influences on sensory euphony, the
              latter is assessed with great accuracy. The correlation between
              the calculated and measured sensory euphony is greater than 90\%.",
  journal  = "Acustica",
  volume   =  59,
  number   =  2,
  pages    = "130--141",
  year     =  1985
}

@INCOLLECTION{Patterson2012-rf,
  title     = "Auditory masking",
  booktitle = "Handbook of Perception, Volume {IV}: Hearing",
  author    = "Patterson, Roy D and Green, David M",
  editor    = "Carterette, Edward",
  publisher = "Elsevier",
  pages     = "337--361",
  year      =  2012,
  address   = "Amsterdam, The Netherlands"
}

@ARTICLE{Scharf1971-zf,
  title   = "Fundamentals of auditory masking",
  author  = "Scharf, B",
  journal = "Audiology: official organ of the International Society of
             Audiology",
  volume  =  10,
  pages   = "30--40",
  year    =  1971,
  issn    = "0020-6091"
}

@PHDTHESIS{Aures1984-wp,
  title   = "Berechnungsverfahren f{\"u}r den Wohlklang beliebiger
             Schallsignale, ein Beitrag zur geh{\"o}rbezogenen Schallanalyse",
  author  = "Aures, W",
  year    =  1984,
  address = "Munich, Germany",
  school  = "Technical University of Munich"
}

@ARTICLE{Bilsen1977-hc,
  title    = "Pitch of noise signals: evidence for a ``central spectrum''",
  author   = "Bilsen, F A",
  abstract = "A review is given of pitches associated with different types of
              noise signals. When two narrow bands of noise are presented, with
              centre frequencies at nf and (n+1)f, a pitch corresponding to f
              may be perceived if n is low (3 or 4). This breaks down for
              higher n (6 or 7). Results are similar for monotic and dichotic
              presentation. Dichotic noise with two interaural phase shifts may
              also give rise to the perception of a missing fundamental. These
              pitches, and others resulting from two interaurally delayed
              noises can be explained in terms of the central spectrum. It is
              suggested that the shape of the central spectrum, is reflected in
              the masked threshold of a pure tone obtained in a BMLD
              experiment.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  61,
  number   =  1,
  pages    = "150--161",
  year     =  1977,
  issn     = "0001-4966",
  pmid     = "833366",
  doi      = "10.1121/1.381276"
}

@ARTICLE{Shamma2000-op,
  title    = "The case of the missing pitch templates: How harmonic templates
              emerge in the early auditory system",
  author   = "Shamma, Shihab and Klein, David",
  abstract = "Periodicity pitch is the most salient and important of all pitch
              percepts. Psychoacoustical models of this percept have long
              postulated the existence of internalized harmonic templates
              against which incoming resolved spectra can be compared, and
              pitch determined according to the best matching templates [J.
              Goldstein, J. Acoust. Soc. Am. 54, 1496-1516 (1973)]. However, it
              has been a mystery where and how such harmonic templates can come
              about. We present here a biologically plausible model for how
              such templates can form in the early stages of the auditory
              system. The model demonstrates that any broadband stimulus,
              including noise and random click trains, suffices for generating
              the templates, and that there is no need for any delay lines,
              oscillators, or other neural temporal structures. The model
              consists of two key stages: cochlear filtering followed by
              coincidence detection. The cochlear stage provides responses
              analogous to those recorded in the auditory nerve and cochlear
              nucleus. Specifically, it performs moderately sharp frequency
              analysis via a filterbank with tonotopically ordered center
              frequencies (CFs); the rectified and phase-locked filter
              responses are further enhanced temporally to resemble the
              synchronized responses of cells in the cochlear nucleus. The
              second stage is a matrix of coincidence detectors that compute
              the average pairwise instantaneous correlation (or product)
              between responses from all CFs across the channels. Model
              simulations show that for any broadband stimulus, a degree of
              high coincidence occurs among cochlear channels that are spaced
              precisely at harmonic intervals. Accumulating coincidences over
              time results in the formation of harmonic templates for all
              fundamental frequencies in the phase-locking frequency range. The
              model accounts for the critical role played by three subtle but
              important factors in cochlear function: the nonlinear
              transformations following the filtering stage, the rapid phase
              shifts of the traveling wave near its resonance, and the spectral
              resolution of the cochlear filters. Finally, we discuss the
              physiological correlates and location of such a process and its
              resulting templates.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  107,
  number   =  5,
  pages    = "2631--2644",
  year     =  2000,
  issn     = "0001-4966",
  pmid     = "10830385",
  doi      = "10.1121/1.428649"
}

@INCOLLECTION{De_Cheveigne2005-vr,
  title     = "Pitch perception models",
  booktitle = "Pitch: Neural coding and perception",
  author    = "de Cheveign{\'e}, A",
  editor    = "Plack, C J and Oxenham, Andrew J",
  publisher = "Springer",
  pages     = "169--233",
  year      =  2005,
  address   = "New York, NY",
  doi       = "10.1007/0-387-28958-5\_6"
}

@ARTICLE{Balaguer-Ballester2008-xa,
  title    = "A cascade autocorrelation model of pitch perception",
  author   = "Balaguer-Ballester, Emili and Denham, Susan L and Meddis, Ray",
  abstract = "Autocorrelation algorithms, in combination with computational
              models of the auditory periphery, have been successfully used to
              predict the pitch of a wide range of complex stimuli. However,
              new stimuli are frequently offered as counterexamples to the
              viability of this approach. This study addresses the issue of
              whether in the light of these challenges the predictive power of
              autocorrelation can be preserved by changes to the peripheral
              model and the computational algorithm. An existing model is
              extended by the addition of a low-pass filter of the summary
              integration of the individual within-channel autocorrelations.
              Other recent developments are also incorporated, including
              nonlinear processing on the basilar membrane and the use of
              integration time constants that are proportional to the
              autocorrelation lags. The modified and extended model predicts
              with reasonable success the pitches of a range of stimuli that
              have proved problematic for earlier implementations of the
              autocorrelation principle. The evaluation stimuli include short
              tone sequences, click trains consisting of alternating interclick
              intervals, click trains consisting of mixtures of regular and
              irregular intervals, shuffled click trains, and transposed tones.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  124,
  number   =  4,
  pages    = "2186--2195",
  year     =  2008,
  issn     = "0001-4966",
  pmid     = "19062858",
  doi      = "10.1121/1.2967829"
}

@INPROCEEDINGS{Slaney1990-oz,
  title     = "A perceptual pitch detector",
  booktitle = "International Conference on Acoustics, Speech, and Signal
               Processing",
  author    = "Slaney, M and Lyon, R F",
  abstract  = "A pitch detector based on Licklider's (1979) duplex theory
               of\textbackslashnpitch perception was implemented and tested on
               a variety of stimuli from\textbackslashnhuman perceptual tests.
               It is believed that this approach
               accurately\textbackslashnmodels how people perceive pitch. It is
               shown that it correctly\textbackslashnidentifies the pitch of
               complex harmonic and inharmonic stimuli and
               that\textbackslashnit is robust in the face of noise and phase
               changes. This perceptual\textbackslashnpitch detector combines a
               cochlear model with a bank of autocorrelators.\textbackslashnBy
               performing an independent autocorrelation for each channel, the
               pitch\textbackslashndetector is relatively insensitive to phase
               changes across channels. The\textbackslashninformation in the
               correlogram is filtered, nonlinearly enhanced,
               and\textbackslashnsummed across channels. Peaks are identified
               and a pitch is then\textbackslashnproposed that is consistent
               with the peaks",
  volume    =  1,
  pages     = "357--360",
  year      =  1990,
  issn      = "1520-6149",
  doi       = "10.1109/ICASSP.1990.115684"
}

@ARTICLE{Harczos2018-ts,
  title    = "Modeling pitch perception with an active auditory model extended
              by octopus cells",
  author   = "Harczos, Tamas and Klefenz, Frank Markus",
  abstract = "Pitch is an essential category for musical sensations. Models of
              pitch perception are vividly discussed up to date. Most of them
              rely on definitions of mathematical methods in the spectral or
              temporal domain. Our proposed pitch perception model is composed
              of an active auditory model extended by octopus cells. The active
              auditory model is the same as used in the SAM (Stimulation based
              on Auditory Modeling), a successful cochlear implant sound
              processing strategy extended here by modeling the functional
              behavior of the octopus cells in the ventral cochlear nucleus and
              by modeling their connections to the auditory nerve fibers. The
              neurophysiological parameterization of the extended model is
              fully described in the time domain. The model is based on
              latency-phase en- and decoding as octopus cells are latency-phase
              rectifiers in their local receptive fields. Pitch is ubiquitously
              represented by cascaded firing sweeps of octopus cells. Based on
              the firing patterns of octopus cells, inter-spike interval
              histograms can be aggregated, in which the place of the global
              maximum is assumed to encode the pitch.",
  journal  = "Frontiers in neuroscience",
  volume   =  12,
  pages    = "1--12",
  year     =  2018,
  keywords = "Hough-transform; auditory modeling; hough-transform; inter-spike
              interval; inter-spike interval histogram; latency-phase coding;
              octopus neuron; parameterization; pitch; pitch estimation; time
              domain parameterization",
  issn     = "1662-4548, 1662-453X",
  doi      = "10.3389/fnins.2018.00660"
}

@ARTICLE{Duifhuis1982-st,
  title    = "Measurement of pitch in speech: An implementation of Goldstein's
              theory of pitch perception",
  author   = "Duifhuis, H and Willems, L F and Sluyter, R J",
  abstract = "Recent developments in hearing theory have resulted in the rather
              general acceptance of the idea that the perception of pitch of
              complex sounds is the result of the psychological pattern
              recognition process. The pitch is supposedly mediated by the
              fundamental of the harmonic spectrum which fits the spectrum of
              the complex sound optimally. The problem of finding the pitch is
              then equivalent to finding the best harmonic match. Goldstein [J.
              Acoust. Soc. Am. 54, 1496-1516 (1973)] has described an objective
              procedure for finding the best fit for stimuli containing
              relatively few spectral components. He uses maximum likelihood
              criterion. Application of this procedure to various data on the
              pitch of complex sounds yielded good results. This motivated our
              efforts to apply the pattern recognition theory of pitch to the
              problem of measuring pitch in speech. Although we were able to
              follow the main line of Goldstein's procedure, some essential
              changes had to be made. The most important is that in our
              implementation not all spectral components of the complex sound
              have to be classified as belonging to the harmonic pattern. We
              introduced a harmonics sieve to determine whether components are
              rejected or accepted at a candidate pitch. A simple criterion,
              based on the components accepted and rejected, led to the
              decision on which candidate pitch was to be finally selected. The
              performance and reliability of this psychoacoustically based
              pitch meter were tested in a LPC-vocoder system.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  71,
  number   =  6,
  pages    = "1568--1580",
  year     =  1982,
  issn     = "0001-4966",
  pmid     = "7108032",
  doi      = "10.1121/1.387811"
}

@ARTICLE{Cariani1996-rt,
  title    = "Neural correlates of the pitch of complex tones. I. Pitch and
              pitch salience",
  author   = "Cariani, P A and Delgutte, B",
  abstract = "1. The temporal discharge patterns of auditory nerve fibers in
              Dial-anesthetized cats were studied in response to periodic
              complex acoustic waveforms that evoke pitches at their
              fundamental frequencies. Single-formant vowels,
              amplitude-modulated (AM) and quasi-frequency-modulated tones. AM
              noise, click trains, and other complex tones were utilized.
              Distributions of intervals between successive spikes (``1st-order
              intervals'') and between both successive and nonsuccessive spikes
              (``all-order intervals'') were computed from spike trains.
              Intervals from many fibers were pooled to estimate interspike
              interval distributions for the entire auditory nerve. Properties
              of these ``pooled interspike interval distributions,'' such as
              the positions of interval peaks and their relative heights, were
              examined for correspondence to the psychophysical data on pitch
              frequency and pitch salience. 2. For a diverse set of complex
              stimuli and levels, the most frequent all-order interspike
              interval present in the pooled distribution corresponded to the
              pitch heard in psychophysical experiments. Pitch estimates based
              on pooled interval distributions (30-85 fibers, 100 stimulus
              presentations per fiber) were highly accurate (within 1\%) for
              harmonic stimuli that produce strong pitches at 60 dB SPL. 3.
              Although the most frequent intervals in pooled all-order interval
              distributions were very stable with respect to sound intensity
              level (40, 60, and 80 dB total SPL), this was not necessarily the
              case for first-order interval distributions. Because the low
              pitches of complex tones are largely invariant with respect to
              level, pitches estimated from all-order interval distributions
              correspond better to perception. 4. Spectrally diverse stimuli
              that evoke similar low pitches produce pooled interval
              distributions with similar most-frequent intervals. This suggests
              that the pitch equivalence of these different stimuli could
              result from central auditory processing mechanisms that analyze
              interspike interval patterns. 5. Complex stimuli that evoke
              strong or ``salient'' pitches produce pooled interval
              distributions with high peak-to-mean ratios. Those stimuli that
              evoke weak pitches produce pooled interval distributions with low
              peak-to-mean ratios. 6. Pooled interspike interval distributions
              for stimuli consisting of low-frequency components generally
              resembled the short-time auto-correlation function of stimulus
              waveforms. Pooled interval distributions for stimuli consisting
              of high-frequency components resembled the short-time
              autocorrelation function of the waveform envelope. 7. Interval
              distributions in populations of neurons constitute a general,
              distributed means of encoding, transmitting, and representing
              information. Existence of a central processor capable of
              analyzing these interval patterns could provide a unified
              explanation for many different aspects of pitch perception.",
  journal  = "Journal of neurophysiology",
  volume   =  76,
  number   =  3,
  pages    = "1698--1716",
  year     =  1996,
  keywords = "Acoustic Stimulation; Afferent/*physiology; Algorithms; Animals;
              Auditory/physiology; Cats; Evoked Potentials; Nerve
              Fibers/physiology; Neurons; P.H.S.; Pitch Perception/*physiology;
              Research Support; U.S. Gov't",
  issn     = "0022-3077"
}

@ARTICLE{Cohen1995-qg,
  title    = "A spectral network model of pitch perception",
  author   = "Cohen, Michael A and Grossberg, Stephen and Wyse, Lonce L",
  abstract = "A model of pitch perception, called the spatial pitch network or
              SPINET model, is developed and analyzed. The model neurally
              instantiates ideas from the spectral pitch modeling literature
              and joins them to basic neural network signal processing designs
              to stimulate a broader range of perceptual pitch data than
              previous spectral models. The components of the model are
              interpreted as peripheral mechanical and neural processing
              stages, which are capable of being incorporated into a larger
              network architecture for separating multiple sound sources in the
              environment. The core of the new model transforms a spectral
              representation of an acoustic source into a spatial distribution
              of pitch strengths. The SPINET model uses a weighted ``harmonic
              sieve'' whereby the strength of activation of a given pitch
              depends upon a weighted sum of narrow regions around the
              harmonics of the nominal pitch value, and higher harmonics
              contribute less to a pitch than lower ones. Suitably chosen
              harmonic weighting functions enable computer simulations of pitch
              perception data involving mistuned components, shifted harmonics,
              and various types of continuous spectra including rippled noise.
              It is shown how the weighting functions produce the dominance
              region, how they lead to octave shifts of pitch in response to
              ambiguous stimuli, and how they lead to a pitch region in
              response to the octave-spaced Shepard tone complexes and Deutsch
              tritones without the use of attentional mechanisms to limit pitch
              choices. An on-center off-surround network in the model helps to
              produce noise suppression, partial masking, and edge pitch.
              Finally, it is shown how peripheral filtering and short-term
              energy measurements produce a model pitch estimate that is
              sensitive to certain component phase relationships.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  98,
  number   =  2,
  pages    = "862--879",
  year     =  1995,
  issn     = "0001-4966",
  pmid     = "7642825",
  doi      = "10.1121/1.413512"
}

@ARTICLE{Langner1983-co,
  title    = "Evidence for neuronal periodicity detection in the auditory
              system of the Guinea fowl: Implications for pitch analysis in the
              time domain",
  author   = "Langner, G",
  abstract = "Evidence for periodicity analysis was obtained by recording from
              420 single units in the auditory midbrain nucleus (MLD) of awake
              Guinea fowls (Numida meleagris). The results were compatible with
              a neuronal correlation model consisting of three main components:
              an oscillator, an interval multiplier and a coincidence unit. The
              model makes use of a neuronal time constant in order to measure
              the periodicities of auditory signals. For 180 units the sequence
              of spike intervals in response to tone bursts and amplitude
              modulations (AM) was studied with 10 ~ts resolution. In 69 of
              these units (38\%) amplitude fluctuations like stimulus onset or
              the modulation cycles produced periodic spike trains resembling
              damped oscillations. The periods of these oscillations did not
              correspond to either the best frequency (BF) of these units or
              the periodicities of the stimuli. They were interpreted as
              multiples of a neuronal time constant, x~ = 0.4 ms, probably a
              minimal synaptic delay. These units were tuned to AM-signals with
              particular combinations of the modulation frequency, fr,, and the
              carrier frequency, ft. The corresponding periods \% and Xc were
              related to the intrinsic oscillation by a periodicity equation: m
              9 ``gm -t- n 9 \% = 1 9 ~1, where a few small integers for m, n
              and 1 were adequate to describe all observed properties of a
              unit. Variation of fm or fc shifted the phase delays of the
              coupled spike activities proportional to m 9 ~m or n 9 \%,
              respectively. These effects were explained by coincidence of
              neuronal activity phase coupled to fc, with intrinsic
              oscillations triggered by the fm-cycles. The coincidence
              condition at the level of the recorded units was given by the
              periodicity equation. Psychophysical experiments using AM-signals
              indicated that the described mechanisms, together with *
              Supported by the DFG, SFB 45 the same neuronal time constant, xt,
              are adequate to explain pitch perception in humans.",
  journal  = "Experimental brain research. Experimentelle Hirnforschung.
              Experimentation cerebrale",
  volume   =  52,
  number   =  3,
  pages    = "333--355",
  year     =  1983,
  keywords = "Auditory system; Neuronal correlation mechanism; Neuronal
              oscillations; Pitch analysis",
  issn     = "0014-4819",
  pmid     = "6653696",
  doi      = "10.1007/BF00238028"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Meddis1991-xm,
  title    = "Virtual pitch and phase sensitivity of a computer model of the
              auditory periphery. {II}: Phase sensitivity",
  author   = "Meddis, Ray and Hewitt, Michael J",
  abstract = "In a companion article [Meddis and Hewitt, J. Acoust. Soc. Am.
              89, 2866-2882 ( 1991 ) ] it was shown that a computational model
              of the auditory periphery followed by a system of autocorrelation
              analyses was able to account for a wide range of human virtual
              pitch perception phenomena. In this article it is shown that the
              same model, with no substantial modification, can predict a
              number of results concerning human sensitivity to phase
              relationships among harmonic components of tone complexes. The
              model is successfully evaluated using (a) amplitude-modulated and
              quasifrequency-modulated stimuli, (b) harmonic complexes with
              alternating phase change and monotonic phase change across
              harmonic components, and (c) mistuned harmonics. The model is
              contrasted with phase- insensitive theories of low-level auditory
              processing and offered as further evidence in favor of the value
              of analysing time intervals among spikes in the auditory nerve
              when explaining l•sychophysical phenome",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  89,
  number   =  6,
  pages    = "2883--2894",
  year     =  1991,
  issn     = "0001-4966",
  doi      = "10.1121/1.400726"
}

@ARTICLE{Goldstein1973-be,
  title    = "An optimum processor theory for the central formation of the
              pitch of complex tones",
  author   = "Goldstein, Julius L",
  abstract = "A comprehensive theory is formulated for the central formation of
              the pitch of complex tones, i.e., periodicity pitch [Schouten,
              Ritsma, and Cardozo, J. Acoust. Soc. Amer. 34, 1418--1424
              (1962)]. This theory is a logical deduction from statistical
              estimation theory of the optimal estimate for fundamental
              frequency, when this estimate is constrained in ways inferred
              from empirical phenomena. The basic constraints are (i) the
              estimator receives noisy information on the frequencies, but not
              amplitudes and phases, of aurally resolvable simple tones from
              the stimulus and its aural combination tones, and (ii) the
              estimator presumes all stimuli are periodic with spectra
              comprising successive harmonics. The stochastic signals
              representing the frequencies of resolved tones are characterized
              by independent Gaussian distributions with mean equal to the
              frequency represented and a variance that serves as free
              parameter. The theory is applicable whether frequency is coded by
              place or time. Optimum estimates of fundamental frequency and
              harmonic numbers are calculated upon each stimulus presentation.
              Multimodal probability distributions for the estimated
              fundamental are predicted in consequence of variability in the
              estimated harmonic numbers. Quantification of the variance
              parameter from musical intelligibility data in Houtsma and
              Goldstein [J. Acoust. Soc. Amer. 51, 520--529 (1972)] shows it to
              be dependent upon the frequency represented and not upon other
              stimulus frequencies. The quantified optimum processor theory
              consolidates known data on pitch of complex tones.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  54,
  number   =  6,
  pages    = "1496--1516",
  year     =  1973,
  issn     = "0001-4966",
  pmid     = "4780803",
  doi      = "10.1121/1.1914448"
}

@ARTICLE{Meddis1997-kk,
  title    = "A unitary model of pitch perception",
  author   = "Meddis, Ray and O'Mard, Lowel",
  abstract = "A model of the mechanism of residue pitch perception is
              revisited. It is evaluated in the context of some new empirical
              results, and it is proposed that the model is able to reconcile a
              number of differing approaches in the history of theories of
              pitch perception. The model consists of four sequential
              processing stages: peripheral frequency selectivity,
              within-channel half-wave rectification and low-pass filtering,
              within-channel periodicity extraction, and cross-channel
              aggregation of the output. The pitch percept is represented by
              the aggregated periodicity function. Using autocorrelation as the
              periodicity extraction method and the summary autocorrelation
              function (SACF) as the method for representing pitch information,
              it is shown that the model can simulate new experimental results
              that show how the quality of the pitch percept is influenced by
              the resolvability of the harmonic components of the stimulus
              complex. These include: (i) the pitch of harmonic stimuli whose
              components alternate in phase; (ii) the increased frequency
              difference limen of tones consisting of higher harmonics; and
              (iii) the influence of a mistuned harmonic on the pitch of the
              complex as a function of its harmonic number. To accommodate
              these paradigms, it was necessary to compare stimuli along the
              length of the SACF rather than relying upon the highest peak
              alone. These new results demonstrate that the model responds
              differently to complexes consisting of low and high harmonics. As
              a consequence, it is not necessary to postulate two separate
              mechanisms to explain different pitch percepts associated with
              resolved and unresolved harmonics.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  102,
  number   =  3,
  pages    = "1811--1820",
  year     =  1997,
  issn     = "0001-4966",
  pmid     = "9301058",
  doi      = "10.1121/1.420088"
}

@ARTICLE{Cariani1999-db,
  title    = "Temporal coding of periodicity pitch in the auditory system: An
              overview",
  author   = "Cariani, Peter",
  journal  = "Neural plasticity",
  volume   =  6,
  number   =  4,
  pages    = "147--172",
  year     =  1999,
  keywords = "autocorrelation; interspike intervals; neural codes;
              phase-locking; sensory coding; speech perception; temporal
              correlation; voice pitch; vowels",
  issn     = "2090-5904"
}

@ARTICLE{Meddis1991-ec,
  title    = "Virtual pitch and phase sensitivity of a computer model of the
              auditory periphery. I: Pitch identification",
  author   = "Meddis, Ray and Hewitt, Michael J",
  abstract = "Licklider [Expcrientia 7, 128-133 ( 1951 \} ] presented a theory
              of pitch highlighting the role of auditory-nerve
              interspike-interval timing information in the process of pitch
              extraction. His theory is simplified and amended and presented as
              a computer here implementation. This implementation been has
              successfully using tested simulations of a wide range of
              classical demonstrations of pitch phenomena including the missing
              fundamental, ambiguous pitch, pitch shift of equally spaced,
              inharmonic components, musical chords, repetition pitch, the
              pitch of interrupted noise, the existence region, and the
              dominance region for pitch. The theory is compared with a number
              of alternative theories and the physiological plausibility of a
              temporal model is considere",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  89,
  number   =  6,
  pages    = "2866--2882",
  year     =  1991,
  issn     = "0001-4966",
  doi      = "10.1121/1.400725"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Wightman1973-tj,
  title    = "The pattern‐transformation model of pitch",
  author   = "Wightman, Frederic L",
  abstract = "Outlines a new approach to pitch perception based on auditory
              pattern recognition. The general approach is formalized in a
              mathematical ``pattern transformation'' model. In this model an
              acoustic stimulus is 1st transformed by the sense organ into a
              pattern of peripheral neural activity. This peripheral pattern is
              assumed roughly to represent the power spectrum of the stimulus.
              Thus, the temporal fine structure of the stimulus is virtually
              ignored; the model is phase insensitive. The peripheral pattern
              is then assumed to be Fourier-transformed into another pattern of
              activity. This 2nd pattern roughly represents the autocorrelation
              function of the stimulus. Pitch is derived from positions of
              maximal activity in this pattern. From preliminary tests it
              appears that the model can successfully predict the pitch of many
              types of complex stimuli. In addition, the model provides
              estimates of pitch strength or clarity. These estimates also
              agree, at least qualitatively, with available data. (PsycINFO
              Database Record (c) 2004 APA, all rights reserved)",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  54,
  number   =  2,
  pages    = "407--416",
  year     =  1973,
  issn     = "0001-4966",
  pmid     = "4759014",
  doi      = "10.1121/1.1913592"
}

@ARTICLE{Bernstein2005-ve,
  title    = "An autocorrelation model with place dependence to account for the
              effect of harmonic number on fundamental frequency discrimination",
  author   = "Bernstein, Joshua G W and Oxenham, Andrew J",
  abstract = "Fundamental frequency (f0) difference limens (DLs) were measured
              as a function of f0 for sine- and random-phase harmonic
              complexes, bandpass filtered with 3-dB cutoff frequencies of 2.5
              and 3.5 kHz (low region) or 5 and 7 kHz (high region), and
              presented at an average 15 dB sensation level (approximately 48
              dB SPL) per component in a wideband background noise. Fundamental
              frequencies ranged from 50 to 300 Hz and 100 to 600 Hz in the low
              and high spectral regions, respectively. In each spectral region,
              f0 DLs improved dramatically with increasing f0 as approximately
              the tenth harmonic appeared in the passband. Generally, f0 DLs
              for complexes with similar harmonic numbers were similar in the
              two spectral regions. The dependence of f0 discrimination on
              harmonic number presents a significant challenge to
              autocorrelation (AC) models of pitch, in which predictions
              generally depend more on spectral region than harmonic number. A
              modification involving a ``lag window''is proposed and tested,
              restricting the AC representation to a limited range of lags
              relative to each channel's characteristic frequency. This
              modified unitary pitch model was able to account for the
              dependence of f0 DLs on harmonic number, although this correct
              behavior was not based on peripheral harmonic resolvability.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  117,
  number   =  6,
  pages    = "3816--3831",
  year     =  2005,
  issn     = "0001-4966",
  pmid     = "16018484",
  doi      = "10.1121/1.1904268"
}

@ARTICLE{De_Cheveigne1998-ba,
  title    = "Cancellation model of pitch perception",
  author   = "de Cheveign{\'e}, Alain",
  abstract = "A model of pitch perception is presented involving an array of
              delay lines and inhibitory gating neurons. In response to a
              periodic sound, a minimum appears in the pattern of outputs of
              the inhibitory neurons at a lag equal to the period of the sound.
              The position of this minimum is the cue to pitch. The model is
              similar to the autocorrelation model of pitch, multiplication
              being replaced by an operation similar to subtraction, and maxima
              by minima. The two models account for a wide class of pitch
              phenomena in very much the same way. The principal goal of this
              paper is to demonstrate this fact. Several features of the
              cancellation model may be to its advantage: it is closely related
              to the operation of harmonic cancellation that can account for
              segregation of concurrent harmonic stimuli, it can be generalized
              to explain the perception of multiple pitches, and it shows a
              greater degree of sensitivity to phase than autocorrelation,
              which may allow it to explain certain phenomena that
              autocorrelation cannot account for.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  103,
  number   =  3,
  pages    = "1261--1271",
  year     =  1998,
  issn     = "0001-4966",
  pmid     = "9514016",
  doi      = "10.1121/1.423232"
}

@ARTICLE{Boomsliter1961-qs,
  title   = "The long pattern hypothesis in harmony and hearing",
  author  = "Boomsliter, P and Creel, W",
  journal = "Journal of Mathematics \& Music. Mathematical and Computational
             Approaches to Music Theory, Analysis, Composition and Performance",
  volume  =  5,
  number  =  1,
  pages   = "2--31",
  year    =  1961,
  issn    = "1745-9737, 0022-2909"
}

@ARTICLE{Licklider1951-hm,
  title   = "A duplex theory of pitch perception",
  author  = "Licklider, J C R",
  journal = "Experientia",
  volume  =  7,
  number  =  4,
  pages   = "128--134",
  year    =  1951,
  issn    = "0014-4754"
}

@BOOK{Polak1900-xs,
  title     = "{\"U}ber Zeitenheit in Bezug auf Konsonanz, Harmonie und
               Tonalit{\"a}t",
  author    = "Polak, A J",
  publisher = "Verlag Breitkopf \& H{\"a}rtel",
  year      =  1900,
  address   = "Leipzig, Germany"
}

@ARTICLE{Licklider1962-wv,
  title   = "Periodicity pitch and related auditory process models",
  author  = "Licklider, J C R",
  journal = "International Audiology",
  volume  =  1,
  number  =  1,
  pages   = "11--34",
  year    =  1962,
  doi     = "10.3109/05384916209074592"
}

@ARTICLE{Sugimoto2010-va,
  title    = "Preference for consonant music over dissonant music by an infant
              chimpanzee",
  author   = "Sugimoto, Tasuku and Kobayashi, Hiromi and Nobuyoshi, Noritomo
              and Kiriyama, Yasushi and Takeshita, Hideko and Nakamura,
              Tomoyasu and Hashiya, Kazuhide",
  journal  = "Primates; journal of primatology",
  volume   =  51,
  pages    = "7--12",
  year     =  2010,
  keywords = "chimpanzee {\'a} infant {\'a}; music {\'a} consonance {\'a}",
  issn     = "0032-8332",
  doi      = "10.1007/s10329-009-0160-3"
}

@ARTICLE{Chiandetti2011-bu,
  title    = "Chicks like consonant music",
  author   = "Chiandetti, Cinzia and Vallortigara, Giorgio",
  journal  = "Psychological science",
  volume   =  22,
  number   =  10,
  pages    = "1270--1273",
  year     =  2011,
  keywords = "11; 14; 7; a preference for consonance; comparative psychology;
              consonance; dissonance; domestic chick; enculturation;
              imprinting; innateness; is rooted; music; received 2; revision
              accepted 6; the question of whether",
  issn     = "0956-7976",
  doi      = "10.1177/0956797611418244"
}

@ARTICLE{Perani2010-jg,
  title   = "Functional specializations for music processing in the human
             newborn brain",
  author  = "Perani, Daniela and Cristina, Maria and Scifo, Paola and Spada,
             Danilo and Andreolli, Guido and Rovelli, Rosanna",
  journal = "Proceedings of the National Academy of Sciences",
  volume  =  107,
  number  =  10,
  pages   = "4758--4763",
  year    =  2010,
  doi     = "10.1073/pnas.0909074107"
}

@ARTICLE{Bidelman2011-we,
  title    = "Brainstem correlates of behavioral and compositional preferences
              of musical harmony",
  author   = "Bidelman, Gavin M and Krishnan, Ananthanarayan",
  journal  = "Neuroreport",
  volume   =  22,
  number   =  5,
  pages    = "212--216",
  year     =  2011,
  keywords = "auditory system; consonance-dissonance; harmony; music; pitch
              perception; pre-attentive",
  issn     = "0959-4965",
  doi      = "10.1097/WNR.0b013e328344a689"
}

@ARTICLE{Wand2012-op,
  title   = "On the conception and measure of consonance",
  author  = "Wand, Alex",
  journal = "Leonardo Music Journal",
  volume  =  22,
  pages   = "73--78",
  year    =  2012
}

@ARTICLE{Nordmark1988-pi,
  title   = "Beat theories of musical consonance",
  author  = "Nordmark, J and Fahl{\'e}n, L E",
  journal = "STL-QPSR",
  volume  =  29,
  number  =  1,
  pages   = "111--122",
  year    =  1988
}

@ARTICLE{Bidelman2011-lz,
  title   = "Auditory-nerve responses predict pitch attributes related to
             musical consonance-dissonance for normal and impaired hearing",
  author  = "Bidelman, Gavin M and Heinz, Michael G",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  130,
  number  =  3,
  pages   = "1488--1502",
  year    =  2011,
  issn    = "0001-4966",
  doi     = "10.1121/1.3605559"
}

@ARTICLE{Lundin1947-jn,
  title   = "Toward a cultural theory of consonance",
  author  = "Lundin, Robert W",
  journal = "The Journal of psychology",
  volume  =  23,
  number  =  1,
  pages   = "45--49",
  year    =  1947,
  issn    = "0022-3980",
  doi     = "10.1080/00223980.1947.9917318"
}

@ARTICLE{Cazden1980-gs,
  title   = "The definition of consonance and dissonance",
  author  = "Cazden, Norman",
  journal = "International Review of the Aesthetics and Sociology of Music",
  volume  =  11,
  number  =  2,
  pages   = "123--168",
  year    =  1980
}

@ARTICLE{Langner1997-ze,
  title   = "Temporal processing of pitch in the auditory system",
  author  = "Langner, Gerald",
  journal = "Journal of New Music Research",
  volume  =  26,
  number  =  2,
  pages   = "116--132",
  year    =  1997,
  doi     = "10.1080/09298219708570721"
}

@ARTICLE{Huron1992-jp,
  title   = "Critical bands and the spelling of vertical sonorities",
  author  = "Huron, David and Sellmer, Peter",
  journal = "Music perception",
  volume  =  10,
  number  =  2,
  pages   = "129--149",
  year    =  1992,
  issn    = "0730-7829"
}

@INPROCEEDINGS{Huron2002-si,
  title     = "A new theory of sensory dissonance: A role for perceived
               numerosity",
  booktitle = "Proceedings of the 7th International Conference for Music
               Perception and Cognition ({ICMPC-7})",
  author    = "Huron, David",
  year      =  2002,
  address   = "Sydney, Australia"
}

@ARTICLE{Cartwright2001-qa,
  title  = "Pitch perception : A dynamical-systems perspective",
  author = "Cartwright, Julyan H E and Gonza, Diego L and Piro, Oreste",
  volume =  98,
  number =  9,
  pages  = "4855--4859",
  year   =  2001
}

@ARTICLE{Dillon2013-ym,
  title   = "Calculating the dissonance of a chord according to Helmholtz",
  author  = "Dillon, Giorgio",
  journal = "European Physical Journal Plus",
  volume  =  128,
  number  =  90,
  year    =  2013,
  doi     = "10.1140/epjp/i2013-13090-4"
}

@ARTICLE{Otsuka2013-jo,
  title    = "Neuromagnetic Auditory Steady State Response to Chords : Effect
              of Frequency Ratio *",
  author   = "Otsuka, Asuka and Yumoto, Masato and Kuriki, Shinya and Nakagawa,
              Seiji",
  pages    = "4418--4421",
  year     =  2013,
  keywords = "MEG imaging; auditory cortex; consonance; dissonance; frequency
              characteristics; human; magnetoencephalography"
}

@ARTICLE{Guernsey1928-lo,
  title   = "The R{\^o}le of Consonance and Dissonance in Music",
  author  = "Guernsey, Martha",
  journal = "The American journal of psychology",
  volume  =  40,
  number  =  2,
  pages   = "173--204",
  year    =  1928,
  issn    = "0002-9556"
}

@ARTICLE{Bidelman2014-fs,
  title     = "Functional organization for musical consonance and tonal pitch
               hierarchy in human auditory cortex",
  author    = "Bidelman, Gavin M and Grall, Jeremy",
  journal   = "NeuroImage",
  publisher = "Elsevier Inc.",
  volume    =  101,
  pages     = "204--214",
  year      =  2014,
  keywords  = "Auditory event-related potentials (ERPs); Musical tonality;
               Neural organization; Pitch perception; Pitch-onset response
               (POR); auditory event-related potentials; erps",
  issn      = "1053-8119",
  doi       = "10.1016/j.neuroimage.2014.07.005"
}

@ARTICLE{Mcdermott2004-ik,
  title   = "Are consonant intervals music to their ears? Spontaneous acoustic
             preferences in a nonhuman primate",
  author  = "Mcdermott, Josh and Hauser, Marc",
  journal = "Cognition",
  volume  =  94,
  number  =  2,
  pages   = "B11--B21",
  year    =  2004,
  issn    = "0010-0277",
  doi     = "10.1016/j.cognition.2004.04.004"
}

@ARTICLE{Marin2015-mz,
  title     = "Affective evaluation of simultaneous tone combinations in
               congenital amusia",
  author    = "Marin, Manuela M and Forde, William and Gingras, Bruno and
               Stewart, Lauren",
  journal   = "Neuropsychologia",
  publisher = "Elsevier",
  volume    =  78,
  pages     = "207--220",
  year      =  2015,
  keywords  = "Chord quality; Congenital amusia; Consonance; Emotion; Pitch
               impairment",
  issn      = "0028-3932",
  doi       = "10.1016/j.neuropsychologia.2015.10.004"
}

@INPROCEEDINGS{Breen_undated-mt,
  title  = "Capturing and ranking perspectives on the consonance and dissonance
            of dyads",
  author = "Breen, Aidan and Riordan, Colm O",
  volume =  2015
}

@ARTICLE{Crespo-Bojorque2015-ta,
  title   = "The use of interval ratios in consonance perception by rats
             (Rattus norvegicus) and humans (Homo sapiens)",
  author  = "Crespo-Bojorque, Paola and Toro, Juan M",
  journal = "Journal of comparative psychology",
  volume  =  129,
  number  =  1,
  pages   = "42--51",
  year    =  2015,
  issn    = "0093-4127",
  doi     = "10.1037/a0037991"
}

@ARTICLE{Boersma1993-bt,
  title   = "Accurate short-term analysis of the fundamental frequency and the
             harmonics-to-noise ratio of a sampled sound",
  author  = "Boersma, Paul",
  journal = "Proceedings of the Institute of Phonetic Sciences",
  volume  =  17,
  number  =  1193,
  pages   = "97--110",
  year    =  1993
}

@ARTICLE{Cousineau2015-ud,
  title   = "On the relevance of natural stimuli for the study of brainstem
             correlates: The example of consonance perception",
  author  = "Cousineau, Marion and Bidelman, Gavin M and Peretz, Isabelle and
             Lehmann, Alexandre",
  journal = "PloS one",
  volume  =  10,
  number  =  12,
  year    =  2015,
  doi     = "10.1371/journal.pone.0145439"
}

@ARTICLE{Proverbio2016-qb,
  title    = "Brain processing of consonance/dissonance in musicians and
              controls: a hemispheric asymmetry revisited",
  author   = "Proverbio, Alice Mado and Orlandi, Andrea and Pisanu, Francesca",
  journal  = "The European journal of neuroscience",
  volume   =  44,
  number   =  6,
  pages    = "2340--2356",
  year     =  2016,
  keywords = "address for correspondence; aep; alice mado proverbio; atonal;
              auditory; dept of psychology; dissonance; dissonant intervals in
              musicians; emotions; erps; event-related potentials; expertise;
              hemisphere; keywords; left hemispheric asymmetry for; music;
              musicians; perception; running title; temporal; university of
              milano-",
  issn     = "0953-816X",
  doi      = "10.1111/ejn.13330"
}

@ARTICLE{Toro2017-kv,
  title    = "Consonance processing in the absence of relevant experience:
              Evidence from nonhuman animals",
  author   = "Toro, Juan M and Crespo-Bojorque, Paola",
  journal  = "Comparative cognition \& behavior reviews",
  volume   =  12,
  pages    = "33--44",
  year     =  2017,
  keywords = "consonance; interval ratios; rats; vocal learning",
  doi      = "10.3819/CCBR.2017.120004"
}

@INPROCEEDINGS{Skovenborg2002-oa,
  title     = "Measuring sensory consonance by auditory modelling",
  booktitle = "Proceedings of the 5th International Conference on Digital Audio
               Effects ({DAFX-02})",
  author    = "Skovenborg, Esben and Nielsen, S{\o}ren H",
  pages     = "251--256",
  year      =  2002,
  address   = "Hamburg, Germany"
}

@BOOK{Sethares2005-ko,
  title     = "Tuning, timbre, spectrum, scale",
  author    = "Sethares, William A",
  publisher = "Springer",
  year      =  2005,
  address   = "London, UK",
  isbn      = "9781852337971"
}

@ARTICLE{noauthor_undated-qq,
  title    = "Cross-cultural empirical aesthetics",
  keywords = "aesthetics; art; cross-cultural; disposition; universals",
  doi      = "10.1016/bs.pbr.2018.03.002"
}

@ARTICLE{Kaestner1909-xd,
  title   = "Untersuchungen {\"u}ber den Gef{\"u}hlseindruck unanalysierter
             Zweikl{\"a}nge",
  author  = "Kaestner, G",
  journal = "Psychologische Studien",
  volume  =  4,
  pages   = "473--504",
  year    =  1909
}

@BOOK{Lipps1885-ck,
  title     = "Psychologische Studien",
  author    = "Lipps, T",
  publisher = "Verlag G. Weiss",
  pages     = "92--161",
  year      =  1885,
  address   = "Heidelberg, Germany"
}

@BOOK{Preyer1879-xu,
  title     = "Akustiche Untersuchungen",
  author    = "Preyer, W",
  publisher = "Verlag G. Fischer",
  pages     = "44--61",
  year      =  1879,
  address   = "Jena, Germany"
}

@ARTICLE{Krueger1904-ak,
  title   = "Differenzt{\"o}ne und Konsonanz",
  author  = "Krueger, F",
  journal = "Archiv fur die gesamte Psychologie",
  volume  =  2,
  pages   = "1--80",
  year    =  1904,
  issn    = "0724-7842"
}

@ARTICLE{Wild2002-yg,
  title   = "The computation behind consonance and dissonance",
  author  = "Wild, Jan",
  journal = "Interdisciplinary science reviews: ISR",
  volume  =  27,
  number  =  4,
  pages   = "299--302",
  year    =  2002,
  issn    = "0308-0188",
  doi     = "10.1179/030801802225005662"
}

@ARTICLE{Itoh2003-nq,
  title    = "Ear advantage and consonance of dichotic pitch intervals in
              absolute-pitch possessors",
  author   = "Itoh, Kosuke and Miyazaki, Ken {\~O} and Nakada, Tsutomu",
  journal  = "Brain and cognition",
  volume   =  53,
  pages    = "464--471",
  year     =  2003,
  keywords = "chord; consonance; ear advantage; harmony; hemispheric asymmetry;
              interval",
  issn     = "0278-2626",
  doi      = "10.1016/S0278-2626(03)00236-7"
}

@ARTICLE{Andor2001-wz,
  title   = "Physical basis of two-tone interference in hearing",
  author  = "Andor, Daniel and Duke, Thomas and Ju, Frank",
  journal = "Proceedings of the National Academy of Sciences",
  volume  =  98,
  number  =  16,
  pages   = "9080--9085",
  year    =  2001,
  doi     = "10.1073/pnas.151257898"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Peretz2001-jo,
  title    = "Cortical deafness to dissonance",
  author   = "Peretz, Isabelle and Blood, Anne J and Penhune, Virginia and
              Zatorre, Robert",
  journal  = "Brain: a journal of neurology",
  volume   =  124,
  number   =  5,
  pages    = "928--940",
  year     =  2001,
  keywords = "abbreviation; amusia; auditory cortex; auditory disorder; blood
              flow; musical emotions; perception of dissonance; rcbf ϭ regional
              cerebral",
  issn     = "0006-8950"
}

@ARTICLE{Tramo2001-ae,
  title   = "Neurobiological foundations for the theory of harmony in Western
             tonal music",
  author  = "Tramo, Mark Jude and Cariani, Peter A and Delgutte, Bertrand",
  journal = "Annals of the New York Academy of Sciences",
  volume  =  930,
  pages   = "92--116",
  year    =  2001,
  issn    = "0077-8923"
}

@ARTICLE{Fishman2001-yy,
  title   = "Consonance and dissonance of musical chords: Neural correlates in
             auditory cortex of monkeys and humans",
  author  = "Fishman, Yonatan I and Volkov, Igor O and Noh, M Daniel and
             Garell, P Charles and Bakken, Hans and Arezzo, Joseph C and
             Howard, Matthew A and Steinschneider, Mitchell",
  journal = "Journal of neurophysiology",
  volume  =  86,
  number  =  6,
  pages   = "2761--2788",
  year    =  2001,
  issn    = "0022-3077"
}

@ARTICLE{Bodner2007-lt,
  title   = "The unexpected side-effects of dissonance",
  author  = "Bodner, Ehud and Gilboa, Avi and Amir, Dorit",
  journal = "Psychology of Music",
  volume  =  35,
  number  =  286,
  pages   = "286--305",
  year    =  2007,
  doi     = "10.1177/0305735607070381"
}

@ARTICLE{Izumi2000-ui,
  title   = "Japanese monkeys perceive sensory consonance of chords",
  author  = "Izumi, Akihiro",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  108,
  number  =  6,
  pages   = "3073--3078",
  year    =  2000,
  issn    = "0001-4966"
}

@ARTICLE{Masataka2006-eq,
  title   = "Preference for consonance over dissonance by hearing newborns of
             deaf parents and of hearing parents",
  author  = "Masataka, Nobuo",
  journal = "Developmental science",
  volume  =  9,
  number  =  1,
  pages   = "46--50",
  year    =  2006,
  issn    = "1363-755X",
  doi     = "10.1111/j.1467-7687.2005.00462.x"
}

@ARTICLE{Schon2005-ao,
  title   = "Sensory consonance: An {ERP} study",
  author  = "Sch{\"o}n, Daniele and Regnault, Pascaline and Ystad, S{\o}lvi and
             Besson, Mireille",
  journal = "Music perception",
  volume  =  23,
  number  =  2,
  pages   = "105--117",
  year    =  2005,
  issn    = "0730-7829",
  doi     = "10.1525/mp.2005.23.2.105"
}

@ARTICLE{Kuusi2005-cl,
  title   = "The consonance and the context guiding the participants' ratings
             of chords representing different set-classes",
  author  = "Kuusi, Tuire",
  journal = "Musicae scientiae: the journal of the European Society for the
             Cognitive Sciences of Music",
  volume  = "IX",
  number  =  2,
  pages   = "313--339",
  year    =  2005,
  issn    = "1029-8649",
  doi     = "10.1177/102986490500900209"
}

@ARTICLE{Klemenz2005-md,
  title   = "Sound Synthesis of Starting Electric Railbound Vehicles and the
             Influence of Consonance on Sound Quality",
  author  = "Klemenz, Martin",
  journal = "Acta Acustica united with Acustica",
  volume  =  91,
  number  =  4,
  pages   = "779--788",
  year    =  2005
}

@ARTICLE{Watanabe2005-zq,
  title    = "Discrimination of consonance and dissonance in Java sparrows",
  author   = "Watanabe, S and Uozumi, M and Tanaka, N",
  journal  = "Behavioural processes",
  volume   =  70,
  number   =  2,
  pages    = "203--208",
  year     =  2005,
  keywords = "auditory discrimination; chord; music",
  issn     = "0376-6357",
  doi      = "10.1016/j.beproc.2005.06.001"
}

@ARTICLE{Tufts2005-gy,
  title   = "Perception of dissonance by people with normal hearing and
             sensorineural hearing loss",
  author  = "Tufts, Jennifer B and Molis, Michelle R and Leek, Marjorie R",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  118,
  number  =  2,
  pages   = "955--967",
  year    =  2005,
  issn    = "0001-4966",
  doi     = "10.1121/1.1942347"
}

@ARTICLE{Duke2003-ff,
  title  = "Physical Basis of Interference Effects in Hearing",
  author = "Duke, Thomas and Andor, Dan",
  volume =  2,
  pages  = "667--669",
  year   =  2003,
  doi    = "10.1007/s00023-003-0951-9"
}

@ARTICLE{Kursell2008-aa,
  title    = "Hermann von Helmholtz und Carl Stumpf {\"u}ber Konsonanz und
              Dissonanz",
  author   = "Kursell, Julia",
  journal  = "Berichte zur Wissenschaftsgeschichte",
  volume   =  31,
  number   =  2,
  pages    = "130--143",
  year     =  2008,
  keywords = "consonance; disso-; dissonance; experiment; hearing; h{\"o}ren;
              konsonanz; physiologie; physiology; psychologie; psychology;
              schl{\"u}sselw{\"o}rter",
  issn     = "0170-6233",
  doi      = "10.1002/bewi.200801314"
}

@ARTICLE{Sethares1997-ny,
  title   = "Specifying spectra for musical scales",
  author  = "Sethares, William A",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  102,
  number  =  4,
  pages   = "2422--2431",
  year    =  1997,
  issn    = "0001-4966",
  doi     = "10.1121/1.419604"
}

@ARTICLE{Foss2007-uv,
  title    = "Neural correlates of the Pythagorean ratio rules",
  author   = "Foss, Alexander H and Altschuler, Eric L and James, Karin H",
  journal  = "Neuroreport",
  volume   =  18,
  number   =  15,
  pages    = "1521--1525",
  year     =  2007,
  keywords = "anterior cingulate respond; functional mri; gyrus; in musicians;
              inferior frontal gyrus; inferior parietal lobule and; medial
              frontal; neural correlates; pythagorean ratio rules; superior
              temporal gyrus; the; the neurophysiologic correlates of; the
              ratio rules",
  issn     = "0959-4965",
  doi      = "10.1097/WNR.0b013e3282ef6b51"
}

@ARTICLE{Frosch2007-pe,
  title   = "Psycho-acoustic experiments on the sensory consonance of musical
             two-tones",
  author  = "Frosch, Reinhart",
  journal = "Canadian Acoustics - Acoustique Canadienne",
  volume  =  35,
  number  =  3,
  pages   = "38--45",
  year    =  2007
}

@ARTICLE{Passynkova2007-dz,
  title    = "Spatial organization of {EEG} coherence during listening to
              consonant and dissonant chords",
  author   = "Passynkova, Natalia and Neubauer, Heinrich and Scheich, Henning",
  journal  = "Neuroscience letters",
  volume   =  412,
  number   =  1,
  pages    = "6--11",
  year     =  2007,
  keywords = "central to harmony is; consonance; damental principles of
              western; dissonance; e; eeg coherence; fun-; harmony or vertical
              structure; i; into chords; is one of the; music; musical harmony;
              of music; of simultaneous musical sounds; the combination",
  issn     = "0304-3940",
  doi      = "10.1016/j.neulet.2006.09.029"
}

@ARTICLE{Rogers2007-xb,
  title   = "Memory for musical intervals: Cognitive differences for consonance
             and dissonance",
  author  = "Rogers, Susan E and Levitin, Daniel J",
  journal = "Canadian Acoustics - Acoustique Canadienne",
  volume  =  35,
  number  =  3,
  pages   = "56--57",
  year    =  2007
}

@ARTICLE{DeWitt1987-jh,
  title   = "Tonal fusion of consonant musical intervals: The oomph in Stumpf",
  author  = "DeWitt, Lucinda A and Crowder, Robert G",
  journal = "Perception and Psychophysics",
  volume  =  41,
  number  =  1,
  pages   = "73--84",
  year    =  1987
}

@ARTICLE{Mazzola1989-sh,
  title   = "A symmetry-oriented mathematical model of classical counterpoint
             and related neurophysiological investigations by depth {EEG}",
  author  = "Mazzola, G and Wieser, Heinz-Gregor and Brunner, V and Muzzulini,
             D",
  journal = "Computers \& mathematics with applications",
  volume  =  17,
  number  = "4-6",
  pages   = "539--594",
  year    =  1989,
  issn    = "0898-1221",
  doi     = "10.1016/0898-1221(89)90250-2"
}

@ARTICLE{Fung1996-tu,
  title   = "Musicians' and nonmusicians' preferences for world musics:
             Relation to musical characteristics and familiarity",
  author  = "Fung, C Victor",
  journal = "Journal of Research in Music Education",
  volume  =  44,
  number  =  1,
  pages   = "60--83",
  year    =  1996,
  doi     = "10.2307/3345414"
}

@ARTICLE{Sethares1994-si,
  title   = "Adaptive tunings for musical scales",
  author  = "Sethares, William A",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  96,
  number  =  1,
  pages   = "10--18",
  year    =  1994,
  issn    = "0001-4966",
  doi     = "10.1121/1.410471"
}

@ARTICLE{Tramo1990-nv,
  title   = "Music perception and cognition following bilateral lesions of
             auditory cortex",
  author  = "Tramo, Mark Jude and Bharucha, Jamshed J and Musiek, Frank E",
  journal = "Journal of cognitive neuroscience",
  volume  =  2,
  number  =  3,
  pages   = "195--212",
  year    =  1990,
  issn    = "0898-929X",
  doi     = "10.1162/jocn.1990.2.3.195"
}

@ARTICLE{Parncutt1994-gf,
  title   = "Template-matching models of musical pitch and rhythm perception",
  author  = "Parncutt, Richard",
  journal = "Journal of New Music Research",
  volume  =  23,
  number  =  2,
  pages   = "145--167",
  year    =  1994,
  doi     = "10.1080/09298219408570653"
}

@ARTICLE{Smith1997-gn,
  title   = "A ``cumulative'' method of quantifying tonal consonance in musical
             key contexts",
  author  = "Smith, Allan B",
  journal = "Music perception",
  volume  =  15,
  number  =  2,
  pages   = "175--188",
  year    =  1997,
  issn    = "0730-7829",
  doi     = "10.2307/40285748"
}

@ARTICLE{Metz1981-ko,
  title   = "A psychophysical study of the perception of consonance and
             dissonance",
  author  = "Metz, Stephen and Pick, Anne D and Unze, Marsha G",
  journal = "Bulletin of the Psychonomic Society",
  volume  =  17,
  number  =  2,
  pages   = "89--92",
  year    =  1981,
  issn    = "0090-5054"
}

@INCOLLECTION{Schneider1997-rn,
  title     = "``Verschmelzung'', tonal fusion, and consonance: Carl Stumpf
               revisited",
  booktitle = "Music, Gestalt, and Computing: Studies in Cognitive and
               Systematic Musicology",
  author    = "Schneider, Albert",
  editor    = "Leman, Marc",
  pages     = "115--143",
  year      =  1997,
  doi       = "10.1007/BFb0034111"
}

@ARTICLE{Van_de_Geer1962-am,
  title   = "The connotation of musical consonance",
  author  = "van de Geer, W J and Levelt, W J M and Plomp, R",
  journal = "Acta psychologica",
  volume  =  20,
  number  =  4,
  pages   = "308--319",
  year    =  1962,
  issn    = "0001-6918",
  doi     = "10.1016/0001-6918(62)90028-8"
}

@ARTICLE{Wieser1986-lo,
  title   = "Musical consonances and dissonances: Are they distinguished
             independently by the right and left hippocampi?",
  author  = "Wieser, Heinz-Gregor and Mazzola, Guerino",
  journal = "Neuropsychologia",
  volume  =  24,
  number  =  6,
  pages   = "805--812",
  year    =  1986,
  issn    = "0028-3932",
  doi     = "10.1016/0028-3932(86)90079-5"
}

@ARTICLE{Danner1985-ki,
  title   = "The use of acoustic measures of dissonance to characterize
             pitch-class sets",
  author  = "Danner, Gregory",
  journal = "Music perception",
  volume  =  3,
  number  =  1,
  pages   = "103--122",
  year    =  1985,
  issn    = "0730-7829"
}

@ARTICLE{Terhardt1984-im,
  title   = "The concept of musical consonance: A link between music and
             psychoacoustics",
  author  = "Terhardt, Ernst",
  journal = "Music perception",
  volume  =  1,
  number  =  3,
  pages   = "276--295",
  year    =  1984,
  issn    = "0730-7829"
}

@ARTICLE{Wright1987-su,
  title   = "Auditory stream segregation and the control of dissonance in
             polyphonic music",
  author  = "Wright, James K and Bregman, Albert S",
  journal = "Contemporary Music Review",
  volume  =  2,
  pages   = "63--93",
  year    =  1987
}

@ARTICLE{Omigie2017-dj,
  title   = "Effects of learning on dissonance judgments",
  author  = "Omigie, Diana and Dellacherie, Delphine and Samson, S{\'e}verine",
  journal = "Journal of Interdisciplinary Music Studies",
  volume  =  8,
  number  = "1-2",
  pages   = "11--28",
  year    =  2017,
  doi     = "10.4407/jims.2016.12.001"
}

@ARTICLE{Pierce1966-si,
  title   = "Attaining consonance in arbitrary scales",
  author  = "Pierce, J R",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  40,
  number  =  1,
  pages   = "249",
  year    =  1966,
  issn    = "0001-4966"
}

@ARTICLE{Slaymaker1970-uy,
  title   = "Chords from tones having stretched partials",
  author  = "Slaymaker, Frank H",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  47,
  pages   = "1569--1571",
  year    =  1970,
  issn    = "0001-4966",
  doi     = "10.1121/1.1912089"
}

@ARTICLE{Bugg1939-bk,
  title   = "An analysis of conditions influencing consonance discrimination",
  author  = "Bugg, Eugene G",
  journal = "Journal of experimental psychology",
  volume  =  24,
  number  =  1,
  pages   = "54--72",
  year    =  1939,
  issn    = "0022-1015"
}

@ARTICLE{Borchgrevink1975-ve,
  title   = "Musical consonance preference in man elucidated by animal
             experiments (Norwegian)",
  author  = "Borchgrevink, H M",
  journal = "Tidsskrift for den Norske laegeforening: tidsskrift for praktisk
             medicin, ny raekke",
  volume  =  95,
  number  =  6,
  pages   = "356--358",
  year    =  1975,
  issn    = "0029-2001"
}

@ARTICLE{Parncutt2018-uj,
  title   = "Consonance and prevalence of sonorities in Western polyphony:
             Roughness, harmonicity, familiarity, evenness, diatonicity",
  author  = "Parncutt, Richard and Reisinger, Daniel and Fuchs, Andreas and
             Kaiser, Fabio",
  journal = "Journal of New Music Research",
  volume  =  48,
  number  =  1,
  year    =  2018,
  doi     = "10.1080/09298215.2018.1477804"
}

@ARTICLE{Geary1980-bo,
  title   = "Consonance and dissonance of pairs of inharmonic sounds",
  author  = "Geary, J M",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  67,
  number  =  5,
  pages   = "1785--1789",
  year    =  1980,
  issn    = "0001-4966",
  doi     = "10.1121/1.384307"
}

@ARTICLE{Ayres_T_Aeschbach_S1980-ul,
  title   = "Psychoacoustic and experiential determinants of tonal consonance",
  author  = "Ayres T., Aeschbach S., Walker E L",
  journal = "The Journal of auditory research",
  volume  =  20,
  number  =  1,
  pages   = "31--42",
  year    =  1980,
  issn    = "0021-9177"
}

@ARTICLE{Heffernan2009-et,
  title    = "Pulse-coupled neuron models as investigative tools for musical
              consonance",
  author   = "Heffernan, B and Longtin, A",
  journal  = "Journal of neuroscience methods",
  volume   =  183,
  number   =  1,
  pages    = "95--106",
  year     =  2009,
  keywords = "leaky integrate-and-fire",
  issn     = "0165-0270",
  doi      = "10.1016/j.jneumeth.2009.06.041"
}

@ARTICLE{Cook2009-ks,
  title    = "Harmony perception: Harmoniousness is more than the sum of
              interval consonance",
  author   = "Cook, Norman D",
  journal  = "Music perception",
  volume   =  27,
  number   =  1,
  pages    = "25--41",
  year     =  2009,
  keywords = "harmony perception; major; minor; tension",
  issn     = "0730-7829",
  doi      = "10.1525/MP.2009.27.1.25"
}

@INPROCEEDINGS{Ebeling2007-kb,
  title     = "Calculating tonal fusion by the generalized coincidence function",
  booktitle = "International Conference on Mathematics and Computation in Music",
  author    = "Ebeling, Martin",
  publisher = "Springer",
  pages     = "140--155",
  year      =  2007,
  address   = "Berlin, Germany",
  doi       = "10.1007/978-3-642-04579-0\_14"
}

@ARTICLE{Arthurs2018-da,
  title    = "Perception of isolated chords: Examining frequency of occurrence,
              instrumental timbre, acoustic descriptors and musical training",
  author   = "Arthurs, Yuko and Beeston, Amy V and Timmers, Renee",
  abstract = "This study investigated the perception of isolated chords using a
              combination of experimental manipulation and exploratory
              analysis. Twelve types of chord (five triads and seven tetrads)
              were presented in two instrumental timbres (piano and organ) to
              listeners who rated the chords for consonance, pleasantness,
              stability and relaxation. Listener ratings varied by chord, by
              timbre, and according to musical expertise, and revealed that
              musicians distinguish consonance from the other variables in a
              way that other listeners did not. To further explain the data, a
              principal component analysis and linear regression examined three
              potential predictors of the listener ratings. First, each chord's
              frequency of occurrence was obtained by counting its appearances
              in selected works of music. Second, listeners rated their
              familiarity with the instrumental timbre in which the chord was
              played. Third, chords were described using a set of acoustic
              features derived using the Timbre Toolbox and MIR Toolbox.
              Results of the study indicated that listeners' ratings of both
              consonance and stability were influenced by the degree of musical
              training and knowledge of tonal hierarchy. Listeners' ratings of
              pleasantness and relaxation, on the other hand, depended more on
              the instrumental timbre and other acoustic descriptions of the
              chord.",
  journal  = "Psychology of Music",
  volume   =  46,
  number   =  5,
  pages    = "662--681",
  year     =  2018,
  keywords = "a single chord can; a single chord has; but also the power;
              consonance; frequency of occurrence; in the listener; musical
              chords; musical training; not only physical sonority; play a
              significant role; s experience; timbre familiarity; to an; to
              refer the listener; underlying tonal hierarchy",
  doi      = "10.1177/0305735617720834"
}

@ARTICLE{Trainor1998-id,
  title   = "The development of evaluative responses to music: Infants prefer
             to listen to consonance over dissonance",
  author  = "Trainor, Laurel J and Heinmiller, Becky M",
  journal = "Infant behavior \& development",
  volume  =  21,
  number  =  1,
  pages   = "77--88",
  year    =  1998,
  issn    = "0163-6383",
  doi     = "10.1016/S0163-6383(98)90055-8"
}

@ARTICLE{Costa2000-mq,
  title   = "Psychological connotations of harmonic musical intervals",
  author  = "Costa, Marco and Bitti, Pio Enrico Ricci and Bonfiglioli, Luisa",
  journal = "Psychology of Music",
  volume  =  28,
  number  =  1,
  pages   = "4--22",
  year    =  2000
}

@ARTICLE{Kamo2000-km,
  title    = "Evolution of preference for consonances as a by-product",
  author   = "Kamo, Masashi and Iwasa, Yoh",
  journal  = "Evolutionary ecology research",
  volume   =  2,
  pages    = "375--383",
  year     =  2000,
  keywords = "auditory signals; consonance and dissonance; evolution of biased
              preference; generalization; harmonics; neural network",
  issn     = "1522-0613"
}

@ARTICLE{Dibben1999-af,
  title   = "The perception of structural stability in atonal music: The
             influence of salience, stability, horizontal motion, pitch
             commonality, and dissonance",
  author  = "Dibben, Nicola",
  journal = "Music perception",
  volume  =  16,
  number  =  3,
  pages   = "265--294",
  year    =  1999,
  issn    = "0730-7829",
  doi     = "10.2307/40285794"
}

@ARTICLE{Zentner1998-hr,
  title   = "Infants' perception of consonance and dissonance in music",
  author  = "Zentner, Marcel R and Kagan, Jerome",
  journal = "Infant behavior \& development",
  volume  =  21,
  number  =  3,
  pages   = "483--492",
  year    =  1998,
  issn    = "0163-6383"
}

@ARTICLE{Lots2008-ug,
  title    = "Perception of musical consonance and dissonance: An outcome of
              neural synchronization",
  author   = "Lots, Inbal Shapira and Stone, Lewi",
  journal  = "Journal of the Royal Society, Interface / the Royal Society",
  volume   =  5,
  number   =  29,
  pages    = "1429--1434",
  year     =  2008,
  keywords = "consonance; coupled oscillator; dissonance; mode locking; musical
              interval; neural synchronization",
  issn     = "1742-5689",
  doi      = "10.1098/rsif.2008.0143"
}

@ARTICLE{Perchy2016-ug,
  title  = "{DISSONANCES} : {BRIEF} {DESCRIPTION} {AND} {ITS} {COMPUTATIONAL}
            {REPRESENTATION} {IN} {THE} {RTCC} {CALCULUS} Salim Perchy ,
            Gerardo Sarria To cite this version : {HAL} Id : hal-01257147",
  author = "Perchy, Salim and Sarria, Gerardo and Brief, Dissonances and
            Computa-, I T S",
  year   =  2016
}

@ARTICLE{Minati2009-xx,
  title    = "Functional {MRI/Event-related} potential study of sensory
              consonance and dissonance in musicians and nonmusicians",
  author   = "Minati, Ludovico and Rosazza, Cristina and Incerti, Ludovico D
              and Pietrocini, Emanuela and Valentini, Laura and Scaioli, Vidmer
              and Loveday, Catherine and Grazia, Maria Grazia",
  journal  = "Neuroreport",
  volume   =  20,
  number   =  1,
  pages    = "87--92",
  year     =  2009,
  keywords = "c neurosurgery; chords; departments of b neuroradiology;
              event-related potential component; event-related potentials;
              functional mri; helmholtz; lateralization; n2 event-related
              potential component; p1; pythagorean ratios; s; science direction
              unit; sensory consonance; theory",
  issn     = "0959-4965",
  doi      = "10.1097/WNR.0b013e32831af235"
}

@ARTICLE{Fisher2018-bu,
  title   = "Model Class Reliance: Variable importance measures for any machine
             learning model class, from the ``Rashomon'' perspective",
  author  = "Fisher, Aaron and Rudin, Cynthia and Dominici, Francesca",
  year    =  2018,
  arxivid = "1801.01489v2"
}

@INPROCEEDINGS{Weisser2013-kr,
  title     = "Investigating non-Western musical timbre: A need for joint
               approaches",
  booktitle = "Proceedings of the Third International Workshop on Folk Music
               Analysis",
  author    = "Weisser, St{\'e}phanie and Lartillot, Olivier",
  pages     = "33--39",
  year      =  2013,
  address   = "Amsterdam, The Netherlands",
  isbn      = "9789070389789"
}

@ARTICLE{Trulla2018-nv,
  title    = "Computational approach to musical consonance and dissonance",
  author   = "Trulla, Lluis L and Stefano, Nicola Di and Giuliani, Alessandro",
  journal  = "Frontiers in psychology",
  volume   =  9,
  year     =  2018,
  keywords = "Devil's staircase; beating; complex systems; non-linear signal
              analysis methods; recurrence quantification analysis",
  doi      = "10.3389/fpsyg.2018.00381"
}

@TECHREPORT{Lartillot2014-xc,
  title   = "{MIRtoolbox} 1.6.1 User's manual",
  author  = "Lartillot, Olivier",
  year    =  2014,
  address = "Aalborg, Denmark"
}

@BOOK{Dahlhaus1990-ql,
  title     = "Studies on the origin of harmonic tonality",
  author    = "Dahlhaus, Carl",
  publisher = "Princeton University Press",
  year      =  1990,
  address   = "Princeton, NJ"
}

@INPROCEEDINGS{Bogdanov2013-po,
  title     = "Essentia: An audio analysis library for music
               informationretrieval",
  booktitle = "Proceedings of the 14th International Society for Music
               Information Retrieval Conference",
  author    = "Bogdanov, Dmitry and Wack, Nicolas and G{\'o}mez, Emilia and
               Gulati, Sankalp and Herrera, Perfecto and Mayor, Oscar and Roma,
               Gerard and Salamon, Justin and Zapata, J and Serra, Xavier",
  year      =  2013,
  address   = "Curitiba, Brazil"
}

@ARTICLE{Camerer2018-px,
  title     = "Evaluating the replicability of social science experiments in
               Nature and Science between 2010 and 2015",
  author    = "Camerer, Colin F and Dreber, Anna and Holzmeister, Felix and Ho,
               Teck-Hua and Huber, J{\"u}rgen and Johannesson, Magnus and
               Kirchler, Michael and Nave, Gideon and Nosek, Brian A and
               Pfeiffer, Thomas and Altmejd, Adam and Buttrick, Nick and Chan,
               Taizan and Chen, Yiling and Forsell, Eskil and Gampa, Anup and
               Heikensten, Emma and Hummer, Lily and Imai, Taisuke and
               Isaksson, Siri and Manfredi, Dylan and Rose, Julia and
               Wagenmakers, Eric-Jan and Wu, Hang",
  journal   = "Nature Human Behaviour",
  publisher = "Springer US",
  volume    =  2,
  number    = "September",
  year      =  2018,
  issn      = "2397-3374",
  doi       = "10.1038/s41562-018-0399-z"
}

@ARTICLE{Cross2006-mc,
  title   = "Music, cognition, culture, and evolution",
  author  = "Cross, Ian",
  journal = "Annals of the New York Academy of Sciences",
  volume  =  930,
  number  =  1,
  pages   = "28--42",
  year    =  2006,
  issn    = "0077-8923",
  doi     = "10.1111/j.1749-6632.2001.tb05723.x"
}

@INCOLLECTION{Stainsby2009-hc,
  title     = "The perception of pitch",
  booktitle = "The Oxford handbook of music psychology",
  author    = "Stainsby, Thomas and Cross, Ian",
  editor    = "Hallam, Susan and Cross, Ian and Thaut, Michael",
  publisher = "Oxford University Press",
  pages     = "47--58",
  year      =  2009,
  address   = "New York, NY"
}

@ARTICLE{Heim2003-eg,
  title    = "Distributed cortical networks for syntax processing: Broca's area
              as the common denominator",
  author   = "Heim, St and Opitz, B and Friederici, A D",
  abstract = "Different types of syntactic information (word category,
              grammatical gender) are processed at different times during word
              recognition. However, it is an open issue which brain systems
              support these processes. In the present event-related fMRI study,
              subjects performed either a syntactic gender decision task on
              German nouns (GEN), a word category decision task (WC, nouns vs.
              prepositions), or a physical baseline task (BASE). Reaction times
              in WC were faster than in GEN, supporting earlier
              electrophysiological results. Relative to BASE, both syntactic
              tasks activated the inferior tip of BA 44. In addition, BA 45
              showed activation in GEN, whereas BA 47 was activated in WC. The
              imaging data indicate that the inferior portion of BA 44 together
              with type-specific prefrontal areas supports both initial word
              category related and later syntactic processes. \copyright{} 2003
              Elsevier Science (USA). All rights reserved.",
  journal  = "Brain and language",
  volume   =  85,
  number   =  3,
  pages    = "402--408",
  year     =  2003,
  keywords = "Broca's area; Gender; Language comprehension; Syntax; Word
              category; fMRI",
  issn     = "0093-934X",
  pmid     = "12744952",
  doi      = "10.1016/S0093-934X(03)00068-3"
}

@ARTICLE{Bornstein1989-xn,
  title   = "Exposure and affect: Overview and meta-analysis of research,
             1968-1987",
  author  = "Bornstein, Robert F",
  journal = "Psychological bulletin",
  volume  =  106,
  number  =  2,
  pages   = "265--289",
  year    =  1989,
  issn    = "0033-2909",
  doi     = "10.1037/0033-2909.106.2.265"
}

@ARTICLE{Jakubowski2016-hq,
  title   = "Dissecting an earworm: Melodic features and song popularity
             predict involuntary musical imagery",
  author  = "Jakubowski, Kelly and Finkel, Sebastian and Stewart, Lauren and
             M{\"u}llensiefen, Daniel",
  journal = "Psychology of Aesthetics, Creativity, and the Arts",
  volume  =  11,
  number  =  2,
  pages   = "122--135",
  year    =  2016,
  issn    = "1931-390X",
  doi     = "10.1037/aca0000090"
}

@ARTICLE{Strange2005-dh,
  title    = "Information theory, novelty and hippocampal responses:
              Unpredicted or unpredictable?",
  author   = "Strange, Bryan A and Duggins, Andrew and Penny, William and
              Dolan, Raymond J and Friston, Karl J",
  abstract = "Shannon's information theory provides a principled framework for
              the quantitative analysis of brain responses during the encoding
              and representation of event streams. In particular, entropy
              measures the expected uncertainty of events in a given context.
              This contextual uncertainty or unpredictability may, itself, be
              important for balancing [bottom-up] sensory information and
              [top-down] prior expectations during perceptual synthesis. Using
              event-related functional magnetic resonance imaging (fMRI), we
              found that the anterior hippocampus is sensitive to the entropy
              of a visual stimulus stream. In contrast, activity in an
              extensive bilateral cortico-thalamic network was dictated by the
              surprise or information associated with each particular stimulus.
              In short, we show that the probabilistic structure or context in
              which events occur is an important predictor of hippocampal
              activity. \copyright{} 2005 Elsevier Ltd. All rights reserved.",
  journal  = "Neural networks: the official journal of the International Neural
              Network Society",
  volume   =  18,
  number   =  3,
  pages    = "225--230",
  year     =  2005,
  keywords = "Entropy; Functional magnetic resonancce imaging; Hippocampus;
              Information theory; Novelty; Predictive coding; Surprise",
  issn     = "0893-6080",
  pmid     = "15896570",
  doi      = "10.1016/j.neunet.2004.12.004"
}

@ARTICLE{Koelsch2002-qz,
  title    = "Bach speaks: A cortical ``language-network'' serves the
              processing of music",
  author   = "Koelsch, Stefan and Gunter, Thomas C and V. Cramon, D Yves and
              Zysset, Stefan and Lohmann, Gabriele and Friederici, Angela D",
  abstract = "The aim of the present study was the investigation of neural
              correlates of music processing with fMRI. Chord sequences were
              presented to the participants, infrequently containing unexpected
              musical events. These events activated the areas of Broca and
              Wernicke, the superior temporal sulcus, Heschl's gyrus, both
              planum polare and planum temporale, as well as the anterior
              superior insular cortices. Some of these brain structures have
              previously been shown to be involved in music processing, but the
              cortical network comprising all these structures has up to now
              been thought to be domain-specific for language processing. To
              what extent this network might also be activated by the
              processing of non-linguistic information has remained unknown.
              The present fMRI-data reveal that the human brain employs this
              neuronal network also for the processing of musical information,
              suggesting that the cortical network known to support language
              processing is less domain-specific than previously believed.
              \copyright{} 2002 Elsevier Science (USA).",
  journal  = "NeuroImage",
  volume   =  17,
  number   =  2,
  pages    = "956--966",
  year     =  2002,
  keywords = "Brain; Broca; FMRI; Insular cortex; Language; Modulation; Music;
              Superior temporal gyrus; Superior temporal sulcus; Wer-nicke",
  issn     = "1053-8119",
  pmid     = "12377169",
  doi      = "10.1016/S1053-8119(02)91154-7"
}

@ARTICLE{Benedek2011-wb,
  title     = "Physiological correlates and emotional specificity of human
               piloerection",
  author    = "Benedek, Mathias and Kaernbach, Christian",
  abstract  = "Piloerection is known as an indicator of strong emotional
               experiences. However, little is known about the physiological
               and emotional specificity of this psychophysiological response.
               In the presented study, piloerection was elicited by audio
               stimuli taken from music and film episodes. The physiological
               response accompanying the incidence of piloerection was recorded
               with respect to electrodermal, cardiovascular and respiratory
               measures and compared to a matched control condition. The
               employment of an optical recording system allowed for a direct
               and objective assessment of visible piloerection. The occurrence
               of piloerection was primarily accompanied by an increase of
               phasic electrodermal activity and increased respiration depth as
               compared to a matched control condition. This physiological
               response pattern is discussed in the context of dominant
               theories of human piloerection. Consideration of all available
               evidence suggests that emotional piloerection represents a
               valuable indicator of the state of being moved or touched.
               \copyright{} 2011 Elsevier B.V.",
  journal   = "Biological psychology",
  publisher = "Elsevier B.V.",
  volume    =  86,
  number    =  3,
  pages     = "320--329",
  year      =  2011,
  keywords  = "Being moved; Being touched; Cardiovascular system; Electrodermal
               system; Emotion; Goose bumps; Piloerection; Respiratory system",
  issn      = "0301-0511",
  pmid      = "21276827",
  doi       = "10.1016/j.biopsycho.2010.12.012"
}

@INPROCEEDINGS{Leman2000-nc,
  title     = "Visualization and calculation of the roughness of acoustical
               music signals using the Synchronization Index Model",
  booktitle = "Proceedings of the {COSTG-6} Conference on Digital Audio Effects
               ({DAFX-00})",
  author    = "Leman, Marc",
  year      =  2000,
  address   = "Verona, Italy"
}

@ARTICLE{Loui2007-lw,
  title    = "Harmonic expectation and affect in Western music: Effects of
              attention and training",
  author   = "Loui, Psyche and Wessel, Davtd",
  abstract = "We investigated the effects of selective attention and musical
              training on the processing ofharmonic expectations. In Experiment
              1, participants with and without musical training were required
              to respond to the contour of melodies as they were presented with
              chord progressions that were highly expected, slightly
              unexpected, or extremely unexpected. Reaction time and accuracy
              results showed that when attention was focused on the melody,
              musically trained participants were still sensitive to different
              harmonic expectations, whereas participants with no musical
              training were undifferentiated across expectation conditions. In
              Experiment 2, participants were required to listen holistically
              to the entire chord progression and to rate their preference for
              each chord progression. Results from preference ratings showed
              that all the participants, with or without musical training, were
              sensitive to manipulations of harmonic expectations. Experiments
              3 and 4 showed that changing the speed of presentation of chord
              progressions did not affect the pattern of results. The four
              experiments together highlight the importance of attentional
              focus in musical training, especially as it relates to the
              processing of harmonic expectations.",
  journal  = "Perception and Psychophysics",
  volume   =  69,
  number   =  7,
  pages    = "1084--1092",
  year     =  2007,
  issn     = "0031-5117",
  pmid     = "18038947",
  doi      = "10.3758/BF03193946"
}

@BOOK{Berlyne1971-xe,
  title     = "Aesthetics and Psychobiology",
  author    = "Berlyne, D E",
  publisher = "Appleton Century Crofts",
  year      =  1971,
  address   = "New York, NY"
}

@INCOLLECTION{Vuust2009-ms,
  title     = "The Pleasure of Music",
  booktitle = "Pleasures of the Brain",
  author    = "Vuust, Peter and Kringelbach, Morten L",
  editor    = "Kringelbach, Morten L and Berridge, Kent C",
  publisher = "Oxford University Press",
  pages     = "255--269",
  year      =  2009,
  address   = "Oxford, UK"
}

@INCOLLECTION{Zald2011-wh,
  title     = "On music and reward",
  booktitle = "The Neurobiology of Sensation and Reward",
  author    = "Zald, David H and Zatorre, Robert J",
  editor    = "Gottfried, J A",
  publisher = "Taylor and Francis",
  pages     = "405--428",
  year      =  2011,
  address   = "Abingdon, UK"
}

@ARTICLE{Gebauer2012-ym,
  title    = "Ever-changing cycles of musical pleasure: The role of dopamine
              and anticipation",
  author   = "Gebauer, Line and Kringelbach, Morten L and Vuust, Peter",
  abstract = "Music listening is highly pleasurable and important part of most
              people's lives. Because music has no obvious importance for
              survival, the ubiquity of music remains puzzling and the brain
              processes underlying this attraction to music are not well
              understood. Like other rewards (such as food, sex, and money),
              pleasurable music activates structures in the dopaminergic reward
              system, but how music manages to tap into the brain's reward
              system is less clear. Here we propose a novel framework for
              understanding musical pleasure, suggesting that music conforms to
              the recent concept of pleasure cycles with phases of
              ``wanting/expectation,'' ``liking,'' and ``learning.'' We argue
              that expectation is fundamental to musical pleasure, and that
              music can be experienced as pleasurable both when it fulfills and
              violates expectations. Dopaminergic neurons in the midbrain
              represent expectations and violations of expectations (prediction
              errors) in response to ``rewards'' and ``alert/incentive salience
              signals.'' We argue that the human brain treats music as an
              alert/incentive salience signal, and suggest that the activity of
              dopamine neurons represents aspects of the phases of musical
              expectation and musical learning, but not directly the phase of
              music liking. Finally, we propose a computational model for
              understanding musical anticipation and pleasure operationalized
              through the recent theory of predictive coding. (PsycINFO
              Database Record (c) 2013 APA, all rights reserved) (journal
              abstract)",
  journal  = "Psychomusicology: Music, Mind, and Brain",
  volume   =  22,
  number   =  2,
  pages    = "152--167",
  year     =  2012,
  keywords = "10; 1037; a0031126; anticipation; bob dylan; but common to most;
              doi; dopamine; dx; http; music; of us is that; or; org; pleasure;
              reward; some people prefer mozart; supp; supplemental materials;
              we find great; whereas others prefer nirvana",
  issn     = "2162-1535",
  doi      = "10.1037/a0031126"
}

@ARTICLE{North1995-ds,
  title    = "Subjective complexity, familiarity, and liking for popular music",
  author   = "North, Adrian C and Hargreaves, David J",
  abstract = "The optimal complexity and preference-feedback hypotheses make
              specific predictions about the effects of stimulus familiarity
              and subjective complexity on liking for music excerpts. This
              study investigates the relationships between each of these three
              variables within the same experimental design. Seventy- five
              undergraduate subjects rated 60 excerpts of contemporary popular
              music for liking, subjective complexity, or familiarity. The
              results strongly supported the predictions of the two models,
              indicating a positive relationship between liking and
              familiarity, and an inverted-U relationship between liking and
              sub- jective complexity. The observed relationship between
              familiarity and subjec- tive complexity was more difficult to
              predict and explain, although there was some evidence that this
              relationship might best be described as an inverted-U function.
              The different relationships of these two variables with liking
              are ex- plained in terms of subjective complexity being related
              to objective properties of the stimuli, and familiarity being
              determined by cultural exposure and sub- jects own volition.",
  journal  = "Psychomusicology: A Journal of Research in Music Cognition",
  volume   =  14,
  number   = "1-2",
  pages    = "77--93",
  year     =  1995,
  issn     = "2162-1535",
  doi      = "10.1037/h0094090"
}

@ARTICLE{Brown2014-ss,
  title    = "Crowdsourcing for cognitive science - The utility of smartphones",
  author   = "Brown, Harriet R and Zeidman, Peter and Smittenaar, Peter and
              Adams, Rick A and McNab, Fiona and Rutledge, Robb B and Dolan,
              Raymond J",
  abstract = "By 2015, there will be an estimated two billion smartphone users
              worldwide. This technology presents exciting opportunities for
              cognitive science as a medium for rapid, large-scale
              experimentation and data collection. At present, cost and
              logistics limit most study populations to small samples,
              restricting the experimental questions that can be addressed. In
              this study we investigated whether the mass collection of
              experimental data using smartphone technology is valid, given the
              variability of data collection outside of a laboratory setting.
              We presented four classic experimental paradigms as short games,
              available as a free app and over the first month 20,800 users
              submitted data. We found that the large sample size vastly
              outweighed the noise inherent in collecting data outside a
              controlled laboratory setting, and show that for all four games
              canonical results were reproduced. For the first time, we provide
              experimental validation for the use of smartphones for data
              collection in cognitive science, which can lead to the collection
              of richer data sets and a significant cost reduction as well as
              provide an opportunity for efficient phenotypic screening of
              large populations.",
  journal  = "PloS one",
  volume   =  9,
  number   =  7,
  year     =  2014,
  issn     = "1932-6203",
  pmid     = "25025865",
  doi      = "10.1371/journal.pone.0100662"
}

@ARTICLE{Griffiths2015-gw,
  title     = "Manifesto for a new (computational) cognitive revolution",
  author    = "Griffiths, Thomas L",
  abstract  = "The cognitive revolution offered an alternative to merely
               analyzing human behavior, using the notion of computation to
               rigorously express hypotheses about the mind. Computation also
               gives us new tools for testing these hypotheses - large
               behavioral databases generated by human interactions with
               computers and with one another. This kind of data is typically
               analyzed by computer scientists, who focus on predicting
               people's behavior based on their history. A new cognitive
               revolution is needed, demonstrating the value of minds as
               intervening variables in these analyses and using the results to
               evaluate models of human cognition.",
  journal   = "Cognition",
  publisher = "Elsevier B.V.",
  volume    =  135,
  pages     = "21--23",
  year      =  2015,
  keywords  = "Big data; Computational modeling; Crowdsourcing",
  issn      = "0010-0277, 1873-7838",
  pmid      = "25497482",
  doi       = "10.1016/j.cognition.2014.11.026"
}

@INPROCEEDINGS{Harrison2015-zp,
  title     = "Constructing adaptive tests of musical ability",
  booktitle = "Ninth Triennial Conference of the European Society for the
               Cognitive Sciences of Music ({ESCOM})",
  author    = "Harrison, Peter M C and Collins, Tom and Musil, Jason Ji{\v
               r}{\'\i} and M{\"u}llensiefen, Daniel",
  year      =  2015,
  address   = "Manchester, UK",
  doi       = "10.13140/RG.2.1.1494.2160"
}

@INPROCEEDINGS{Cheung2018-fw,
  title     = "Neurocorrelates of predictions in musical harmony: A model-based
               {fMRI} study",
  booktitle = "2018 {OHBM} Annual Meeting",
  author    = "Cheung, Vincent and Harrison, Peter M C and Meyer, Lars and
               Friederici, Angela and Pearce, Marcus T and Haynes, John-Dylan
               and Koelsch, Stefan",
  year      =  2018
}

@INPROCEEDINGS{Gelding2018-ph,
  title     = "Developing a psychometrically advanced version of the Pitch
               Imagery Arrow Task",
  booktitle = "Proceedings of {ICMPC15/ESCOM10}",
  author    = "Gelding, Rebecca W and Harrison, Peter M C and Johnson, Blake W
               and Thompson, William F and M{\"u}llensiefen, Daniel",
  year      =  2018,
  address   = "Graz, Austria"
}

@INPROCEEDINGS{Larrouy-Maestri2017-zq,
  title     = "A new test of the ability to detect mistuning in real music",
  booktitle = "Proceedings of the 25th Anniversary Conference of the European
               Society for the Cognitive Sciences of Music",
  author    = "Larrouy-Maestri, Pauline and Harrison, Peter M C and Walker,
               Dana and M{\"u}llensiefen, Daniel",
  editor    = "Van Dyck, E",
  pages     = "189--190",
  year      =  2017,
  address   = "Ghent, Belgium"
}

@INPROCEEDINGS{Harrison2018-dn,
  title     = "Dissociating sensory and cognitive theories of harmony
               perception through computational modeling",
  booktitle = "Proceedings of {ICMPC15/ESCOM10}",
  author    = "Harrison, Peter M C and Pearce, Marcus T",
  year      =  2018,
  address   = "Graz, Austria",
  doi       = "10.31234/osf.io/wgjyv"
}

@ARTICLE{Savage2016-in,
  title   = "Music perception: No strong evidence to reject innate biases",
  author  = "Savage, Patrick and Currie, Thomas E",
  journal = "SocArXiv",
  year    =  2016,
  doi     = "10.31235/osf.io/964ut"
}

@ARTICLE{Zatorre2016-bj,
  title    = "Amazon music",
  author   = "Zatorre, Robert",
  abstract = "The people of a tribe called the Tsimane', who have been isolated
              from Western music, perceive music differently from Western
              listeners, raising questions about whether musical preference is
              innate or cultural. See Letter p.547",
  journal  = "Nature",
  volume   =  535,
  pages    = "496--497",
  year     =  2016,
  issn     = "0028-0836, 1476-4687",
  pmid     = "27409815",
  doi      = "10.1038/nature18913"
}

@ARTICLE{Grose2012-dq,
  title   = "Binaural beat salience",
  author  = "Grose, John H and Buss, Emily and Hall, III, Joseph W",
  journal = "Hearing research",
  volume  =  285,
  number  = "1-2",
  pages   = "40--45",
  year    =  2012,
  issn    = "0378-5955",
  doi     = "10.1016/j.heares.2012.01.012"
}

@ARTICLE{Bowling2017-ew,
  title    = "The nature and nurture of musical consonance",
  author   = "Bowling, Daniel L and Hoeschele, Marisa and Gill, Kamraan Z and
              Fitch, W Tecumseh",
  abstract = "In a recent Nature paper, McDermott et al. (2016) conclude that
              the perception of consonance arises from familiarity with the
              conventions of Western harmonic music and is relatively
              unconstrained by auditory neurobiology. We refute this idea,
              citing cross-cultural, developmental and comparative evidence to
              the contrary, and raising concerns over McDermott et al.'s
              methodology. We conclude that although familiarity plays an
              important role in shaping tonal preferences, it must not be cast
              in opposition to clear biological constraints. Biology and
              culture (nature and nurture) interact to shape how we experience
              music, and theories that neglect the former do so at their peril.",
  journal  = "Music perception",
  volume   =  35,
  number   =  1,
  pages    = "118--121",
  year     =  2017,
  keywords = "aesthetics; neurobiology; psychoacoustics",
  issn     = "0730-7829",
  doi      = "10.1525/mp.2017.35.1.118"
}

@ARTICLE{Snyder1980-cl,
  title   = "Harmonic dualism and the origin of the minor triad",
  author  = "Snyder, John L",
  journal = "Indiana Theory Review",
  volume  =  4,
  number  =  1,
  pages   = "45--78",
  year    =  1980
}

@ARTICLE{Plantinga2014-us,
  title    = "Revisiting the innate preference for consonance",
  author   = "Plantinga, Judy and Trehub, Sandra E",
  abstract = "The origin of the Western preference for consonance remains
              unresolved, with some suggesting that the preference is innate.
              In Experiments 1 and 2 of the present study, 6-month-old infants
              heard six different consonant/dissonant pairs of stimuli,
              including those tested in previous research. In contrast to the
              findings of others, infants in the present study failed to listen
              longer to consonant stimuli. After 3 minutes of exposure to
              consonant or dissonant stimuli in Experiment 3, 6-month-old
              infants listened longer to the familiar stimulus, whether
              consonant or dissonant. Our findings are inconsistent with innate
              preferences for consonant stimuli. Instead, the effect of
              short-term exposure is consistent with the view that familiarity
              underlies the origin of the Western preference for consonant
              intervals. (PsycINFO Database Record (c) 2013 APA, all rights
              reserved).",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  40,
  number   =  1,
  pages    = "40--49",
  year     =  2014,
  keywords = "Consonance; Dissonance; Infants; Music; Preference",
  issn     = "0096-1523",
  pmid     = "23815480",
  doi      = "10.1037/a0033471"
}

@INPROCEEDINGS{Mullensiefen2017-vc,
  title     = "Music abilities and academic achievement - what's the
               difference?",
  booktitle = "Proceedings of the 25th Anniversary Conference of the European
               Society for the Cognitive Sciences of Music",
  author    = "M{\"u}llensiefen, Daniel and Shapiro, Renee and Harrison, Peter
               M C and Bashir, Zaariyah and Fancourt, Amy",
  editor    = "Van Dyck, E",
  pages     = "63",
  year      =  2017,
  address   = "Ghent, Belgium"
}

@INPROCEEDINGS{Mullensiefen2016-or,
  title     = "Investigating the importance of self-theories of intelligence
               and musicality for students' academic and musical development",
  booktitle = "Proceedings of the 14th International Conference on Music
               Perception and Cognition",
  author    = "M{\"u}llensiefen, Daniel and Harrison, Peter M C and Caprini,
               Francesco and Fancourt, Amy",
  pages     = "673",
  year      =  2016,
  address   = "San Francisco, CA"
}

@INPROCEEDINGS{Harrison2016-xl,
  title     = "Modelling melodic discrimination using computational models of
               melodic similarity and complexity",
  booktitle = "Proceedings of the 14th International Conference on Music
               Perception and Cognition",
  author    = "Harrison, Peter M C and M{\"u}llensiefen, Daniel",
  pages     = "86",
  year      =  2016,
  address   = "San Francisco, CA",
  isbn      = "9781876346652"
}

@BOOK{Harrison2010-in,
  title     = "{Pre-U} Chemistry Revision Guide",
  author    = "Harrison, Peter M C and Hunter, Max",
  publisher = "Lulu Press",
  year      =  2010,
  address   = "Morrisville, NC",
  isbn      = "9781471706196"
}

@ARTICLE{Harrison2017-vm,
  title   = "Mathemusical conversations: Mathematics and computation in music
             performance and composition",
  author  = "Harrison, Peter M C",
  journal = "Empirical musicology review: EMR",
  volume  =  12,
  number  = "1/2",
  pages   = "109--114",
  year    =  2017
}

@ARTICLE{Harrison_undated-hf,
  title   = "Statistics and Experimental Design for Psychologists: A model
             comparison approach by Rory Allen",
  author  = "Harrison, Peter M C",
  journal = "PsyPAG Quarterly"
}

@ARTICLE{DiCiccio1996-nn,
  title   = "Bootstrap confidence intervals",
  author  = "DiCiccio, Thomas J and Efron, Bradley",
  journal = "Statistical science: a review journal of the Institute of
             Mathematical Statistics",
  volume  =  11,
  number  =  3,
  pages   = "189--212",
  year    =  1996,
  issn    = "0883-4237"
}

@INPROCEEDINGS{Sears2018-qo,
  title     = "Evaluating language models of tonal harmony",
  booktitle = "Proceedings of the 19th International Society for Music
               Information Retrieval Conference",
  author    = "Sears, David R W and Korzeniowski, Filip and Widmer, Gerhard",
  abstract  = "This study borrows and extends probabilistic language models
               from natural language processing to discover the syntactic
               properties of tonal harmony. Language models come in many shapes
               and sizes, but their central purpose is always the same: to
               predict the next event in a sequence of letters, words, notes,
               or chords. However, few studies employing such models have
               evaluated the most state-of-the-art architectures using a
               large-scale corpus of Western tonal music, instead preferring to
               use relatively small datasets containing chord annotations from
               contemporary genres like jazz, pop, and rock. Using symbolic
               representations of prominent instrumental genres from the
               common-practice period, this study applies a flexible,
               data-driven encoding scheme to (1) evaluate Finite Context (or
               n-gram) models and Recurrent Neural Networks (RNNs) in a chord
               prediction task; (2) compare predictive accuracy from the
               best-performing models for chord onsets from each of the
               selected datasets; and (3) explain differences between the two
               model architectures in a regression analysis. We find that
               Finite Context models using the Prediction by Partial Match
               (PPM) algorithm outperform RNNs, particularly for the piano
               datasets, with the regression model suggesting that RNNs
               struggle with particularly rare chord types.",
  year      =  2018,
  address   = "Paris, France"
}

@ARTICLE{Steinruecken2015-is,
  title    = "Improving {PPM} with Dynamic Parameter Updates",
  author   = "Steinruecken, Christian and Ghahramani, Zoubin and MacKay, David",
  journal  = "Data Compression Conference Proceedings",
  volume   = "2015-July",
  pages    = "193--202",
  year     =  2015,
  keywords = "PPM; blending; data compression; dynamic updates; escape
              mechanism; gradients",
  issn     = "1068-0314",
  doi      = "10.1109/DCC.2015.77"
}

@ARTICLE{Harrison2018-oe,
  title    = "Development and Validation of the Computerised Adaptive Beat
              Alignment Test ({CA-BAT})",
  author   = "Harrison, Peter M C and M{\"u}llensiefen, Daniel",
  abstract = "Beat perception is increasingly being recognised as a fundamental
              musical ability. A number of psychometric instruments have been
              developed to assess this ability, but these tests do not take
              advantage of modern psychometric techniques, and rarely receive
              systematic validation. The present research addresses this gap in
              the literature by developing and validating a new test, the
              Computerised Adaptive Beat Alignment Test (CA-BAT), a variant of
              the Beat Alignment Test (BAT) that leverages recent advances in
              psychometric theory, including item response theory, adaptive
              testing, and automatic item generation. The test is constructed
              and validated in four empirical studies. The results support the
              reliability and validity of the CA-BAT for laboratory testing,
              but suggest that the test is not well-suited to online testing,
              owing to its reliance on fine perceptual discrimination.",
  journal  = "Scientific reports",
  volume   =  8,
  number   =  1,
  pages    = "12395",
  year     =  2018,
  issn     = "2045-2322",
  doi      = "10.1038/s41598-018-30318-8"
}

@ARTICLE{Bittner2016-cv,
  title    = "Medleydb 2.0 : New Data and a System for Sustainable Data
              Collection",
  author   = "Bittner, Rachel M and Wilkins, Julia and Yip, Hanna and Bello,
              Juan P",
  abstract = "We present MedleyDB 2.0, the second iteration of a dataset of
              multitrack recordings created to support Music Informa-tion
              Retrieval (MIR) research. MedleyDB 2.0 introduces several new
              tools to reduce the effort required to add new content, ensure
              dataset sustainability, and improve the qual-ity of multitrack
              audio files. The dataset has now grown to contain over 250
              multitracks after the addition of 132 tracks in this release.",
  number   =  1,
  pages    = "2--4",
  year     =  2016
}

@ARTICLE{Jesteadt1980-eb,
  title    = "An adaptive procedure for subjective judgments",
  author   = "Jesteadt, Walt",
  abstract = "Briefly discusses the advantages and disadvantges of the
              conventional methods of constant stimuli, adjustment, and limits
              as applied to the problem of stimulus selection in psychophysical
              experiments. A forced-choice adaptive procedure is described that
              has applications to single-interval tasks in which the stimulus
              is to be compared with a remembered standard.",
  journal  = "Perception \& psychophysics",
  volume   =  28,
  number   =  1,
  pages    = "85--88",
  year     =  1980,
  issn     = "0031-5117",
  pmid     = "7413416",
  doi      = "10.3758/BF03204321"
}

@ARTICLE{Wier1976-te,
  title    = "A comparison of method-of-adjustment and forced-choice procedures
              in frequency discrimination",
  author   = "Wier, Craig C and Jesteadt, Walt and Green, David M",
  abstract = "Studied the relationship between reported estimates of the
              frequency difference limen (DL) for tones and 3 psychophysical
              methods. Five paid Ss gave 3 estimates of the DL at 1,000 Hz
              using each method. Measures included (a) the standard deviation
              of final settings in a method of adjustment, (b) the average of
              several reversals in an adaptive 2-interval forced-choice
              procedure, and (c) the 76\%-correct point in a 2-interval
              forced-choice procedure using constant stimuli. The 2
              forced-choice procedures yielded very similar DLs. The adjustment
              procedure yielded significantly smaller estimates. It is
              suggested that step size and repeated stimulus presentations in
              the method of adjustment may have influenced the DL and involved
              sequential decision-making. (18 ref) ((c) 1997 APA/PsycINFO, all
              rights reserved)",
  journal  = "Perception \& psychophysics",
  volume   =  19,
  number   =  1,
  pages    = "75--79",
  year     =  1976,
  issn     = "0031-5117",
  doi      = "10.3758/BF03199389"
}

@ARTICLE{Bittner2014-ng,
  title    = "{MedleyDB}: A multitrack dataset for annotation - intensive mir
              research",
  author   = "Bittner, Rachel and Salamon, Justin and Tierney, Mike and Mauch,
              Matthias and Cannam, Chris and Bello, Juan",
  abstract = "We introduce MedleyDB: a dataset of annotated, royalty- free
              multitrack recordings. The dataset was primarily de- veloped to
              support research on melody extraction, address- ing important
              shortcomings of existing collections. For each song we provide
              melody f0 annotations as well as instrument activations for
              evaluating automatic instrument recognition. The dataset is also
              useful for research on tasks that require access to the
              individual tracks of a song such as source separation and
              automatic mixing. In this paper we provide a detailed description
              of MedleyDB, including curation, annotation, and musical content.
              To gain insight into the new challenges presented by the dataset,
              we run a set of experiments using a state-of-the-art melody
              extrac- tion algorithm and discuss the results. The dataset is
              shown to be considerably more challenging than the current test
              sets used in the MIREX evaluation campaign, thus open- ing new
              research avenues in melody extraction research. 1.",
  journal  = "International Society for Music Information Retrieval Conference",
  pages    = "155--160",
  year     =  2014
}

@ARTICLE{Zentner2017-zs,
  title    = "Assessing musical ability quickly and objectively: development
              and validation of the {Short-PROMS} and the {Mini-PROMS}",
  author   = "Zentner, Marcel and Strauss, Hannah",
  abstract = "The study of musical ability has gained considerable traction
              across disciplines in recent years. In comparison, less effort
              has been invested in the development of sound measures of musical
              ability. To redress this gap, we conducted four studies to
              empirically validate two brief measures derived from the Profile
              of Music Perception Skills (PROMS)---an exceptionally inclusive
              battery of musical abilities that takes about 1 h to complete. In
              the Short-PROMS, test duration was reduced to less than half an
              hour by substantially reducing the number of trials per subtest.
              In the Mini-PROMS, the number of subtests was reduced to four,
              resulting in a battery that takes 15 min to complete. Both
              measures exhibited good internal consistency and retest
              reliability. Support for convergent, discriminant, and criterion
              validity was found across the studies. Additional strengths of
              the new instruments include their suitability for online
              administration and a feature called Modular PROMS, which offers
              researchers the possibility to request customized batteries that
              may include any combination of the subtests. The role of refining
              objective assessment instruments in research on music and the
              mind is discussed.",
  journal  = "Annals of the New York Academy of Sciences",
  volume   =  1400,
  number   =  1,
  pages    = "33--45",
  year     =  2017,
  keywords = "assessment; intelligence; music perception; musical ability;
              musicians",
  issn     = "0077-8923, 1749-6632",
  pmid     = "28704888",
  doi      = "10.1111/nyas.13410"
}

@ARTICLE{Larsson1996-sz,
  title    = "Extended application of suffix trees to data compression",
  author   = "Larsson, N J",
  abstract = "A practical scheme for maintaining an index for a sliding
              window\textbackslashnin optimal time and space, by use of a
              suffix tree, is presented. The\textbackslashnindex supports
              location of the longest matching substring in
              time\textbackslashnproportional to the length of the match. The
              total time for build and\textbackslashnupdate operations is
              proportional to the size of the input.
              The\textbackslashnalgorithm, which is simple and straightforward,
              is presented in detail.\textbackslashnThe most prominent lossless
              data compression scheme, when
              considering\textbackslashncompression performance, is prediction
              by partial matching with\textbackslashnunbounded context lengths
              (PPM). However, previously presented\textbackslashnalgorithms are
              hardly practical, considering their extensive use
              of\textbackslashncomputational resources. We show that our scheme
              can be applied to\textbackslashnPPM-style compression, obtaining
              an algorithm that runs in linear time,\textbackslashnand in space
              bounded by an arbitrarily chosen window size.
              Application\textbackslashnto Ziv-Lempel (1977) compression
              methods is straightforward and the\textbackslashnresulting
              algorithm runs in linear time",
  journal  = "Proceedings of Data Compression Conference - DCC '96",
  year     =  1996,
  issn     = "1068-0314",
  doi      = "10.1109/DCC.1996.488324"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Yoshii2011-es,
  title    = "a {Vocabulary-Free} {Infinity-Gram} Model for Nonparametric
              Bayesian Chord Progression Analysis",
  author   = "Yoshii, Kazuyoshi",
  abstract = "This paper presents probabilistic n-gram models for sym-bolic
              chord sequences. To overcome the fundamental lim-itations in
              conventional models---that the model optimality is not
              guaranteed, that the value of n is fixed uniquely, and that a
              vocabulary of chord types (e.g., major, minor, · · ·) is defined
              in an arbitrary way---we propose a vocabulary-free infinity-gram
              model based on Bayesian nonparametrics. It accepts any
              combinations of notes as chord types and allows each chord
              appearing in a sequence to have an unbounded and variable-length
              context. All possibilities of n are taken into account when
              calculating the predictive probability of a next chord given a
              particular context, and when an unseen chord type emerges we can
              avoid out-of-vocabulary error by adaptively evaluating the 0-gram
              probability, i.e., the com-binatorial probability of note
              components. Our experiments using Beatles songs showed that the
              predictive performance of the proposed model is better than that
              of the state-of-the-art models and that we could find
              stochastically-coherent chord patterns by sorting variable-length
              n-grams in a line according to their generative probabilities.",
  journal  = "Science And Technology",
  volume   =  2011,
  number   = "ISMIR",
  pages    = "645--650",
  year     =  2011
}

@ARTICLE{Peeters2011-rn,
  title   = "The Timbre Toolbox: Extracting audio descriptors from musical
             signals",
  author  = "Peeters, Geoffroy and Giordano, Bruno L and Susini, Patrick and
             Misdariis, Nicolas and Susini, Patrick and McAdams, Stephen",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  130,
  number  =  5,
  pages   = "2902--2916",
  year    =  2011,
  issn    = "0001-4966",
  doi     = "10.1121/1.3642604"
}

@PHDTHESIS{Vassilakis2001-cd,
  title   = "Perceptual and physical properties of amplitude fluctuation and
             their musical significance",
  author  = "Vassilakis, P N",
  year    =  2001,
  address = "Los Angeles, CA",
  school  = "Unpublished doctoral dissertation, University of California"
}

@ARTICLE{Schwartz2003-lm,
  title    = "The statistical structure of human speech sounds predicts musical
              universals",
  author   = "Schwartz, David A and Howe, Catherine Q and Purves, Dale",
  journal  = "The Journal of Neuroscience",
  volume   =  23,
  number   =  18,
  pages    = "7160--7168",
  year     =  2003,
  keywords = "audition; auditory system; consonance; music; perception;
              probability; scales; tones",
  issn     = "0270-6474"
}

@ARTICLE{Lattner2018-fe,
  title    = "A Predictive Model for Music Based on Learned Interval
              Representations",
  author   = "Lattner, Stefan and Grachten, Maarten and Widmer, Gerhard",
  abstract = "Connectionist sequence models (e.g., RNNs) applied to musical
              sequences suffer from two known problems: First, they have
              strictly ``absolute pitch perception''. Therefore, they fail to
              generalize over musical concepts which are commonly perceived in
              terms of relative distances between pitches (e.g., melodies,
              scale types, modes, cadences, or chord types). Second, they fall
              short of capturing the concepts of repetition and musical form.
              In this paper we introduce the recurrent gated autoencoder
              (RGAE), a recurrent neural network which learns and operates on
              interval representations of musical sequences. The relative pitch
              modeling increases generalization and reduces sparsity in the
              input data. Furthermore, it can learn sequences of copy-and-shift
              operations (i.e. chromatically transposed copies of musical
              fragments)---a promising capability for learning musical
              repetition structure. We show that the RGAE improves the state of
              the art for general connectionist sequence models in learning to
              predict monophonic melodies, and that ensembles of relative and
              absolute music processing models improve the results appreciably.
              Furthermore, we show that the relative pitch processing of the
              RGAE naturally facilitates the learning and the generation of
              sequences of copy-and-shift operations, wherefore the RGAE
              greatly outperforms a common absolute pitch recurrent neural
              network on this task.",
  year     =  2018,
  arxivid  = "1806.08686"
}

@ARTICLE{Koelsch2014-wm,
  title    = "Brain correlates of music-evoked emotions",
  author   = "Koelsch, Stefan",
  abstract = "Music is a universal feature of human societies, partly owing to
              its power to evoke strong emotions and influence moods. During
              the past decade, the investigation of the neural correlates of
              music-evoked emotions has been invaluable for the understanding
              of human emotion. Functional neuroimaging studies on music and
              emotion show that music can modulate activity in brain structures
              that are known to be crucially involved in emotion, such as the
              amygdala, nucleus accumbens, hypothalamus, hippocampus, insula,
              cingulate cortex and orbitofrontal cortex. The potential of music
              to modulate activity in these structures has important
              implications for the use of music in the treatment of psychiatric
              and neurological disorders.",
  journal  = "Nature reviews. Neuroscience",
  volume   =  15,
  pages    = "170--180",
  year     =  2014,
  issn     = "1471-003X",
  pmid     = "24552785",
  doi      = "10.1038/nrn3666"
}

@ARTICLE{Van_der_Weij2017-iv,
  title    = "A probabilistic model of meter perception: Simulating
              enculturation",
  author   = "van der Weij, Bastiaan and Pearce, Marcus T and Honing, Henkjan",
  abstract = "Enculturation is known to shape the perception ofmeter inmusic
              but this is not explicitly accounted for by current
              cognitivemodels ofmeter perception.We hypothesize that the
              induction ofmeter is a result of predictive coding: interpreting
              onsets in a rhythmrelative to a periodic meter facilitates
              prediction of future onsets. Such prediction, we hypothesize, is
              based on previous exposure to rhythms. As such, predictive coding
              provides a possible explanation for thewaymeter perception is
              shaped by the cultural environment.Based on this hypothesis, we
              present a probabilisticmodel ofmeter perception that uses
              statistical properties of the relation between rhythm and meter
              to infer meter from quantized rhythms. We show that our model can
              successfully predict annotated time signatures fromquantized
              rhythmic patterns derived fromfolkmelodies. Furthermore, we show
              that by inferringmeter, ourmodel improves prediction of the
              onsets of future events compared to a similar probabilistic model
              that does not infer meter. Finally, as a proof of concept, we
              demonstrate how our model can be used in a simulation of
              enculturation. From the results of this simulation, we derive a
              class of rhythms that are likely to be interpreted differently by
              enculturated listeners with different histories of exposure to
              rhythms.",
  journal  = "Frontiers in psychology",
  volume   =  8,
  year     =  2017,
  keywords = "Cognition; Computational modeling; Enculturation; Meter
              perception; Predictive coding; Rhythm",
  issn     = "1664-1078",
  doi      = "10.3389/fpsyg.2017.00824"
}

@ARTICLE{Soranzo2014-ct,
  title    = "{PSYCHOACOUSTICS}: A comprehensive {MATLAB} toolbox for auditory
              testing",
  author   = "Soranzo, Alessandro and Grassi, Massimo",
  abstract = "PSYCHOACOUSTICS is a new MATLAB toolbox which implements three
              classic adaptive procedures for auditory threshold estimation.
              The first includes those of the Staircase family (method of
              limits, simple up-down and transformed up-down); the second is
              the Parameter Estimation by Sequential Testing (PEST); and the
              third is the Maximum Likelihood Procedure (MLP). The toolbox
              comes with more than twenty built-in experiments each provided
              with the recommended (default) parameters. However, if desired,
              these parameters can be modified through an intuitive and user
              friendly graphical interface and stored for future use (no
              programming skills are required). Finally, PSYCHOACOUSTICS is
              very flexible as it comes with several signal generators and can
              be easily extended for any experiment.",
  journal  = "Frontiers in psychology",
  volume   =  5,
  pages    = "1--13",
  year     =  2014,
  keywords = "and; auditory perception; extends the maximum; likelihood
              procedure; matlab toolb; matlab toolbox; maximum likelihood
              estimation; mlp; old estimation; pest; psychoacoustics;
              psychoacoustics is a matlab; staircase; the toolbox improves and;
              toolbox advanced by grassi; toolbox for auditory thresh-",
  issn     = "1664-1078",
  doi      = "10.3389/fpsyg.2014.00712"
}

@ARTICLE{Wolf2018-ug,
  title    = "Development and Validation of the Musical Ear Training Assessment
              ({META})",
  author   = "Wolf, Anna and Kopiez, Reinhard",
  abstract = "In the following study, we have developed an assessment
              instrument for the practice-dependent skill of analytical hearing
              following a strict test theoretical validation, resulting in the
              Musical Ear Training Assessment (META). By means of three pilot
              studies, a developmental study, and a validation study, we
              verified a one-dimensional test model using item response theory
              identifying the best 53 items to measure a person?s ear training
              and analytical hearing skill. For better application, two test
              versions with 10 and 25 items have been compiled (META-10 and
              META-25). Aside from psychometric test development, it was
              possible to investigate a variety of moderator variables assumed
              to influence ear training skill. The participants? main
              instrument did not influence the META score, nor did whether
              participants had learned some method of solmization. However, the
              most played genre (d = 0.20) and, unforeseen by us, the
              participants? gender (d = 0.23; males outperforming females) had
              significant impacts on the test score. This test instrument
              enables empirical research into the relevance of ear training for
              general musical skills, intervention studies on skill
              acquisition, and standardized assessment for advanced music
              students and musicians.",
  journal  = "Journal of Research in Music Education",
  volume   =  66,
  number   =  1,
  pages    = "53--70",
  year     =  2018,
  keywords = "Rasch model; achievement test; ear training; item response
              theory; musical skills",
  issn     = "0022-4294",
  doi      = "10.1177/0022429418754845"
}

@ARTICLE{Swaminathan2018-pg,
  title     = "Musical competence is predicted by music training, cognitive
               abilities, and personality",
  author    = "Swaminathan, Swathi and Schellenberg, E Glenn",
  abstract  = "Individuals differ in musical competence, which we defined as
               the ability to perceive, remember, and discriminate sequences of
               tones or beats. We asked whether such differences could be
               explained by variables other than music training, including
               socioeconomic status (SES), short-term memory, general cognitive
               ability, and personality. In a sample of undergraduates, musical
               competence had positive simple associations with duration of
               music training, SES, short-term memory, general cognitive
               ability, and openness-to-experience. When these predictors were
               considered jointly, musical competence had positive partial
               associations with music training, general cognitive ability, and
               openness. Nevertheless, moderation analyses revealed that the
               partial association between musical competence and music
               training was evident only among participants who scored below
               the mean on our measure of general cognitive ability. Moreover,
               general cognitive ability and openness had indirect associations
               with musical competence by predicting music training, which in
               turn predicted musical competence. Musical competence appears to
               be the result of multiple factors, including but not limited to
               music training. Musical engagement is widespread, yet
               individuals vary in musical ability. Some of this variance stems
               from learning by way of music listening and formal training in
               music. The remainder stems from natural ability, or musical
               aptitude, which may interact with learning. In the present
               investigation, we use the term musical compe-tence to describe
               listeners' ability to perceive, remember, and discriminate
               musical melodies and rhythms. Unlike aptitude, ability, or
               talent, the term competence is meant to be neutral with respect
               to the relative roles of nature and nurture. On most tests of
               musical competence 1--4",
  journal   = "Scientific reports",
  publisher = "Springer US",
  volume    =  8,
  pages     = "1--7",
  year      =  2018,
  issn      = "2045-2322",
  doi       = "10.1038/s41598-018-27571-2"
}

@INCOLLECTION{Eerola2018-gf,
  title     = "Music and emotions",
  booktitle = "Springer Handbook of Systematic Musicology",
  author    = "Eerola, Tuomas",
  editor    = "Bader, R",
  publisher = "Springer-Verlag",
  pages     = "539--554",
  year      =  2018,
  address   = "Berlin, Germany"
}

@INCOLLECTION{Rohrmeier2018-bj,
  title     = "Musical syntax I: Theoretical perspectives",
  booktitle = "Springer Handbook of Systematic Musicology",
  author    = "Rohrmeier, Martin and Pearce, Marcus T",
  editor    = "Bader, R",
  publisher = "Springer-Verlag",
  pages     = "473--486",
  year      =  2018,
  address   = "Berlin, Germany",
  doi       = "10.1007/978-3-662-55004-5\_2"
}

@INCOLLECTION{Pearce2018-rn,
  title     = "Musical syntax {II}: Empirical perspectives",
  booktitle = "Springer Handbook of Systematic Musicology",
  author    = "Pearce, Marcus Thomas and Rohrmeier, Martin",
  editor    = "Bader, R",
  publisher = "Springer-Verlag",
  pages     = "487--505",
  year      =  2018,
  address   = "Berlin, Germany",
  isbn      = "9783662550045",
  doi       = "10.1007/978-3-662-55004-5\_26"
}

@ARTICLE{Parncutt1994-kc,
  title   = "A perceptual model of pulse salience and metrical accent in
             musical rhythms",
  author  = "Parncutt, Richard",
  journal = "Music perception",
  volume  =  11,
  number  =  4,
  pages   = "409--464",
  year    =  1994,
  issn    = "0730-7829"
}

@ARTICLE{Begel2018-wt,
  title   = "Test-retest reliability of the Battery for the Assessment of
             Auditory Sensorimotor and Timing Abilities ({BAASTA})",
  author  = "B{\'e}gel, Valentin and Verga, Laura and Benoit, Charles-Etienne
             and Kotz, Sonja A and Dalla Bella, Simone",
  journal = "Annals of physical and rehabilitation medicine",
  year    =  2018,
  issn    = "1877-0657",
  doi     = "10.1016/j.rehab.2018.04.001"
}

@INPROCEEDINGS{Stolzenburg2017-bn,
  title     = "Periodicity detection by neural transformation",
  booktitle = "Proceedings of the 25th Anniversary Conference of the European
               Society for the Cognitive Sciences of Music",
  author    = "Stolzenburg, Frieder",
  editor    = "Van Dyck, E",
  pages     = "159--162",
  year      =  2017,
  address   = "Ghent, Belgium"
}

@ARTICLE{Ireland2018-mt,
  title    = "Rhythm and melody tasks for school-aged children with and without
              musical training: Age-equivalent scores and reliability",
  author   = "Ireland, Kierla and Parker, Averil and Foster, Nicholas and
              Penhune, Virginia",
  abstract = "Measuring musical abilities in childhood can be challenging. When
              music training and maturation occur simultaneously, it is
              difficult to separate the effects of specific experience from
              age-based changes in cognitive and motor abilities. The goal of
              this study was to develop age-equivalent scores for two measures
              of musical ability that could be reliably used with school-aged
              children (7-13) with and without musical training. The children's
              Rhythm Synchronization Task (c-RST) and the children's Melody
              Discrimination Task (c-MDT) were adapted from adult tasks
              developed and used in our laboratories. The c-RST is a motor task
              in which children listen and then try to synchronize their taps
              with the notes of a woodblock rhythm while it plays twice in a
              row. The c-MDT is a perceptual task in which the child listens to
              two melodies and decides if the second was the same or different.
              We administered these tasks to 213 children in music camps
              (musicians, n = 130) and science camps (non-musicians, n = 83).
              We also measured children's paced tapping, non-paced tapping, and
              phonemic discrimination as baseline motor and auditory abilities.
              We estimated internal-consistency reliability for both tasks, and
              compared children's performance to results from studies with
              adults. As expected, musically trained children outperformed
              those without music lessons, scores decreased as difficulty
              increased, and older children performed the best. Using
              non-musicians as a reference group, we generated a set of
              age-based z-scores, and used them to predict task performance
              with additional years of training. Years of lessons significantly
              predicted performance on both tasks, over and above the effect of
              age. We also assessed the relation between musicians' scores on
              music tasks, baseline tasks, auditory working memory, and
              nonverbal reasoning. Unexpectedly, musician children outperformed
              non-musicians in two of three baseline tasks. The c-RST and c-MDT
              fill an important need for researchers interested in evaluating
              the impact of musical training in longitudinal studies, those
              interested in comparing the efficacy of different training
              methods, and for those assessing the impact of training on
              non-musical cognitive abilities such as language processing.",
  journal  = "Frontiers in psychology",
  volume   =  9,
  pages    = "1--14",
  year     =  2018,
  keywords = "Age-equivalent scores; Discrimination; Musical tasks; School-aged
              children; Synchronization",
  issn     = "1664-1078",
  doi      = "10.3389/fpsyg.2018.00426"
}

@ARTICLE{Kim_undated-pi,
  title   = "{Self-Bounded} Prediction Suffix Tree via Approximate String
             Matching",
  author  = "Kim, Dongwoo and Walder, Christian",
  arxivid = "1802.03184v1"
}

@ARTICLE{Van_Hedger2018-vs,
  title  = "Absolute pitch can be learned by some adults",
  author = "Van Hedger, Stephen C and Heald, Shannon L M and Nusbaum, Howard C",
  year   =  2018
}

@ARTICLE{Schurgin2018-hw,
  title  = "Psychological Scaling Reveals a Single Parameter Framework For
            Visual Working Memory",
  author = "Schurgin, Mark W and Wixted, John T and Brady, Timothy F",
  pages  = "0--24",
  year   =  2018
}

@ARTICLE{Hancock2016-ea,
  title    = "First citation speed for articles in Psychology of Music",
  author   = "Hancock, Carl B and Price, Harry E",
  abstract = "This study examined the speed of initial research impact and
              dissemination for 619 articles published in Psychology of Music
              (POM) from 1973 to 2012. A computer script calculated the time
              elapsed from publication to receiving a first-citation from a
              referencing journal and discipline. Journal references (n =
              7,969) to POM were extracted from Google Scholar and divided into
              business, education, medical, music, music education, natural
              science, psychology, social science, and technology collections.
              Stratified plots revealed that journals in the disciplines of
              music education and psychology cited POM articles more quickly
              than other fields; music psychology journals cited POM more
              quickly than music education journals from US and worldwide
              sources, and POM articles published from 1973--1992 were more
              quickly cited by journals in music education, while articles from
              1993--2012 by those in music psychology. Cox regression indicated
              research-uptake accelerated with later decades, publishers,
              editor eras, and increased article impact. Results confirm the
              importance of recent POM articles to journals in the discipline
              of music psychology and earlier articles to journals in the field
              of music education. POM was cited broadly, though adoption speeds
              were slower for journals in fields beyond music education and
              psychology.",
  journal  = "Psychology of Music",
  volume   =  44,
  number   =  6,
  pages    = "1454--1470",
  year     =  2016,
  keywords = "bibliometrics; citation analysis; citation speed; impact and
              dissemination; interdisciplinary journals; music education; music
              psychology",
  issn     = "1741-3087",
  doi      = "10.1177/0305735616637133"
}

@MISC{Chang2017-gt,
  title  = "shiny: Web Application Framework for {R}",
  author = "Chang, Winston and Cheng, Joe and Allaire, J J and Xie, Yihui and
            McPherson, Jonathan",
  year   =  2017
}

@ARTICLE{Cuddy1995-uj,
  title  = "Expectancies generated by melodic intervals : Perceptual judgments
            of melodic continuity",
  author = "Cuddy, Lola L and Lunney, Carole A",
  volume =  57,
  number =  4,
  year   =  1995
}

@ARTICLE{Arthurs2016-hf,
  title    = "On the Fluidity of Consonance and Dissonance : The Influence of
              Musical Context",
  author   = "Arthurs, Yuko and Timmers, Renee",
  volume   =  26,
  number   =  1,
  pages    = "1--14",
  year     =  2016,
  keywords = "augmented and; chord function; consonance and dissonance; musical
              context; pleasantness"
}

@ARTICLE{Koelsch2007-sr,
  title   = "Untangling syntactic and sensory processing: An {ERP} study of
             music perception",
  author  = "Koelsch, Stefan and Jentschke, Sebastian and Sammler, Daniela and
             Mietchen, Daniel",
  journal = "Psychophysiology",
  volume  =  44,
  pages   = "476--490",
  year    =  2007,
  issn    = "0048-5772",
  doi     = "10.1111/j.1469-8986.2007.00517.x"
}

@ARTICLE{Teki2011-hb,
  title   = "Distinct neural substrates of duration-based and beat-based
             auditory timing",
  author  = "Teki, Sundeep and Grube, Manon and Kumar, Sukhbinder and
             Griffiths, Timothy D",
  journal = "The Journal of neuroscience: the official journal of the Society
             for Neuroscience",
  volume  =  31,
  number  =  10,
  pages   = "3805--3812",
  year    =  2011,
  issn    = "0270-6474",
  doi     = "10.1523/JNEUROSCI.5561-10.2011"
}

@INPROCEEDINGS{Harrison2018-dq,
  title     = "An energy-based generative sequence model for testing sensory
               theories of Western harmony",
  booktitle = "Proceedings of the 19th International Society for Music
               Information Retrieval Conference",
  author    = "Harrison, P M C and Pearce, Marcus T",
  pages     = "160--167",
  year      =  2018,
  address   = "Paris, France"
}

@ARTICLE{Steinbeis2006-ld,
  title   = "The role of harmonic expectancy violations in musical emotions:
             Evidence from subjective, physiological, and neural responses",
  author  = "Steinbeis, Nikolaus and Koelsch, Stefan and Sloboda, John A",
  journal = "Journal of cognitive neuroscience",
  volume  =  18,
  number  =  8,
  pages   = "1380--1393",
  year    =  2006,
  issn    = "0898-929X"
}

@ARTICLE{Pearce2018-xc,
  title    = "Statistical learning and probabilistic prediction in music
              cognition: Mechanisms of stylistic enculturation",
  author   = "Pearce, Marcus T",
  journal  = "Annals of the New York Academy of Sciences",
  volume   =  1423,
  number   =  1,
  pages    = "378--395",
  year     =  2018,
  keywords = "enculturation; idyom; music perception; probabilistic prediction;
              statistical learning",
  issn     = "0077-8923",
  doi      = "10.1111/nyas.13654"
}

@INCOLLECTION{Shepard1982-wx,
  title     = "Structural representations of musical pitch",
  booktitle = "Psychology of Music",
  author    = "Shepard, R N",
  editor    = "Deutsch, Diana",
  publisher = "Academic Press",
  pages     = "343--390",
  year      =  1982,
  address   = "New York, NY"
}

@ARTICLE{Bharucha1986-ok,
  title   = "Reaction time and musical expectancy: Priming of chords",
  author  = "Bharucha, Jamshed J and Stoeckig, Keiko",
  journal = "Journal of experimental psychology. Human perception and
             performance",
  volume  =  12,
  number  =  4,
  pages   = "403--410",
  year    =  1986,
  issn    = "0096-1523"
}

@ARTICLE{Leeuw2015-nl,
  title    = "jsPsych: A {JavaScript} library for creating behavioral
              experiments in a Web browser",
  author   = "Leeuw, Joshua R De",
  journal  = "Behavioral Research Methods",
  volume   =  47,
  number   =  1,
  year     =  2015,
  keywords = "amazon; javascript; online experiments",
  doi      = "10.3758/s13428-014-0458-y"
}

@ARTICLE{Di_Stefano2017-ix,
  title    = "A new research method to test auditory preferences in young
              listeners: Results from a consonance versus dissonance perception
              study",
  author   = "Di Stefano, Nicola and Focaroli, Valentina and Giuliani,
              Alessandro and Formica, Domenico and Taffoni, Fabrizio and
              Keller, Flavio",
  abstract = "To date, behavioural procedures adopted to assess sound
              preferences in young children have evaluated the responses of
              participants while listening to the stimuli administered by the
              experimenter. Due to the difficulties which may arise in the
              interpretation of the results, recent studies have suggested some
              limitations to these procedures, stimulating the further
              development of behavioural methods. Here, we introduce a new
              method for testing sound preferences in children, in which
              participants actively produce the stimuli during the experimental
              session. The apparatus consists of a musical lever which emits
              different sounds depending on its rotation around a hinge. The
              device was programmed to emit consonant and dissonant harmonic
              intervals. The procedure has been tested with 22 participants
              from 19 to 40 months of age. Results show that: (a) sound
              emission strongly stimulates toy manipulation; (b) the examined
              participants distinguished the two types of sounds, showing a
              preference for producing consonant over dissonant stimuli. This
              method could be used to study a wide range of sound qualities in
              young listeners, such as rhythm or pitch. Grounded in the mutual
              interaction between perception and action, this procedure is in
              line with recent research highlighting the role of embodiment in
              the perception of music.",
  journal  = "Psychology of Music",
  volume   =  45,
  number   =  5,
  pages    = "699--712",
  year     =  2017,
  keywords = "behavioural methods; children; consonance and dissonance
              perception; embodiment; musical toy; toddlers",
  issn     = "1741-3087",
  doi      = "10.1177/0305735616681205"
}

@ARTICLE{Daikoku2018-lv,
  title  = "Time-course variation of statistics embedded in music : Corpus
            study on implicit learning and knowledge",
  author = "Daikoku, Tatsuya",
  pages  = "1--18",
  year   =  2018
}

@BOOK{Gordon2016-qi,
  title    = "A Comparison of Approaches to Advertising Measurement: Evidence
              from Big Field Experiments at Facebook *",
  author   = "Gordon, Brett and Zettelmeyer, Florian and Bhargava, Neha and
              Chapsky, Dan",
  abstract = "We examine how common techniques used to measure the causal
              impact of ad exposures on users' conversion outcomes compare to
              the `` gold standard '' of a true experiment (randomized
              controlled trial). Using data from 12 US advertising lift studies
              at Facebook comprising 435 million user-study observations and
              1.4 billion total impressions we contrast the experimental
              results to those obtained from observational methods, such as
              comparing exposed to unex-posed users, matching methods,
              model-based adjustments, synthetic matched-markets tests, and
              before-after tests. We show that observational methods often fail
              to produce the same results as true experiments even after
              conditioning on information from thousands of behavioral
              variables and using non-linear models. We explain why this is the
              case. Our findings suggest that common approaches used to measure
              advertising effectiveness in industry fail to measure accurately
              the true effect of ads.",
  pages    = "7--16",
  year     =  2016,
  keywords = "advertisers; advertising measurement; alessandro; and fangfang
              tan; brian d; causal inference; digital advertising; field
              experiments; gabrielle gibbs; identifiable information that
              could; identify consumers or; joseph davin; no data contained
              personally; observational methods; to maintain privacy; we thank
              daniel slotwiner",
  issn     = "1556-5068",
  doi      = "10.2139/ssrn.3033144"
}

@ARTICLE{Shrier2008-xi,
  title    = "Reducing bias through directed acyclic graphs",
  author   = "Shrier, Ian and Platt, Robert W",
  abstract = "BACKGROUND: The objective of most biomedical research is to
              determine an unbiased estimate of effect for an exposure on an
              outcome, i.e. to make causal inferences about the exposure.
              Recent developments in epidemiology have shown that traditional
              methods of identifying confounding and adjusting for confounding
              may be inadequate.DISCUSSION: The traditional methods of
              adjusting for ``potential confounders'' may introduce conditional
              associations and bias rather than minimize it. Although previous
              published articles have discussed the role of the causal directed
              acyclic graph approach (DAGs) with respect to confounding, many
              clinical problems require complicated DAGs and therefore
              investigators may continue to use traditional practices because
              they do not have the tools necessary to properly use the DAG
              approach. The purpose of this manuscript is to demonstrate a
              simple 6-step approach to the use of DAGs, and also to explain
              why the method works from a conceptual point of view.SUMMARY:
              Using the simple 6-step DAG approach to confounding and selection
              bias discussed is likely to reduce the degree of bias for the
              effect estimate in the chosen statistical model.",
  journal  = "BMC medical research methodology",
  volume   =  8,
  pages    = "1--15",
  year     =  2008,
  issn     = "1471-2288",
  pmid     = "18973665",
  doi      = "10.1186/1471-2288-8-70"
}

@PHDTHESIS{Langhabel2017-gc,
  title  = "Learning a Predictive Model for Music Using {PULSE}",
  author = "Langhabel, Jonas and Lieck, Robert and M{\"u}ller, Klaus- Robert
            and Toussaint, Marc",
  year   =  2017
}

@ARTICLE{McDermott2016-sf,
  title    = "Indifference to dissonance in native Amazonians reveals cultural
              variation in music perception",
  author   = "McDermott, Josh H and Schultz, Alan F and Undurraga, Eduardo A
              and Godoy, Ricardo A",
  abstract = "Music is present in every culture, but the degree to which it is
              shaped by biology remains debated. One widely discussed
              phenomenon is that some combinations of notes are perceived by
              Westerners as pleasant, or consonant, whereas others are
              perceived as unpleasant, or dissonant 1 . The contrast between
              consonance and dissonance is central to Western music 2,3 , and
              its origins have fascinated scholars since the ancient Greeks
              4--10 . Aesthetic responses to consonance are commonly assumed by
              scientists to have biological roots 11--14 , and thus to be
              universally present in humans 15,16 . Ethnomusicologists 17 and
              composers 8 , in contrast, have argued that consonance is a
              creation of Western musical culture 6 . The issue has remained
              unresolved, partly because little is known about the extent of
              cross-cultural variation in consonance preferences 18 . Here we
              report experiments with the Tsimane'---a native Amazonian society
              with minimal exposure to Western culture---and comparison
              populations in Bolivia and the United States that varied in
              exposure to Western music. Participants rated the pleasantness of
              sounds. Despite exhibiting Western-like discrimination abilities
              and Western-like aesthetic responses to familiar sounds and
              acoustic roughness, the Tsimane' rated consonant and dissonant
              chords and vocal harmonies as equally pleasant. By contrast,
              Bolivian city-and town-dwellers exhibited significant preferences
              for consonance, albeit to a lesser degree than US residents. The
              results indicate that consonance preferences can be absent in
              cultures sufficiently isolated from Western music, and are thus
              unlikely to reflect innate biases or exposure to harmonic natural
              sounds. The observed variation in preferences is presumably
              determined by exposure to musical harmony, suggesting that
              culture has a dominant role in shaping aesthetic responses to
              music. We conducted two studies to measure consonance preferences
              in populations with varying exposure to Western music. In Study
              1, we measured preferences for sounds in residents of the United
              States and compared them to three populations in Bolivia: (1)
              residents of the capital city (La Paz); (2) residents of a rural
              town (San Borja); and (3) members of a native society of
              horticulturalist-foragers (the Tsimane') in a remote village
              (Santa Maria) in the Amazon rainforest. City-and town-dwellers
              were fluent in Spanish and generally had tele-visions and radios.
              By contrast, the Tsimane' were mostly monolingual in their own
              language, lacked televisions, and had limited access to music via
              radio 19 . The Tsimane' village lacked electricity and tap water,
              was inaccessible by road, and could be reached only by canoe
              (Fig. 1a). Their contact with Western culture was mainly limited
              to occasional trips to nearby towns. To compare differences
              between cultures to intra-cultural variation within Westerners,
              we tested two groups from the United States---one with at least
              two years of experience playing a musical instrument, and one
              with at most one year of experience. The Tsimane' were of
              particular interest because harmony, polyph-ony, and group
              performances are by all accounts absent from their music. This
              conclusion was suggested by previous recordings and documentation",
  journal  = "Nature",
  volume   =  535,
  number   =  7613,
  pages    = "547--550",
  year     =  2016,
  issn     = "0028-0836, 1476-4687",
  pmid     = "27409816",
  doi      = "10.1038/nature18635"
}

@ARTICLE{Bones2015-ve,
  title    = "Losing the Music: Aging Affects the Perception and Subcortical
              Neural Representation of Musical Harmony",
  author   = "Bones, O and Plack, C J",
  abstract = "When two musical notes with simple frequency ratios are played
              simultaneously, the resulting musical chord is pleasing and
              evokes a sense of resolution or ``consonance''. Complex frequency
              ratios, on the other hand, evoke feelings of tension or
              ``dissonance''. Consonance and dissonance form the basis of
              harmony, a central component of Western music. In earlier work,
              we provided evidence that consonance perception is based on
              neural temporal coding in the brainstem (Bones et al., 2014).
              Here, we show that for listeners with clinically normal hearing,
              aging is associated with a decline in both the perceptual
              distinction and the distinctiveness of the neural representations
              of different categories of two-note chords. Compared with younger
              listeners, older listeners rated consonant chords as less
              pleasant and dissonant chords as more pleasant. Older listeners
              also had less distinct neural representations of consonant and
              dissonant chords as measured using a Neural Consonance Index
              derived from the electrophysiological ``frequency-following
              response.'' The results withstood a control for the effect of age
              on general affect, suggesting that different mechanisms are
              responsible for the perceived pleasantness of musical chords and
              affective voices and that, for listeners with clinically normal
              hearing, age-related differences in consonance perception are
              likely to be related to differences in neural temporal coding.",
  journal  = "Journal of Neuroscience",
  year     =  2015,
  issn     = "0270-6474",
  pmid     = "25740534",
  doi      = "10.1523/JNEUROSCI.3214-14.2015"
}

@ARTICLE{Cong2016-yc,
  title  = "A {Multi-Dimensional} Analytical Model for Musical Harmony
            Perception",
  author = "Cong, Ning",
  number = "November",
  pages  = "1--228",
  year   =  2016
}

@ARTICLE{Stolzenburg2015-ab,
  title    = "Harmony perception by periodicity detection",
  author   = "Stolzenburg, Frieder",
  abstract = "ISSN: 1745-9737 (Print) 1745-9745 (Online) Journal homepage:
              http://www.tandfonline.com/loi/tmam20 The perception of
              consonance/dissonance of musical harmonies is strongly correlated
              with their peri-odicity. This is shown in this article by
              consistently applying recent results from psychophysics and
              neuroacoustics, namely that the just noticeable difference
              between two pitches for humans is about 1\% for the musically
              important low frequency range and that periodicities of complex
              chords can be detected in the human brain. Based thereon, the
              concepts of relative and logarithmic periodicity with smooth-ing
              are introduced as powerful measures of harmoniousness. The
              presented results correlate significantly with empirical
              investigations on the perception of chords. Even for scales,
              plausible results are obtained. For example, all classical church
              modes appear in the front ranks of all theoretically possible
              seven-tone scales.",
  journal  = "Journal of Mathematics \& Music",
  volume   =  9,
  number   =  3,
  pages    = "215--238",
  year     =  2015,
  keywords = "consonance/dissonance; dyads, triads, chords, and scales; harmony
              perception; periodicity",
  issn     = "1745-9737, 1745-9745",
  arxivid  = "1306.6458",
  doi      = "10.1080/17459737.2015.1033024"
}

@ARTICLE{McLachlan2013-hr,
  title    = "Consonance and pitch",
  author   = "McLachlan, Neil and Marco, David and Light, Maria and Wilson,
              Sarah",
  abstract = "To date, no consensus exists in the literature as to theories of
              consonance and dissonance. Experimental data collected over the
              last century have raised questions about the dominant theories
              that are based on frequency relationships between the harmonics
              of music chords. This study provides experimental evidence that
              strongly challenges these theories and suggests a new theory of
              dissonance based on relationships between pitch perception and
              recognition. Experiment 1 shows that dissonance does not increase
              with increasing numbers of harmonics in chords as predicted by
              Helmholtz's (1863/1954) roughness theory, nor does it increase
              with fewer pitch-matching errors as predicted by Stumpf's (1898)
              tonal fusion theory. Dissonance was strongly correlated with
              pitch-matching error for chords, which in turn was reduced by
              chord familiarity and greater music training. This led to the
              proposition that long-term memory templates for common chords
              assist the perception of pitches in chords by providing an
              estimate of the chord intervals from spectral information. When
              recognition mechanisms based on these templates fail, the
              spectral pitch estimate is inconsistent with the period of the
              waveform, leading to cognitive incongruence and the negative
              affect of dissonance. The cognitive incongruence theory of
              dissonance was rigorously tested in Experiment 2, in which
              nonmusicians were trained to match the pitches of a random
              selection of 2-pitch chords. After 10 training sessions, they
              rated the chords they had learned to pitch match as less
              dissonant than the unlearned chords, irrespective of their
              tuning, providing strong support for a cognitive mechanism of
              dissonance.",
  journal  = "Journal of experimental psychology: General",
  volume   =  142,
  number   =  4,
  pages    = "1142--1158",
  year     =  2013,
  keywords = "Dissonance; Model; Perception; Pitch; Recognition",
  issn     = "0096-3445",
  pmid     = "23294344",
  doi      = "10.1037/a0030830"
}

@ARTICLE{Ebeling2008-iu,
  title    = "Neuronal periodicity detection as a basis for the perception of
              consonance: A mathematical model of tonal fusion",
  author   = "Ebeling, Martin",
  abstract = "A mathematical model is presented here to explain the sensation
              of consonance and dissonance on the basis of neuronal coding and
              the properties of a neuronal periodicity detection mechanism.
              This mathematical model makes use of physiological data from a
              neuronal model of periodicity analysis in the midbrain, whose
              operation can be described mathematically by autocorrelation
              functions with regard to time windows. Musical intervals produce
              regular firing patterns in the auditory nerve that depend on the
              vibration ratio of the two tones. The mathematical model makes it
              possible to define a measure for the degree of these regularities
              for each vibration ratio. It turns out that this measure value is
              in line with the degree of tonal fusion as described by Stumpf
              [Tonpsychologie (Psychology of Tones) (Knuf, Hilversum),
              reprinted 1965]. This finding makes it probable that tonal fusion
              is a consequence of certain properties of the neuronal
              periodicity detection mechanism. Together with strong roughness
              resulting from interval tones with fundamentals close together or
              close to the octave, this neuronal mechanism may be regarded as
              the basis of consonance and dissonance.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  124,
  number   =  4,
  pages    = "2320--2329",
  year     =  2008,
  issn     = "0001-4966",
  pmid     = "19062870",
  doi      = "10.1121/1.2968688"
}

@INPROCEEDINGS{Cherla_undated-hn,
  title  = "A distributed model for multiple-viewpoint melodic prediction",
  author = "Cherla, Srikanth",
  doi    = "10.1106/00330330510578796"
}

@ARTICLE{Parncutt2006-qh,
  title   = "Commentary on Cook \& Fujisawa's ``The Psychophysics of Harmony
             Perception: Harmony is a {Three-Tone} Phenomenon''",
  author  = "Parncutt, Richard",
  journal = "Empirical musicology review: EMR",
  volume  =  1,
  number  =  4,
  pages   = "204--209",
  year    =  2006
}

@ARTICLE{Schachner2009-ou,
  title    = "Spontaneous Motor Entrainment to Music in Multiple Vocal
              Mimicking Species",
  author   = "Schachner, Adena and Brady, Timothy F and Pepperberg, Irene M and
              Hauser, Marc D",
  abstract = "The human capacity for music consists of certain core phenomena,
              including the tendency to entrain, or align movement, to an
              external auditory pulse [1-3]. This ability, fundamental both for
              music production and for coordinated dance, has been repeatedly
              highlighted as uniquely human [4-11]. However, it has recently
              been hypothesized that entrainment evolved as a by-product of
              vocal mimicry, generating the strong prediction that only vocal
              mimicking animals may be able to entrain [12, 13]. Here we
              provide comparative data demonstrating the existence of two
              proficient vocal mimicking nonhuman animals (parrots) that
              entrain to music, spontaneously producing synchronized movements
              resembling human dance. We also provide an extensive comparative
              data set from a global video database systematically analyzed for
              evidence of entrainment in hundreds of species both capable and
              incapable of vocal mimicry. Despite the higher representation of
              vocal nonmimics in the database and comparable exposure of mimics
              and nonmimics to humans and music, only vocal mimics showed
              evidence of entrainment. We conclude that entrainment is not
              unique to humans and that the distribution of entrainment across
              species supports the hypothesis that entrainment evolved as a
              by-product of selection for vocal mimicry. \copyright{} 2009
              Elsevier Ltd. All rights reserved.",
  journal  = "Current biology: CB",
  volume   =  19,
  number   =  10,
  pages    = "831--836",
  year     =  2009,
  issn     = "0960-9822",
  pmid     = "19409786",
  doi      = "10.1016/j.cub.2009.03.061"
}

@INCOLLECTION{Nguyen2018-fb,
  title     = "Rhythm and beat perception",
  booktitle = "Springer Handbook of Systematic Musicology",
  author    = "Nguyen, Tram and Gibbings, Aaron and Grahn, Jessica",
  editor    = "Bader, R",
  publisher = "Springer-Verlag",
  pages     = "507--521",
  year      =  2018,
  address   = "Berlin, Germany"
}

@ARTICLE{Ross2016-tc,
  title    = "Motor simulation theories of musical beat perception",
  author   = "Ross, Jessica M and Iversen, John R and Balasubramaniam, Ramesh",
  journal  = "Neurocase",
  volume   =  22,
  number   =  6,
  pages    = "558--565",
  year     =  2016,
  keywords = "auditory perception; motor; motor simulation; planning",
  issn     = "1355-4794",
  doi      = "10.1080/13554794.2016.1242756"
}

@ARTICLE{Ross2018-lw,
  title   = "The role of posterior parietal cortex in beat-based timing
             perception: A continuous theta burst stimulation study",
  author  = "Ross, Jessica Marie and Iversen, John R and Balasubramaniam,
             Ramesh",
  journal = "Journal of cognitive neuroscience",
  volume  =  30,
  number  =  5,
  pages   = "634--643",
  year    =  2018,
  issn    = "0898-929X",
  doi     = "10.1162/jocn\_a\_01237"
}

@ARTICLE{Trost2017-dd,
  title     = "Rhythmic entrainment as a musical affect induction mechanism",
  author    = "Trost, W J and Labb{\'e}, C and Grandjean, D",
  abstract  = "One especially important feature of metrical music is that it
               contains periodicities that listeners' bodily rhythms can adapt
               to. Recent psychological frameworks have introduced the notion
               of rhythmic entrainment, among other mechanisms, as an emotion
               induction principle. In this review paper, we discuss rhythmic
               entrainment as an affect induction mechanism by differentiating
               four levels of entrainment in humans---perceptual, autonomic
               physiological, motor, and social---all of which could contribute
               to a subjective feeling component. We review the theoretical and
               empirical literature on rhythmic entrainment to music that
               supports the existence of these different levels of entrainment
               by describing the phenomena and characterizing the associated
               underlying brain processes. The goal of this review is to
               present the theoretical implications and empirical findings
               about rhythmic entrainment as an important principle at the
               basis of affect induction via music, since it rests upon the
               temporal dimension of music, which is a specificity of music as
               an affective stimulus.",
  journal   = "Neuropsychologia",
  publisher = "Elsevier",
  volume    =  96,
  pages     = "96--110",
  year      =  2017,
  keywords  = "Affect; Brain; Entrainment; Feeling; Music; Rhythm",
  issn      = "0028-3932, 1873-3514",
  pmid      = "28069444",
  doi       = "10.1016/j.neuropsychologia.2017.01.004"
}

@ARTICLE{Tarr2014-zt,
  title    = "Music and social bonding: ``self-other'' merging and
              neurohormonal mechanisms",
  author   = "Tarr, Bronwyn and Launay, Jacques and Dunbar, Robin I M",
  abstract = "It has been suggested that a key function of music during its
              development and spread amongst human populations was its capacity
              to create and strengthen social bonds amongst interacting group
              members. However, the mechanisms by which this occurs have not
              been fully discussed. In this paper we review evidence supporting
              two thus far independently investigated mechanisms for this
              social bonding effect: self-other merging as a consequence of
              inter-personal synchrony, and the release of endorphins during
              exertive rhythmic activities including musical interaction. In
              general, self-other merging has been experimentally investigated
              using dyads, which provide limited insight into large-scale
              musical activities. Given that music can provide an external
              rhythmic framework that facilitates synchrony, explanations of
              social bonding during group musical activities should include
              reference to endorphins, which are released during synchronised
              exertive movements. Endorphins (and the Endogenous Opioid System
              (EOS) in general) are involved in social bonding across primate
              species, and are associated with a number of human social
              behaviours (e.g. laughter, synchronised sports), as well as
              musical activities (e.g. singing and dancing). Furthermore,
              passively listening to music engages the EOS, so here we suggest
              that both self-other merging and the EOS are important in the
              social bonding effects of music. In order to investigate possible
              interactions between these two mechanisms, future experiments
              should recreate ecologically valid examples of musical
              activities.",
  journal  = "Frontiers in psychology",
  volume   =  5,
  pages    = "1--10",
  year     =  2014,
  keywords = "Endorphins; Music; Rhythm; Self-other merging; Social bonding;
              Synchrony",
  issn     = "1664-1078",
  pmid     = "25324805",
  doi      = "10.3389/fpsyg.2014.01096"
}

@ARTICLE{Schellenberg1996-kc,
  title   = "Sensory consonance and the perceptual similarity of complex-tone
             harmonic intervals: Tests of adult and infant listeners",
  author  = "Schellenberg, E Glenn and Trainor, Laurel J",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  100,
  number  =  5,
  pages   = "3321--3328",
  year    =  1996,
  issn    = "0001-4966"
}

@ARTICLE{Johnson-Laird2012-dl,
  title    = "On musical dissonance",
  author   = "Johnson-Laird, Phil N and Kang, Olivia E and Leong, Yuan Chang",
  journal  = "Music perception",
  volume   =  30,
  number   =  1,
  pages    = "19--35",
  year     =  2012,
  keywords = "consonance; dissonance; harmony; sensory",
  issn     = "0730-7829",
  doi      = "10.1525/mp.2012.30.1.19"
}

@ARTICLE{Huron1991-vl,
  title   = "Harmony: A Psychoacoustical Approach by Richard Parncutt",
  author  = "Huron, David",
  journal = "Psychology of Music",
  volume  =  19,
  number  =  2,
  pages   = "219--222",
  year    =  1991
}

@BOOK{Efron1993-yn,
  title     = "An introduction to the bootstrap",
  author    = "Efron, B and Tibshirani, R J",
  publisher = "Chapman \& Hall",
  year      =  1993,
  address   = "Boca Raton, FL"
}

@ARTICLE{Regnault2001-kw,
  title  = "Different Brain Mechanisms Mediate Sensitivity to Sensory
            Consonance and Harmonic Context : Evidence from Auditory
            {Event-Related} Brain Potentials",
  author = "Regnault, Pascaline and Bigand, E and Besson, Mireille",
  pages  = "241--255",
  year   =  2001
}

@ARTICLE{Bowling2018-hz,
  title   = "Vocal similarity predicts the relative attraction of musical
             chords",
  author  = "Bowling, Daniel L and Purves, Dale and Gill, Kamraan Z",
  journal = "Proceedings of the National Academy of Sciences",
  volume  =  115,
  number  =  1,
  pages   = "216--221",
  year    =  2018,
  doi     = "10.1073/pnas.1713206115"
}

@ARTICLE{Trainor2002-dj,
  title   = "Preference for sensory consonance in 2- and 4-month-old infants",
  author  = "Trainor, Laurel J and Tsang, Christine D and Cheung, Vivian H W",
  journal = "Music perception",
  volume  =  20,
  number  =  2,
  pages   = "187--194",
  year    =  2002,
  issn    = "0730-7829"
}

@ARTICLE{Cousineau2012-vb,
  title   = "The basis of musical consonance as revealed by congenital amusia",
  author  = "Cousineau, Marion and McDermott, Josh H and Peretz, Isabelle",
  journal = "Proceedings of the National Academy of Sciences",
  volume  =  109,
  number  =  48,
  pages   = "19858--19863",
  year    =  2012,
  doi     = "10.1073/pnas.1207989109"
}

@ARTICLE{Vencovsky2016-oz,
  title    = "Roughness Prediction Based on a Model of Cochlear Hydrodynamics",
  author   = "Vencovsk{\'y}, V{\'a}clav",
  journal  = "Archives of Acoustics",
  volume   =  41,
  number   =  2,
  pages    = "189--201",
  year     =  2016,
  keywords = "auditory models; peripheral ear; prediction of roughness;
              roughness",
  doi      = "10.1515/aoa-2016-0019"
}

@BOOK{Stumpf2012-od,
  title     = "The Origins of Music",
  author    = "Stumpf, C",
  publisher = "Oxford University Press",
  year      =  2012,
  address   = "Oxford, UK"
}

@ARTICLE{Tymoczko2008-iw,
  title    = "Scale theory, serial theory and voice leading",
  author   = "Tymoczko, Dmitri",
  abstract = "Efficient voice leading, in which melodic lines move by short
              distances from chord to chord, is a hallmark of many different
              Western musical styles. Although musicians can often find
              maximally efficient voice leadings with relative ease, theorists
              have not adequately described general principles or procedures
              for doing so. This article formalises the notion of voice
              leading, shows how to classify voice leadings according to
              transpositional and inversional equivalence and supplies
              algorithms for identifying maximally efficient voice leadings
              between arbitrarily chosen chords. The article also includes
              analytical and theoretical discussions of neo-Riemannian theory,
              the 'tritone substitution' in contemporary jazz, the music of
              Wagner and Debussy, the relation between harmony and counterpoint
              and the connections between scale theory and serial theory.",
  journal  = "Music Analysis",
  volume   =  27,
  number   =  1,
  pages    = "1--49",
  year     =  2008,
  issn     = "0262-5245",
  doi      = "10.1111/j.1468-2249.2008.00257.x"
}

@ARTICLE{Regnault2001-xn,
  title    = "Different Brain Mechanisms Mediate Sensitivity to Sensory
              Consonance and Harmonic Context: Evidence from Auditory
              {Event-Related} Brain Potentials",
  author   = "Regnault, Pascaline and Bigand, E and Besson, Mireille",
  abstract = "The goal of this study was to analyze the time-course of sensory
              (bottom-up) and cognitive (top-down) processes that govern
              musical harmonic expectancy. Eight-chord sequences were presented
              to 12 musicians and 12 nonmusicians. Expectations for the last
              chord were manipulated both at the sensory level (i.e., the last
              chord was sensory consonant or dissonant) and at the cognitive
              level (the harmonic function of the target was varied by
              manipulating the harmonic context built up by the first six
              chords of the sequence). Changes in the harmonic function of the
              target chord mainly modulate the amplitude of a positive
              component peaking around 300 msec (P3) after target onset,
              reflecting top-down influences on the perceptual stages of
              processing. In contrast, changes in the acoustic structure of the
              target chord (sensory consonance) mainly modulate the amplitude
              of a late positive component that develops between 300 and 800
              msec after target onset. Most importantly, the effects of sensory
              consonance and harmonic context on the event-related brain
              potentials associated with the target chords were found to be
              independent, thus suggesting that two separate processors
              contribute to the building up of musical expectancy.",
  journal  = "Journal of cognitive neuroscience",
  volume   =  13,
  number   =  2,
  pages    = "241--255",
  year     =  2001,
  issn     = "0898-929X",
  pmid     = "11244549",
  doi      = "10.1162/089892901564298"
}

@INPROCEEDINGS{Harrison2017-gs,
  title     = "A {Statistical-Learning} Model of Harmony Perception",
  booktitle = "Proceedings of {DMRN+12}: Digital Music Research Network
               {One-Day} Workshop",
  author    = "Harrison, Peter M C and Pearce, Marcus T",
  pages     = "15",
  year      =  2017,
  address   = "London, UK"
}

@BOOK{Sun2006-fe,
  title     = "Optimization Theory and Methods: Nonlinear Programming",
  author    = "Sun, Wenyu and Yuan, Ya-Xiang",
  publisher = "Springer Science \& Business Media",
  year      =  2006,
  address   = "New York, NY"
}

@INPROCEEDINGS{Pickens2005-hy,
  title     = "Markov Random Fields and Maximum Entropy Modeling for Music
               Information Retrieval",
  booktitle = "Proceedings of the 6th International Conference on Music
               Information Retrieval",
  author    = "Pickens, Jeremy and Iliopoulos, Costa",
  abstract  = "Music information retrieval is characterized by a number of
               various user information needs. Systems are being de-veloped
               that allow searchers to find melodies, rhythms, genres, and
               singers or artists, to name but a few. At the heart of all these
               systems is the need to find models or measures that answer the
               question `` how similar are two given pieces of music '' .
               However, similarity has a variety of meanings depending on the
               nature of the system be-ing developed. More importantly, the
               features extracted from a music source are often either
               single-dimensional (i.e.: only pitch, or only rhythm, or only
               timbre) or else as-sumed to be orthogonal. In this paper we
               present a frame-work for developing systems which combine a wide
               vari-ety of non-independent features without having to make the
               independence assumption. As evidence of effective-ness, we
               evaluate the system on the polyphonic theme similarity task over
               symbolic data. Nevertheless, we em-phasize that the framework is
               general, and can handle a range of music information retrieval
               tasks.",
  pages     = "207--214",
  year      =  2005,
  address   = "London, UK",
  keywords  = "bodies of music collections; browsing and organization
               techniques; for the growing; ing; may be successfully met; music
               modeling; random fields"
}

@ARTICLE{Press2018-ay,
  title  = "The Concept of Musical Consonance : A Link between Music and
            Psychoacoustics Author ( s ): Ernst Terhardt Source : Music
            Perception : An Interdisciplinary Journal , Vol . 1 , No . 3 ,
            Dedicated to Published by : University of California Press Stable
            {URL} :",
  author = "Press, California",
  volume =  1,
  number =  3,
  pages  = "276--295",
  year   =  2018
}

@ARTICLE{Parncutt2011-ki,
  title    = "Consonance and dissonance in music theory and psychology:
              Disentangling dissonant dichotomies",
  author   = "Parncutt, Richard and Hair, Graham",
  abstract = "Background in music theory. Consonance and dissonance (C/D) has
              been central to music theory since ancient Greece. It refers to
              both vertical and horizontal relationships in the musical score.
              On longer time scales, it refers to local and global
              relationships. Modern thinking about C/D has been influenced by
              theorists such as Pythagoras, Fux, Rameau, Riemann, Schenker and
              Schoenberg. Tenney (1988) gave a historical overview of C/D
              concepts in different periods, summarizing the contribution of
              culture (stylistic familiarity) and changing beliefs about the
              role of nature. Background in music psychology. The consonance of
              a sonority depends on its spectral harmonicity (cf. Stumpf,
              1883), temporal smoothness (Helmholtz, 1863), and cultural
              familiarity (Cazden, 1945). The consonance of successive
              sonorities depends on their pitch commonality and proximity
              (Parncutt, 1989); of a tonal passage, on its perceived structure
              (Krumhansl, 1990). Many aspects of C/D are ultimately based on
              the learning and recognition of familiar pitch patterns in speech
              and music (Terhardt, 1974) and involve both sides of the
              nature/culture dichotomy. Aim. We develop a new conceptual
              structure for Western C/D that brings together, balances and
              synergizes relevant humanities (history of music, history of
              music theory) and sciences, (acoustics, psychology and
              psychoacoustics). We clarify terminology and develop a holistic
              approach. Main contribution. We cover a broad epistemological
              spectrum that includes the popular conception of C/D as
              pleasant/unpleasant and the history of C/D in Western music and
              music theory. We juxtapose terms, references and styles of
              musical and psychological discourse. We compare and contrast
              dichotomies that overlap or interact with the C/D concept such as
              tense/relaxed, primary/subordinate, centric/acentric,
              diatonic/chromatic, stable/unstable, close/distant,
              similar/different, rough/smooth, fused/segregated,
              related/unrelated, familiar/unfamiliar, implied/realized,
              tonal/atonal; our perception of these dichotomous pairs often
              intensifies, parallels or stands in for our perception of C/D. We
              consider the ``atonal'' music and theoretical writings of Arnold
              Schoenberg, and the radical interrogation of previous assumptions
              about C/D that he provoked. We conclude that vertically,
              consonance involves the creation of multiple incomplete harmonic
              series of partials, while dissonance involves roughness;
              horizontally, consonance involves perceived pitches in common
              while dissonance involves linear pitch distance; and in both
              cases consonance involves familiar patterns of pitch. The listed
              dichotomies lead us to perceive events separated in time either
              as part of a largerscale consonant event or as a counter-foil
              against which such a harmonious whole is perceived. In music
              listening, C/D is generally holistic: it encompasses vertical and
              horizontal elements, which listeners have difficulty
              distinguishing. Implications. C/D will continue to constrain
              composition in the 21st Century. Research on C/D should integrate
              humanities (questions about individual manifestations of music)
              and sciences (questions about music's nature and functions).",
  journal  = "Journal of Interdisciplinary Music Studies",
  volume   =  5,
  number   =  2,
  pages    = "119--166",
  year     =  2011,
  keywords = "Consonance; familiarity; fusion; harmonicity; pitch; roughness;
              tension; tonality R Parncutt and G Hair 120",
  issn     = "1307-0401",
  doi      = "10.4407/jims.2011.11.002"
}

@ARTICLE{Huron2001-or,
  title    = "Tone and voice: A derivation of the rules of voice-leading from
              perceptual principles",
  author   = "Huron, David",
  abstract = "The traditional rules of voice-leading in Western music are
              explicated using experimentally established perceptual
              principles. Six core principles are shown to account for the
              majority of voice-leading rules given in historical and
              contemporary music theory tracts. These principles are treated in
              a manner akin to axioms in a formal system from which the
              traditional rules of voice-leading are derived. Nontraditional
              rules aris- ing from the derivation are shown to predict formerly
              unnoticed aspects of voice-leading practice. In addition to the
              core perceptual principles, several auxiliary principles are
              described. These auxiliary principles are occasionally linked to
              voice-leading practice and may be regarded as com- positional
              ``options'' that shape the music-making in perceptually unique
              ways. It is suggested that these auxiliary principles distinguish
              different types of part writing, such as polyphony, homophony,
              and close har- mony. A theory is proposed to account for the
              aesthetic origin of voice- leading practices.",
  journal  = "Music perception",
  volume   =  19,
  number   =  1,
  pages    = "1--64",
  year     =  2001,
  issn     = "0730-7829",
  pmid     = "14",
  doi      = "10.1525/mp.2001.19.1.1"
}

@TECHREPORT{Hadjeres2016-tr,
  title    = "Style Imitation and Chord Invention in Polyphonic Music with
              Exponential Families",
  author   = "Hadjeres, Ga{\"e}tan and Sakellariou, Jason and Pachet, Fran{\c
              c}ois",
  abstract = "Modeling polyphonic music is a particularly challenging task
              because of the intricate interplay between melody and harmony. A
              good model should satisfy three requirements: statistical
              accuracy (capturing faithfully the statistics of correlations at
              various ranges, horizontally and vertically), flexibility (coping
              with arbitrary user constraints), and generalization capacity
              (inventing new material, while staying in the style of the
              training corpus). Models proposed so far fail on at least one of
              these requirements. We propose a statistical model of polyphonic
              music, based on the maximum entropy principle. This model is able
              to learn and reproduce pairwise statistics between neighboring
              note events in a given corpus. The model is also able to invent
              new chords and to harmonize unknown melodies. We evaluate the
              invention capacity of the model by assessing the amount of cited,
              re-discovered, and invented chords on a corpus of Bach chorales.
              We discuss how the model enables the user to specify and enforce
              user-defined constraints, which makes it useful for style-based,
              interactive music generation.",
  year     =  2016
}

@ARTICLE{McCauley2017-fm,
  title    = "Computational Investigations of Multiword Chunks in Language
              Learning",
  author   = "McCauley, Stewart M and Christiansen, Morten H",
  abstract = "Second-language learners rarely arrive at native proficiency in a
              number of linguistic domains, including morphological and
              syntactic processing. Previous approaches to understanding the
              different outcomes of first- versus second-language learning have
              focused on cognitive and neural factors. In contrast, we explore
              the possibility that children and adults may rely on different
              linguistic units throughout the course of language learning, with
              specific focus on the granularity of those units. Following
              recent psycholinguistic evidence for the role of multiword chunks
              in online language processing, we explore the hypothesis that
              children rely more heavily on multiword units in language
              learning than do adults learning a second language. To this end,
              we take an initial step toward using large-scale, corpus-based
              computational modeling as a tool for exploring the granularity of
              speakers' linguistic units. Employing a computational model of
              language learning, the Chunk-Based Learner, we compare the
              usefulness of chunk-based knowledge in accounting for the speech
              of second-language learners versus children and adults speaking
              their first language. Our findings suggest that while multiword
              units are likely to play a role in second-language learning,
              adults may learn less useful chunks, rely on them to a lesser
              extent, and arrive at them through different means than children
              learning a first language.",
  journal  = "Topics in cognitive science",
  volume   =  9,
  number   =  3,
  pages    = "637--652",
  year     =  2017,
  keywords = "Chunking; Computational modeling; Corpora; L2; Language learning",
  issn     = "1756-8757, 1756-8765",
  pmid     = "28481476",
  doi      = "10.1111/tops.12258"
}

@ARTICLE{Thiessen2013-wf,
  title    = "iMinerva: A mathematical model of distributional statistical
              learning",
  author   = "Thiessen, Erik D and Pavlik, Philip I",
  abstract = "Statistical learning refers to the ability to identify structure
              in the input based on its statistical properties. For many
              linguistic structures, the relevant statistical features are
              distributional: They are related to the frequency and variability
              of exemplars in the input. These distributional regularities have
              been suggested to play a role in many different aspects of
              language learning, including phonetic categories, using phonemic
              distinctions in word learning, and discovering non-adjacent
              relations. On the surface, these different aspects share few
              commonalities. Despite this, we demonstrate that the same
              computational framework can account for learning in all of these
              tasks. These results support two conclusions. The first is that
              much, and perhaps all, of distributional statistical learning can
              be explained by the same underlying set of processes. The second
              is that some aspects of language can be learned due to
              domain-general characteristics of memory.",
  journal  = "Cognitive science",
  volume   =  37,
  number   =  2,
  pages    = "310--343",
  year     =  2013,
  keywords = "Computational modeling; Language; Memory; Statistical learning",
  issn     = "0364-0213",
  pmid     = "23126517",
  doi      = "10.1111/cogs.12011"
}

@ARTICLE{Mareschal2017-za,
  title    = "{TRACX2}: a connectionist autoencoder using graded chunks to
              model infant visual statistical learning",
  author   = "Mareschal, Denis and French, Robert M",
  abstract = "Even newborn infants are able to extract structure from a stream
              of sensory inputs; yet how this is achieved remains largely a
              mystery. We present a connectionist autoencoder model, TRACX2,
              that learns to extract sequence structure by gradually
              constructing chunks, storing these chunks in a distributed manner
              across its synaptic weights and recognizing these chunks when
              they re-occur in the input stream. Chunks are graded rather than
              all-or-nothing in nature. As chunks are learnt their component
              parts become more and more tightly bound together. TRACX2
              successfully models the data from five experiments from the
              infant visual statistical learning literature, including tasks
              involving forward and backward transitional probabilities,
              low-salience embedded chunk items, part-sequences and illusory
              items. The model also captures performance differences across
              ages through the tuning of a single-learning rate parameter.
              These results suggest that infant statistical learning is
              underpinned by the same domain-general learning mechanism that
              operates in auditory statistical learning and, potentially, in
              adult artificial grammar learning.",
  journal  = "Philosophical transactions of the Royal Society of London. Series
              B, Biological sciences",
  volume   =  372,
  number   =  1711,
  pages    = "20160057",
  year     =  2017,
  issn     = "0962-8436",
  doi      = "10.1098/rstb.2016.0057"
}

@ARTICLE{French2011-na,
  title    = "{TRACX}: A {Recognition-Based} Connectionist Framework for
              Sequence Segmentation and Chunk Extraction",
  author   = "French, Robert M and Addyman, Caspar and Mareschal, Denis",
  abstract = "Individuals of all ages extract structure from the sequences of
              patterns they encounter in their environment, an ability that is
              at the very heart of cognition. Exactly what underlies this
              ability has been the subject of much debate over the years. A
              novel mechanism, implicit chunk recognition (ICR), is proposed
              for sequence segmentation and chunk extraction. The mechanism
              relies on the recognition of previously encountered subsequences
              (chunks) in the input rather than on the prediction of upcoming
              items in the input sequence. A connectionist autoassociator model
              of ICR, truncated recursive autoassociative chunk extractor
              (TRACX), is presented in which chunks are extracted by means of
              truncated recursion. The performance and robustness of the model
              is demonstrated in a series of 9 simulations of empirical data,
              covering a wide range of phenomena from the infant statistical
              learning and adult implicit learning literatures, as well as 2
              simulations demonstrating the model's ability to generalize to
              new input and to develop internal representations whose structure
              reflects that of the items in the input sequence. TRACX
              outperforms PARSER (Perruchet \& Vintner, 1998) and the simple
              recurrent network (SRN, Cleeremans \& McClelland, 1991) in
              matching human sequence segmentation on existing data. A new
              study is presented exploring 8-month-olds' use of backward
              transitional probabilities to segment auditory sequences.",
  journal  = "Psychological review",
  volume   =  118,
  number   =  4,
  pages    = "614--636",
  year     =  2011,
  keywords = "Autoassociators; Chunk extraction; Implicit learning; Recursive
              autoassociative memory; Statistical learning",
  issn     = "0033-295X",
  pmid     = "22003842",
  doi      = "10.1037/a0025255"
}

@ARTICLE{Huron1991-on,
  title   = "Tonal consonance versus tonal fusion in polyphonic sonorities",
  author  = "Huron, David",
  journal = "Music perception",
  volume  =  9,
  number  =  2,
  pages   = "135--154",
  year    =  1991,
  issn    = "0730-7829"
}

@ARTICLE{Virtala2017-su,
  title    = "Neurocognition of major-minor and consonance-dissonance",
  author   = "Virtala, Paula and Tervaniemi, Mari",
  journal  = "Music perception",
  volume   =  34,
  number   =  4,
  pages    = "387--404",
  year     =  2017,
  keywords = "enculturation; learning; music; plasticity",
  issn     = "0730-7829",
  doi      = "10.1525/mp.2017.34.4.387"
}

@BOOK{Gusfield_undated-xz,
  title  = "Algorithms of strings, trees, and sequences",
  author = "Gusfield, Dan"
}

@ARTICLE{Statistics2018-ox,
  title  = "Do Robust Estimators Work with Real Data ? Author ( s ): Stephen
            {M} . Stigler Source : The Annals of Statistics , Vol . 5 , No . 6
            ( Nov ., 1977 ), pp . 1055-1098 Published by : Institute of
            Mathematical Statistics Stable {URL} : http://www.jstor.org/stable/",
  author = "Statistics, Mathematical",
  volume =  5,
  number =  6,
  pages  = "1055--1098",
  year   =  2018
}

@ARTICLE{Wiggins2012-gi,
  title   = "On the correctness of imprecision and the existential fallacy of
             absolute music",
  author  = "Wiggins, Geraint A",
  journal = "Journal of Mathematics \& Music. Mathematical and Computational
             Approaches to Music Theory, Analysis, Composition and Performance",
  volume  =  6,
  number  =  2,
  pages   = "93--101",
  year    =  2012,
  issn    = "1745-9737"
}

@ARTICLE{Omigie2019-xh,
  title  = "Intracranial Recordings and Computational Modeling of Music Reveal
            the Time Course of Prediction Error Signaling in Frontal and
            Temporal Cortices",
  author = "Omigie, Diana and Pearce, Marcus and Lehongre, Katia and Hasboun,
            Dominique and Navarro, Vincent and Adam, Claude and Samson,
            Severine",
  pages  = "1--19",
  year   =  2019,
  doi    = "10.1162/jocn"
}

@ARTICLE{Wiggins2012-cg,
  title   = "Music, mind and mathematics: theory, reality and formality",
  author  = "Wiggins, Geraint A",
  journal = "Journal of Mathematics \& Music. Mathematical and Computational
             Approaches to Music Theory, Analysis, Composition and Performance",
  volume  =  6,
  number  =  2,
  pages   = "111--123",
  year    =  2012,
  issn    = "1745-9737"
}

@ARTICLE{Sears2018-rt,
  title     = "Simulating melodic and harmonic expectations for tonal cadences
               using probabilistic models",
  author    = "Sears, David R W and Pearce, Marcus T and Caplin, William E and
               McAdams, Stephen",
  journal   = "Journal of New Music Research",
  publisher = "Routledge",
  volume    =  47,
  number    =  1,
  pages     = "29--52",
  year      =  2018,
  keywords  = "cadence; expectation; statistical learning",
  issn      = "0929-8215",
  doi       = "10.1080/09298215.2017.1367010"
}

@ARTICLE{Wiggins2012-sq,
  title   = "The future of (mathematical) music theory",
  author  = "Wiggins, Geraint A",
  journal = "Journal of Mathematics \& Music. Mathematical and Computational
             Approaches to Music Theory, Analysis, Composition and Performance",
  volume  =  6,
  number  =  2,
  pages   = "135--144",
  year    =  2012,
  issn    = "1745-9737"
}

@ARTICLE{Dienes2011-za,
  title    = "Bayesian versus orthodox statistics: Which side are you on?",
  author   = "Dienes, Zoltan",
  abstract = "Researchers are often confused about what can be inferred from
              significance tests. One problem occurs when people apply Bayesian
              intuitions to significance testing---two approaches that must be
              firmly separated. This article presents some common situations in
              which the approaches come to different conclusions; you can see
              where your intuitions initially lie. The situations include
              multiple testing, deciding when to stop running participants, and
              when a theory was thought of relative to finding out results. The
              interpretation of nonsignificant results has also been
              persistently problematic in a way that Bayesian inference can
              clarify. The Bayesian and orthodox approaches are placed in the
              context of different notions of rationality, and I accuse myself
              and others as having been irrational in the way we have been
              using statistics on a key notion of rationality. The reader is
              shown how to apply Bayesian inference in practice, using free
              online software, to allow more coherent inferences from data.",
  journal  = "Perspectives on psychological science: a journal of the
              Association for Psychological Science",
  volume   =  6,
  number   =  3,
  pages    = "274--290",
  year     =  2011,
  keywords = "Bayes; Evidence; Likelihood principle; Significance testing;
              Statistical inference",
  issn     = "1745-6916",
  pmid     = "26168518",
  doi      = "10.1177/1745691611406920"
}

@ARTICLE{Wagenmakers2016-gd,
  title    = "Bayesian benefits for the pragmatic researcher",
  author   = "Wagenmakers, Eric Jan and Morey, Richard D and Lee, Michael D",
  abstract = "The practical advantages of Bayesian inference are demonstrated
              through two concrete examples. In the first example, we wish to
              learn about a crimi-nal's IQ: a problem of parameter estimation.
              In the second example, we wish to quantify support in favor of a
              null hypothesis, and track this support as the data accumulate: a
              problem of hypothesis testing. The Bayesian frame-work unifies
              both problems within a coherent predictive framework, where
              parameters and models that predict the data successfully will
              receive a boost in plausibility, whereas parameters and models
              that predict poorly suffer a decline. Our examples demonstrate
              how Bayesian analyses can be more in-formative, more elegant, and
              more flexible than the orthodox methodology that remains dominant
              within the field of psychology. On a sunny morning in Florida,
              while the birds were singing and the crickets chirping, Bob
              decided to throw his wife from the bedroom balcony, killing her
              instantly. The case is",
  journal  = "Current directions in psychological science",
  volume   =  25,
  number   =  3,
  pages    = "169--176",
  year     =  2016,
  keywords = "Bayesian inference; hypothesis testing; parameter estimation;
              prediction; updating",
  issn     = "0963-7214, 1467-8721",
  doi      = "10.1177/0963721416643289"
}

@BOOK{Allen2017-zz,
  title     = "Statistics and experimental design for psychologists: A model
               comparison approach",
  author    = "Allen, Rory",
  publisher = "World Scientific",
  year      =  2017,
  address   = "London, UK"
}

@ARTICLE{Masson2011-rl,
  title    = "A tutorial on a practical Bayesian alternative to null-hypothesis
              significance testing",
  author   = "Masson, Michael E J",
  pages    = "679--690",
  year     =  2011,
  keywords = "bayesian analysis; in psychological research has; nhst;
              null-hypothesis; null-hypothesis significance testing;
              significance testing; the widespread use of; withstood numerous",
  doi      = "10.3758/s13428-010-0049-5"
}

@BOOK{Maxwell2018-uz,
  title     = "Designing experiments and analyzing data: A model comparison
               perspective",
  author    = "Maxwell, Scott E and Delaney, Harold D and Kelley, Ken",
  publisher = "Routledge",
  year      =  2018,
  address   = "New York, NY"
}

@BOOK{Field2012-ui,
  title     = "Discovering statistics using {R}",
  author    = "Field, Andy and Miles, Jeremy and Field, Zo{\"e}",
  publisher = "Sage",
  year      =  2012,
  address   = "London, UK"
}

@BOOK{Judd2017-tm,
  title     = "Data analysis: A model comparison approach to regression,
               {ANOVA}, and beyond",
  author    = "Judd, Charles M and McClelland, Gary H and Ryan, Carey S",
  publisher = "Routledge",
  year      =  2017,
  address   = "New York, NY"
}

@ARTICLE{Nickerson2000-tr,
  title    = "Null hypothesis significance testing: A review of an old and
              continuing controversy",
  author   = "Nickerson, Raymond S",
  abstract = "Null hypothesis significance testing (NHST) is arguably the most
              widely used approach to hypothesis evaluation among behavioral
              and social scientists. It is also very controversial. A major
              concern expressed by critics is that such testing is
              misunderstood by many of those who use it. Several other
              objections to its use have also been raised. In this article the
              author reviews and comments on the claimed misunderstandings as
              well as on other criticisms of the approach, and he notes
              arguments that have been advanced in support of NHST.
              Alternatives and supplements to NHST are considered, as are
              several related recommendations regarding the interpretation of
              experimental data. The concluding opinion is that NHST is easily
              misunderstood and misused but that when applied with good
              judgment it can be an effective aid to the interpretation of
              experimental data.",
  journal  = "Psychological methods",
  volume   =  5,
  number   =  2,
  pages    = "241--301",
  year     =  2000,
  issn     = "1082-989X, 1939-1463",
  pmid     = "10937333",
  doi      = "10.1037/1082-989X.5.2.241"
}

@BOOK{Field2017-vb,
  title     = "Discovering Statistics Using {IBM} {SPSS} Statistics",
  author    = "Field, Andy",
  publisher = "Sage",
  year      =  2017,
  address   = "London, UK"
}

@ARTICLE{Rodgers2010-ew,
  title    = "The Epistemology of Mathematical and Statistical Modeling",
  author   = "Rodgers, Joseph Lee",
  journal  = "The American psychologist",
  volume   =  65,
  number   =  1,
  pages    = "1--12",
  year     =  2010,
  keywords = "has; hypothesis significance testing; mathematical models; nhst;
              null; relatively silent methodological revolution; sir ronald
              fisher; statistical models; teaching methodology",
  issn     = "0003-066X",
  doi      = "10.1037/a0018326"
}

@BOOK{Coolican2014-gz,
  title     = "Research methods and statistics in psychology",
  author    = "Coolican, Hugh",
  publisher = "Psychology Press",
  year      =  2014,
  address   = "Hove, UK"
}

@ARTICLE{Raffalovich2008-pa,
  title    = "Model selection procedures in social research: {Monte-Carlo}
              simulation results",
  author   = "Raffalovich, Lawrence E and Deane, Glenn D and Armstrong, David
              and Tsao, Hui-Shien",
  abstract = "Model selection strategies play an important, if not explicit,
              role in quantitative research. The inferential properties of
              these strategies are largely unknown, therefore, there is little
              basis for recommending (or avoiding) any particular set of
              strategies. In this paper, we evaluate several commonly used
              model selection procedures [Bayesian information criterion (BIC),
              adjusted R 2, Mallows? C p, Akaike information criteria (AIC),
              AICc, and stepwise regression] using Monte-Carlo simulation of
              model selection when the true data generating processes (DGP) are
              known. We find that the ability of these selection procedures to
              include important variables and exclude irrelevant variables
              increases with the size of the sample and decreases with the
              amount of noise in the model. None of the model selection
              procedures do well in small samples, even when the true DGP is
              largely deterministic; thus, data mining in small samples should
              be avoided entirely. Instead, the implicit uncertainty in model
              specification should be explicitly discussed. In large samples,
              BIC is better than the other procedures at correctly identifying
              most of the generating processes we simulated, and stepwise does
              almost as well. In the absence of strong theory, both BIC and
              stepwise appear to be reasonable model selection strategies in
              large samples. Under the conditions simulated, adjusted R 2,
              Mallows? C p AIC, and AICc are clearly inferior and should be
              avoided. Model selection strategies play an important, if not
              explicit, role in quantitative research. The inferential
              properties of these strategies are largely unknown, therefore,
              there is little basis for recommending (or avoiding) any
              particular set of strategies. In this paper, we evaluate several
              commonly used model selection procedures [Bayesian information
              criterion (BIC), adjusted R 2, Mallows? C p, Akaike information
              criteria (AIC), AICc, and stepwise regression] using Monte-Carlo
              simulation of model selection when the true data generating
              processes (DGP) are known. We find that the ability of these
              selection procedures to include important variables and exclude
              irrelevant variables increases with the size of the sample and
              decreases with the amount of noise in the model. None of the
              model selection procedures do well in small samples, even when
              the true DGP is largely deterministic; thus, data mining in small
              samples should be avoided entirely. Instead, the implicit
              uncertainty in model specification should be explicitly
              discussed. In large samples, BIC is better than the other
              procedures at correctly identifying most of the generating
              processes we simulated, and stepwise does almost as well. In the
              absence of strong theory, both BIC and stepwise appear to be
              reasonable model selection strategies in large samples. Under the
              conditions simulated, adjusted R 2, Mallows? C p AIC, and AICc
              are clearly inferior and should be avoided.",
  journal  = "Journal of applied statistics",
  volume   =  35,
  number   =  10,
  pages    = "1093--1114",
  year     =  2008,
  issn     = "0266-4763",
  doi      = "10.1080/03081070802203959"
}

@INPROCEEDINGS{Villegas2010-ug,
  title     = "Influence of Psychoacoustic Roughness on Musical Intonation
               Preference",
  booktitle = "128th Audio Engineering Society Convention",
  author    = "Villegas, Julian and Cohen, Michael and Wilson, Ian and Martens,
               William",
  pages     = "1--11",
  year      =  2010,
  address   = "London, England",
  keywords  = "intonation; musical consonance; pleasantness; preference;
               roughness; tuning",
  isbn      = "9781617387739"
}

@ARTICLE{Oh2012-sm,
  title    = "Evaluating crowdsourcing through amazon mechanical turk as a
              technique for conducting music perception experiments",
  author   = "Oh, Jieun and Wang, Ge",
  abstract = "Online crowdsourcing marketplaces, such as the Amazon Mechanical
              Turk, provide an environment for cost-effective crowdsourcing on
              a massive scale, leveraging human intelligence, expertise, and
              judgment. While the Mechanical Turk is typically used by
              businesses to clean data, categorize items, and moderate content,
              the scientific community, too, has begun experimenting with it to
              conduct academic research. In this paper, we evaluate
              crowdsourcing as a technique for conducting music perception
              experiments by first describing how principles of experimental
              design can be implemented on the Mechanical Turk. Then, we
              discuss the pros and cons of online crowdsourcing with respect to
              subject demography, answer quality, recruitment cost, and ethical
              concerns. Finally, we address audio-specific factors relevant to
              researchers in the field of music perception and cognition. The
              goal of this review is to offer practical guidelines for
              designing experiments that best leverage the benefits and
              overcome the challenges of employing crowdsourcing as a research
              methodology.",
  journal  = "ICMPC: Proceedings / edited by Catherine Stevens ... [et al.].
              International Conference on Music Perception and Cognition",
  number   = "February",
  pages    = "738--743",
  year     =  2012
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Plomp1965-mc,
  title    = "Tonal consonance and critical bandwidth",
  author   = "Plomp, R and Levelt, W J M",
  abstract = "Firstly, theories are reviewed on the explanation of tonal
              consonance as the singular nature of tone intervals with
              frequency ratios corresponding with small integer numbers. An
              evaluation of these explanations in the light of some
              experimental studies supports the hypothesis, as promoted by von
              Helmholtz, that the difference between consonant and dissonant
              intervals is related to beats of adjacent partials. This relation
              was studied more fully by experiments in which subjects had to
              judge simple‐tone intervals as a function of test frequency and
              interval width. The results may be considered as a modification
              of von Helmholtz's conception and indicate that, as a function of
              frequency, the transition range between consonant and dissonant
              intervals is related to critical bandwidth. Simple‐tone intervals
              are evaluated as consonant for frequency differences exceeding
              this bandwidth. whereas the most dissonant intervals correspond
              with frequency differences of about a quarter of this bandwidth.
              On the base of these results, some properties of consonant
              intervals consisting of complex tones are explained. To answer
              the question whether critical bandwidth also plays a r{\^o}le in
              music, the chords of two compositions (parts of a trio sonata of
              J. S. Bach and of a string quartet of A. Dvo{\v r}{\'a}k) were
              analyzed by computing interval distributions as a function of
              frequency and number of harmonics taken into account. The results
              strongly suggest that, indeed, critical bandwidth plays an
              important r{\^o}le in music: for a number of harmonics
              representative for musical instruments, the ``density'' of
              simultaneous partials alters as a function of frequency in the
              same way as critical bandwidth does.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  38,
  number   =  4,
  pages    = "548--560",
  year     =  1965,
  issn     = "0001-4966",
  doi      = "10.1121/1.1909741"
}

@ARTICLE{Wang2013-pq,
  title     = "Roughness modelling based on human auditory perception for sound
               quality evaluation of vehicle interior noise",
  author    = "Wang, Y S and Shen, G Q and Guo, H and Tang, X L and Hamade, T",
  abstract  = "In this paper, a roughness model, which is based on human
               auditory perception (HAP) and known as HAP-RM, is developed for
               the sound quality evaluation (SQE) of vehicle noise. First, the
               interior noise signals are measured for a sample vehicle and
               prepared for roughness modelling. The HAP-RM model is based on
               the process of sound transfer and perception in the human
               auditory system by combining the structural filtering function
               and nonlinear perception characteristics of the ear. The HAP-RM
               model is applied to the measured vehicle interior noise signals
               by considering the factors that affect hearing, such as the
               modulation and carrier frequencies, the time and frequency
               maskings and the correlations of the critical bands. The HAP-RM
               model is validated by jury tests. An anchor-scaled scoring
               method (ASM) is used for subjective evaluations in the jury
               tests. The verification results show that the novel developed
               model can accurately calculate vehicle noise roughness below 0.6
               asper. Further investigation shows that the total roughness of
               the vehicle interior noise can mainly be attributed to frequency
               components below 12 Bark. The time masking effects of the
               modelling procedure enable the application of the HAP-RM model
               to stationary and nonstationary vehicle noise signals and the
               SQE of other sound-related signals in engineering problems.",
  journal   = "Journal of sound and vibration",
  publisher = "Elsevier",
  volume    =  332,
  number    =  16,
  pages     = "3893--3904",
  year      =  2013,
  issn      = "0022-460X",
  doi       = "10.1016/j.jsv.2013.02.030"
}

@ARTICLE{Benoit2014-ra,
  title    = "Musically cued gait-training improves both perceptual and motor
              timing in Parkinson's disease",
  author   = "Benoit, Charles-Etienne and Dalla Bella, Simone and Farrugia,
              Nicolas and Obrig, Hellmuth and Mainka, Stefan and Kotz, Sonja A",
  abstract = "It is well established that auditory cueing improves gait in
              patients with idiopathic Parkinson's disease (IPD).
              Disease-related reductions in speed and step length can be
              improved by providing rhythmical auditory cues via a metronome or
              music. However, effects on cognitive aspects of motor control
              have yet to be thoroughly investigated. If synchronization of
              movement to an auditory cue relies on a supramodal timing system
              involved in perceptual, motor, and sensorimotor integration,
              auditory cueing can be expected to affect both motor and
              perceptual timing. Here, we tested this hypothesis by assessing
              perceptual and motor timing in 15 IPD patients before and after a
              4-week music training program with rhythmic auditory cueing.
              Long-term effects were assessed 1 month after the end of the
              training. Perceptual and motor timing was evaluated with a
              battery for the assessment of auditory sensorimotor and timing
              abilities and compared to that of age-, gender-, and
              education-matched healthy controls. Prior to training, IPD
              patients exhibited impaired perceptual and motor timing. Training
              improved patients' performance in tasks requiring synchronization
              with isochronous sequences, and enhanced their ability to adapt
              to durational changes in a sequence in hand tapping tasks.
              Benefits of cueing extended to time perception (duration
              discrimination and detection of misaligned beats in musical
              excerpts). The current results demonstrate that auditory cueing
              leads to benefits beyond gait and support the idea that coupling
              gait to rhythmic auditory cues in IPD patients relies on a
              neuronal network engaged in both perceptual and motor timing.",
  journal  = "Frontiers in human neuroscience",
  volume   =  8,
  pages    = "1--11",
  year     =  2014,
  keywords = "Parkinson disease; auditory cueing; motor behavior; parkinson
              disease; perception; timing",
  issn     = "1662-5161",
  pmid     = "25071522",
  doi      = "10.3389/fnhum.2014.00494"
}

@ARTICLE{Bella2017-bz,
  title     = "Gait improvement via rhythmic stimulation in Parkinson's disease
               is linked to rhythmic skills",
  author    = "Bella, Simone Dalla and Benoit, Charles Etienne and Farrugia,
               Nicolas and Keller, Peter E and Obrig, Hellmuth and Mainka,
               Stefan and Kotz, Sonja A",
  journal   = "Scientific reports",
  publisher = "Nature Publishing Group",
  volume    =  7,
  pages     = "1--11",
  year      =  2017,
  issn      = "2045-2322",
  pmid      = "28233776",
  doi       = "10.1038/srep42005"
}

@PHDTHESIS{Harrison2016-gq,
  title  = "Predicting with the wisdom of the crowd",
  author = "Harrison, Peter M C",
  year   =  2016
}

@ARTICLE{Mckinney2007-ju,
  title   = "Evaluation of audio beat tracking and music tempo extraction
             algorithms",
  author  = "Mckinney, M F and Moelants, D and Davies, M E P and Klapuri, A",
  journal = "Journal of New Music Research",
  volume  =  36,
  number  =  1,
  pages   = "1--16",
  year    =  2007,
  doi     = "10.1080/09298210701653252"
}

@ARTICLE{Grahn2012-lq,
  title    = "Individual differences in rhythmic ability: Behavioral and
              neuroimaging investigations",
  author   = "Grahn, Jessica A and Schuit, Dirk",
  journal  = "Psychomusicology",
  volume   =  22,
  number   =  2,
  pages    = "105--121",
  year     =  2012,
  keywords = "10; 1037; a0031188; anecdotally; auditory perception; doi; dx;
              healthy individuals; http; music; no sense of; org; rhythm;
              rhythmic ability is thought; several individuals report having;
              supp; supplemental materials; timing; to vary widely across",
  doi      = "10.1037/a0031188"
}

@ARTICLE{Katz2017-vn,
  title    = "Harmonic syntax of the twelve-bar blues form: A corpus study",
  author   = "Katz, Jonah",
  journal  = "Music perception",
  volume   =  35,
  number   =  2,
  pages    = "165--192",
  year     =  2017,
  keywords = "a corpus of; blues; complexity; corpus methods; form as used by;
              formal language; harmonic principles active in; jazz harmony;
              jazz musicians; syntax; the 12-bar blues",
  issn     = "0730-7829"
}

@INPROCEEDINGS{Masada2017-kq,
  title     = "Chord recognition in symbolic music using semi-Markov
               Conditional Random Fields",
  booktitle = "Proceedings of the 18th International Society for Music
               Information Retrieval Conference",
  author    = "Masada, Kristen and Bunescu, Razvan",
  pages     = "272--278",
  year      =  2017,
  address   = "Suzhou, China"
}

@ARTICLE{Di_Giorgi2017-zh,
  title   = "A data-driven model of tonal chord sequence complexity",
  author  = "Di Giorgi, Bruno and Dixon, Simon and Zanoni, Massimiliano and
             Sarti, Augusto",
  journal = "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
  volume  =  25,
  number  =  11,
  pages   = "2237--2250",
  year    =  2017,
  issn    = "2329-9290",
  doi     = "10.1109/TASLP.2017.2756443"
}

@ARTICLE{Fiveash2014-qo,
  title    = "Music and language: Do they draw on similar syntactic working
              memory resources?",
  author   = "Fiveash, Anna and Pammer, Kristen",
  abstract = "The cognitive processing similarities between music and language
              is an emerging field of study, with research finding evidence for
              shared processing pathways in the brain, especially in relation
              to syntax. This research combines theory from the shared
              syntactic integration resource hypothesis (SSIRH; Patel, 2008)
              and syntactic working memory (SWM) theory (Kljajevic, 2010), and
              suggests there will be shared processing costs when music and
              language concurrently access SWM. To examine this, word lists and
              complex sentences were paired with three music conditions:
              normal; syntactic manipulation (out-of-key chord); and a control
              condition with an instrument manipulation. As predicted, memory
              for sentences declined when paired with the syntactic
              manipulation compared to the other two music manipulations, but
              the same pattern did not occur in word lists. This suggests that
              both sentences and music with a syntactic irregularity are
              accessing SWM. Word lists, however, are thought to be primarily
              accessing the phonological loop, and therefore did not show
              effects of shared processing. Musicians performed differently
              from non-musicians, suggesting that the processing of musical and
              linguistic syntax differs with musical ability. Such results
              suggest a separation in processing between the phonological loop
              and SWM, and give evidence for shared processing mechanisms
              between music and language syntax.",
  journal  = "Psychology of Music",
  volume   =  42,
  number   =  2,
  pages    = "190--209",
  year     =  2014,
  keywords = "(); 2006; 2008; 2009; and language has a; and whether music and;
              hypothesis; johansson; language share similar cognitive; long
              history of research; memory; mithen; musicians; peretz;
              phonological loop; process-; shared syntactic integration
              resource; syntax; the connection between music",
  issn     = "0305-7356",
  doi      = "10.1177/0305735612463949"
}

@ARTICLE{London2013-hv,
  title    = "Building a representative corpus of classical music",
  author   = "London, Justin",
  journal  = "Music perception",
  volume   =  31,
  number   =  1,
  pages    = "68--90",
  year     =  2013,
  keywords = "classical music; common practice; corpus; genres; historical
              styles; period",
  issn     = "0730-7829"
}

@INPROCEEDINGS{Langhabel2017-wl,
  title     = "Feature discovery for sequential prediction of monophonic music",
  booktitle = "Proceedings of the 18th International Society for Music
               Information Retrieval Conference",
  author    = "Langhabel, Jonas and Lieck, Robert and Toussaint, Marc and
               Rohrmeier, Martin",
  pages     = "649--656",
  year      =  2017,
  address   = "Suzhou, China"
}

@ARTICLE{Bowling2015-vx,
  title    = "A biological rationale for musical consonance",
  author   = "Bowling, Daniel L and Purves, Dale",
  abstract = "Scales are collections of tones that divide octaves into specific
              intervals used to create music. Since humans can distinguish
              about 240 different pitches over an octave in the mid-range of
              hearing, in principle a very large number of tone combinations
              could have been used for this purpose. Nonetheless, compositions
              in Western classical, folk and popular music as well as in many
              other musical traditions are based on a relatively small number
              of scales that typically comprise only five to seven tones. Why
              humans employ only a few of the enormous number of possible tone
              combinations to create music is not known. Here we show that the
              component intervals of the most widely used scales throughout
              history and across cultures are those with the greatest overall
              spectral similarity to a harmonic series. These findings suggest
              that humans prefer tone combinations that reflect the spectral
              characteristics of conspecific vocalizations. The analysis also
              highlights the spectral similarity among the scales used by
              different cultures.",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  112,
  number   =  36,
  pages    = "11155--11160",
  year     =  2015,
  doi      = "10.1073/pnas.1505768112"
}

@ARTICLE{Gill2009-tq,
  title    = "A biological rationale for musical scales",
  author   = "Gill, Kamraan Z and Purves, Dale",
  abstract = "Scales are collections of tones that divide octaves into specific
              intervals used to create music. Since humans can distinguish
              about 240 different pitches over an octave in the mid-range of
              hearing, in principle a very large number of tone combinations
              could have been used for this purpose. Nonetheless, compositions
              in Western classical, folk and popular music as well as in many
              other musical traditions are based on a relatively small number
              of scales that typically comprise only five to seven tones. Why
              humans employ only a few of the enormous number of possible tone
              combinations to create music is not known. Here we show that the
              component intervals of the most widely used scales throughout
              history and across cultures are those with the greatest overall
              spectral similarity to a harmonic series. These findings suggest
              that humans prefer tone combinations that reflect the spectral
              characteristics of conspecific vocalizations. The analysis also
              highlights the spectral similarity among the scales used by
              different cultures.",
  journal  = "PloS one",
  volume   =  4,
  number   =  12,
  year     =  2009,
  issn     = "1932-6203",
  pmid     = "19997506",
  doi      = "10.1371/journal.pone.0008144"
}

@ARTICLE{Koelsch2005-ip,
  title    = "Adults and children processing music: An {fMRI} study",
  author   = "Koelsch, Stefan and Fritz, Thomas and Schulze, Katrin and Alsop,
              David and Schlaug, Gottfried",
  abstract = "The present study investigates the functional neuroanatomy of
              music perception with functional magnetic resonance imaging
              (fMRI). Three different subject groups were investigated to
              examine developmental aspects and effects of musical training:
              10-year-old children with varying degrees of musical training,
              adults without formal musical training (nonmusicians), and adult
              musicians. Subjects made judgements on sequences that ended on
              chords that were music-syntactically either regular or irregular.
              In adults, irregular chords activated the inferior frontal gyrus,
              orbital frontolateral cortex, the anterior insula, ventrolateral
              premotor cortex, anterior and posterior areas of the superior
              temporal gyrus, the superior temporal sulcus, and the
              supramarginal gyrus. These structures presumably form different
              networks mediating cognitive aspects of music processing (such as
              processing of musical syntax and musical meaning, as well as
              auditory working memory), and possibly emotional aspects of music
              processing. In the right hemisphere, the activation pattern of
              children was similar to that of adults. In the left hemisphere,
              adults showed larger activations than children in prefrontal
              areas, in the supramarginal gyrus, and in temporal areas. In both
              adults and children, musical training was correlated with
              stronger activations in the frontal operculum and the anterior
              portion of the superior temporal gyrus. \copyright{} 2005
              Elsevier Inc. All rights reserved.",
  journal  = "NeuroImage",
  volume   =  25,
  number   =  4,
  pages    = "1068--1076",
  year     =  2005,
  keywords = "Auditory processing; BA 21; BA 22; BA 37; BA 44; BA 45; BA 47; BA
              6; Children; Functional plasticity; Music; Musical expertise;
              fMRI",
  issn     = "1053-8119",
  pmid     = "15850725",
  doi      = "10.1016/j.neuroimage.2004.12.050"
}

@ARTICLE{Schellenberg2004-zh,
  title   = "Music lessons enhance {IQ}",
  author  = "Schellenberg, E Glenn",
  journal = "Psychological science",
  volume  =  15,
  number  =  8,
  pages   = "511--514",
  year    =  2004,
  issn    = "0956-7976",
  doi     = "10.1111/j.0956-7976.2004.00711.x"
}

@INCOLLECTION{Bigand2009-iu,
  title     = "Tonal cognition",
  booktitle = "The Oxford handbook of music psychology",
  author    = "Bigand, E and Poulin-Charronnat, B{\'e}n{\'e}dicte",
  editor    = "Hallam, Susan and Cross, Ian and Thaut, Michael",
  publisher = "Oxford University Press",
  year      =  2009,
  address   = "Oxford, England"
}

@ARTICLE{Bountouridis2016-kx,
  title    = "A data-driven approach to chord similarity and chord mutability",
  author   = "Bountouridis, Dimitrios and Koops, Hedrik Vincent and Wiering,
              Frans and Veltkamp, Remco C",
  abstract = "Assessing the relationship between chord sequences is an
              important\textbackslashnongoing research topic in the fields of
              music cognition and music\textbackslashninformation retrieval.
              Heuristic and cognitive models of chord\textbackslashnsimilarity
              have been investigated but none has aimed to capture
              the\textbackslashncollective perception of chord similarity from
              a large dataset of\textbackslashnuser-generated content. Devising
              a large-scale experiment to gather\textbackslashnsufficient data
              from human subjects has always been a major
              stumbling\textbackslashnblock. We present a novel chord
              similarity model based on a large amount\textbackslashnof
              crowd-sourced transcriptions from a popular automatic
              chord\textbackslashnestimation service. We show that our model
              outperforms heuristic-based\textbackslashnmodels in a song
              identification task. Secondly, a model of
              chord\textbackslashnmutations based on a large amount of
              crowd-sourced cover songs\textbackslashntranscriptions is
              introduced. From crowd-sourced data, we
              create\textbackslashnsubstitution matrices that capture the
              perceived similarity and\textbackslashnmutability between chords.
              These results show that modelling the\textbackslashncollective
              perception can not only substitute alternative,
              sophisticated\textbackslashnmodels but also further enhance
              performance in various music information\textbackslashnretrieval
              tasks.",
  journal  = "Proceedings - 2016 IEEE 2nd International Conference on
              Multimedia Big Data, BigMM 2016",
  pages    = "275--278",
  year     =  2016,
  pmid     = "1812551337",
  doi      = "10.1109/BigMM.2016.18"
}

@INCOLLECTION{Oxenham2013-jn,
  title     = "The Perception of Musical Tones",
  booktitle = "The Psychology of Music",
  author    = "Oxenham, Andrew J",
  editor    = "Deutsch, Diana",
  publisher = "Academic Press",
  year      =  2013,
  address   = "London, England"
}

@ARTICLE{Rocher2010-ua,
  title    = "A Survey of Chord Distances With Comparison for Chord Analysis",
  author   = "Rocher, Thomas and Robine, Matthias and Hanna, Pierre and
              Desainte-catherine, Myriam",
  abstract = "This paper proposes a comparative study of different distance
              measures between chords in Western Music. These distances are
              described, and experimented using a chord recognition system. In
              this system, the distance between chords is used to compute a
              chord transition cost between different chord candidates, and
              thus helps a best path to be found in the chord candidate graph,
              which is the final chord sequence identified by the system.
              Experiments have been run on a MIDI file database. Results
              depending on the chord distance used are then compared. These
              results show that the different chord distances rely on different
              musical information. A statistical study shows that different
              classes of distances can be proposed.",
  journal  = "Proceedings of the International Computer Music Conference",
  number   = "March",
  pages    = "187--190",
  year     =  2010
}

@ARTICLE{McDermott2010-ui,
  title    = "Individual differences reveal the basis of consonance",
  author   = "McDermott, Josh H and Lehr, Andriana J and Oxenham, Andrew J",
  abstract = "Some combinations of musical notes are consonant (pleasant),
              whereas others are dissonant (unpleasant), a distinction central
              to music. Explanations of consonance in terms of acoustics,
              auditory neuroscience, and enculturation have been debated for
              centuries [1-12]. We utilized individual differences to
              distinguish the candidate theories. We measured preferences for
              musical chords as well as nonmusical sounds that isolated
              particular acoustic factors - specifically, the beating and the
              harmonic relationships between frequency components, two factors
              that have long been thought to potentially underlie consonance
              [2, 3, 10, 13-20]. Listeners preferred stimuli without beats and
              with harmonic spectra, but across more than 250 subjects, only
              the preference for harmonic spectra was consistently correlated
              with preferences for consonant over dissonant chords. Harmonicity
              preferences were also correlated with the number of years
              subjects had spent playing a musical instrument, suggesting that
              exposure to music amplifies preferences for harmonic frequencies
              because of their musical importance. Harmonic spectra are
              prominent features of natural sounds, and our results indicate
              that they also underlie the perception of consonance.
              \copyright{} 2010 Elsevier Ltd. All rights reserved.",
  journal  = "Current biology",
  volume   =  20,
  number   =  11,
  pages    = "1035--1041",
  year     =  2010,
  issn     = "0960-9822",
  pmid     = "20493704",
  doi      = "10.1016/j.cub.2010.04.019"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Macrae2011-an,
  title    = "Guitar tab mining, analysis and ranking",
  author   = "Macrae, Robert and Dixon, Simon",
  abstract = "With over 4.5 million tablatures and chord sequences (col-
              lectively known as tabs), the web holds vast quantities of hand
              annotated scores in non-standardised text ﬁles. These scores are
              typically error-prone and incomplete, and tab col- lections
              contain many duplicates, making retrieval of high quality tabs
              difﬁcult. Despite this, tabs are by far the most popular means of
              sharing musical instructions on the in- ternet. We have developed
              tools that use text analysis and alignment for the automatic
              retrieval, interpretation and anal- ysis of such tabs in order to
              ﬁlter and estimate the most ac- curate tabs from the multitude
              available. We show that the standard means of ranking tabs, such
              as search engine ranks or user ratings, have little correlation
              with the accuracy of a tab and that a better ranking method is to
              use features such as the concurrency between tabs of the same
              song. We also compare the quality of top-ranked tabs with
              state-of-the-art chord transcription output and ﬁnd that the
              latter provides a more reliable source of chord symbols with an
              accuracy rate 10\% higher than the ranked hand annotations.",
  journal  = "12th International Society for Music Information Retrieval
              Conference (ISMIR 2011)",
  number   = "Ismir",
  pages    = "453--458",
  year     =  2011
}

@ARTICLE{Poulin-Charronnat2016-vv,
  title   = "Familiar units prevail over statistical cues in word segmentation",
  author  = "Poulin-Charronnat, B{\'e}n{\'e}dicte and Perruchet, Pierre and
             Tillmann, Barbara and Peereman, Ronald",
  journal = "Psychological research",
  volume  =  81,
  number  =  5,
  pages   = "990--1003",
  year    =  2016,
  issn    = "0340-0727, 1430-2772",
  doi     = "10.1007/s00426-016-0793-y"
}

@ARTICLE{Patel2017-uk,
  title     = "Using music to study the evolution of cognitive mechanisms
               relevant to language",
  author    = "Patel, Aniruddh D",
  abstract  = "This article argues that music can be used in cross-species
               research to study the evolution of cognitive mechanisms relevant
               to spoken language. This is because music and language share
               certain cognitive processing mechanisms and because music offers
               specific advantages for cross-species research. Music has
               relatively simple building blocks (tones without semantic
               properties), yet these building blocks are combined into rich
               hierarchical structures that engage complex cognitive
               processing. I illustrate this point with regard to the
               processing of musical harmonic structure. Because the processing
               of musical harmonic structure has been shown to interact with
               linguistic syntactic processing in humans, it is of interest to
               know if other species can acquire implicit knowledge of harmonic
               structure through extended exposure to music during development
               (vs. through explicit training). I suggest that domestic dogs
               would be a good species to study in addressing this question.",
  journal   = "Psychonomic bulletin \& review",
  publisher = "Psychonomic Bulletin \& Review",
  volume    =  24,
  number    =  1,
  pages     = "177--180",
  year      =  2017,
  keywords  = "Music cognition,Language evolution,Comparative psy; comparative
               psychology; differences; instrumental music and spoken; language
               evolution; language have many obvious; music cognition; ranging
               from the acoustic; structure of their fun-",
  issn      = "1069-9384",
  pmid      = "27368629",
  doi       = "10.3758/s13423-016-1088-4"
}

@ARTICLE{Tillmann2004-ns,
  title    = "The relative importance of local and global structures in music
              perception",
  author   = "Tillmann, Barbara and Bigand, E",
  abstract = "... 54 VJ Konecni, ``Elusive Effects of Artists ''Messages,'{}''
              in Cognitive Processes in the Perception of Art (Amsterdam:
              North-Holland, 1984). 55 ... 75--89. 60 B. Tillmann, E. Bigand,
              and F. Madurell, `` Local versus Global Processing of Harmonic
              Cadences in the Solution of ...",
  journal  = "The Journal of Aesthetics and Art Criticism",
  volume   =  62,
  number   =  2,
  pages    = "211--222",
  year     =  2004,
  issn     = "0021-8529",
  doi      = "10.1111/j.1540-594X.2004.00153.x"
}

@ARTICLE{Tillmann2006-il,
  title    = "Influence of tonal and temporal expectations on chord processing
              and on completion judgments of chord sequences",
  author   = "Tillmann, Barbara and Lebrun-Guillaud, G{\'e}raldine",
  abstract = "Pitch and time are two principal form-bearing dimensions in
              Western tonal music. Research on melody perception has shown that
              listeners develop expectations about ``What'' note is coming next
              and ``When'' in time it will occur. Our study used sequences of
              chords (i.e., simultaneously sounding notes) to investigate the
              influence of these expectations on chord processing (Experiments
              1 and 4) and subjective judgments of completion (Experiments 2
              and 3). Both tasks showed an influence of tonal relations and
              temporal regularities: expected events occurring at the expected
              moment were processed faster and led to higher completion
              judgments. However, pitch and time dimensions interacted only for
              completion judgments. The present outcome suggests that for chord
              perception the influence of pitch and time might depend on the
              required processing: with a more global judgment favoring
              interactive influences in contrast to a task focusing on local
              chord processing.",
  journal  = "Psychological research",
  volume   =  70,
  number   =  5,
  pages    = "345--358",
  year     =  2006,
  issn     = "0340-0727",
  pmid     = "16177925",
  doi      = "10.1007/s00426-005-0222-0"
}

@ARTICLE{Miles2017-mn,
  title    = "A statistical analysis of the relationship between harmonic
              surprise and preference in popular music",
  author   = "Miles, Scott A and Rosen, David S and Grzywacz, Norberto M",
  abstract = "Studies have shown that somemusical piecesmay preferentially
              activate reward centers in the brain. Less is known, however,
              about the structural aspects of music that are associated with
              this activation. Based on the music cognition literature, we
              propose two hypotheses for why some musical pieces are preferred
              over others. The first, the Absolute-Surprise Hypothesis, states
              that unexpected events in music directly lead to pleasure. The
              second, the Contrastive-Surprise Hypothesis, proposes that the
              juxtaposition of unexpected events and subsequent expected events
              leads to an overall rewarding response. We tested these
              hypotheses within the framework of information theory, using the
              measure of ``surprise.'' This information-theoretic variable
              mathematically describes how improbable an event is given a known
              distribution. We performed a statistical investigation of
              surprise in the harmonic structure of songs within a
              representative corpus of Western popular music, namely, the
              McGill Billboard Project corpus. We found that chords of songs in
              the top quartile of the Billboard chart showed greater average
              surprise than those in the bottom quartile. We also found that
              the different sections within top-quartile songs variedmore in
              their average surprise than the sections within bottom-quartile
              songs. The results of this study are consistent with both the
              Absolute- and Contrastive-Surprise Hypotheses. Although these
              hypotheses seem contradictory to one another, we cannot yet
              discard the possibility that both absolute and contrastive types
              of surprise play roles in the enjoyment of popular music. We call
              this possibility the Hybrid-Surprise Hypothesis. The results of
              this statistical investigation have implications for bothmusic
              cognition and the human neuralmechanisms of esthetic judgments.",
  journal  = "Frontiers in human neuroscience",
  volume   =  11,
  pages    = "1--13",
  year     =  2017,
  keywords = "expectation violation; information the; information theory;
              music; music cognition; music preference; neuroaesthetics;
              perception; popular music",
  issn     = "1662-5161",
  doi      = "10.3389/fnhum.2017.00263"
}

@ARTICLE{Tillmann2012-qt,
  title    = "Music and Language Perception: Expectations, Structural
              Integration, and Cognitive Sequencing",
  author   = "Tillmann, Barbara",
  abstract = "Music can be described as sequences of events that are structured
              in pitch and time. Studying music processing provides insight
              into how complex event sequences are learned, perceived, and
              represented by the brain. Given the temporal nature of sound,
              expectations, structural integration, and cognitive sequencing
              are central in music perception (i.e., which sounds are most
              likely to come next and at what moment should they occur?). This
              paper focuses on similarities in music and language cognition
              research, showing that music cognition research provides insight
              into the understanding of not only music processing but also
              language processing and the processing of other structured
              stimuli. The hypothesis of shared resources between music and
              language processing and of domain-general dynamic attention has
              motivated the development of research to test music as a means to
              stimulate sensory, cognitive, and motor processes.",
  journal  = "Topics in cognitive science",
  volume   =  4,
  number   =  4,
  pages    = "568--584",
  year     =  2012,
  keywords = "Cognitive expectations; Expertise; Implicit processing; Music and
              language processing; Priming; Shared neural correlates;
              Structural integration; Temporal processing",
  issn     = "1756-8757",
  pmid     = "22760955",
  doi      = "10.1111/j.1756-8765.2012.01209.x"
}

@ARTICLE{Janata2002-uk,
  title    = "The cortical topography of tonal structures underlying Western
              music",
  author   = "Janata, Petr and Birk, Jeffrey L and Van Horn, John D and Leman,
              Marc and Tillmann, Barbara and Bharucha, Jamshed J",
  abstract = "Western tonal music relies on a formal geometric structure that
              determines distance relationships within a harmonic or tonal
              space. In functional magnetic resonance imaging experiments, we
              identified an area in the rostromedial prefrontal cortex that
              tracks activation in tonal space. Different voxels in this area
              exhibited selectivity for different keys. Within the same set of
              consistently activated voxels, the topography of tonality
              selectivity rearranged itself across scanning sessions. The
              tonality structure was thus maintained as a dynamic topography in
              cortical areas known to be at a nexus of cognitive, affective,
              and mnemonic processing.",
  journal  = "Science",
  volume   =  298,
  number   =  5601,
  pages    = "2167--2170",
  year     =  2002,
  issn     = "0036-8075",
  pmid     = "12481131",
  doi      = "10.1126/science.1076262"
}

@ARTICLE{Patel2014-uy,
  title    = "The evolutionary neuroscience of musical beat perception: the
              Action Simulation for Auditory Prediction ({ASAP}) hypothesis",
  author   = "Patel, Aniruddh D and Iversen, John R",
  journal  = "Frontiers in systems neuroscience",
  volume   =  8,
  pages    = "1--14",
  year     =  2014,
  keywords = "brain; comparative psychology; evolution; music cogniti; music
              cognition; rhythm perception",
  doi      = "10.3389/fnsys.2014.00057"
}

@ARTICLE{Honing2012-dv,
  title    = "Without it no music: beat induction as a fundamental musical
              trait",
  author   = "Honing, Henkjan",
  journal  = "Annals of the New York Academy of Sciences",
  volume   =  1252,
  pages    = "85--91",
  year     =  2012,
  keywords = "attention; cognitive biology; event-related brain potentials;
              meter; musicality; rhythm",
  issn     = "0077-8923",
  doi      = "10.1111/j.1749-6632.2011.06402.x"
}

@ARTICLE{Harrison2017-iv,
  title   = "Applying modern psychometric techniques to melodic discrimination
             testing: Item response theory, computerised adaptive testing, and
             automatic item generation",
  author  = "Harrison, Peter M C and Collins, Tom and M{\"u}llensiefen, Daniel",
  journal = "Scientific reports",
  volume  =  7,
  pages   = "1--18",
  year    =  2017,
  doi     = "10.1038/s41598-017-03586-z"
}

@ARTICLE{Woods2017-rf,
  title   = "Headphone screening to facilitate web-based auditory experiments",
  author  = "Woods, Kevin J P and Siegel, Max H and Traer, James and Mcdermott,
             Josh H",
  journal = "Attention, perception \& psychophysics",
  volume  =  79,
  number  =  7,
  pages   = "2064--2072",
  year    =  2017,
  issn    = "1943-3921",
  doi     = "10.3758/s13414-017-1361-2"
}

@ARTICLE{Pearce2017-xp,
  title     = "Compression-based modelling of musical similarity perception",
  author    = "Pearce, Marcus T and M{\"u}llensiefen, Daniel",
  journal   = "Journal of New Music Research",
  publisher = "Routledge",
  volume    =  46,
  number    =  2,
  pages     = "135--155",
  year      =  2017,
  issn      = "0929-8215",
  doi       = "10.1080/09298215.2017.1305419"
}

@INCOLLECTION{Jones2009-oq,
  title     = "Musical time",
  booktitle = "The Oxford handbook of music psychology",
  author    = "Jones, Mari Riess",
  editor    = "Hallam, Susan and Cross, Ian and Thaut, Michael",
  publisher = "Oxford University Press",
  year      =  2009,
  address   = "New York, NY"
}

@ARTICLE{Tierney2013-vh,
  title    = "Neural responses to sounds presented on and off the beat of
              ecologically valid music",
  author   = "Tierney, Adam and Kraus, Nina",
  journal  = "Frontiers in systems neuroscience",
  volume   =  7,
  number   = "May",
  pages    = "1--7",
  year     =  2013,
  keywords = "auditory; brainstem; cortex; music; rhythm",
  doi      = "10.3389/fnsys.2013.00014"
}

@ARTICLE{Todd1998-ja,
  title  = "Frankensteinian Methods for Evolutionary Music Composition",
  author = "Todd, Peter M and Werner, Gregory M",
  pages  = "1--25",
  year   =  1998
}

@ARTICLE{Wolpert1996-ss,
  title  = "The Lack of A Priori Distinctions Between Learning Algorithms",
  author = "Wolpert, David H",
  volume =  1390,
  pages  = "1341--1390",
  year   =  1996
}

@ARTICLE{Gillick2004-yl,
  title  = "Machine Learning of Jazz Grammars",
  author = "Gillick, Jon and Tang, Kevin and Keller, Robert M",
  number =  1981,
  pages  = "56--66",
  year   =  2004
}

@ARTICLE{Bengio2014-vt,
  title   = "Representation Learning : A Review and New Perspectives",
  author  = "Bengio, Yoshua and Courville, Aaron and Vincent, Pascal",
  number  =  1993,
  pages   = "1--30",
  year    =  2014,
  arxivid = "1206.5538v3"
}

@ARTICLE{Tsushima_undated-yr,
  title    = "Generative Statistical Models with {Self-Emergent} Grammar of
              Chord Sequences",
  author   = "Tsushima, Hiroaki and Nakamura, Eita and Itoyama, Katsutoshi and
              Yoshii, Kazuyoshi",
  keywords = "bayesian inference; context-free grammar; function; harmonic;
              hidden markov model; probabilistic; statistical music language
              model; tonal; unsupervised grammar induction",
  arxivid  = "1708.02255v1"
}

@ARTICLE{Kirby2008-uw,
  title    = "Cumulative cultural evolution in the laboratory: An experimental
              approach to the origins of structure in human language",
  author   = "Kirby, S and Cornish, H and Smith, K",
  abstract = "We introduce an experimental paradigm for studying the cumulative
              cultural evolution of language. In doing so we provide the first
              experimental validation for the idea that cultural transmission
              can lead to the appearance of design without a designer. Our
              experiments involve the iterated learning of artificial languages
              by human participants. We show that languages transmitted
              culturally evolve in such a way as to maximize their own
              transmissibility: over time, the languages in our experiments
              become easier to learn and increasingly structured. Furthermore,
              this structure emerges purely as a consequence of the
              transmission of language over generations, without any
              intentional design on the part of individual language learners.
              Previous computational and mathematical models suggest that
              iterated learning provides an explanation for the structure of
              human language and link particular aspects of linguistic
              structure with particular constraints acting on language during
              its transmission. The experimental work presented here shows that
              the predictions of these models, and models of cultural evolution
              more generally, can be tested in the laboratory.",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  105,
  number   =  31,
  pages    = "10681--10686",
  year     =  2008,
  issn     = "0027-8424",
  pmid     = "18667697",
  doi      = "10.1073/pnas.0707835105"
}

@ARTICLE{Miranda2003-lu,
  title    = "On Computational Models of the Evolution of Music: From the
              Origins of Musical Taste to the Emergence of Grammars",
  author   = "Miranda, Eduardo Reck and Kirby, Simon and Todd, Peter",
  abstract = "Evolutionary computing is a powerful tool for studying the
              origins and evolution of music. In this case, music is studied as
              an adaptive complex dynamic system and its origins and evolution
              are studied in the context of the cultural conventions that may
              emerge under a number of constraints (e.g. psychological,
              physiological and ecological). This paper introduces three case
              studies of evolutionary modelling of music. It begins with a
              model for studying the role of mating-selective pressure in the
              evolution of musical taste. Here the agents evolve ``courting
              tunes'' in a society of ``male'' composers and ``female''
              critics. Next, a mimetic model is introduced to study the
              evolution of musical expectation in a community of autonomous
              agents furnished with a vocal synthesizer, a hearing system and
              memory. Finally, an iterated learning model is proposed for
              studying the evolution of compositional grammars. In this case,
              the agents evolve grammars for composing music to express a set
              of emotions.",
  journal  = "Contemporary Music Review",
  volume   =  22,
  number   =  3,
  pages    = "91--111",
  year     =  2003,
  issn     = "0749-4467",
  doi      = "10.1080/0749446032000150915"
}

@ARTICLE{Wang2011-vu,
  title    = "Ckmeans.1d.dp: Optimal k-means clustering in one dimension by
              dynamic programming",
  author   = "Wang, Haizhou and Song, Mingzhou",
  abstract = "The heuristic k-means algorithm, widely used for cluster
              analysis, does not guarantee optimal- ity. We developed a dynamic
              programming al- gorithm for optimal one-dimensional clustering.
              The algorithm is implemented as an R package called
              Ckmeans.1d.dp. We demonstrate its ad- vantage in optimality and
              runtime over the stan- dard iterative k-means algorithm.",
  journal  = "The R journal",
  volume   =  3,
  number   =  2,
  pages    = "29--33",
  year     =  2011,
  keywords = "clustering; dynamic programming",
  issn     = "2073-4859"
}

@ARTICLE{Kemp2009-mj,
  title    = "Structured statistical models of inductive reasoning",
  author   = "Kemp, Charles and Tenenbaum, Joshua B",
  abstract = "Everyday inductive inferences are often guided by rich background
              knowledge. Formal models of induction should aim to incorporate
              this knowledge and should explain how different kinds of
              knowledge lead to the distinctive patterns of reasoning found in
              different inductive contexts. This article presents a Bayesian
              framework that attempts to meet both goals and describes
              [corrected] 4 applications of the framework: a taxonomic model, a
              spatial model, a threshold model, and a causal model. Each model
              makes probabilistic inferences about the extensions of novel
              properties, but the priors for the 4 models are defined over
              different kinds of structures that capture different
              relationships between the categories in a domain. The framework
              therefore shows how statistical inference can operate over
              structured background knowledge, and the authors argue that this
              interaction between structure and statistics is critical for
              explaining the power and flexibility of human reasoning.",
  journal  = "Psychological review",
  volume   =  116,
  number   =  1,
  pages    = "20--58",
  year     =  2009,
  keywords = "bayesian inference; direct experience; even young children can;
              humans are adept at; inductive reasoning; knowledge
              representation; learn; making inferences that take; novel word
              from a; property induction; single labeled example; the limits of
              their; the meaning of a; them beyond",
  issn     = "0033-295X, 1939-1471",
  pmid     = "19159147",
  doi      = "10.1037/a0014282"
}

@INPROCEEDINGS{Rendell1987-ii,
  title     = "Layered concept-learning and dynamically-variable bias
               management",
  booktitle = "Proceedings of the International Joint Conference on Artificial
               Intelligence, {IJCAI} '87",
  author    = "Rendell, L and Seshu, R and Tcheng, D",
  abstract  = "Concept learning is inherently complex. Without severe
               constraint or inductive ``bias, '' the general problem is
               intractable. While most learning systems have been designed with
               built-in biases, these systems typically work well only in
               narrowly circumscribed problem domains. Here we present a model
               of concept formation that views learning as a simultaneous
               optimization problem at three different levels, with dynamically
               chosen biases guiding the search for satisfactory hypotheses. In
               this model, the partitioning of events into classes occurs
               through dynamic interactions among three layers: event space,
               hypothesis space, and bias space. This view of the induction
               process may help clarify the problem of learning and lead to
               more general and efficient induction systems. To test this model
               of meta-knowledge, a variable bias management system (VBMS) has
               been designed and partly implemented. The system will
               dynamically alter evolving hypotheses, concept representation
               languages, and concept formation algorithms by monitoring
               progress and selecting biases based on characteristics of the
               particular induction problems presented. VBMS is designed to
               learn the best biases for different types of induction problems.
               Thus it is robust (effective and efficient in many domains). The
               system can learn incrementally despite noisy data at any level.
               I.",
  pages     = "308--314",
  year      =  1987,
  doi       = "10.1.1.104.7032"
}

@MISC{Michalski1983-tj,
  title    = "A Theory of Methodology of Inductive Learning",
  author   = "Michalski, Ryszard S",
  abstract = "A theory of inductive learning is presented that characterizes it
              as a heuristic search through a space of symbolic descriptions,
              generated by an application of certain inference rules to the
              initial observational statements (the teacher-provided examples
              of some concepts, or facts about a class of objects or a
              phenomenon). The inference rules include generalization rules,
              which perform generalizing transformations on descriptions, and
              conventional truth-preserving deductive rules (specialization and
              reformulation rules). The application of the inference rules to
              descriptions is constrained by background knowledge and guided by
              criteria evaluating the 'quality' of generated inductive
              assertions. Based on this theory, a general methodology for
              learning structural descriptions from examples, called STAR, is
              described and illustrated by a problem from the area of
              conceptual data analysis.",
  journal  = "Machine Learning: An Artificial Intelligence Approach",
  pages    = "111--161",
  year     =  1983,
  issn     = "0004-3702",
  isbn     = "9781558601635",
  pmid     = "19618469",
  doi      = "10.1016/0004-3702(83)90016-4"
}

@INCOLLECTION{Pearl2016-zs,
  title     = "Statistical Learning, Inductive Bias, and Bayesian Inference in
               Language Acquisition",
  booktitle = "The Oxford Handbook of Developmental Linguistics",
  author    = "Pearl, Lisa and Goldwater, Sharon",
  editor    = "Lidz, Jeffrey L and Snyder, William and Pater, Joe",
  publisher = "Oxford University Press",
  year      =  2016,
  address   = "Oxford, England"
}

@ARTICLE{Provost1995-qp,
  title    = "Inductive Policy: The Pragmatics of Bias Selection",
  author   = "Provost, Foster John and Buchanan, Bruce G",
  abstract = "This paper extends the currently accepted model of inductive bias
              by identifying six categories of bias and separates inductive
              bias from the policy for its selection (the inductive policy). We
              analyze existing ``bias selection'' systems, examining the
              similarities and differences in their inductive policies, and
              identify three techniques useful for building inductive policies.
              We then present a framework for representing and automatically
              selecting a wide variety of biases and describe experiments with
              an instantiation of the framework addressing various pragmatic
              tradeoffs of time, space, accuracy, and the cost of errors. The
              experiments show that a common framework can be used to implement
              policies for a variety of different types of bias selection, such
              as parameter selection, term selection, and example selection,
              using similar techniques. The experiments also show that
              different tradeoffs can be made by the implementation of
              different policies; for example, from the same data different
              rule sets can be learned based on different tradeoffs of accuracy
              versus the cost of erroneous predictions. \copyright{} 1995
              Kluwer Academic Publishers.",
  journal  = "Machine learning",
  volume   =  20,
  number   =  1,
  pages    = "35--61",
  year     =  1995,
  keywords = "bias selection; inductive bias; inductive learning; inductive
              policy; pragmatics",
  issn     = "0885-6125, 1573-0565",
  doi      = "10.1023/A:1022634118255"
}

@ARTICLE{Briscoe2000-kg,
  title    = "Grammatical Acquisition: Inductive Bias and Coevolution of
              Language and the Language Acquisition Device",
  author   = "Briscoe, T",
  abstract = "An account of grammatical acquisition is developed within the
              parameter setting framework applied to a generalized categorial
              grammar (GCG). The GCG is embedded in a default inheritance
              network yielding a natural partial ordering (reflecting
              generality) of parameters that determines a partial order for
              parameter setting. Computational simulation shows that several
              resulting acquisi- tion procedures are effective on a parameter
              set expressing major typological distinctions based on
              constituent order, and defining 70 distinct full languages and
              over 200 subset languages. The effects on acquisition of
              inductive bias, that is, of differing initial parameter settings,
              are explored via computational simulation. Computational
              simulation of POPULATIONS of language learners and users
              instantiating the acqui- sition model shows that: (1) variant
              acquisition procedures, with differing inductive biases, exert
              differing selective pressures on the evolution of language(s);
              and (2) acquisition procedures will evolve towards more efficient
              variants in the environment of adaptation. The reciprocal
              evolution of language acquisition procedures and of languages
              creates a genuinely coevolutionary dynamic, despite the relative
              speed of linguistic selection for language variants compared to
              natural selection for variant language acquisition procedures.",
  journal  = "Language",
  volume   =  76,
  number   =  2,
  pages    = "245--296",
  year     =  2000,
  issn     = "0097-8507",
  doi      = "10.2307/417657"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Brighton2006-mf,
  title     = "Robust inference with simple cognitive models",
  booktitle = "{AAAI} spring symposium: Cognitive science principles meet
               {AI-hard} problems",
  author    = "Brighton, Henry",
  editor    = "Lebiere, C and Wray, R",
  abstract  = "Developing theories of how information is processed to yield
               inductive inferences is a key step in understanding intelligence
               in humans and machines. Humans, across tasks as diverse as
               vision and decision making, appear to be extremely adaptive and
               successful in dealing with uncertainty in the world. Yet even a
               cursory examination of the books and journals covering machine
               learning reveals that this branch of AI rarely draws on the
               cognitive system as a source of insight. In this article I show
               how fast and frugal heuristics cognitive process models of
               inductive inference frequently outperform a wide selection of
               standard machine learning algorithms. This ﬁnding suggests a
               cognitive-inspired route toward robust inference in the context
               of meta-learning.",
  publisher = "American Association for Artificial Intelligence",
  pages     = "17--22",
  year      =  2006,
  address   = "Menlo Park, CA",
  isbn      = "9781577352631"
}

@BOOK{Chomsky1980-ts,
  title     = "Rules and representations",
  author    = "Chomsky, N",
  publisher = "Basil Blackwell",
  year      =  1980,
  address   = "Oxford, England"
}

@ARTICLE{Salimbeni2017-le,
  title    = "Doubly Stochastic Variational Inference for Deep Gaussian
              Processes",
  author   = "Salimbeni, Hugh and Deisenroth, Marc",
  abstract = "Gaussian processes (GPs) are a good choice for function
              approximation as they are flexible, robust to over-fitting, and
              provide well-calibrated predictive uncertainty. Deep Gaussian
              processes (DGPs) are multi-layer generalisations of GPs, but
              infer-ence in these models has proved challenging. Existing
              approaches to inference in DGP models assume approximate
              posteriors that force independence between the layers, and do not
              work well in practice. We present a doubly stochastic variational
              inference algorithm, which does not force independence between
              layers. With our method of inference we demonstrate that a DGP
              model can be used effectively on data ranging in size from
              hundreds to a billion points. We provide strong empirical
              evidence that our inference scheme for DGPs works well in
              practice in both classification and regression.",
  year     =  2017,
  arxivid  = "1705.08933"
}

@BOOK{Schoenberg1999-pp,
  title     = "Structural functions of harmony",
  author    = "Schoenberg, A",
  publisher = "Faber \& Faber",
  year      =  1999,
  address   = "London, England"
}

@ARTICLE{Sturm2013-nr,
  title    = "Classification accuracy is not enough: On the evaluation of music
              genre recognition systems",
  author   = "Sturm, Bob L",
  abstract = "We argue that an evaluation of system behavior at the level of
              the music is required to usefully address the fundamental
              problems of music genre recognition (MGR), and indeed other tasks
              of music information retrieval, such as autotagging. A recent
              review of works in MGR since 1995 shows that most (82 \%) measure
              the capacity of a system to recognize genre by its classification
              accuracy. After reviewing evaluation in MGR, we show that neither
              classification accuracy, nor recall and precision, nor confusion
              tables, necessarily reflect the capacity of a system to recognize
              genre in musical signals. Hence, such figures of merit cannot be
              used to reliably rank, promote or discount the genre recognition
              performance of MGR systems if genre recognition (rather than
              identification by irrelevant confounding factors) is the
              objective. This motivates the development of a richer
              experimental toolbox for eval- uating any system designed to
              intelligently extract information from music signals.",
  journal  = "Journal of intelligent information systems",
  volume   =  41,
  number   =  3,
  pages    = "371--406",
  year     =  2013,
  keywords = "Classification; Evaluation; Genre; Music",
  issn     = "0925-9902",
  doi      = "10.1007/s10844-013-0250-y"
}

@ARTICLE{Meeus2000-dk,
  title    = "Toward a post-Schoenbergian grammar of tonal and pre-tonal
              harmonic progressions",
  author   = "Meeus, Nicolas",
  abstract = "Schoenberg appears to have been among the first authors to revive
              Rameau's theory of fundamental bass progressions. His
              categorization of the progressions in three categories (``strong
              or ascending,'' ``descending,'' and ``superstrong'') can be
              further systematized on the basis of a theory of chord
              substitutions. A study of the use of the progressions so
              categorized allows a general description of harmonically
              well-formed tonal phrases. A comparison with the usage of
              progressions in pre-tonal music evidences important differences.",
  journal  = "Music Theory Online",
  volume   =  6,
  number   =  1,
  year     =  2000,
  keywords = "Rameau; Schoenberg; fundamental bass; progression"
}

@ARTICLE{Agmon1995-yd,
  title   = "Functional harmony revisited: A prototype-theoretic approach",
  author  = "Agmon, Eytan",
  journal = "Music Theory Spectrum",
  volume  =  17,
  number  =  2,
  pages   = "196--214",
  year    =  1995,
  issn    = "0195-6167",
  doi     = "10.1525/mts.1995.17.2.02a00030"
}

@BOOK{Sadai1980-vl,
  title     = "Harmony in its systemic and phenomenological aspects",
  author    = "Sadai, Yizhak",
  publisher = "Yanetz",
  year      =  1980,
  address   = "Jerusalem, Israel"
}

@BOOK{Vogler1776-lh,
  title     = "Tonwissenschaft und Tonsezkunst",
  author    = "Vogler, Georg",
  publisher = "Kurf{\"u}rstliche Hofbuchdruckere",
  year      =  1776,
  address   = "Mannheim, Germany"
}

@BOOK{Weber1817-vf,
  title     = "Versuch einer gordneten Theorie der Tonsetzkunst",
  author    = "Weber, Gottfried",
  publisher = "B. Schott",
  year      =  1817,
  address   = "Mainz, Germany"
}

@ARTICLE{Cook1987-ec,
  title   = "The perception of large-scale tonal closure",
  author  = "Cook, Nicholas",
  journal = "Music perception",
  volume  =  5,
  number  =  2,
  pages   = "197--205",
  year    =  1987,
  issn    = "0730-7829"
}

@ARTICLE{Ben-David2011-sk,
  title   = "Universal learning vs. no free lunch results",
  author  = "Ben-David, Shai and Srebro, Nathan and Urner, R",
  journal = "Philosophy and Machine Learning - Workshop at NIPS",
  pages   = "1--3",
  year    =  2011
}

@ARTICLE{Brighton2015-er,
  title     = "The bias bias",
  author    = "Brighton, Henry and Gigerenzer, Gerd",
  abstract  = "In marketing and finance, surprisingly simple models sometimes
               predict more accurately than more complex, sophisticated models.
               Here, we address the question of when and why simple models
               succeed - or fail - by framing the forecasting problem in terms
               of the bias-variance dilemma. Controllable error in forecasting
               consists of two components, the ``bias'' and the ``variance''.
               We argue that the benefits of simplicity are often overlooked
               because of a pervasive ``bias bias'': the importance of the bias
               component of prediction error is inflated, and the variance
               component of prediction error, which reflects an oversensitivity
               of a model to different samples from the same population, is
               neglected. Using the study of cognitive heuristics, we discuss
               how to reduce variance by ignoring weights, attributes, and
               dependencies between attributes, and thus make better decisions.
               Bias and variance, we argue, offer a more insightful perspective
               on the benefits of simplicity than Occam''s razor.",
  journal   = "Journal of business research",
  publisher = "Elsevier B.V.",
  volume    =  68,
  number    =  8,
  pages     = "1772--1784",
  year      =  2015,
  keywords  = "Bias bias; Bias-variance dilemma; Occam's razor; Out-of-sample
               prediction; Simple heuristics; Uncertainty",
  issn      = "0148-2963",
  doi       = "10.1016/j.jbusres.2015.01.061"
}

@ARTICLE{Cui2015-ks,
  title    = "Continuous online sequence learning with an unsupervised neural
              network model",
  author   = "Cui, Yuwei and Ahmad, Subutai and Hawkins, Jeff",
  abstract = "The ability to recognize and predict temporal sequences of
              sensory inputs is vital for survival in natural environments.
              Based on many known properties of cortical neurons, hierarchical
              temporal memory (HTM) sequence memory is recently proposed as a
              theoretical framework for sequence learning in the cortex. In
              this paper, we analyze properties of HTM sequence memory and
              apply it to sequence learning and prediction problems with
              streaming data. We show the model is able to continuously learn a
              large number of variable-order temporal sequences using an
              unsupervised Hebbian-like learning rule. The sparse temporal
              codes formed by the model can robustly handle branching temporal
              sequences by maintaining multiple predictions until there is
              sufficient disambiguating evidence. We compare the HTM sequence
              memory with other sequence learning algorithms, including
              statistical methods: autoregressive integrated moving average
              (ARIMA), feedforward neural networks: online sequential extreme
              learning machine (ELM), and recurrent neural networks: long
              short-term memory (LSTM) and echo-state networks (ESN), on
              sequence prediction problems with both artificial and real-world
              data. The HTM model achieves comparable accuracy to other
              state-of-the-art algorithms. The model also exhibits properties
              that are critical for sequence learning, including continuous
              online learning, the ability to handle multiple predictions and
              branching sequences with high order statistics, robustness to
              sensor noise and fault tolerance, and good performance without
              task-specific hyper- parameters tuning. Therefore the HTM
              sequence memory not only advances our understanding of how the
              brain may solve the sequence learning problem, but is also
              applicable to a wide range of real-world problems such as
              discrete and continuous sequence prediction, anomaly detection,
              and sequence classification.",
  volume   =  228,
  number   =  2015,
  pages    = "216--228",
  year     =  2015,
  issn     = "1530-888X",
  pmid     = "25602775",
  arxivid  = "1512.05463",
  doi      = "10.1162/NECO"
}

@ARTICLE{Wolpert2012-yu,
  title    = "What the no free lunch theorems really mean ; how to improve
              search algorithms",
  author   = "Wolpert, David H",
  abstract = "The NFL theorems have stimulated lots of subsequent work, with
              over 2500 citations of [12] alone by spring 2012 according to
              Google Scholar. However, arguably much of that research has
              missed the most important implications of the theorems. As stated
              in [12], the primary importance of the NFL theorems for search is
              what they tell us about ``the underlying mathematical `skeleton'
              of optimization theory before the `flesh' of the probability
              distributions of a particular context and set of optimization
              problems are imposed''. So in particular, while the NFL theorems
              have strong implications if one believes in a uniform
              distribution over optimization problems, in no sense should they
              be interpreted as advocating such a distribution. In this short
              note I elaborate this perspective on what it is that is really
              important about the NFL theorems for search. I then discuss how
              the fact that there are NFL theorems for both search and for
              supervised learning is symptomatic of the deep formal
              relationship between those two fields. Once that relationship is
              disentangled, it suggests many ways that we can exploit practical
              techniques that were first developed in supervised learning to
              help us do search. I summarize some experiments that confirm the
              power of search algorithms developed in this way. I end by
              briefly discussing the various free lunch theorems that have been
              derived, and possible directions for future research.",
  pages    = "1--13",
  year     =  2012
}

@ARTICLE{Zhang_undated-nx,
  title    = "{Cross-Validation} for Selecting a Model Selection Procedure",
  author   = "Zhang, Yongli",
  pages    = "1--52",
  keywords = "adaptive procedure selection; criterion; cross-validation;
              cross-validation paradox; data splitting ratio; information;
              lasso; mcp; scad"
}

@TECHREPORT{Fox2012-ng,
  title  = "Bootstrapping regression models in R: An appendix to ``An {R}
            Companion to Applied Regression, Second Edition''",
  author = "Fox, John and Weisberg, Sanford",
  pages  = "1--17",
  year   =  2012
}

@ARTICLE{Wickham2011-ll,
  title   = "testthat: Get Started with Testing",
  author  = "Wickham, Hadley",
  journal = "The R journal",
  volume  =  3,
  number  =  1,
  pages   = "5--10",
  year    =  2011
}

@ARTICLE{Raphael2011-io,
  title   = "The Informatics Philharmonic",
  author  = "Raphael, Christopher",
  journal = "Communications of the ACM",
  volume  =  54,
  number  =  3,
  pages   = "87--93",
  year    =  2011,
  issn    = "0001-0782",
  pmid    = "59423985",
  doi     = "10.1145/1897852"
}

@ARTICLE{Bamberger2003-ff,
  title   = "Music as embodied mathematics: A study of a mutually informing
             affinity",
  author  = "Bamberger, Jeanne and DiSessa, Andrea",
  journal = "International Journal of Computers for Mathematical Learning",
  volume  =  8,
  number  =  2,
  pages   = "123--160",
  year    =  2003
}

@PHDTHESIS{Chew2000-uk,
  title   = "Towards a mathematical model of tonality",
  author  = "Chew, Elaine",
  year    =  2000,
  address = "Cambridge, MA",
  school  = "MIT"
}

@INBOOK{Raphael2010-pt,
  title     = "Music Plus One and machine learning",
  booktitle = "Proceedings of the 27th International Conference on Machine
               Learning",
  author    = "Raphael, Christopher",
  abstract  = "A system for musical accompaniment is presented in which a
               computer-driven orchestra follows and learns from a soloist in a
               concerto-like setting. The system is decomposed into three
               modules: the first computes a real-time score match using a
               hidden Markov model; the second generates the output audio by
               phase-vocoding a preexisting audio recording; the third provides
               a link between these two, by predicting future timing evolution
               using a Kalman filter-like model. Several examples are presented
               showing the system in action in diverse musical settings.
               Connections with machine learning are highlighted, showing
               current weaknesses and new possible directions.",
  pages     = "21--28",
  year      =  2010,
  isbn      = "9781422103326"
}

@ARTICLE{Chew2016-xk,
  title    = "Playing with the edge: Tipping points and the role of tonality",
  author   = "Chew, Elaine",
  journal  = "Music perception",
  volume   =  33,
  number   =  3,
  pages    = "344--366",
  year     =  2016,
  keywords = "expressive timing; music performance; thresholds; tonality;
              visualization",
  issn     = "0730-7829",
  doi      = "10.1525/MP.2016.33.03.344"
}

@INPROCEEDINGS{Chew2005-ln,
  title     = "{ESP}: A Driving Interface for Expression Synthesis",
  booktitle = "Proceedings of the 2005 International Conference on New
               Interfaces for Musical Expression ({NIME05})",
  author    = "Chew, Elaine and Fran{\c c}ois, Alexander R J and Liu, Jie and
               Yang, Aaron",
  abstract  = "In the Expression Synthesis Project (ESP), we propose a driving
               interface for expression synthesis. ESP aims to provide a
               compelling metaphor for expressive performance so as to make
               high-level expressive decisions accessible to non-experts. In
               ESP, the user drives a car on a virtual road that represents the
               music with its twists and turns; and makes decisions on how to
               traverse each part of the road. The driver's decisions affect in
               real-time the rendering of the piece. The pedals and wheel
               provide a tactile interface for controlling the car dynamics and
               musical expression, while the display portrays a first person
               view of the road and dashboard from the driver's seat. This
               game-like interface allows non-experts to create expressive
               renderings of existing music without having to master an
               instrument, and allows expert musicians to experiment with
               expressive choice without having to first master the notes of
               the piece. The prototype system has been tested and refined in
               numerous demonstrations. This paper presents the concepts
               underlying the ESP system and the architectural design and
               implementation of a prototype.",
  pages     = "224--227",
  year      =  2005,
  keywords  = "driving interface; music expression synthesis system"
}

@ARTICLE{Hutchinson1979-fu,
  title   = "The significance of the acoustic component of consonance in
             Western triads",
  author  = "Hutchinson, William and Knopoff, Leon",
  journal = "Journal of musicological research",
  volume  =  3,
  number  = "1-2",
  pages   = "5--22",
  year    =  1979,
  doi     = "10.1080/01411897908574504"
}

@ARTICLE{Vos1986-zv,
  title   = "Purity ratings of tempered fifths and major thirds",
  author  = "Vos, Joos",
  journal = "Music perception",
  volume  =  3,
  number  =  3,
  pages   = "221--257",
  year    =  1986,
  issn    = "0730-7829"
}

@ARTICLE{Zwicker1957-co,
  title   = "Critical band width in loudness summation",
  author  = "Zwicker, E and Flottorp, G and Stevens, S S",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  29,
  number  =  5,
  pages   = "548--557",
  year    =  1957,
  issn    = "0001-4966",
  doi     = "10.1121/1.1908963"
}

@INPROCEEDINGS{Spiro2007-zm,
  title     = "In search of motive: Identification of repeated patterns in
               performances and their structural contexts",
  booktitle = "Proceedings of the International Conference on Music
               Communication Sciences ({ICOMCS})",
  author    = "Spiro, Neta and Gold, Nicolas and Rink, John",
  pages     = "151--154",
  year      =  2007
}

@ARTICLE{Kameoka1969-ki,
  title   = "Consonance theory Part I: Consonance of dyads",
  author  = "Kameoka, Akio and Kuriyagawa, Mamoru",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  45,
  number  =  6,
  pages   = "1451--1459",
  year    =  1969,
  issn    = "0001-4966",
  doi     = "10.1121/1.1911623"
}

@ARTICLE{Parncutt2006-mo,
  title    = "Commentary on Keith Mashinter's ``Calculating sensory dissonance:
              Some discrepancies arising from the models of Kameoka \&
              Kuriyagawa, and Hutchinson \& Knopoff",
  author   = "Parncutt, Richard",
  journal  = "Empirical musicology review: EMR",
  volume   =  1,
  number   =  4,
  pages    = "201--203",
  year     =  2006,
  keywords = "1989; 1990; 2000; a fundamental problem in; and cultural;
              aspects; between sensory; bottom-up; bregman; consonance; deal
              with the interaction; dissonance; e; enculturation; g; how to;
              innate; learned; models of the perception; of musical structure
              is; parncutt; perception; primitive; schema-based; sensory; the;
              the old question of; top-down"
}

@ARTICLE{Mashinter2006-qh,
  title    = "Calculating sensory dissonance: Some discrepancies arising from
              the models of Kameoka \& Kuriyagawa, and Hutchinson \& Knopoff",
  author   = "Mashinter, Keith",
  journal  = "Empirical musicology review: EMR",
  volume   =  1,
  number   =  2,
  pages    = "65--84",
  year     =  2006,
  keywords = "consonance; dissonance; modelling; perception; sensory"
}

@INPROCEEDINGS{Spiro2007-hu,
  title     = "Performance motives: Analysis and comparison of performance
               timing repetitions using pattern matching and Formal Concept
               Analysis",
  booktitle = "Proceedings of the International Symposium on Performance
               Science",
  author    = "Spiro, Neta and Gold, Nicolas and Rink, John",
  year      =  2007
}

@BOOK{Meyer1967-ja,
  title     = "Music, the arts, and ideas",
  author    = "Meyer, Leonard B",
  publisher = "University of Chicago Press",
  year      =  1967,
  address   = "Chicago, IL"
}

@INPROCEEDINGS{Bergeron2011-hn,
  title     = "Subsumption of vertical viewpoint patterns",
  booktitle = "Mathematics and Computation in Music: Third International
               Conference, {MCM} 2011, Paris, France, June 2011, Proceedings",
  author    = "Bergeron, Mathieu and Conklin, Darrell",
  editor    = "Agon, C and Andreatta, M and Assayag, G and Amiot, E and
               Bresson, J and Mandereau, J",
  pages     = "1--12",
  year      =  2011,
  keywords  = "Computational musicology; Music representation; Pattern
               subsumption; Polyphonic patterns; Score slicing",
  issn      = "0302-9743",
  isbn      = "9783642215896",
  doi       = "10.1007/978-3-642-21590-2\_1"
}

@ARTICLE{Abadi2010-mf,
  title     = "A {PSO-based} weighting method for linear combination of neural
               networks",
  author    = "Abadi, M and Kabir, E",
  journal   = "Computers \& Electrical Engineering",
  publisher = "Elsevier Ltd",
  volume    =  36,
  number    =  5,
  pages     = "886--894",
  year      =  2010,
  keywords  = "classifier combination; particle swarm optimization",
  issn      = "0045-7906",
  doi       = "10.1016/j.compeleceng.2008.04.006"
}

@PHDTHESIS{Hashem1993-kb,
  title   = "Optimal linear combinations of neural networks",
  author  = "Hashem, Sherif",
  year    =  1993,
  address = "West Lafayette, IN",
  school  = "Purdue University"
}

@INPROCEEDINGS{Fumera2002-bm,
  title     = "Performance Analysis and Comparison of Linear Combiners for
               Classifier Fusion",
  booktitle = "Proceedings of the joint international workshop on structural,
               syntactic, and statistical pattern recognition",
  author    = "Fumera, Giorgio and Roli, Fabio",
  editor    = "Berlin, Germany",
  publisher = "Springer",
  year      =  2002
}

@ARTICLE{Ueda2000-ci,
  title    = "Optimal linear combination of neural networks for improving
              classification performance",
  author   = "Ueda, N",
  abstract = "This paper presents a new method for linearly combining multiple
              neural network classifiers based on the statistical pattern
              recognition theory. In our approach, several neural networks are
              first selected based on which works best for each class in terms
              of minimizing classification errors. Then, they are linearly
              combined to form an ideal classifier that exploits the strengths
              of the individual classifiers. In this approach, the minimum
              classification error criterion is utilized to estimate the
              optimal linear weights. In this formulation, because the
              classification decision rule is incorporated into the cost
              function, a more suitable better combination of weights for the
              classification objective could be obtained. Experimental results
              using artificial and real data sets show that the proposed method
              can construct a better combined classifier that outperforms the
              best single classifier in terms of overall classification errors
              for test data",
  journal  = "IEEE transactions on pattern analysis and machine intelligence",
  volume   =  22,
  number   =  2,
  pages    = "207--215",
  year     =  2000,
  keywords = "cost function; ensemble learning; learning (artificial
              intelligence); linear combination; minimum classification error;
              neural nets; neural network; optimisation; pattern
              classification; statistical pattern recognition",
  issn     = "0162-8828",
  doi      = "10.1109/34.825759"
}

@ARTICLE{Zoph2016-hf,
  title    = "Simple, Fast {Noise-Contrastive} Estimation for Large {RNN}
              Vocabularies",
  author   = "Zoph, Barret and Vaswani, Ashish and May, Jonathan and Knight,
              Kevin",
  abstract = "We present a simple algorithm to efficiently train language
              models with noise-contrastive estimation (NCE) on graphics
              processing units (GPUs). Our NCE-trained language models achieve
              significantly lower perplexity on the One Billion Word Benchmark
              language modeling challenge, and contain one sixth of the
              parameters in the best single model in Chelba et al. (2013). When
              incorporated into a strong Arabic-English machine translation
              system they give a strong boost in translation quality. We
              release a toolkit so that others may also train large-scale,
              large vocabulary LSTM language models with NCE, paralleliz- ing
              computation across multiple GPUs.",
  journal  = "North American Chapter of the Association for Computational
              Linguistics (NAACL)",
  pages    = "1217--1222",
  year     =  2016
}

@ARTICLE{Han2012-bf,
  title    = "Fixing the c parameter in the three-parameter logistic model",
  author   = "Han, Kt",
  abstract = "For several decades, the three-parameter logistic model (3PLM)
              has been the dominant choice for practitioners in the field of
              educational measurement for modeling examinees' response data
              from multiple-choice (MC) items. Past studies, however, have
              pointed out that the c-parameter of 3PLM should not be
              interpreted as a guessing parameter. This study found logical,
              empirical evidence showing that neither the a-, b-, or
              c-parameters of 3PLM can accurately reflect the discrimination,
              difficulty, and guessing properties of an item, respectively.
              This study reconceptualized the problem-solving and guessing
              processes with a modification of the 3PLM that eliminates
              ambiguity in modeling the guessing process. A series of studies
              using various real and simulated data demonstrated that the
              suggested model, in which the c-parameters were fixed at a
              computed probability for successful random guessing (i.e., c = 1
              / k with k being the number of options), could provide a more
              feasible, stable, and accurate item estimation solution without
              sacrificing the model fit compared with a typical 3PLM.",
  journal  = "Practical Assessment, Research \& Evaluation",
  volume   =  17,
  number   =  1,
  year     =  2012,
  keywords = "Statistical Analysis, Models, Multiple Choice Test",
  issn     = "1531-7714"
}

@ARTICLE{Rios2016-qa,
  title    = "Evaluating the impact of careless responding on
              aggregated-scores: To filter unmotivated examinees or not?",
  author   = "Rios, Joseph A and Guo, Hongwen and Mao, Liyang and Liu, Ou Lydia",
  abstract = "When examinees' test-taking motivation is questionable,
              practitioners must determine whether careless responding is of
              practical concern and if so, decide on the best approach to
              filter such responses. As there has been insufficient research on
              these topics, the objectives of this study were to: a) evaluate
              the degree of underestimation in the true mean when careless
              responses are present, and b) compare the effectiveness of two
              filtering procedures in purifying biased aggregated-scores.
              Results demonstrated that: a) the true mean was underestimated by
              around 0.20 SDs if the total amount of careless responses
              exceeded 6.25\%, 12.5\%, and 12.5\% for easy, moderately
              difficult, and difficult tests, respectively, and b) listwise
              deleting data from unmotivated examinees artificially inflated
              the true mean by as much as .42 SDs when ability was related to
              careless responding. Findings from this study have implications
              for when and how practitioners should handle careless responses
              for group-based low-stakes asses...",
  journal  = "International Journal of Testing",
  volume   =  17,
  number   =  1,
  pages    = "1--31",
  year     =  2016,
  issn     = "1532-7574",
  doi      = "10.1080/15305058.2016.1231193"
}

@ARTICLE{Vega2003-bn,
  title   = "A perceptual experiment on harmonic tension and melodic attraction
             in Lerdahl's Tonal Pitch Space",
  author  = "Vega, Diego",
  journal = "Musicae scientiae: the journal of the European Society for the
             Cognitive Sciences of Music",
  volume  = "VII",
  number  =  1,
  pages   = "35--55",
  year    =  2003,
  issn    = "1029-8649"
}

@ARTICLE{Bigand2003-dl,
  title   = "Book review: Tonal Pitch Space",
  author  = "Bigand, E and Temperley, David",
  journal = "Musicae scientiae: the journal of the European Society for the
             Cognitive Sciences of Music",
  volume  = "VII",
  number  =  1,
  pages   = "121--155",
  year    =  2003,
  issn    = "1029-8649"
}

@ARTICLE{Milne2016-mr,
  title   = "Empirically testing Tonnetz, voice-leading, and spectral models of
             perceived triadic distance",
  author  = "Milne, Andrew J and Holland, Simon",
  journal = "Journal of Mathematics \& Music. Mathematical and Computational
             Approaches to Music Theory, Analysis, Composition and Performance",
  volume  =  10,
  number  =  1,
  pages   = "59--85",
  year    =  2016,
  issn    = "1745-9737",
  doi     = "10.1080/17459737.2016.1152517"
}

@ARTICLE{Tymoczko2006-of,
  title   = "The geometry of musical chords",
  author  = "Tymoczko, Dmitri",
  journal = "Science",
  volume  =  313,
  number  =  5783,
  pages   = "72--74",
  year    =  2006,
  issn    = "0036-8075",
  doi     = "10.1126/science.1126287"
}

@INCOLLECTION{Tymoczko2016-lx,
  title     = "In quest of musical vectors",
  booktitle = "Mathemusical Conversations",
  author    = "Tymoczko, Dmitri",
  editor    = "Smith, Jordan B L and Chew, Elaine and Assayag, G{\'e}rard",
  publisher = "World Scientific",
  pages     = "256--282",
  year      =  2016,
  address   = "London, UK"
}

@ARTICLE{Gangireddy_undated-xm,
  title  = "Prosodically-enhanced Recurrent Neural Network Language Models",
  author = "Gangireddy, Siva Reddy and Renals, Steve and Nankaku, Yoshihiko and
            Lee, Akinobu"
}

@ARTICLE{Chung2014-ts,
  title   = "Gated Feedback Recurrent Neural Networks",
  author  = "Chung, Junyoung and Gulcehre, Caglar and Cho, Kyunghyun and
             Bengio, Yoshua",
  year    =  2014,
  arxivid = "1502.02367v4"
}

@ARTICLE{Sundermeyer_undated-ug,
  title  = "{LSTM} Neural Networks for Language Modeling",
  author = "Sundermeyer, Martin and Schl, Ralf and Ney, Hermann"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Karafi2010-mj,
  title  = "ˇ a s a s",
  author = "Karafi, Martin and Cernock, Jan Honza",
  number = "September",
  pages  = "1045--1048",
  year   =  2010
}

@ARTICLE{Clark2013-wb,
  title    = "Whatever next? Predictive brains, situated agents, and the future
              of cognitive science",
  author   = "Clark, Andy",
  journal  = "The Behavioral and brain sciences",
  volume   =  36,
  pages    = "181--253",
  year     =  2013,
  keywords = "1; action; attention; bayesian brain; expectation; from helmholtz
              to action-oriented; generative model; hierarchy; introduction;
              perception; precision; prediction; prediction error; prediction
              machines; predictive; predictive coding; top-down processing",
  issn     = "0140-525X",
  doi      = "10.1017/S0140525X12000477"
}

@ARTICLE{Sanborn2016-ur,
  title   = "Bayesian Brains without Probabilities",
  author  = "Sanborn, Adam N and Chater, Nick",
  journal = "Trends in cognitive sciences",
  volume  =  20,
  number  =  12,
  pages   = "883--893",
  year    =  2016,
  issn    = "1364-6613",
  doi     = "10.1016/j.tics.2016.10.003"
}

@ARTICLE{Conklin2008-ws,
  title    = "Discovery of distinctive patterns in music",
  author   = "Conklin, Darrell",
  number   = "July",
  year     =  2008,
  keywords = "anticorpus; distinctive pattern; folk songs; pattern discovery"
}

@INPROCEEDINGS{Quinn2011-hs,
  title     = "Voice-leading prototypes and harmonic function",
  booktitle = "Mathematics and Computation in Music: Third International
               Conference",
  author    = "Quinn, Ian and Mavromatis, Panayotis",
  publisher = "Springer",
  pages     = "230--240",
  year      =  2011,
  address   = "Berlin, Germany",
  keywords  = "clustering; corpus analysis; function; harmonic; modality;
               tonality; voice leading"
}

@ARTICLE{Debeer2013-iv,
  title   = "Modeling item-position effects within an {IRT} framework",
  author  = "Debeer, Dries and Janssen, Rianne",
  journal = "Journal of Educational Measurement",
  volume  =  50,
  number  =  2,
  pages   = "164--185",
  year    =  2013
}

@ARTICLE{Wise2015-vi,
  title  = "Low Examinee Effort in {Low-Stakes} Assessment : Problems and
            Potential Solutions",
  author = "Wise, Steven L and DeMars, Christine E",
  number = "February 2005",
  year   =  2015,
  doi    = "10.1207/s15326977ea1001"
}

@ARTICLE{Lecun2006-wg,
  title  = "A Tutorial on {Energy-Based} Learning 1 Introduction :
            {Energy-Based} Models",
  author = "Lecun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, Marc
            Aurelio and Huang, Fu Jie",
  pages  = "1--59",
  year   =  2006
}

@ARTICLE{Friston2010-yi,
  title     = "The free-energy principle: a unified brain theory?",
  author    = "Friston, Karl",
  journal   = "Nature reviews. Neuroscience",
  publisher = "Nature Publishing Group",
  volume    =  11,
  number    =  2,
  pages     = "127--138",
  year      =  2010,
  issn      = "1471-003X",
  doi       = "10.1038/nrn2787"
}

@ARTICLE{Parncutt1993-ec,
  title   = "Pitch properties of chords of octave-spaced tones",
  author  = "Parncutt, Richard",
  journal = "Contemporary Music Review",
  volume  =  9,
  number  = "1-2",
  pages   = "35--50",
  year    =  1993
}

@ARTICLE{Daniel1997-ll,
  title   = "Psychoacoustical roughness: Implementation of an optimized model",
  author  = "Daniel, P and Weber, R",
  journal = "Acta Acustica united with Acustica",
  volume  =  83,
  number  =  1,
  pages   = "113--123",
  year    =  1997
}

@ARTICLE{Aures1985-sv,
  title   = "Ein Berechnungsverfahren der Rauhigkeit",
  author  = "Aures, W",
  journal = "Acustica",
  volume  =  58,
  number  =  5,
  pages   = "268--281",
  year    =  1985
}

@ARTICLE{Quinn2010-fm,
  title    = "Are pitch-class profiles really ``key for key''?",
  author   = "Quinn, Ian",
  abstract = "Most current approaches to key-finding, either from symbolic data
              such as MIDI or from digital audio data, rely on pitch-class
              profiles. Our alternative approach is based on two ideas: first,
              that chord progressions, understood rather loosely as pairs of
              neighboring harmonic states demarcated by note onsets, are
              sufficient as windows for key-finding, at least in the chorale
              context; and second, that the encapsulated identity of a chord
              progression (modulo pitch-class transposition and revoicing) is
              sufficient -- that is, that reduction of progressions to
              pitch-class distributions is not necessary for key-finding. The
              system has no access to explicit information about a chord
              progression other than its transpositional distribution in the
              training corpus, yet it is able to reach an almost stunning
              degree of subtlety in its harmonic analysis of chorales it's
              never heard before. This suggests that reductionist approaches to
              tonality may be off the mark, or at least that pitch-class
              reductionism might not be necessary for a principled account of
              key.",
  journal  = "Zeitschrift der Gesellschaft f{\"u}r Musiktheorie",
  volume   =  7,
  number   =  2,
  pages    = "151--163",
  year     =  2010
}

@ARTICLE{Huron1994-yo,
  title   = "Interval-class content in equally tempered pitch-class sets:
             Common scales exhibit optimum tonal consonance",
  author  = "Huron, David",
  journal = "Music perception",
  volume  =  11,
  number  =  3,
  pages   = "289--305",
  year    =  1994,
  issn    = "0730-7829",
  doi     = "10.2307/40285624"
}

@PHDTHESIS{White2013-db,
  title  = "Some statistical properties of tonality, 1650-1900",
  author = "White, Christopher Wm",
  year   =  2013,
  school = "Yale University"
}

@INPROCEEDINGS{White2013-fw,
  title     = "An {Alphabet-Reduction} Algorithm for Chordal n-Grams",
  booktitle = "Proceedings of the 4th International Conference on Mathematics
               and Computation in Music",
  author    = "White, Christopher Wm",
  pages     = "201--212",
  year      =  2013,
  keywords  = "alphabet; cognitive modeling; computation; corpus analysis;
               harmonic function; syntax; tonality"
}

@ARTICLE{Pressnitzer2000-ps,
  title   = "Perception of musical tension for nontonal orchestral timbres and
             its relation to psychoacoustic roughness",
  author  = "Pressnitzer, Daniel and McAdams, Stephen and Winsberg, Suzanne and
             Fineberg, Joshua",
  journal = "Perception \& psychophysics",
  volume  =  62,
  number  =  1,
  pages   = "66--80",
  year    =  2000,
  issn    = "0031-5117"
}

@ARTICLE{Lerdahl2007-co,
  title    = "Modeling tonal tension",
  author   = "Lerdahl, Fred and Krumhansl, Carol L",
  journal  = "Music perception",
  volume   =  24,
  number   =  4,
  pages    = "329--366",
  year     =  2007,
  keywords = "attraction; multiple regression; pitch space; prolongational
              structure; tonal tension",
  issn     = "0730-7829"
}

@ARTICLE{Parncutt1994-fr,
  title   = "Applying psychoacoustics in composition: ``Harmonic'' progressions
             of ``nonharmonic'' sonorities",
  author  = "Parncutt, Richard and Strasburger, Hans",
  journal = "Perspectives of New Music",
  volume  =  32,
  number  =  2,
  pages   = "88--129",
  year    =  1994
}

@ARTICLE{Smith2003-xr,
  title   = "Perceptions of musical dimensions in Beethoven's Waldstein sonata:
             An application of Tonal Pitch Space theory",
  author  = "Smith, Nicholas A and Cuddy, Lola L",
  journal = "Musicae scientiae: the journal of the European Society for the
             Cognitive Sciences of Music",
  volume  = "VII",
  number  =  1,
  pages   = "7--34",
  year    =  2003,
  issn    = "1029-8649",
  doi     = "10.1177/102986490300700102"
}

@ARTICLE{Sethares1993-tw,
  title   = "Local consonance and the relationship between timbre and scale",
  author  = "Sethares, William A",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  94,
  number  =  3,
  pages   = "1218--1228",
  year    =  1993,
  issn    = "0001-4966",
  doi     = "10.1121/1.408175"
}

@ARTICLE{Kameoka1969-tt,
  title   = "Consonance theory Part {II}: Consonance of complex tones and its
             calculation method",
  author  = "Kameoka, Akio and Kuriyagawa, Mamoru",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  45,
  number  =  6,
  pages   = "1460--1469",
  year    =  1969,
  issn    = "0001-4966",
  doi     = "10.1121/1.1911624"
}

@ARTICLE{Hutchinson1978-uz,
  title   = "The acoustic component of Western consonance",
  author  = "Hutchinson, William and Knopoff, Leon",
  journal = "Journal of New Music Research",
  volume  =  7,
  number  =  1,
  pages   = "1--29",
  year    =  1978,
  doi     = "10.1080/09298217808570246"
}

@ARTICLE{Greenwood1991-td,
  title   = "Critical bandwidth and consonance in relation to cochlear
             frequency-position coordinates",
  author  = "Greenwood, Donald D",
  journal = "Hearing research",
  volume  =  54,
  number  =  2,
  pages   = "164--208",
  year    =  1991,
  issn    = "0378-5955"
}

@ARTICLE{Callender2004-zk,
  title    = "Continuous transformations",
  author   = "Callender, Clifton",
  journal  = "Music Theory Online",
  volume   =  10,
  number   =  3,
  pages    = "1--43",
  year     =  2004,
  keywords = "interpolation; ligeti; nancarrow; saariaho; transformation; voice
              leading"
}

@INCOLLECTION{Cohn2016-cc,
  title     = "Graph-theoric and geometric models of music",
  booktitle = "Mathemusical Conversations: Mathematics and Computation in Music
               Performance and Composition",
  author    = "Cohn, Richard",
  editor    = "Smith, Jordan B L and Chew, Elaine and Assayag, G{\'e}rard",
  publisher = "World Scientific Publishing",
  pages     = "237--255",
  year      =  2016,
  address   = "Singapore"
}

@BOOK{Lerdahl2001-uu,
  title     = "Tonal Pitch Space",
  author    = "Lerdahl, Fred",
  publisher = "Oxford University Press",
  year      =  2001,
  address   = "Oxford, England"
}

@ARTICLE{Callender2008-ss,
  title   = "Generalized voice-leading",
  author  = "Callender, Clifton and Quinn, Ian and Tymoczko, Dmitri",
  journal = "Science",
  volume  =  320,
  number  =  346,
  pages   = "346--348",
  year    =  2008,
  issn    = "0036-8075",
  doi     = "10.1126/science.1153021"
}

@BOOK{Tymoczko2011-ih,
  title     = "A Geometry of Music",
  author    = "Tymoczko, Dmitri",
  publisher = "Oxford University Press",
  year      =  2011,
  address   = "New York, NY"
}

@INCOLLECTION{Parncutt1997-ip,
  title     = "A model of the perceptual root(s) of a chord accounting for
               voicing and prevailing tonality",
  booktitle = "Music, Gestalt, and Computing: Studies in Cognitive and
               Systematic Musicology",
  author    = "Parncutt, Richard",
  editor    = "Leman, Marc",
  publisher = "Springer",
  pages     = "181--199",
  year      =  1997,
  address   = "Berlin, Germany",
  isbn      = "9783540695912",
  doi       = "10.1007/BFb0034114"
}

@INCOLLECTION{Maxwell1992-tm,
  title     = "An Expert System for Harmonizing Analysis of Tonal Music",
  booktitle = "Understanding Music With {AI}: Perspectives on Music Cognition",
  author    = "Maxwell, J H",
  publisher = "MIT Press",
  pages     = "335--353",
  year      =  1992,
  address   = "Cambridge, MA"
}

@ARTICLE{Winograd1968-qu,
  title   = "Linguistics and the computer analysis of tonal harmony",
  author  = "Winograd, Terry",
  journal = "Journal of Mathematics \& Music. Mathematical and Computational
             Approaches to Music Theory, Analysis, Composition and Performance",
  volume  =  12,
  number  =  1,
  pages   = "2--49",
  year    =  1968,
  issn    = "1745-9737"
}

@ARTICLE{Raphael2004-bl,
  title   = "Functional harmonic analysis using probabilistic models",
  author  = "Raphael, Christopher and Stoddard, Joshua",
  journal = "Computer Music Journal",
  volume  =  28,
  number  =  3,
  pages   = "45--52",
  year    =  2004,
  issn    = "0148-9267",
  doi     = "10.1162/0148926041790676"
}

@ARTICLE{Temperley1997-oq,
  title   = "An algorithm for harmonic analysis",
  author  = "Temperley, David",
  journal = "Music perception",
  volume  =  15,
  number  =  1,
  pages   = "31--68",
  year    =  1997,
  issn    = "0730-7829"
}

@BOOK{Temperley2007-yj,
  title     = "Music and Probability",
  author    = "Temperley, David",
  publisher = "MIT Press",
  year      =  2007,
  address   = "Cambridge, MA"
}

@ARTICLE{Vos1996-na,
  title   = "A parallel-processing key-finding model",
  author  = "Vos, Piet G and Geenen, Erwin W",
  journal = "Music perception",
  volume  =  14,
  number  =  2,
  pages   = "185--223",
  year    =  1996,
  issn    = "0730-7829"
}

@ARTICLE{Shmulevich2000-uk,
  title   = "Localized key finding: Algorithms and applications",
  author  = "Shmulevich, Ilya and Yli-Harja, Olli",
  journal = "Music perception",
  volume  =  17,
  number  =  4,
  pages   = "531--544",
  year    =  2000,
  issn    = "0730-7829"
}

@INPROCEEDINGS{Bellmann2005-po,
  title     = "About the determination of key of a musical excerpt",
  booktitle = "Proceedings of the Third International Symposium of Computer
               Music Modeling and Retrieval",
  author    = "Bellmann, H",
  editor    = "Kronland-Martinet, Richard and Voinier, Thierry and Ystad,
               S{\o}lvi",
  publisher = "Springer",
  pages     = "76--91",
  year      =  2005,
  address   = "Berlin, Germany"
}

@PHDTHESIS{Budge1943-zy,
  title   = "A study of chord frequencies based on the music of representative
             composers of the eighteenth and nineteenth centuries",
  author  = "Budge, H",
  year    =  1943,
  address = "New York, NY",
  school  = "Columbia University Teacher's College"
}

@ARTICLE{Temperley2008-au,
  title   = "Pitch-class distribution and the identification of key",
  author  = "Temperley, David and Marvin, Elizabeth West",
  journal = "Music perception",
  volume  =  25,
  number  =  3,
  pages   = "193--212",
  year    =  2008,
  issn    = "0730-7829"
}

@PHDTHESIS{Sapp2011-od,
  title   = "Computational methods for the analysis of musical structure",
  author  = "Sapp, Craig Stewart",
  year    =  2011,
  address = "Stanford, CA",
  school  = "Stanford University"
}

@ARTICLE{Albrecht2013-hy,
  title   = "The use of large corpora to train a new type of key-finding
             algorithm: An improved treatment of the minor mode",
  author  = "Albrecht, Joshua and Shanahan, Daniel",
  journal = "Music perception",
  volume  =  31,
  number  =  1,
  pages   = "59--67",
  year    =  2013,
  issn    = "0730-7829",
  doi     = "10.1525/MP.2013.31.1.59"
}

@INPROCEEDINGS{Hu2009-ex,
  title     = "A probabilistic topic model for unsupervised learning of musical
               key-profiles",
  booktitle = "Proceedings of the 10th International Society for Music
               Information Retrieval Conference",
  author    = "Hu, Diane J and Saul, Lawrence K",
  year      =  2009,
  address   = "Kobe, Japan"
}

@PHDTHESIS{Aarden2003-me,
  title   = "Dynamic melodic expectancy",
  author  = "Aarden, Bret J",
  year    =  2003,
  address = "Columbus, OH",
  school  = "Ohio State University"
}

@ARTICLE{Temperley1999-qk,
  title   = "What's key for key? The {Krumhansl-Schmuckler} key-finding
             algorithm reconsidered",
  author  = "Temperley, David",
  journal = "Music perception",
  volume  =  17,
  number  =  1,
  pages   = "65--100",
  year    =  1999,
  issn    = "0730-7829"
}

@ARTICLE{Brown1988-yd,
  title   = "The interplay of set content and temporal context in a functional
             theory of tonality perception",
  author  = "Brown, Helen",
  journal = "Music perception",
  volume  =  5,
  number  =  3,
  pages   = "219--250",
  year    =  1988,
  issn    = "0730-7829"
}

@ARTICLE{Schmuckler2005-kv,
  title    = "Perceptual tests of an algorithm for musical key-finding",
  author   = "Schmuckler, Mark A and Tomovski, Robert",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  31,
  number   =  5,
  pages    = "1124--1149",
  year     =  2005,
  keywords = "1997b; as a subdiscipline with; cognitive psychology;
              functioning; including basic psychophysical; investigating
              general psychological; key-finding; music cognition; music
              perception; provides a microcosm for; schmuckler; tonality",
  issn     = "0096-1523",
  doi      = "10.1037/0096-1523.31.5.1124"
}

@ARTICLE{Padilla_Martin-Caro2016-vs,
  title    = "Statistical Generation of {Two-Voice} Florid Counterpoint",
  author   = "Padilla Mart{\'\i}n-Caro, V{\'\i}ctor and Conklin, Darrell",
  abstract = "In this paper, we explore a method for statistical genera-tion of
              music based on the style of Palestrina. First, we find patterns
              in one piece that are selected and organized according to a
              probabilistic distribution, using horizontal viewpoints to
              describe melodic properties of events. Once the template is
              chosen and covered with patterns, two-voice counterpoint in a
              florid style is generated using a first-order Markov model with
              constraints obtained from the template. For constructing the
              model, vertical slices of pitch and rhythm are compiled from a
              corpus of Pale-strina masses. The template enforces different
              restrictions that filter the possible paths through the
              generation pro-cess. A double backtracking algorithm is
              implemented to handle cases where no solutions are found at some
              point within a generation path.",
  journal  = "Proceedings Sound and Music Computing 2016",
  pages    = "380--387",
  year     =  2016
}

@INPROCEEDINGS{Madsen2007-fl,
  title     = "Key-finding with interval profiles",
  booktitle = "Proceedings of the International Computer Music Conference
               ({ICMC})",
  author    = "Madsen, S{\o}ren Tjagvad and Widmer, Gerhard",
  year      =  2007,
  address   = "Copenhagen, Denmark"
}

@TECHREPORT{Alamkan1999-pb,
  title       = "Stylistic Structures: An Initial Investigation of the
                 Stochastic Generation of Tonal Music",
  author      = "Alamkan, C and Birmingham, William P and Simoni, M",
  institution = "University of Michigan",
  year        =  1999
}

@ARTICLE{Conklin2016-pk,
  title    = "Chord sequence generation with semiotic patterns",
  author   = "Conklin, Darrell",
  journal  = "Journal of Mathematics \& Music. Mathematical and Computational
              Approaches to Music Theory, Analysis, Composition and Performance",
  volume   =  10,
  number   =  2,
  pages    = "92--106",
  year     =  2016,
  keywords = "chord sequences; electronic dance music; harmony; machine
              learning; musicgeneration; semiotic analysis; statistical models",
  issn     = "1745-9737",
  doi      = "10.1080/17459737.2016.1188172"
}

@ARTICLE{Agres2016-xw,
  title    = "Harmonic Structure Predicts the Enjoyment of Uplifting Trance
              Music",
  author   = "Agres, Kat and Herremans, Dorien and Bigo, Louis and Conklin,
              Darrell",
  abstract = "An empirical investigation of how local harmonic structures
              (e.g., chord progressions) contribute to the experience and
              enjoyment of uplifting trance (UT) music is presented. The
              connection between rhythmic and percussive elements and resulting
              trance-like states has been highlighted by musicologists, but no
              research, to our knowledge, has explored whether repeated
              harmonic elements influence affective responses in listeners of
              trance music. Two alternative hypotheses are discussed, the first
              highlighting the direct relationship between
              repetition/complexity and enjoyment, and the second based on the
              theoretical inverted-U relationship described by the Wundt curve.
              We investigate the connection between harmonic structure and
              subjective enjoyment through interdisciplinary behavioral and
              computational methods: First we discuss an experiment in which
              listeners provided enjoyment ratings for computer-generated UT
              anthems with varying levels of harmonic repetition and
              complexity. The anthems were generated using a statistical model
              trained on a corpus of 100 uplifting trance anthems created for
              this purpose, and harmonic structure was constrained by imposing
              particular repetition structures (semiotic patterns defining the
              order of chords in the sequence) on a professional UT music
              production template. Second, the relationship between harmonic
              structure and enjoyment is further explored using two
              computational approaches, one based on average Information
              Content, and another that measures average tonal tension between
              chords. The results of the listening experiment indicate that
              harmonic repetition does in fact contribute to the enjoyment of
              uplifting trance music. More compelling evidence was found for
              the second hypothesis discussed above, however some maximally
              repetitive structures were also preferred. Both computational
              models provide evidence for a Wundt-type relationship between
              complexity and enjoyment. By systematically manipulating the
              structure of chord progressions, we have discovered specific
              harmonic contexts in which repetitive or complex structure
              contribute to the enjoyment of uplifting trance music.",
  journal  = "Frontiers in psychology",
  volume   =  7,
  number   = "January",
  pages    = "1999",
  year     =  2016,
  keywords = "Complexity; Computational Creativity; Uplifting Trance music;
              Wundt curve; enjoyment; music cognition; repetition; tension",
  issn     = "1664-1078",
  doi      = "10.3389/FPSYG.2016.01999"
}

@ARTICLE{Pardo2002-xf,
  title    = "Algorithms for chordal analysis",
  author   = "Pardo, Bryan and Birmingham, William P",
  abstract = "The harmonic analysis of tonal music by computer is an important
              area of interest in the computer music research community. While
              the problem is interesting in its own right, the ability to parse
              and use chords and harmonies in a tonal composition also adds an
              important dimension to a computer agent's ability to manipulate
              musical material. Au-tomated arranging, accompaniment, and
              phrasing are all aided by an understanding of the chordal
              structure of a piece. Although musicians analyze tonal music of
              all types, it is dif cult to create algorithms that have this
              generality. In this article, we describe a set of algorithms for
              harmonic analysis that make mini-mal use of stylistic and
              contextual cues, such as metric strength, harmonic context, and
              known sty-listic constraints. The system described in this
              arti-cle is purposefully simple in its approach. This allows us
              to specify its workings to the point where the work may be
              duplicated and extended by oth-ers. The system is designed both
              to explore basic computational properties of algorithms to solve
              the task and to provide a baseline against which other systems
              can be measured. In this way, it is possible to measure the
              change in performance introduced by use of such things as tonal
              context, voice-leading rules, and metrical information. We divide
              harmonic analysis into two tasks. Seg-mentation is the task of
              splitting the music into appropriate chunks (segments) for
              analysis. As a de-fault, we assume segmentation takes place in
              the time dimension. Labeling is the task of giving each segment
              the proper quality and root pitch. Figure 1 shows a measure of
              music partitioned into labeled segments. The algorithms we
              describe in this article per-form both segmentation and labeling.
              Previous re-search in the area of automated harmonic analysis of
              music (Winograd), with the no-table exception of recent work by
              Temperley and Sleator (1999), has either avoided the issue of
              seg-mentation by taking already segmented input, or has been
              unclear about how segmentation is done. Temperley and Sleator
              describe a clear and ef cient approach. While Temperley and
              Sleator do address the seg-mentation problem, they only return
              the root name (rather than the chord quality) and do not give any
              statistical analysis of the performance of their sys-tem when
              compared to an outside measure. To our knowledge, no researchers
              have published statisti-cal performance results on a system
              designed to an-alyze tonal music. The lack of such measures in
              the literature makes comparisons among systems diff cult. We
              present an empirical evaluation of the algo-rithms in this
              article, using a corpus of 45 excerpts of tonal music compiled by
              David Temperley, from the Kostka and Payne music theory textbook
              (Kostka and Payne 1984), hereafter referred to as the KP corpus.
              (The appendix lists each piece used in this corpus.) The analyses
              provided by our sys-tem are compared to an answer key based on
              the analyses in the teacher's edition of the textbook us-ing a
              grading metric described later in this article. Both statistical
              results and analyses of individual excerpts are provided, and
              classes of error are tabu-lated and reported.",
  journal  = "Computer Music Journal",
  volume   =  26,
  number   =  2,
  pages    = "27--49",
  year     =  2002,
  issn     = "0148-9267",
  doi      = "10.1162/014892602760137167"
}

@ARTICLE{Whorley2016-uq,
  title  = "A Transformational Method for Chorale Generation",
  author = "Whorley, Raymond and Conklin, Darrell",
  pages  = "71--75",
  year   =  2016
}

@BOOK{Parncutt1989-sm,
  title     = "Harmony: A psychoacoustical approach",
  author    = "Parncutt, Richard",
  publisher = "Springer-Verlag",
  year      =  1989,
  address   = "Berlin, Germany"
}

@ARTICLE{Terhardt1982-uc,
  title   = "Pitch of complex signals according to virtual-pitch theory: Tests,
             examples and predictions",
  author  = "Terhardt, Ernst and Stoll, Gerhard and Seewann, Manfred",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  71,
  number  =  3,
  pages   = "671--678",
  year    =  1982,
  issn    = "0001-4966",
  doi     = "10.1121/1.387543"
}

@ARTICLE{Laden1989-mg,
  title   = "The representation of pitch in a neural net model of chord
             classification",
  author  = "Laden, Bernice and Keefe, D H",
  journal = "Computer Music Journal",
  volume  =  13,
  number  =  4,
  pages   = "12--26",
  year    =  1989,
  issn    = "0148-9267, 1531-5169"
}

@INPROCEEDINGS{Lartillot2001-um,
  title     = "Automatic Modeling of Musical Style",
  booktitle = "Proceedings of the 2001 International Computer Music Conference
               ({ICMC'01})",
  author    = "Lartillot, Olivier and Dubnov, Shlomo and Assayag, G{\'e}rard
               and Bejerano, Gill",
  abstract  = "In this paper, we describe and compare two methods for
               unsupervised learning of musical style, both of which perform
               analyses of musical sequences and then compute a model from
               which new interpretations / improvisations close to the
               original's style can be generated. In both cases, an important
               part of the musical structure is captured, including rhythm,
               melodic contour, and polyphonic relationships. The first method
               is a drastic improvement of the Incremental Parsing (IP) method,
               a method derived from compression theory and proven useful in
               the musical domain. The second one is an application to music of
               Prediction Suffix Trees (PST), a learning technique initially
               developed for statistical modeling of complex sequences with
               applications in linguistics and biology.",
  pages     = "447--454",
  year      =  2001
}

@ARTICLE{Whorley2016-ao,
  title   = "Music generation from statistical models of harmony",
  author  = "Whorley, Raymond P and Conklin, Darrell",
  journal = "Journal of New Music Research",
  volume  =  45,
  number  =  2,
  pages   = "160--183",
  year    =  2016
}

@ARTICLE{Conklin2015-vf,
  title  = "Trance Generation by Transformation",
  author = "Conklin, Darrell",
  pages  = "4--6",
  year   =  2015
}

@INPROCEEDINGS{Lemstrom2000-mh,
  title     = "Searching monophonic patterns within polyphonic sources",
  booktitle = "Proceedings of the Conference on {Content-Based} Multimedia
               Information Access ({RIAO} 2000)",
  author    = "Lemstr{\"o}m, Kjell and Tarhio, Jorma",
  abstract  = "The string matching problem for strings in which one should find
               the occurrences of a pattern string within a text, is
               well-studied in the past literature. The problem can be solved
               efficiently, e.g., by using so-called bit-parallel algorithms.
               We adapt the bit-parallel approach to music information
               retrieval. We consider a situation where the pattern is
               monophonic and the text (the musical source) is polyphonic, that
               is, the pattern is a sequence of symbols, while the source is a
               sequence of sets of symbols (i.e., chords). The application of
               the bit-parallel approach is straightforward, if the
               transposition invariance is not allowed in the matching.
               However, the problem becomes trickier with transposition
               invariance, a necessary property in practice. We present
               algorithms for both cases. Our main contribution is a
               linear-time transposition-invariant filtering-algorithm for
               static music databases. We show by experiments that, if the
               average size of the chords keeps reasonably low, our filtering
               method clearly outperforms a straightforward approach.",
  volume    =  2,
  pages     = "1261--1278",
  year      =  2000
}

@ARTICLE{Mozer1994-tz,
  title    = "Neural Network Music Composition by Prediction: Exploring the
              Benefits of Psychoacoustic Constraints and Multi-scale Processing",
  author   = "Mozer, Michael C",
  abstract = "In algorithmic music composition, a simple technique involves
              selecting notes sequentially according to a
              \textbackslashntransition table that specifies the probability of
              the next note as a function of the previous context. I
              \textbackslashndescribe an extension of this transition table
              approach using a recurrent autopredictive connectionist net-
              \textbackslashnwork called CONCERT. CONCERT is trained on a set
              of pieces with the aim of extracting stylistic regulari-
              \textbackslashnties. CONCERT can then be used to compose new
              pieces. A central ingredient of CONCERT is the incor-
              \textbackslashnporation of psychologically-grounded
              representations of pitch, duration, and harmonic structure. CON-
              \textbackslashnCERT was tested on sets of examples artificially
              generated according to simple rules and was shown to
              \textbackslashnlearn the underlying structure, even where other
              approaches failed. In larger experiments, CONCERT was
              \textbackslashntrained on sets of J. S. Bach pieces and
              traditional European folk melodies and was then allowed to com-
              \textbackslashnpose novel melodies. Although the compositions are
              occasionally pleasant, and are preferred over com-
              \textbackslashnpositions generated by a third-order transition
              table, the compositions suffer from a lack of global coher-
              \textbackslashnence. To overcome this limitation, several methods
              are explored to permit CONCERT to induce structure
              \textbackslashnat both fine and coarse scales. In experiments
              with a training set of waltzes, these methods yielded lim-
              \textbackslashnited success, but the overall results cast doubt
              on the promise of note-by-note prediction for composition.",
  journal  = "Connection science",
  volume   =  6,
  number   = "2 \& 3",
  pages    = "247--280",
  year     =  1994,
  issn     = "0954-0091",
  doi      = "10.1080/09540099408915726"
}

@ARTICLE{Sala2017-nq,
  title     = "When the music's over. Does music skill transfer to children' s
               and young adolescents' cognitive and academic skills? A
               meta-analysis",
  author    = "Sala, Giovanni and Gobet, Fernand",
  journal   = "Educational Research Review",
  publisher = "Elsevier Ltd",
  volume    =  20,
  pages     = "55--67",
  year      =  2017,
  issn      = "1747-938X",
  doi       = "10.1016/j.edurev.2016.11.005"
}

@ARTICLE{Rosenberg_undated-yq,
  title  = "{CLSQL} Users' Guide",
  author = "Rosenberg, Kevin M and Pearce, Marcus T and Mai, Pierre R"
}

@ARTICLE{Nakamura_undated-lj,
  title    = "{Tree-Structured} Probabilistic Model of Monophonic Written Music
              Based on the Generative Theory of Tonal Music",
  author   = "Nakamura, Eita and Hamanaka, Masatoshi and Hirata, Keiji and
              Yoshii, Kazuyoshi",
  abstract = "This paper presents a probabilistic formulation of music language
              modelling based on the generative theory of tonal music (GTTM)
              named probabilistic GTTM (PGTTM). GTTM is a well-known mu-sic
              theory that describes the tree structure of written music in
              anal-ogy with the phrase structure grammar of natural language.
              To de-velop a computational music language model incorporating
              GTTM and a machine-learning framework for data-driven music
              grammar induction, we construct a generative model of monophonic
              music based on probabilistic context-free grammar, in which the
              time-span tree proposed in GTTM corresponds to the parse tree.
              Applying the techniques of natural language processing, we also
              derive super-vised and unsupervised learning algorithms based on
              the maximal-likelihood estimation, and a Bayesian inference
              algorithm based on the Gibbs sampling. Despite the conceptual
              simplicity of the model, we found that the model automatically
              acquires music grammar from data and reproduces time-span trees
              of written music as accurately as an analyser that required
              elaborate manual parameter tuning.",
  keywords = "GTTM; Index Terms--- Statistical music language model; PCFG;
              statistical grammar induction; time-span tree analysis"
}

@ARTICLE{Choi2014-ts,
  title    = "Automatic processing of abstract musical tonality",
  author   = "Choi, Inyong and Bharadwaj, Hari M and Bressler, Scott and Loui,
              Psyche and Lee, Kyogu and Shinn-Cunningham, Barbara G",
  abstract = "Music perception builds on expectancy in harmony, melody, and
              rhythm. Neural responses to the violations of such expectations
              are observed in event-related potentials (ERPs) measured using
              electroencephalography. Most previous ERP studies demonstrating
              sensitivity to musical violations used stimuli that were
              temporally regular and musically structured, with less-frequent
              deviant events that differed from a specific expectation in some
              feature such as pitch, harmony, or rhythm. Here, we asked whether
              expectancies about Western musical scale are strong enough to
              elicit ERP deviance components. Specifically, we explored whether
              pitches inconsistent with an established scale context elicit
              deviant components even though equally rare pitches that fit into
              the established context do not, and even when their timing is
              unpredictable. We used Markov chains to create temporally
              irregular pseudo-random sequences of notes chosen from one of two
              diatonic scales. The Markov pitch-transition probabilities
              resulted in sequences that favored notes within the scale, but
              that lacked clear melodic, harmonic, or rhythmic structure. At
              the random positions, the sequence contained probe tones that
              were either within the established scale or were out of key. Our
              subjects ignored the note sequences, watching a self-selected
              silent movie with subtitles. Compared to the in-key probes, the
              out-of-key probes elicited a significantly larger P2 ERP
              component. Results show that random note sequences establish
              expectations of the ``first-order'' statistical property of
              musical key, even in listeners not actively monitoring the
              sequences.",
  journal  = "Frontiers in human neuroscience",
  volume   =  8,
  number   = "December",
  pages    = "988",
  year     =  2014,
  keywords = "ERP; P2; erp; markov-chain; music; tonality",
  issn     = "1662-5161",
  pmid     = "25538607",
  doi      = "10.3389/fnhum.2014.00988"
}

@ARTICLE{Kunert2015-mk,
  title    = "Music and language syntax interact in Broca's area: An {fMRI}
              study",
  author   = "Kunert, Richard and Willems, Roel M and Casasanto, Daniel and
              Patel, Aniruddh D and Hagoort, Peter",
  abstract = "Instrumental music and language are both syntactic systems,
              employing complex, hierarchically-structured sequences built
              using implicit structural norms. This organization allows
              listeners to understand the role of individual words or tones in
              the context of an unfolding sentence or melody. Previous studies
              suggest that the brain mechanisms of syntactic processing may be
              partly shared between music and language. However, functional
              neuroimaging evidence for anatomical overlap of brain activity
              involved in linguistic and musical syntactic processing has been
              lacking. In the present study we used functional magnetic
              resonance imaging (fMRI) in conjunction with an interference
              paradigm based on sung sentences. We show that the processing
              demands of musical syntax (harmony) and language syntax interact
              in Broca's area in the left inferior frontal gyrus (without
              leading to music and language main effects). A language main
              effect in Broca's area only emerged in the complex music harmony
              condition, suggesting that (with our stimuli and tasks) a
              language effect only becomes visible under conditions of
              increased demands on shared neural resources. In contrast to
              previous studies, our design allows us to rule out that the
              observed neural interaction is due to: (1) general attention
              mechanisms, as a psychoacoustic auditory anomaly behaved unlike
              the harmonic manipulation, (2) error processing, as the language
              and the music stimuli contained no structural errors. The current
              results thus suggest that two different cognitive domains-music
              and language-might draw on the same high level syntactic
              integration resources in Broca's area.",
  journal  = "PloS one",
  volume   =  10,
  number   =  11,
  pages    = "1--16",
  year     =  2015,
  issn     = "1932-6203",
  pmid     = "26536026",
  doi      = "10.1371/journal.pone.0141069"
}

@ARTICLE{Kunert2016-to,
  title  = "Language influences music harmony perception : effects of shared
            syntactic integration resources beyond attention",
  author = "Kunert, Richard and Willems, Roel M and Hagoort, Peter",
  year   =  2016
}

@ARTICLE{Lahdelma2016-ss,
  title    = "Mild dissonance preferred over consonance in single chord
              perception",
  author   = "Lahdelma, Imre and Eerola, Tuomas",
  journal  = "i-Perception",
  year     =  2016,
  keywords = "chord; consonance; dissonance; preference; psychoacoustics;
              vertical harmony",
  doi      = "10.1177/2041669516655812"
}

@ARTICLE{Lahdelma2016-da,
  title    = "Single chords convey distinct emotional qualities to both
              na{\"\i}ve and expert listeners",
  author   = "Lahdelma, Imre and Eerola, Tuomas",
  journal  = "Psychology of Music",
  volume   =  44,
  number   =  1,
  pages    = "1--18",
  year     =  2016,
  keywords = "2010; articulation; as tempo; chord; e; emotion perception;
              emotional; g; gabrielsson; harmony; lindstr{\"o}m; many studies
              have addressed; meaning in music such; mode; musical factors in
              creating; the role of different; timbre; vertical harmony",
  doi      = "10.1177/0305735614552006"
}

@ARTICLE{Siedenburg2016-xh,
  title    = "A Comparison of Approaches to Timbre Descriptors in Music
              Information Retrieval and Music Psychology",
  author   = "Siedenburg, Kai and Fujinaga, Ichiro and McAdams, Stephen",
  journal  = "Journal of New Music Research",
  volume   =  45,
  number   =  1,
  pages    = "27--41",
  year     =  2016,
  keywords = "MIR;music psychology;timbre",
  doi      = "10.1080/09298215.2015.1132737"
}

@ARTICLE{Willems2016-jm,
  title    = "Prediction during natural language comprehension",
  author   = "Willems, Roel M and Frank, Stefan L and Nijhof, Annabel D and
              Hagoort, Peter and Van Den Bosch, Antal",
  abstract = "The notion of prediction is increasingly studied in cognitive
              neuroscience. We investigated the neural basis of two distinct
              aspects of word prediction, derived from information theory,
              during story comprehension. We assessed the effect of entropy of
              next-word probabilities as well as surprisal. A computational
              model determined entropy and surprisal for each word in three
              literary stories. Twenty-four healthy participants listened to
              the same three stories while their brain activation was measured
              using fMRI. Reversed speech fragments were presented as a control
              condition. Brain areas sensitive to entropy were left ventral
              premotor cortex, left middle frontal gyrus, right inferior
              frontal gyrus, left inferior parietal lobule, and left
              supplementary motor area. Areas sensitive to surprisal were left
              inferior temporal sulcus ('visual word form area'), bilateral
              superior temporal gyrus, right amygdala, bilateral anterior
              temporal poles, and right inferior frontal sulcus. We conclude
              that prediction during language comprehension can occur at
              several levels of processing, including at the level of word
              form. Our study exemplifies the power of combining computational
              linguistics with cognitive neuroscience, and additionally
              underlines the feasibility of studying continuous spoken language
              materials with fMRI.",
  journal  = "Cerebral cortex",
  volume   =  26,
  number   =  6,
  pages    = "2506--2516",
  year     =  2016,
  keywords = "Entropy; FMRI; Language; Prediction; Word surprisal",
  issn     = "1047-3211, 1460-2199",
  pmid     = "25903464",
  doi      = "10.1093/cercor/bhv075"
}

@ARTICLE{Hedges2016-oj,
  title     = "The prediction of merged attributes with multiple viewpoint
               systems",
  author    = "Hedges, Thomas and Wiggins, Geraint A",
  journal   = "Journal of New Music Research",
  publisher = "Routledge",
  volume    =  45,
  number    =  4,
  pages     = "314--332",
  year      =  2016,
  keywords  = "harmony; information theory; multiple
               viewpoint;cross-entropy;harmony;harmony features;multiple
               viewpoint models",
  issn      = "0929-8215",
  doi       = "10.1080/09298215.2016.1205632"
}

@INPROCEEDINGS{Hedges2016-sk,
  title     = "Improving predictions of derived viewpoints in multiple
               viewpoint systems",
  booktitle = "Proceedings of the 17th International Society for Music
               Information Retrieval Conference",
  author    = "Hedges, Thomas and Wiggins, Geraint A",
  pages     = "420--426",
  year      =  2016,
  address   = "New York, NY",
  keywords  = "cross-entropy;jazz;multiple viewpoint models;music"
}

@INPROCEEDINGS{Pachet2013-mj,
  title     = "A comprehensive online database of machine-readable lead-sheets
               for jazz standards",
  booktitle = "14th International Society for Music Information Retrieval
               Conference ({ISMIR} 2013)",
  author    = "Pachet, Fran{\c c}ois and Suzda, Jeff and Martinez, Dani",
  pages     = "275--280",
  year      =  2013,
  address   = "Curitiba (Brazil)"
}

@ARTICLE{Hedges2014-sf,
  title     = "Predicting the composer and style of jazz chord progressions",
  author    = "Hedges, Thomas and Roy, Pierre and Pachet, Fran{\c c}ois",
  abstract  = "Jazz music is a genre that consists mainly of improvising over
               known tunes, represented as a lead sheet. This study addresses
               the question 'to what extent does a lead sheet carry information
               about its composer?' Primarily, this study considers chord
               progressions alone, and secondarily melodic and temporal
               in-formation combined with various multiple viewpoint models.
               Using these classifiers, a novel subsequence selection
               algo-rithm is presented to trace stylistic similarities within a
               lead sheet. We conclude that composers can, to a reasonable
               extent, be recognized from their chord progressions, and that
               the consideration of melodic and temporal information improves
               classification accuracy by a small but statistically significant
               amount.",
  journal   = "Journal of New Music Research",
  publisher = "Routledge",
  volume    =  433,
  number    =  3,
  pages     = "276--290",
  year      =  2014,
  keywords  = "Markov models; classification; harmony; jazz; multiple
               viewpoints; prediction;harmony features;jazz;multiple viewpoint
               models;style classification",
  issn      = "0929-8215",
  doi       = "10.1080/09298215.2014.925477"
}

@ARTICLE{Temperley2009-hu,
  title    = "A unified probabilistic model for polyphonic music analysis",
  author   = "Temperley, David",
  abstract = "This article presents a probabilistic model of polyphonic music
              analysis. Taking a note pattern as input, the model combines
              three aspects of symbolic music analysismetrical analysis,
              harmonic analysis, and stream segregationinto a single process,
              allowing it to capture the complex interactions between these
              structures. The model also yields an estimate of the probability
              of the note pattern itself; this has implications for the
              modelling of music transcription. I begin by describing the
              generative process that is assumed and the analytical process
              that is used to infer metrical, harmonic, and stream structures
              from a note pattern. I then present some tests of the model on
              metrical analysis and harmonic analysis, and discuss ongoing work
              to integrate the model into a transcription system.",
  journal  = "Journal of New Music Research",
  volume   =  38,
  number   =  1,
  pages    = "3--18",
  year     =  2009,
  issn     = "0929-8215",
  doi      = "10.1080/09298210902928495"
}

@INPROCEEDINGS{Sapp2005-ia,
  title     = "Online database of scores in the Humdrum file format",
  booktitle = "Proceedings of the 6th International Society for Music
               Information Retrieval Conference ({ISMIR} 2005)",
  author    = "Sapp, Craig Stuart",
  pages     = "664--665",
  year      =  2005,
  keywords  = "analysis labels; column in; computational music analysis;
               digital scores; humdrum; in this particular example; musical
               data; the data for harmonic; there is an extra; this example;
               toolkit"
}

@ARTICLE{White2016-uf,
  title    = "The {Yale-Classical} Archives Corpus",
  author   = "White, Christopher Wm and Quinn, Ian",
  journal  = "Empirical musicology review: EMR",
  volume   =  11,
  number   =  1,
  year     =  2016,
  keywords = "academic inquiry; allowing scholars to quantify; amounts of; as
              the fields of; c omputational analysis of; common practice;
              corpus analysis; evidence; experiment with such methods;
              historical trends and bolster; intuitive observations with large;
              large data sets has; machine learning; music theory and
              musicology; style; there arises a need; tonality; transformed
              many aspects of"
}

@ARTICLE{Clercq2016-yz,
  title    = "Big data, big questions: A closer look at the {Yale-Classical}
              Archives Corpus",
  author   = "Clercq, Trevor D E",
  journal  = "Empirical musicology review: EMR",
  volume   =  11,
  number   =  1,
  year     =  2016,
  keywords = "corpus analysis; finding; key; machine learning; modulation;
              tonality"
}

@INPROCEEDINGS{Antila2014-cb,
  title     = "The {VIS} Framework: Analyzing Counterpoint in Large Datasets",
  booktitle = "Proc. of the 15th International Society for Music Information
               Retrieval Conference",
  author    = "Antila, Christopher and Cumming, Julie",
  pages     = "71--76",
  year      =  2014
}

@ARTICLE{Mullensiefen2008-lt,
  title    = "High-level feature descriptors and corpus-based musicology:
              Techniques for modelling music cognition",
  author   = "M{\"u}llensiefen, D and Wiggins, Geraint and Lewis, David",
  abstract = "In recent years large electronic collections of music in a
              symbolically-encoded form have been made available. They have
              enabled music researchers to develop and test precise empirical
              theories of music on large data sets. Both the availability of
              music data and the development of new empirical theories creates
              a new perspective for Systematic Musicology, which, as a
              discipline, often sets out to explain or describe music through
              the induction of empirical laws, regularities or statistical
              correlations in relation to music objects or music related
              behaviour (see e.g. Karbusicky, 1979; Karbusicky \& Schneider,
              1980; Schneider, 1993; Huron, 1999; Parncutt, 2007). We present
              two methodological frameworks, feature-extraction and
              corpus-based musicology, which are the core approaches of a
              particular research project, M4S, whose aim is to discover
              mechanisms of music cognition. These two frameworks are also very
              useful for many other empirical tasks in Systematic Musicology.",
  journal  = "Systematic and Comparative Musicology: Concepts, Methods,
              Findings",
  volume   =  24,
  pages    = "133--155",
  year     =  2008
}

@ARTICLE{Anglade_A_and_Ramirez_R_and_Dixon2009-pv,
  title    = "{FIRST-ORDER} {LOGIC} {CLASSIFICATION} {MODELS} {OF} {MUSICAL}
              {GENRES} {BASED} {ON} {HARMONY} Centre for Digital Music",
  author   = "Anglade, A. and Ramirez, R. and Dixon, S",
  abstract = "We present an approach for the automatic extraction of trans-
              parent classification models of musical genres based on har-
              mony. To allow for human-readable classification models we adopt
              a first-order logic representation of harmony and musical genres:
              pieces of music are represented as lists of chords and musical
              genres are seen as context-free definite clause grammars using
              subsequences of these chord lists. To induce the context-free
              definite clause grammars charac- terising the genres we use a
              first-order logic decision tree induction algorithm, Tilde. We
              test this technique on 856 Band in a Box files representing
              academic, jazz and popular music. We perform 2-class and 3-class
              classification tasks on this dataset and obtain good
              classification results: around 66\% accuracy for the 3-class
              problem and between 72\% and 86\% accuracy for the 2-class
              problems. A preliminary anal- ysis of the most common rules
              extracted from the decision tree models built during these
              experiments reveals a list of interesting and/or well-known jazz,
              academic and popular music harmony patterns.",
  journal  = "6th Sound and Music Computing Conference",
  number   = "July",
  pages    = "309--314",
  year     =  2009
}

@ARTICLE{Granroth-Wilding2014-ok,
  title     = "A Robust {Parser-Interpreter} for Jazz Chord Sequences",
  author    = "Granroth-Wilding, Mark and Steedman, Mark",
  abstract  = "AbstractHierarchical structure similar to that associated with
               prosody and syntax in language can be identified in the rhythmic
               and harmonic progressions that underlie Western tonal music.
               Analysing such musical structure resembles natural language
               parsing: it requires the derivation of an underlying
               interpretation from an unstructured sequence of highly ambiguous
               elements---in the case of music, the notes. The task here is not
               merely to decide whether the sequence is grammatical, but rather
               to decide which among a large number of analyses it has. An
               analysis of this sort is a part of the cognitive processing
               performed by listeners familiar with a musical idiom, whether
               musically trained or not. Our focus is on the analysis of the
               structure of expectations and resolutions created by harmonic
               progressions. Building on previous work, we define a theory of
               tonal harmonic progression, which plays a role analogous to
               semantics in language. Our parser uses a formal grammar of jazz
               chord sequences, of a kind widel...",
  journal   = "Journal of New Music Research",
  publisher = "Routledge",
  volume    =  43,
  number    =  4,
  pages     = "355--374",
  year      =  2014,
  keywords  = "cognition; expectation; grammars; harmony; machine learning",
  issn      = "0929-8215",
  doi       = "10.1080/09298215.2014.910532"
}

@ARTICLE{Aucouturier2013-tk,
  title    = "Seven problems that keep {MIR} from attracting the interest of
              cognition and neuroscience",
  author   = "Aucouturier, Jean Julien and Bigand, E",
  abstract = "Despite one and a half decade of research and an impressive body
              of knowledge on how to represent and process musical audio
              signals, the discipline of Music Information Retrieval still does
              not enjoy broad recognition outside of computer science. In music
              cognition and neuroscience in particular, where MIR's
              contribution could be most needed, MIR technologies are scarcely
              ever utilized--- when they're not simply brushed aside as
              irrelevant. This, we contend here, is the result of a series of
              misunderstandings between the two fields, about deeply different
              methodologies and assumptions that are not often made explicit. A
              collaboration between a MIR researcher and a music psychologist,
              this article attempts to clarify some of these assumptions, and
              offers some suggestions on how to adapt some of MIR's most
              emblematic signal processing paradigms, evaluation procedures and
              application scenarios to the new challenges brought forth by the
              natural sciences of music.",
  journal  = "Journal of intelligent information systems",
  volume   =  41,
  number   =  3,
  pages    = "483--497",
  year     =  2013,
  keywords = "Interdisciplinarity; MIR; Music cognition",
  issn     = "0925-9902",
  doi      = "10.1007/s10844-013-0251-x"
}

@INPROCEEDINGS{Harte2005-gm,
  title     = "Symbolic representation of musical chords: A proposed syntax for
               text annotations",
  booktitle = "Proceedings of the 6th International Conference on Music
               Information Retrieval",
  author    = "Harte, C and Sandler, M and Abdallah, S and G{\'o}mez, E",
  abstract  = "Hand annotation of chords in music files is a long and arduous
               task. In this paper we propose a method for representing musical
               chords in text files that can be readily written and understood
               by musically trained individuals yet simple and unambiguous to
               parse by computer programs.",
  pages     = "66--71",
  year      =  2005,
  address   = "London, England"
}

@ARTICLE{Dixon2011-hq,
  title    = "Probabilistic and logic-based modelling of harmony",
  author   = "Dixon, Simon and Mauch, Matthias and Anglade, Am{\'e}lie",
  journal  = "Lecture notes in computer science",
  volume   = "6684 LNCS",
  pages    = "1--19",
  year     =  2011,
  keywords = "Chord transcription; inductive logic programming; musical harmony",
  issn     = "0302-9743",
  doi      = "10.1007/978-3-642-23126-1\_1"
}

@ARTICLE{Paiement2008-sf,
  title  = "Probabilistic Models for Music",
  author = "Paiement, Jean-Francois",
  volume =  4148,
  pages  = "128",
  year   =  2008
}

@ARTICLE{Broze2013-hm,
  title   = "Diachronic changes in jazz harmony: A cognitive perspective",
  author  = "Broze, Yuri and Shanahan, Daniel",
  journal = "Music perception",
  volume  =  31,
  number  =  1,
  pages   = "32--45",
  year    =  2013,
  issn    = "0730-7829",
  doi     = "10.1525/rep.2008.104.1.92"
}

@PHDTHESIS{Harte2010-yi,
  title   = "Towards automatic extraction of harmony information from music
             signals",
  author  = "Harte, Christopher",
  year    =  2010,
  address = "London, England",
  school  = "Queen Mary University of London"
}

@MISC{Temperley2013-cp,
  title    = "Statistical analysis of harmony and melody in rock music",
  author   = "Temperley, David and De Clercq, Trevor",
  abstract = "We present a corpus of harmonic analyses and melodic
              transcriptions of rock songs. After explaining the creation and
              notation of the corpus, we present results of some explorations
              of the corpus data. We begin by considering the overall
              dis-tribution of scale-degrees in rock. We then address the issue
              of key-finding: how the key of a rock song can be identified from
              harmonic and melodic information. Considering both the
              distribution of melodic scale-degrees and the distribution of
              chords (roots), as well as the metrical placement of chords,
              leads to good key-finding performance. Finally, we discuss how
              songs within the corpus might be categorized with regard to their
              pitch organization. Statistical categorization methods point to a
              clustering of songs that resembles the major/minor distinction in
              common-practice music, though with some im-portant differences.",
  journal  = "Journal of New Music Research",
  volume   =  423,
  number   =  3,
  pages    = "187--204",
  year     =  2013,
  issn     = "0929-8215",
  doi      = "10.1080/09298215.2013.788039"
}

@ARTICLE{Anglade2009-ho,
  title    = "Genre Classification Using Harmony Rules Induced From Automatic
              Chord Transcriptions",
  author   = "Anglade, Am{\'e}lie and Ramirez, Rafael and Dixon, Simon",
  abstract = "We present an automatic genre classification technique mak- ing
              use of frequent chord sequences that can be applied on symbolic
              as well as audio data. We adopt a first-order logic
              representation of harmony and musical genres: pieces of music are
              represented as lists of chords and musical gen- res are seen as
              context-free definite clause grammars using subsequences of these
              chord lists. To induce the context- free definite clause grammars
              characterising the genres we use a first-order logic decision
              tree induction algorithm. We report on the adaptation of this
              classification frame- work to audio data using an automatic chord
              transcription algorithm. We also introduce a high-level harmony
              rep- resentation scheme which describes the chords in term of
              both their degrees and chord categories. When compared to another
              high-level harmony representation scheme used in a previous
              study, it obtains better classification accura- cies and shorter
              run times. We test this framework on 856 audio files synthesized
              from Band in a Box files and cov- ering 3 main genres, and 9
              subgenres. We perform 3-way and 2-way classification tasks on
              these audio files and ob- tain good classification results:
              between 67\% and 79\% ac- curacy for the 2-way classification
              tasks and between 58\% and 72\% accuracy for the 3-way
              classification tasks.",
  journal  = "10th International Society for Music Information Retrieval
              Conference I(SMIR 2009)",
  number   = "Ismir",
  pages    = "669--674",
  year     =  2009
}

@ARTICLE{Shakeshaft2016-pz,
  title   = "Rotation is visualisation, {3D} is 2D: using a novel measure to
             investigate the genetics of spatial ability",
  author  = "Shakeshaft, Nicholas G and Rimfeld, Kaili and Schofield, Kerry L
             and Selzam, Saskia and Malanchini, Margherita and Rodic, Maja and
             Kovas, Yulia and Plomin, Robert and Wai, J and Lubinski, D and
             Benbow, C P and Shepard, S and Metzler, D and Shepard, R N and
             Metzler, J and Kozhevnikov, M and Hegarty, M and Linn, M C and
             Petersen, A C and Ho, C-H and Eastman, C and Catrambone, R and
             DeFries, J C and Vandenberg, S G and McClearn, G E and Loehlin, J
             C and Sharan, S and Jacoby, R and McGee, M G and Smalley, S L and
             Thompson, A L and Spence, M A and Judd, W J and Sparkes, R S and
             Alarc{\'o}n, M and Plomin, R and Fulker, D W and Corley, R and
             DeFries, J C and Pedersen, N L and Plomin, R and Nesselroade, J R
             and McClearn, G E and McClearn, G E and Rietveld, M J H and Dolan,
             C V and van Baal, G C M and Boomsma, D I and Tosto, M G and
             Haworth, C M A and Davis, O S P and Plomin, R and Voyer, D and
             Voyer, S and Bryden, M P and Deary, I J and Lyons, M J and
             Schweizer, K and Goldhammer, F and Rauch, W and Moosbrugger, H and
             McGue, M and Bouchard, T and Rijsdijk, F V and Sham, P C and
             Boker, S and Loehlin, J C",
  journal = "Scientific reports",
  volume  =  6,
  pages   = "1--10",
  year    =  2016,
  issn    = "2045-2322",
  doi     = "10.1038/srep30545"
}

@ARTICLE{Ruano2016-tk,
  title     = "Development of a self-administered web-based test for
               longitudinal cognitive assessment",
  author    = "Ruano, Luis and Sousa, Andreia and Severo, Milton and Alves,
               Iv{\^a}nia and Colunas, M{\'a}rcio and Barreto, Rui and Mateus,
               C{\'a}tia and Moreira, Sandra and Conde, Eduardo and Bento,
               Virg{\'\i}lio and Lunet, Nuno and Pais, Joana and Tedim Cruz,
               V{\'\i}tor",
  abstract  = "Sequential testing with brief cognitive tools has been
               recommended to\textbackslashnimprove cognitive screening and
               monitoring, however the few available\textbackslashntools still
               depend on an external evaluator and periodic visits.
               We\textbackslashndeveloped a self-administered computerized test
               intended for\textbackslashnlongitudinal cognitive testing (Brain
               on Track). The test can be\textbackslashnperformed from a home
               computer and is composed of several
               subtests,\textbackslashnexpected to evaluate different cognitive
               domains, all including random\textbackslashnelements to minimize
               learning effects. An initial (A) and a
               refined\textbackslashnversion of the test (B) were applied to
               patients with mild cognitive\textbackslashnimpairment or early
               dementia (n = 88) and age and
               education-matched\textbackslashncontrols. A subsample of a
               population-based cohort (n = 113) performed\textbackslashnthe
               test at home every three months to evaluate test-retest
               reliability.\textbackslashnThe test's final version Cronbach's
               alpha was 0.90, test scores were\textbackslashnsignificantly
               different between patients and controls (p = 0.001),
               the\textbackslashnarea under the receiver operating
               characteristic curve was 0.75 and the\textbackslashnsmallest
               real difference (43.04) was lower than the clinical
               relevant\textbackslashndifference (56.82). In the test-retest
               reliability analysis 9/10\textbackslashnsubtests showed two-way
               mixed single intraclass consistency
               correlation\textbackslashncoefficient >0.70. These results imply
               good internal consistency,\textbackslashndiscriminative ability
               and reliability when performed at
               home,\textbackslashnencouraging further longitudinal clinical
               and population-based studies.",
  journal   = "Scientific reports",
  publisher = "Nature Publishing Group",
  volume    =  6,
  pages     = "1--10",
  year      =  2016,
  issn      = "2045-2322",
  pmid      = "26743329",
  doi       = "10.1038/srep19114"
}

@ARTICLE{Faubert2013-an,
  title    = "Professional athletes have extraordinary skills for rapidly
              learning complex and neutral dynamic visual scenes",
  author   = "Faubert, Jocelyn",
  abstract = "Evidence suggests that an athlete's sports-related
              perceptual-cognitive expertise is a crucial element of top-level
              competitive sports1. When directly assessing whether such
              experience-related abilities correspond to fundamental and
              non-specific cognitive laboratory measures such as processing
              speed and attention, studies have shown moderate effects leading
              to the conclusion that their special abilities are
              context-specific2. We trained 308 observers on a complex dynamic
              visual scene task void of context and motor control requirements3
              and demonstrate that professionals as a group dramatically differ
              from high-level amateur athletes, who dramatically differ from
              non-athlete university students in their capacity to learn such
              stimuli. This demonstrates that a distinguishing factor
              explaining the capacities of professional athletes is their
              ability to learn how to process complex dynamic visual scenes.
              This gives us an insight as to what is so special about the elite
              athletes' mental abilities, which allows them to express great
              prowess in action.",
  journal  = "Scientific reports",
  volume   =  3,
  pages    = "1--3",
  year     =  2013,
  issn     = "2045-2322",
  pmid     = "23378899",
  doi      = "10.1038/srep01154"
}

@INPROCEEDINGS{Estrada2015-up,
  title     = "The development of a new assessment of notational audiation by
               professional musicians",
  booktitle = "Proceedings of the Ninth Triennial Conference of the European
               Society for the Cognitive Sciences of Music",
  author    = "Estrada, L A and Kopiez, R and Wolf, A and Platz, F",
  pages     = "343",
  year      =  2015,
  address   = "Manchester, England"
}

@ARTICLE{Russo2012-ad,
  title    = "Age-related difference in melodic pitch perception is probably
              mediated by temporal processing",
  author   = "Russo, Frank A and Ives, D Timothy and Goy, Huiwen and
              Pichora-Fuller, M Kathleen and Patterson, Roy D",
  abstract = "OBJECTIVE: This study was designed to examine whether age-related
              differences in melodic pitch perception may be mediated by
              temporal processing. Temporal models of pitch suggest that
              performance will decline as the lowest component of a complex
              tone increases in frequency, regardless of age. In addition, if
              there are age-related deficits in temporal processing in older
              adults, this group may have reduced performance relative to
              younger adults even in the most favorable
              conditions.\textbackslashn\textbackslashnDESIGN: Six younger
              adults and 10 older adults with clinically normal audiograms up
              to 8 kHz were tested in a melodic pitch perception task. In each
              trial, two consecutive four-note melodies were presented to the
              listener. Melodies were identical with the exception of one note
              in the second melody that was shifted in pitch. The listener was
              required to identify which note was shifted. All notes consisted
              of eight successive harmonic components, with the average lowest
              component manipulated to be the 4th, 8th, or 12th component of
              the harmonic series, with lower components being
              absent.\textbackslashn\textbackslashnRESULTS: Age-related
              differences in melodic pitch perception were only apparent when
              stimulus parameters favored temporal processing of pitch.
              Furthermore, modeling a loss of periodicity coding yielded an
              outcome consistent with the observed behavioral results. Although
              younger adults generally outperformed older adults, about
              one-quarter of the older adults performed at levels that were
              equivalent to those of younger adults. The only follow-up tests
              that were able to differentiate these exceptional older adults
              were tests that would be sensitive to temporal processing:
              fundamental frequency difference limens and 500 Hz pure-tone
              difference limens. In contrast, otoacoustic emissions and
              high-frequency pure-tone thresholds, which are more commonly
              associated with spectral processing deficits, were not able to
              differentiate older exceptional adults from older typical
              adults.\textbackslashn\textbackslashnCONCLUSION: Age-related
              declines in temporal processing contribute to deficits in melodic
              pitch perception. However, some exceptional older adults with
              normal audiograms preserve excellent temporal processing and
              continue to perform at levels that are typical of younger adults.",
  journal  = "Ear and hearing",
  volume   =  33,
  number   =  2,
  pages    = "177--186",
  year     =  2012,
  issn     = "0196-0202",
  pmid     = "22367092",
  doi      = "10.1097/AUD.0b013e318233acee"
}

@INCOLLECTION{Jordan2010-ob,
  title     = "The development of competency models: An {IRT-based} approach to
               competency assessment in general music education",
  booktitle = "The Practice of Assessment in Music Education: Frameworks,
               Models, and Designs",
  author    = "Jordan, Anne-Katrin and Knigge, Jens",
  editor    = "Brophy, T S",
  publisher = "GIA Publications",
  pages     = "67--86",
  year      =  2010,
  address   = "Chicago, IL"
}

@ARTICLE{Thompson2000-zv,
  title    = "Expectancies generated by recent exposure to melodic sequences",
  author   = "Thompson, W F and Balkwill, L L and Vernescu, R",
  abstract = "In four experiments, we examined the effects of exposure to
              unfamiliar tone sequences on melodic expectancy and memory. In
              Experiment 1, 30 unfamiliar tone sequences (target sequences)
              were presented to listeners three times each in random order
              (exposure phase), and listeners recorded the number of notes in
              each sequence. Listeners were then presented target and novel
              sequences and rated how well the final note continued the pattern
              of notes that preceded it. Novel sequences were identical to
              target sequences, except for the final note. Ratings were
              significantly higher for target sequences than for novel
              sequences, illustrating the influence of exposure on melodic
              expectancy. Experiment 2 confirmed that without exposure to
              target sequences, ratings were equivalent for target and novel
              sequences. In Experiment 3, new listeners were assessed for
              explicit memory for target sequences following the exposure
              phase. Recognition of target sequences was above chance, but
              unrelated to expectancy judgments in Experiment 1. Experiment 4
              replicated the exposure effect, using a modified experiment
              design, and confirmed that the effect is not dependent on
              explicit memory for sequences. We discuss the idea that melodic
              expectancies are influenced by implicit memory for recently heard
              melodic patterns.",
  journal  = "Memory \& cognition",
  volume   =  28,
  number   =  4,
  pages    = "547--555",
  year     =  2000,
  keywords = "Adult; Female; Humans; Male; Mental Recall; Music; Pitch
              Discrimination; Psychoacoustics; Set (Psychology)",
  issn     = "0090-502X",
  pmid     = "10946538",
  doi      = "10.3758/BF03201245"
}

@ARTICLE{Lima2016-ic,
  title   = "Impaired socio-emotional processing in a developmental music
             disorder",
  author  = "Lima, C{\'e}sar F and Brancatisano, Olivia and Fancourt, Amy and
             M{\"u}llensiefen, Daniel and Scott, Sophie K and Warren, Jason D
             and Stewart, Lauren",
  journal = "Scientific reports",
  volume  =  6,
  number  =  34911,
  pages   = "1--13",
  year    =  2016,
  doi     = "10.1038/srep34911"
}

@INPROCEEDINGS{Lavrenko2003-de,
  title     = "Polyphonic Music Modeling with Random Fields",
  booktitle = "Proceedings of the 11th {\{ACM} International Conference on
               Multimedia\}",
  author    = "Lavrenko, Victor and Pickens, Jeremy",
  editor    = "Rowe, Lawrence A and Vin, Harrick M and Plagemann, Thomas and
               Shenoy, Prashant J and Smith, John R",
  pages     = "120--129",
  year      =  2003,
  address   = "Berkeley, CA",
  isbn      = "9781581137224"
}

@ARTICLE{Scholz2010-wf,
  title  = "Robust modeling of musical chord sequences using probabilistic
            N-grams",
  author = "Scholz, Ricardo and Vincent, Emmanuel and Scholz, Ricardo and
            Vincent, Emmanuel and Scholz, Ricardo and Vincent, Emmanuel and
            Bimbot, Fr{\'e}d{\'e}ric",
  year   =  2010
}

@INPROCEEDINGS{Mearns2010-ek,
  title     = "Characterisation of composer style using high-level musical
               features",
  booktitle = "Proceedings of the 3rd International Workshop on Machine
               Learning and Music",
  author    = "Mearns, Lesley and Tidhar, Dan and Dixon, Simon",
  pages     = "37--40",
  year      =  2010,
  address   = "Florence, Italy",
  keywords  = "counterpoint; machine learning; music; style",
  doi       = "10.1145/1878003.1878016"
}

@ARTICLE{De_Clercq2011-as,
  title   = "A corpus analysis of rock harmony",
  author  = "de Clercq, Trevor and Temperley, David",
  journal = "Popular Music",
  volume  =  30,
  number  =  1,
  pages   = "47--70",
  year    =  2011,
  doi     = "10.1017/S026114301000067X"
}

@ARTICLE{Pachet1999-tv,
  title    = "Surprising Harmonies",
  author   = "Pachet, Fran{\c c}ois",
  journal  = "International Journal on Computing Anticipatory Systems",
  volume   =  4,
  pages    = "139--161",
  year     =  1999,
  keywords = "jazz harmony; models of expectation; models of surprise; musical
              structure; rewriting rules; unsupervised learning of"
}

@INPROCEEDINGS{Mauch2007-xi,
  title     = "Discovering chord idioms through Beatles and Real Book songs",
  booktitle = "Proceedings of the 8th International Conference on Music
               Information Retrieval ({ISMIR} 2007)",
  author    = "Mauch, Matthias and Dixon, Simon and Harte, Christopher and
               Casey, Michael and Fields, Benjamin",
  year      =  2007
}

@ARTICLE{Jacoby2015-gy,
  title     = "An information theoretic approach to chord categorization and
               functional harmony",
  author    = "Jacoby, Nori and Tishby, Naftali and Tymoczko, Dmitri",
  journal   = "Journal of New Music Research",
  publisher = "Routledge",
  volume    =  44,
  number    =  3,
  pages     = "219--244",
  year      =  2015,
  keywords  = "1; analysis; cluster; corpus analysis; functional harmony;
               information bottleneck; information theory; introducing the
               framework",
  issn      = "0929-8215",
  doi       = "10.1080/09298215.2015.1036888"
}

@ARTICLE{Quick2015-wy,
  title  = "Composing with Kulitta",
  author = "Quick, Donya",
  pages  = "306--309",
  year   =  2015
}

@ARTICLE{Quick2014-qq,
  title  = "Kulitta: A Framework for Automated Music Composition",
  author = "Quick, Donya",
  number = "September",
  year   =  2014
}

@ARTICLE{Temperley2013-ll,
  title   = "Introduction to the special issues on corpus methods",
  author  = "Temperley, David and VanHandel, Leigh",
  journal = "Music perception",
  volume  =  31,
  number  =  1,
  pages   = "1--3",
  year    =  2013,
  issn    = "0730-7829"
}

@PHDTHESIS{Mcvicar2013-af,
  title    = "A Machine Learning Approach to Automatic Chord Extraction",
  author   = "Mcvicar, Matthew",
  abstract = "A dissertation submitted to the University of Bristol in
              accordance with the requirements for award of the degree of
              Doctorate of Philosophy (PhD) in the Faculty of Engineering Word
              Count: 40,583 Abstract In this thesis we introduce a machine
              learning based automatic chord recog-nition algorithm that
              achieves state of the art performance. This perfor-mance is
              realised by the introduction of a novel Dynamic Bayesian Net-work
              and chromagram feature vector, which concurrently recognises
              chords, keys and bass note sequences on a set of songs by The
              Beatles, Queen and Zweieck. In the months prior to the completion
              of this thesis, a large number of new, fully-labelled datasets
              have been released to the research community, meaning that the
              generalisation potential of models may be tested. When sufficient
              training examples are available, we find that our model achieves
              similar performance on both the well-known and novel datasets and
              statis-tically significantly outperforms a baseline Hidden Markov
              Model.",
  year     =  2013
}

@ARTICLE{Quick2016-ud,
  title     = "Learning production probabilities for musical grammars",
  author    = "Quick, Donya",
  journal   = "Journal of New Music Research",
  publisher = "Routledge",
  volume    =  45,
  number    =  4,
  pages     = "295--313",
  year      =  2016,
  issn      = "0929-8215",
  doi       = "10.1080/09298215.2016.1228680"
}

@ARTICLE{Tymoczko2010-mr,
  title  = "Local Harmonic Grammar in Western Classical Music",
  author = "Tymoczko, Dmitri",
  year   =  2010
}

@PHDTHESIS{Burgoyne2011-zl,
  title    = "Stochastic processes \& database-driven musicology",
  author   = "Burgoyne, John Ashley",
  abstract = "For more than a decade, music information science and musicology
              have been at what Nicholas Cook has described as a 'moment of
              opportunity' for collaboration on database-driven musicology. The
              literature contains relatively few examples of mathematical tools
              that are suitable for analysing temporally structured data like
              music, however, and there are surprisingly few large databases of
              music that contain information at the semantic levels of interest
              to musicologists. This dissertation compiles a bibliography of
              the most important concepts from probability and statistics for
              analysing musical data, reviews how previous researchers have
              used statistics to study temporal relationships in music, and
              presents a new corpus of carefully curated chord labels from more
              than 1000 popular songs from the latter half of the twentieth
              century, as ranked by Billboard magazine's Hot 100 chart. The
              corpus is based on a careful sampling methodology that maintained
              cost efficiency while ensuring that the corpus is well suited to
              drawing conclusions about how harmonic practises may have evolved
              over time and to what extent they may have affected songs'
              popularity. This dissertation also introduces techniques new to
              the musicological community for analysing databases of this size
              and scope, most importantly the Dirichlet-multinomial
              distribution and constraint-based structure learning for causal
              Bayesian networks. The analysis confirms some common intuitions
              about harmonic practises in popular music and suggests several
              intriguing directions for further research.",
  year     =  2011,
  address  = "Montr{\'e}al, Canada",
  school   = "McGill University"
}

@ARTICLE{Wesolowski2016-lq,
  title    = "Assessing jazz big band performance: The development, validation,
              and application of a facet-factorial rating scale",
  author   = "Wesolowski, Brian C",
  journal  = "Psychology of Music",
  volume   =  44,
  number   =  3,
  pages    = "324--339",
  year     =  2016,
  keywords = "2008; a; and; assessment; b; c; can be used for; ensemble; jazz;
              ments; pedagogy; performance; program quality assurance; students
              are assessed for; three broad reasons; to certify achieve-; to
              promote learning; to provide data that; yorke",
  doi      = "10.1177/0305735614567700"
}

@ARTICLE{Wiggins2010-bh,
  title  = "On the non-existence of music Why music theory is a figment of the
            imagination",
  author = "Wiggins, Geraint A and M{\"u}llensiefen, Daniel and Pearce, Marcus
            T",
  pages  = "231--255",
  year   =  2010
}

@ARTICLE{Greenberg2015-dt,
  title     = "Personality predicts musical sophistication",
  author    = "Greenberg, David M and M{\"u}llensiefen, Daniel and Lamb,
               Michael E and Rentfrow, Peter J",
  journal   = "Journal of research in personality",
  publisher = "Elsevier Inc.",
  volume    =  58,
  pages     = "154--158",
  year      =  2015,
  issn      = "0092-6566",
  doi       = "10.1016/j.jrp.2015.06.002"
}

@INPROCEEDINGS{Cook2005-ap,
  title     = "Towards the compleat musicologist?",
  booktitle = "Proc. {ISMIR}",
  author    = "Cook, Nicholas",
  pages     = "1--7",
  year      =  2005
}

@ARTICLE{Krumhansl1995-yz,
  title   = "Music Psychology and Music Theory: Problems and Prospects",
  author  = "Krumhansl, Carol L",
  journal = "Music Theory Spectrum",
  volume  =  17,
  number  =  1,
  pages   = "53--80",
  year    =  1995
}

@ARTICLE{Tymoczko2003-mj,
  title   = "Progressions fondamentales, fonctions, degr{\'e}s: Une grammaire
             de l'harmonie tonale {\'e}l{\'e}mentaire",
  author  = "Tymoczko, Dmitri",
  journal = "Musurgia",
  volume  =  10,
  number  = "3/4",
  pages   = "35--64",
  year    =  2003
}

@BOOK{Fisher1925-ws,
  title     = "Statistical methods for research workers",
  author    = "Fisher, R A",
  publisher = "Oliver and Boyd",
  year      =  1925,
  address   = "Edinburgh, Scotland"
}

@ARTICLE{Zou2007-ig,
  title    = "Toward using confidence intervals to compare correlations",
  author   = "Zou, Guang Yong",
  journal  = "Psychological methods",
  volume   =  12,
  number   =  4,
  pages    = "399--413",
  year     =  2007,
  keywords = "bootstrap; coefficient of determination; confidence interval;
              hypothesis testing",
  issn     = "1082-989X",
  doi      = "10.1037/1082-989X.12.4.399"
}

@ARTICLE{Diedenhofen2015-gm,
  title   = "cocor: A comprehensive solution for the statistical comparison of
             correlations",
  author  = "Diedenhofen, Birk and Musch, Jochen",
  journal = "PloS one",
  volume  =  10,
  number  =  4,
  year    =  2015,
  doi     = "10.1371/journal.pone.0121945"
}

@ARTICLE{Wilhelm2010-uc,
  title    = "Individual differences in perceiving and recognizing faces - One
              element of social cognition",
  author   = "Wilhelm, Oliver and Herzmann, Grit and Kunina, Olga and Danthiir,
              Vanessa and Schacht, Annekathrin and Sommer, Werner",
  journal  = "Journal of personality and social psychology",
  volume   =  99,
  number   =  3,
  pages    = "530--548",
  year     =  2010,
  keywords = "but in your case; face; face memory; face perception; i; i never
              forget a; ll be glad to; make an exception; speed of face
              cognition",
  issn     = "0022-3514",
  doi      = "10.1037/a0019972"
}

@ARTICLE{Duchaine2006-ma,
  title   = "The Cambridge Face Memory Test: Results for neurologically intact
             individuals and an investigation of its validity using inverted
             face stimuli and prosopagnosic participants",
  author  = "Duchaine, Brad and Nakayama, Ken",
  journal = "Neuropsychologia",
  volume  =  44,
  pages   = "576--585",
  year    =  2006,
  issn    = "0028-3932",
  doi     = "10.1016/j.neuropsychologia.2005.07.001"
}

@ARTICLE{Dalla_Bella2016-ok,
  title    = "{BAASTA}: Battery for the Assessment of Auditory Sensorimotor and
              Timing Abilities",
  author   = "Dalla Bella, Simone and Farrugia, Nicolas and Benoit,
              Charles-Etienne and Begel, Valentin and Verga, Laura and Harding,
              Eleanor and Kotz, Sonja A",
  abstract = "1128--1145",
  journal  = "Behavior research methods",
  volume   =  49,
  number   =  3,
  pages    = "1--18",
  year     =  2016,
  keywords = "Beat deafness; Music cognition; Rhythm perception; Rhythm
              performance; Sensorimotor synchronization; Timing; beat deafness;
              performance; rhythm; rhythm perception; sensorimotor
              synchronization; timing",
  issn     = "1554-351X, 1554-3528",
  doi      = "10.3758/s13428-016-0773-6"
}

@ARTICLE{Mayer2003-es,
  title   = "Measuring emotional intelligence with the {MSCEIT} V2.0",
  author  = "Mayer, John D and Salovey, Peter and Caruso, David R and
             Sitarenios, Gill",
  journal = "Emotion",
  volume  =  3,
  number  =  1,
  pages   = "97--105",
  year    =  2003,
  issn    = "1528-3542",
  doi     = "10.1037/1528-3542.3.1.97"
}

@ARTICLE{Resnicow2004-yw,
  title   = "Is recognition of emotion in music performance an aspect of
             emotional intelligence?",
  author  = "Resnicow, Joel E and Salovey, Peter and Repp, Bruno H",
  journal = "Music perception",
  volume  =  22,
  number  =  1,
  pages   = "145--158",
  year    =  2004,
  issn    = "0730-7829"
}

@ARTICLE{Day2004-zn,
  title    = "Using an ability-based measure of emotional intelligence to
              predict individual performance, group performance, and group
              citizenship behaviours",
  author   = "Day, Arla L and Carroll, Sarah A",
  journal  = "Personality and individual differences",
  volume   =  36,
  pages    = "1443--1458",
  year     =  2004,
  keywords = "citizenship behaviour; emotional intelligence; gender;
              performance; personality; validity",
  issn     = "0191-8869",
  doi      = "10.1016/S0191-8869(03)00240-X"
}

@INCOLLECTION{Mullensiefen2016-zp,
  title     = "Recognition of leitmotives in Richard Wagner's music: An item
               response theory approach",
  booktitle = "Analysis of Large and Complex Data",
  author    = "M{\"u}llensiefen, Daniel and Baker, David and Rhodes, Christophe
               and Crawford, Tim and Dreyfus, Laurence",
  editor    = "Wilhelm, Adalbert F X and Kestler, Hans A",
  publisher = "Springer",
  pages     = "473--483",
  year      =  2016,
  address   = "New York, NY"
}

@INCOLLECTION{Bejar2013-wj,
  title     = "Item generation: Implications for a validity argument",
  booktitle = "Automatic item generation: Theory and practice",
  author    = "Bejar, Isaac I",
  editor    = "Gierl, M J and Haladyna, Thomas M",
  publisher = "Routledge",
  year      =  2013,
  address   = "New York, NY"
}

@ARTICLE{Arendasy2007-ef,
  title    = "Using psychometric technology in educational assessment: The case
              of a schema-based isomorphic approach to the automatic generation
              of quantitative reasoning items",
  author   = "Arendasy, Martin and Sommer, Markus",
  journal  = "Learning and individual differences",
  volume   =  17,
  pages    = "366--383",
  year     =  2007,
  keywords = "1; algebra word problems; automatic item generation; capable of;
              educational assessment; however; in educational assessment we; in
              order to; observe how respondents solve; quantitative reasoning;
              rasch model; tests; the test items presented; theoretical
              introduction; these inferences are inherently; tied to the
              construct; to them to infer; validity of the individual; what
              they are",
  issn     = "1041-6080",
  doi      = "10.1016/j.lindif.2007.03.005"
}

@ARTICLE{Arendasy2012-tv,
  title    = "Using automatic item generation to meet the increasing item
              demands of high-stakes educational and occupational assessment",
  author   = "Arendasy, Martin E and Sommer, Markus",
  journal  = "Learning and individual differences",
  volume   =  22,
  pages    = "112--117",
  year     =  2012,
  keywords = "automatic item generation; measurement invariance",
  issn     = "1041-6080",
  doi      = "10.1016/j.lindif.2011.11.005"
}

@ARTICLE{Sonnleitner2008-qs,
  title   = "Using the {LLTM} to evaluate an item generating system for reading
             comprehension",
  author  = "Sonnleitner, Philipp",
  journal = "Psychology science quarterly",
  volume  =  50,
  number  =  3,
  pages   = "345--362",
  year    =  2008,
  issn    = "1866-6140"
}

@INPROCEEDINGS{Chen2006-ha,
  title     = "{FAST} -- An Automatic Generation System for Grammar Tests",
  booktitle = "Proceedings of the {COLING/ACL} 2006 Interactive Presentation
               Sessions",
  author    = "Chen, Chia-Yin and Chang, Jason S",
  publisher = "Association for Computational Linguistics",
  pages     = "1--4",
  year      =  2006,
  address   = "Sydney, Australia"
}

@ARTICLE{Sijtsma2006-ux,
  title   = "Psychometrics in psychological research: Role model or partner in
             science?",
  author  = "Sijtsma, Klaas",
  journal = "Psychometrika",
  volume  =  71,
  number  =  3,
  pages   = "451--455",
  year    =  2006,
  issn    = "0033-3123"
}

@ARTICLE{Embretson2001-ml,
  title   = "Improving construct validity with cognitive psychology principles",
  author  = "Embretson, Susan",
  journal = "Journal of Educational Measurement",
  volume  =  38,
  number  =  4,
  pages   = "343--368",
  year    =  2001
}

@INPROCEEDINGS{Lai2009-kl,
  title     = "Using Automatic Item Generation to Address Item Demands for
               {CAT}",
  booktitle = "Proceedings of the 2009 {GMAC} Conference on Computerized
               Adaptive Testing",
  author    = "Lai, Hollis and Alves, Cecilia and Gierl, M J",
  year      =  2009
}

@ARTICLE{Deutsch1981-nf,
  title    = "The internal representation of pitch sequences in tonal music",
  author   = "Deutsch, Diana and Feroe, John",
  abstract = "Examines how humans optimally form hierarchies, using a model
              based on the assumptions that tonal music is solely the product
              of human processing systems, and that pitch sequences are
              retained as hierarchical networks. At each level of the
              hierarchy, elements are organized as structural units in
              accordance with gestalt principles such as proximity and good
              continuation. Further, elements that are present at each
              hierarchical level are elaborated by further elements to form
              structural units at the next-lower level, until the lowest level
              is reached. Processing advantages include the following: (a)
              redundancy of representation, (b) use of distinct alphabets at
              different structural levels, and (c) representations formed in
              accordance with the laws of figural goodness. (73 ref) (PsycINFO
              Database Record (c) 2004 APA, all rights reserved)",
  journal  = "Psychological review",
  volume   =  88,
  number   =  6,
  pages    = "503--522",
  year     =  1981,
  issn     = "0033-295X",
  doi      = "10.1037/0033-295X.88.6.503"
}

@ARTICLE{Collins2017-rv,
  title   = "Computer-generated stylistic compositions with long-term
             repetitive and phrasal structure",
  author  = "Collins, Tom and Laney, Robin",
  journal = "Journal of Creative Music Systems",
  volume  =  1,
  number  =  2,
  year    =  2017,
  doi     = "10.5920/JCMS.2017.02"
}

@ARTICLE{Gotham2015-kc,
  title    = "Attractor tempos for metrical structures",
  author   = "Gotham, Mark",
  abstract = "Through new mathematical modelling based on
              experimentally-substantiated principles of cognitive science,
              this article provides robust principles for identifying
              ``attractor tempos'' which optimise the salience of metrical
              structures. This sheds lights on core musical phenomena such as
              the inclination towards parti-cular tempos in given metrical
              contexts, the use of (non-optimal) tempos as a source of
              expressive tension in music, and even what it means for music to
              be ``fast'' or ``slow'' in the first place. The study does not
              purport to set out a comprehensive model of metrical listening,
              but simply to identify the core principles which are necessarily
              involved in establishing attractor tempos. The (limited)
              dependence of those principles on the initial modelling
              parameters is discussed. Furthermore, there is no prescription of
              ``correct'' tempos here, instead the attractors model a set of
              defaults against which musicians may select tempos for expressive
              effect. An Online Supplement to this article, providing a ...",
  journal  = "Journal of Mathematics \& Music. Mathematical and Computational
              Approaches to Music Theory, Analysis, Composition and Performance",
  volume   =  9,
  number   =  1,
  pages    = "23--44",
  year     =  2015,
  keywords = "00A65; 97M80; mathematics; metre; modelling; music; pulse
              salience; tempo; timing",
  issn     = "1745-9737",
  doi      = "10.1080/17459737.2014.980343"
}

@BOOK{Celebi2015-ze,
  title     = "Partitional Clustering Algorithms",
  editor    = "Celebi, M Emre",
  publisher = "Springer",
  year      =  2015,
  address   = "New York, NY"
}

@ARTICLE{Humphrey2013-gb,
  title    = "Feature learning and deep architectures : new directions for
              music informatics",
  author   = "Humphrey, Eric J and Bello, Juan P and Lecun, Yann",
  year     =  2013,
  keywords = "deep learning; music informatics; signal processing",
  doi      = "10.1007/s10844-013-0248-5"
}

@ARTICLE{Murtagh1983-pa,
  title    = "A survey of recent advances in hierarchical clustering algorithms",
  author   = "Murtagh, F",
  abstract = "It has often been asserted that since hierarchical clustering
              algorithms\textbackslashnrequire pairwise interobject
              proximities, the complexity of these\textbackslashnclustering
              procedures is at least O(N^2). Recent work has
              disproved\textbackslashnthis by incorporating efficient nearest
              neighbour searching algorithms\textbackslashninto the clustering
              algorithms. A general framework for
              hierarchical,\textbackslashnagglomerative clustering algorithms
              is discussed here, which opens\textbackslashnup the prospect of
              much improvement on current, widely-used
              algorithms.\textbackslashnThis `progress report' details new
              algorithmic approaches in this\textbackslashnarea, and reviews
              recent results.",
  journal  = "Computer Journal",
  volume   =  26,
  number   =  4,
  pages    = "354--359",
  year     =  1983,
  issn     = "0010-4620",
  doi      = "10.1093/comjnl/26.4.354"
}

@ARTICLE{Gilbert_undated-sz,
  title  = "A Probabilistic {Context-Free} Grammar for Melodic Reduction",
  author = "Gilbert, {\'E}douard and Conklin, Darrell",
  number =  2007,
  pages  = "83--94"
}

@ARTICLE{Melnykov2010-xc,
  title    = "Finite mixture models and model-based clustering",
  author   = "Melnykov, Volodymyr and Maitra, Ranjan",
  abstract = "We investigate the discrepancy principle, a simple method for
              choosing smoothing parameters for nonparametric density
              estimation. The main idea is to maximally smooth subject to a
              constraint on the distance between the data and the estimate.
              This technique is one of the most widely known methods for
              choosing a regularization parameter in (deterministic) inverse
              problems, but has only rarely been applied in statistics. The
              most important execptions originate in Statistical Learning
              Theory and the so-called Data Approximation approach. We unify
              and extend previous results on kernel density estimation with
              bandwidths chosen by the discrepancy principle and derive
              analogous results for regular histograms. We also show that for
              certain densities with infinite peaks using the discrepancy
              principle leads inconsistent estimators. Furthermore, we compare
              the discrepancy principle to standard methods in a simulation
              study. The results show that some versions of the discrepancy
              principle are competetive, and that the behaviour of the methods
              for samples of size at least up to n=2500 can be quite different
              from their asymptotic behaviour.",
  journal  = "Statistics surveys",
  volume   =  4,
  pages    = "80--116",
  year     =  2010,
  keywords = "EM algorithm; magnitude magnetic resonance images; model
              selection; proteomics; teo-dimensional gel electrophoresis data;
              text mining; variable selection. diagnostics",
  issn     = "1935-7516",
  pmid     = "540267",
  arxivid  = "1104.2190",
  doi      = "10.1214/154957804100000000"
}

@ARTICLE{Kameoka_undated-ou,
  title  = "{CONTEXT-FREE} {2D} {TREE} {STRUCTURE} {MODEL} {OF} {MUSICAL}
            {NOTES} {FOR} {BAYESIAN} {MODELING} {OF} {POLYPHONIC}
            {SPECTROGRAMS}",
  author = "Kameoka, Hirokazu and Ochiai, Kazuki and Nakano, Masahiro and
            Tsuchiya, Masato and Sagayama, Shigeki"
}

@ARTICLE{Zeng2014-mq,
  title    = "Constructing better classifier ensemble based on weighted
              accuracy and diversity measure",
  author   = "Zeng, Xiaodong and Wong, Derek F and Chao, Lidia S",
  abstract = "A weighted accuracy and diversity (WAD) method is presented, a
              novel measure used to evaluate the quality of the classifier
              ensemble, assisting in the ensemble selection task. The proposed
              measure is motivated by a commonly accepted hypothesis; that is,
              a robust classifier ensemble should not only be accurate but also
              different from every other member. In fact, accuracy and
              diversity are mutual restraint factors; that is, an ensemble with
              high accuracy may have low diversity, and an overly diverse
              ensemble may negatively affect accuracy. This study proposes a
              method to find the balance between accuracy and diversity that
              enhances the predictive ability of an ensemble for unknown data.
              The quality assessment for an ensemble is performed such that the
              final score is achieved by computing the harmonic mean of
              accuracy and diversity, where two weight parameters are used to
              balance them. The measure is compared to two representative
              measures, Kappa-Error and GenDiv, and two threshold measures that
              consider only accuracy or diversity, with two heuristic search
              algorithms, genetic algorithm, and forward hill-climbing
              algorithm, in ensemble selection tasks performed on 15 UCI
              benchmark datasets. The empirical results demonstrate that the
              WAD measure is superior to others in most cases.",
  journal  = "The Scientific World Journal",
  volume   =  2014,
  year     =  2014,
  issn     = "1537-744X",
  pmid     = "24672402",
  doi      = "10.1155/2014/961747"
}

@ARTICLE{Castellano1984-fv,
  title    = "Tonal hierarchies in the music of north India",
  author   = "Castellano, M A and Bharucha, Jamshed J and Krumhansl, C L",
  abstract = "Cross-culturally, most music is tonal in the sense that one
              particular tone, called the tonic, provides a focus around which
              the other tones are organized. The specific organizational
              structures around the tonic show considerable diversity. Previous
              studies of the perceptual response to Western tonal music have
              shown that listeners familiar with this musical tradition have
              internalized a great deal about its underlying organization.
              Krumhansl and Shepard (1979) developed a probe tone method for
              quantifying the perceived hierarchy of stability of tones. When
              applied to Western tonal contexts, the measured hierarchies were
              found to be consistent with music-theoretic accounts. In the
              present study, the probe tone method was used to quantify the
              perceived hierarchy of tones of North Indian music. Indian music
              is tonal and has many features in common with Western music. One
              of the most significant differences is that the primary means of
              expressing tonality in Indian music is through melody, whereas in
              Western music it is through harmony (the use of chords). Indian
              music is based on a standard set of melodic forms (called rags),
              which are themselves built on a large set of scales (thats). The
              tones within a rag are thought to be organized in a hierarchy of
              importance. Probe tone ratings were given by Indian and Western
              listeners in the context of 10 North Indian rags. These ratings
              confirmed the predicted hierarchical ordering. Both groups of
              listeners gave the highest ratings to the tonic and the fifth
              degree of the scale. These tones are considered by Indian music
              theorists to be structurally significant, as they are immovable
              tones around which the scale system is constructed, and they are
              sounded continuously in the drone. Relatively high ratings were
              also given to the vadi tone, which is designated for each rag and
              is given emphasis in the melody. The ratings of both groups of
              listeners generally reflected the pattern of tone durations in
              the musical contexts. This result suggests that the distribution
              of tones in music is a psychologically effective means of
              conveying the tonal hierarchy to listeners whether they are
              familiar with the musical tradition. Beyond this, only the Indian
              listeners were sensitive to the scales (thats) underlying the
              rags. For Indian listeners, multidimensional scaling of the
              correlations between the rating profiles recovered the
              theoretical representation of scales described by theorists of
              Indian music.",
  journal  = "Journal of experimental psychology. General",
  volume   =  113,
  number   =  3,
  pages    = "394--412",
  year     =  1984,
  issn     = "0096-3445",
  pmid     = "6237169",
  doi      = "10.1037/0096-3445.113.3.394"
}

@ARTICLE{Sturm2016-tq,
  title    = "Music transcription modelling and composition using deep learning",
  author   = "Sturm, Bob L and Santos, Jo{\~a}o Felipe and Ben-Tal, Oded and
              Korshunova, Iryna",
  abstract = "We apply deep learning methods, specifically long short-term
              memory (LSTM) networks, to music transcription modelling and
              composition. We build and train LSTM networks using approximately
              23,000 music transcriptions expressed with a high-level
              vocabulary (ABC notation), and use them to generate new
              transcriptions. Our practical aim is to create music
              transcription models useful in particular contexts of music
              composition. We present results from three perspectives: 1) at
              the population level, comparing descriptive statistics of the set
              of training transcriptions and generated transcriptions; 2) at
              the individual level, examining how a generated transcription
              reflects the conventions of a music practice in the training
              transcriptions (Celtic folk); 3) at the application level, using
              the system for idea generation in music composition. We make our
              datasets, software and sound examples open and available:
              \textbackslashurl\{https://github.com/IraKorshunova/folk-rnn\}.",
  journal  = "arXiv preprint arXiv:1604.08723",
  year     =  2016,
  keywords = "algorithmic composition; deep learning; music modelling;
              recurrent neural network",
  arxivid  = "1604.08723"
}

@ARTICLE{Benetos2013-fu,
  title    = "Automatic music transcription: Challenges and future directions",
  author   = "Benetos, Emmanouil and Dixon, Simon and Giannoulis, Dimitrios and
              Kirchhoff, Holger and Klapuri, Anssi",
  abstract = "Automatic music transcription is considered by many to be a key
              enabling technology in music signal processing. However, the
              performance of transcription systems is still significantly below
              that of a human expert, and accuracies reported in recent years
              seem to have reached a limit, although the field is still very
              active. In this paper we analyse limitations of current methods
              and identify promising directions for future research. Current
              transcription methods use general purpose models which are unable
              to capture the rich diversity found in music signals. One way to
              overcome the limited performance of transcription systems is to
              tailor algorithms to specific use-cases. Semi-automatic
              approaches are another way of achieving a more reliable
              transcription. Also, the wealth of musical scores and
              corresponding audio data now available are a rich potential
              source of training data, via forced alignment of audio to scores,
              but large scale utilisation of such data has yet to be attempted.
              Other promising approaches include the integration of information
              from multiple algorithms and different musical aspects.",
  journal  = "Journal of intelligent information systems",
  volume   =  41,
  number   =  3,
  pages    = "407--434",
  year     =  2013,
  keywords = "Automatic music transcription; Music information retrieval; Music
              signal analysis",
  issn     = "0925-9902",
  doi      = "10.1007/s10844-013-0258-3"
}

@ARTICLE{Vohra2015-qd,
  title   = "Modeling temporal dependencies in data using a {DBN-LSTM}",
  author  = "Vohra, Raunaq and Goel, Kratarth and Sahoo, J K",
  journal = "IEEE International Conference on Data Science and Advanced
             Analytics (DSAA)",
  year    =  2015
}

@ARTICLE{Cross1998-ae,
  title   = "Music analysis and music perception",
  author  = "Cross, Ian",
  journal = "Music perception",
  volume  =  17,
  number  =  1,
  pages   = "3--20",
  year    =  1998,
  issn    = "0730-7829"
}

@PHDTHESIS{Cemgil2004-nx,
  title  = "Bayesian music transcription",
  author = "Cemgil, A T",
  year   =  2004,
  school = "Radboud University, Nijmegen, The Netherlands"
}

@BOOK{Cohn2012-ah,
  title     = "Audacious euphony: Chromatic harmony and the triad's second
               nature",
  author    = "Cohn, Richard",
  publisher = "Oxford University Press",
  year      =  2012,
  address   = "New York, NY"
}

@ARTICLE{Fedorenko2009-kh,
  title    = "Structural integration in language and music: Evidence for a
              shared system",
  author   = "Fedorenko, Evelina and Patel, Aniruddh and Casasanto, Daniel and
              Winawer, Jonathan and Gibson, Edward",
  abstract = "In this study, we investigate whether language and music share
              cognitive resources for structural processing. We report an
              experiment that used sung materials and manipulated linguistic
              complexity (subject-extracted relative clauses, object-extracted
              relative clauses) and musical complexity (in-key critical note,
              out-of-key critical note, auditory anomaly on the critical note
              involving a loudness increase). The auditory-anomaly manipulation
              was included in order to test whether the difference between
              in-key and out-of-key conditions might be due to any salient,
              unexpected acoustic event. The critical dependent measure
              involved comprehension accuracies to questions about the
              propositional content of the sentences asked at the end of each
              trial. The results revealed an interaction between linguistic and
              musical complexity such that the difference between the subject-
              and object-extracted relative clause conditions was larger in the
              out-of-key condition than in the in-key and auditory-anomaly
              conditions. These results provide evidence for an overlap in
              structural processing between language and music. \copyright{}
              2009 The Psychonomic Society, Inc.",
  journal  = "Memory and Cognition",
  volume   =  37,
  number   =  1,
  pages    = "1--9",
  year     =  2009,
  issn     = "0090-502X",
  doi      = "10.3758/MC.37.1.1"
}

@ARTICLE{Franklin2006-af,
  title    = "Recurrent Neural Networks for Music Computation",
  author   = "Franklin, Judy A",
  abstract = "Some researchers in the computational sciences have considered
              music computation, including music reproduction and generation,
              as a dynamic system, i.e., a feedback process. The key element is
              that the state of the musical system depends on a history of past
              states. Recurrent (neural) networks have been deployed as models
              for learning musical processes. We first present a tutorial
              discussion of recurrent networks, covering those that have been
              used for music learning. Following this, we examine a thread of
              development of these recurrent networks for music computation
              that shows how more intricate music has been learned as the state
              of the art in recurrent networks improves. We present our
              findings that show that a long short-term memory recurrent
              network, with new representations that include music knowledge,
              can learn musical tasks, and can learn to reproduce long songs.
              Then, given a reharmonization of the chordal structure, it can
              generate an improvisation.",
  journal  = "INFORMS journal on computing",
  volume   =  18,
  number   =  3,
  pages    = "321--338",
  year     =  2006,
  keywords = "accepted by elaine chew; accepted december 2004; and computation;
              computer music; december 2004; guest editor of the; history;
              january 2004; lstm; music representation; received; recurrent
              neural networks; revised july 2004; special cluster on music",
  issn     = "1091-9856",
  doi      = "10.1287/ijoc.1050.0131"
}

@ARTICLE{Coca2011-hj,
  title    = "Generation of composed musical structures through recurrent
              neural networks based on chaotic inspiration",
  author   = "Coca, Andr{\'e}s E and Romero, Roseli A F and Zhao, Liang",
  abstract = "In this work, an Elman recurrent neural network is used for
              automatic musical structure composition based on the style of a
              music previously learned during the training phase. Furthermore,
              a small fragment of a chaotic melody is added to the input layer
              of the neural network as an inspiration source to attain a
              greater variability of melodies. The neural network is trained by
              using the BPTT (back propagation through time) algorithm. Some
              melody measures are also presented for characterizing the
              melodies provided by the neural network and for analyzing the
              effect obtained by the insertion of chaotic inspiration in
              relation to the original melody characteristics. Specifically, a
              similarity melodic measure is considered for contrasting the
              variability obtained between the learned melody and each one of
              the composite melodies by using different quantities of
              inspiration musical notes.",
  journal  = "Proceedings of the International Joint Conference on Neural
              Networks",
  pages    = "3220--3226",
  year     =  2011,
  issn     = "2161-4393",
  doi      = "10.1109/IJCNN.2011.6033648"
}

@INPROCEEDINGS{Kirchhoff2001-tb,
  title     = "Multi-stream statistical n-gram modeling with application to
               automatic language identification",
  booktitle = "Proceedings of Eurospeech",
  author    = "Kirchhoff, Katrin and Parandekar, Sonia",
  year      =  2001,
  address   = "Aalborg, Denmark"
}

@ARTICLE{Van_der_Linden2000-pf,
  title   = "Capitalization on item calibration error in adaptive testing",
  author  = "van der Linden, Wim J and Glas, Cees A W",
  journal = "Applied Measurement in Education",
  volume  =  13,
  number  =  1,
  pages   = "35--53",
  year    =  2000,
  doi     = "10.1207/s15324818ame1301"
}

@ARTICLE{Whalen1985-ms,
  title   = "Phonetic information is integrated across intervening
             nonlinguistic sounds",
  author  = "Whalen, D H and Samuel, Arthur G",
  journal = "Perception \& psychophysics",
  volume  =  37,
  pages   = "579--587",
  year    =  1985,
  issn    = "0031-5117"
}

@ARTICLE{Lupyan2015-wt,
  title    = "Words and the world: Predictive coding and the
              language-perception-cognition interface",
  author   = "Lupyan, Gary and Clark, Andy",
  journal  = "Current directions in psychological science",
  volume   =  24,
  number   =  4,
  pages    = "279--284",
  year     =  2015,
  keywords = "a picture is emerging; across the cognitive sciences; attention;
              in; language; language and thought; of probabilistic; perception;
              predictive coding; top-down effects; viewed as an engine; which
              the brain is",
  issn     = "0963-7214",
  doi      = "10.1177/0963721415570732"
}

@INPROCEEDINGS{Senuma2011-ci,
  title     = "K-means clustering with feature hashing",
  booktitle = "Proceedings of the {ACL-HLT} 2011 Student Session",
  author    = "Senuma, Hajime",
  pages     = "122--126",
  year      =  2011
}

@INPROCEEDINGS{Li2006-oq,
  title     = "A factored language model of quantized pitch and duration",
  booktitle = "International Conference on Computer Music",
  author    = "Li, Xiao and Ji, Gang and Bilmes, Jeff",
  year      =  2006,
  address   = "New Orleans, LA"
}

@BOOK{Beard2016-nh,
  title     = "Musicology: The key concepts",
  author    = "Beard, David and Gloag, Kenneth",
  publisher = "Routledge",
  year      =  2016,
  address   = "New York, NY"
}

@INPROCEEDINGS{Chen1995-oi,
  title     = "Bayesian grammar induction for language modeling",
  booktitle = "Proceedings of the 33rd annual meeting on Association for
               Computational Linguistics",
  author    = "Chen, Stanley F",
  pages     = "228--235",
  year      =  1995
}

@ARTICLE{Ebcioglu1988-na,
  title   = "An expert system for harmonizing four-part chorales",
  author  = "Ebcio{\u g}lu, Kemal",
  journal = "Computer Music Journal",
  volume  =  12,
  number  =  3,
  pages   = "43--51",
  year    =  1988
}

@ARTICLE{Schwardt_undated-dy,
  title  = "{EFFICIENT} {MIXED-ORDER} {HIDDEN} {MARKOV} {MODEL} {INFERENCE}",
  author = "Schwardt, Ludwig and Preez, Johan",
  pages  = "1--4"
}

@BOOK{Forte1978-cn,
  title     = "The harmonic organization of the Rite of Spring",
  author    = "Forte, Allen",
  publisher = "Yale University Press",
  year      =  1978,
  address   = "London, England"
}

@ARTICLE{Krumhansl1979-ws,
  title   = "The psychological representation of Musical pitch in a tonal
             context",
  author  = "Krumhansl, Carol L",
  journal = "Cognitive psychology",
  volume  =  11,
  pages   = "346--374",
  year    =  1979,
  issn    = "0010-0285"
}

@ARTICLE{Krumhansl1987-mx,
  title   = "The perception of tone hierarchies and mirror forms in twelve-tone
             serial music",
  author  = "Krumhansl, Carol L and Sandell, Gregory J and Sergeant, Desmond C",
  journal = "Music perception",
  volume  =  5,
  number  =  1,
  pages   = "31--77",
  year    =  1987,
  issn    = "0730-7829"
}

@BOOK{Lewin1987-qg,
  title     = "Generalized musical intervals and transformations",
  author    = "Lewin, David",
  publisher = "Yale University Press",
  year      =  1987,
  address   = "New Haven, CT"
}

@BOOK{Dahlhaus1984-iu,
  title     = "Die Musiktheorie im 18. und 19. Jahrhundert: Grundzuge einer
               System",
  author    = "Dahlhaus, Carl",
  publisher = "Wissenschaftliche Buchgesellschaf",
  year      =  1984,
  address   = "Darmstadt, Germany"
}

@INPROCEEDINGS{Viro2011-bn,
  title     = "Peachnote: Music score search and analysis platform",
  booktitle = "Proceedings of the 12th International Society for Music
               Information Retrieval Conference",
  author    = "Viro, Vladimir",
  pages     = "359--362",
  year      =  2011,
  address   = "Miami, FL"
}

@ARTICLE{Margulis2008-qn,
  title   = "Musical style, psychoaesthetics, and prospects for entropy as an
             analytic tool",
  author  = "Margulis, Elizabeth Hellmuth and Beatty, Andrew P",
  journal = "Computer Music Journal",
  volume  =  32,
  number  =  4,
  pages   = "64--78",
  year    =  2008
}

@ARTICLE{Meyer1957-je,
  title   = "Meaning in music and information theory",
  author  = "Meyer, Leonard B",
  journal = "The Journal of Aesthetics and Art Criticism",
  volume  =  15,
  number  =  4,
  pages   = "412--424",
  year    =  1957
}

@ARTICLE{Trivino-Rodriguez2001-qu,
  title   = "Using multiattribute prediction suffix graphs to predict and
             generate music",
  author  = "Trivino-Rodriguez, J L and Morales-Bueno, R",
  journal = "Computer Music Journal",
  volume  =  25,
  number  =  3,
  pages   = "62--79",
  year    =  2001
}

@TECHREPORT{Stolcke1997-rm,
  title  = "{WS96} project report: Dependency language modeling",
  author = "Stolcke, Andreas and Chelba, Ciprian and Engle, David and Jimenez,
            Victor and Mangu, Lidia and Printz, Harry and Ristad, Eric and
            Rosenfield, Roni and Wu, Dekai and Jelinek, Fred and Khudanpur,
            Sanjeev",
  year   =  1997
}

@BOOK{Densmore1918-ao,
  title     = "Teton Sioux music",
  author    = "Densmore, Frances",
  publisher = "Government Printing Office",
  year      =  1918,
  address   = "Washington, DC"
}

@ARTICLE{Youngblood1958-yt,
  title   = "Style as information",
  author  = "Youngblood, Joseph E",
  journal = "Journal of Mathematics \& Music. Mathematical and Computational
             Approaches to Music Theory, Analysis, Composition and Performance",
  volume  =  2,
  number  =  1,
  pages   = "24--35",
  year    =  1958,
  issn    = "1745-9737"
}

@ARTICLE{Cohen1962-ah,
  title   = "Information theory and music",
  author  = "Cohen, Joel E",
  journal = "Behavioral science",
  volume  =  7,
  number  =  2,
  pages   = "137--163",
  year    =  1962,
  issn    = "0005-7940"
}

@ARTICLE{Knopoff1983-vc,
  title   = "Entropy as a measure of style: The influence of sample length",
  author  = "Knopoff, Leon and Hutchinson, William",
  journal = "Journal of Mathematics \& Music. Mathematical and Computational
             Approaches to Music Theory, Analysis, Composition and Performance",
  volume  =  27,
  number  =  1,
  pages   = "75--97",
  year    =  1983,
  issn    = "1745-9737"
}

@INPROCEEDINGS{Quastler_undated-qf,
  title     = "Discussion, following Mathematical theory of word formation, by
               W. Fucks",
  booktitle = "Information Theory -- Third London Symposium",
  author    = "Quastler, H",
  editor    = "Cherry, E C",
  publisher = "Academic Press",
  address   = "New York, NY"
}

@ARTICLE{Huron2013-do,
  title   = "On the virtuous and the vexatious in an age of big data",
  author  = "Huron, David",
  journal = "Music perception",
  volume  =  31,
  number  =  1,
  pages   = "4--9",
  year    =  2013,
  issn    = "0730-7829"
}

@ARTICLE{Vos1989-nr,
  title   = "Ascending and descending melodic intervals: Statistical findings
             and their perceptual relevance",
  author  = "Vos, Piet G and Troost, Jim M",
  journal = "Music perception",
  volume  =  6,
  number  =  4,
  pages   = "383--396",
  year    =  1989,
  issn    = "0730-7829"
}

@ARTICLE{Gjerdingen1986-nl,
  title   = "The formation and deformation of {Classic/Romantic} phrase
             schemata: A theoretical model and historical study",
  author  = "Gjerdingen, Robert",
  journal = "Music Theory Spectrum",
  volume  =  8,
  pages   = "25--43",
  year    =  1986
}

@INPROCEEDINGS{Klein2001-ru,
  title     = "A generative constituent-context model for improved grammar
               induction",
  booktitle = "Proceedings of the 40th Annual Meeting on Association for
               Computational Linguistics",
  author    = "Klein, Dan and Manning, Christopher D",
  pages     = "128--135",
  year      =  2001
}

@ARTICLE{Krumhansl2000-zf,
  title   = "Cross-cultural music cognition: Cognitive methodology applied to
             North Sami yoiks",
  author  = "Krumhansl, Carol L and Toivanen, Pekka and Eerola, Tuomas and
             Toiviainen, Petri and J{\"a}rvinena, Topi and Louhivuoria, Jukka",
  journal = "Cognition",
  volume  =  76,
  pages   = "13--58",
  year    =  2000,
  issn    = "0010-0277"
}

@ARTICLE{Cook1987-hh,
  title   = "Musical form and the listener",
  author  = "Cook, Nicholas",
  journal = "The Journal of Aesthetics and Art Criticism",
  volume  =  46,
  number  =  1,
  pages   = "23--29",
  year    =  1987
}

@ARTICLE{Swain1986-ez,
  title   = "The need for limits in hierarchical theories of music",
  author  = "Swain, Joseph P",
  journal = "Music perception",
  volume  =  4,
  number  =  1,
  pages   = "121--147",
  year    =  1986,
  issn    = "0730-7829"
}

@ARTICLE{Hochreiter1997-rx,
  title   = "Long short-term memory",
  author  = "Hochreiter, Sepp and Schmidhuber, J{\"u}rgen",
  journal = "Neural computation",
  volume  =  9,
  number  =  8,
  pages   = "1735--1780",
  year    =  1997,
  issn    = "0899-7667"
}

@ARTICLE{Gers2001-lo,
  title   = "{LSTM} recurrent networks learn simple context-free and
             context-sensitive languages",
  author  = "Gers, Felix A and Schmidhuber, J{\"u}rgen",
  journal = "IEEE transactions on neural networks / a publication of the IEEE
             Neural Networks Council",
  volume  =  12,
  number  =  6,
  pages   = "1333--1340",
  year    =  2001,
  issn    = "1045-9227"
}

@INCOLLECTION{Conklin2002-tx,
  title     = "Representation and discovery of vertical patterns in music",
  booktitle = "Music and Artificial Intelligence: Proc. {ICMAI} 2002",
  author    = "Conklin, Darrell",
  editor    = "Anagnostopoulou, Christina and Ferrand, M and Smaill, A",
  publisher = "Springer-Verlag",
  pages     = "32--42",
  year      =  2002,
  address   = "Berlin, Germany"
}

@PHDTHESIS{Whorley2013-tf,
  title   = "The construction and evaluation of statistical models of melody
             and harmony",
  author  = "Whorley, Raymond Peter",
  year    =  2013,
  address = "London, England",
  school  = "Goldsmiths College, University of London"
}

@ARTICLE{Chordia2016-hd,
  title  = "Predictive Tabla Modelling Using Variable-length Markov and Hidden
            Markov Models Predictive Tabla Modelling Using Variable-length
            Markov and Hidden Markov Models",
  author = "Chordia, Parag and Sastry, Avinash and {\c S}ent{\"u}rk, Sertan and
            Chordia, Parag and Sastry, Avinash and Sertan, S",
  volume =  8215,
  number = "December",
  year   =  2016,
  doi    = "10.1080/09298215.2011.576318"
}

@BOOK{Koelsch2000-ch,
  title     = "Brain and music",
  author    = "Koelsch, Stefan",
  publisher = "John Wiley \& Sons",
  year      =  2000,
  address   = "Chichester, England"
}

@ARTICLE{Cohn1998-of,
  title   = "Introduction to {Neo-Riemannian} Theory: A survey and historical
             perspective",
  author  = "Cohn, Richard",
  journal = "Journal of Mathematics \& Music. Mathematical and Computational
             Approaches to Music Theory, Analysis, Composition and Performance",
  volume  =  42,
  number  =  2,
  pages   = "167--180",
  year    =  1998,
  issn    = "1745-9737"
}

@BOOK{Patel2008-nk,
  title     = "Music, language and the brain",
  author    = "Patel, Aniruddh D",
  publisher = "Oxford University Press",
  year      =  2008,
  address   = "New York, NY"
}

@BOOK{Blacking1995-iq,
  title     = "Music, culture and experience",
  author    = "Blacking, J",
  publisher = "University of Chicago Press",
  year      =  1995,
  address   = "London, England"
}

@INCOLLECTION{Marsden2016-pg,
  title     = "Music analysis by computer: Ontology and epistemology",
  booktitle = "Computational Music Analysis",
  author    = "Marsden, Alan",
  editor    = "Meredith, David",
  publisher = "Springer",
  pages     = "3--28",
  year      =  2016,
  address   = "New York, NY"
}

@INCOLLECTION{Giraud2016-ad,
  title     = "Computational analysis of musical form",
  booktitle = "Computational Music Analysis",
  author    = "Giraud, Mathieu and Groult, Richard and Lev, Florence",
  editor    = "Meredith, David",
  publisher = "Springer",
  pages     = "113--136",
  year      =  2016,
  address   = "New York, NY"
}

@ARTICLE{Thomson1993-le,
  title   = "The harmonic root: A fragile marriage of concept and percept",
  author  = "Thomson, William",
  journal = "Music perception",
  volume  =  10,
  number  =  4,
  pages   = "385--415",
  year    =  1993,
  issn    = "0730-7829"
}

@INCOLLECTION{Christensen2002-sm,
  title     = "Introduction",
  booktitle = "The Cambridge history of Western music theory",
  author    = "Christensen, Thomas",
  editor    = "Christensen, Thomas",
  publisher = "Cambridge University Press",
  pages     = "1--23",
  year      =  2002,
  address   = "New York, NY"
}

@BOOK{Fux1965-rc,
  title     = "The study of counterpoint: From Johann Joseph Fux's Gradus Ad
               Parnassum",
  author    = "Fux, Johann Joseph",
  publisher = "W. W. Norton \& Company",
  year      =  1965,
  address   = "New York, NY"
}

@INCOLLECTION{Bohlman1999-cu,
  title     = "Ontologies of music",
  booktitle = "Rethinking Music",
  author    = "Bohlman, P",
  publisher = "Oxford University Press",
  pages     = "17--34",
  year      =  1999,
  address   = "Oxford, England"
}

@BOOK{Piston1988-zf,
  title     = "Harmony",
  author    = "Piston, Walter",
  publisher = "W. W. Norton \& Company",
  year      =  1988,
  address   = "New York, NY"
}

@ARTICLE{Nettheim1997-ur,
  title   = "A bibliography of statistical applications in musicology",
  author  = "Nettheim, Nigel",
  journal = "Musicology Australia",
  volume  =  20,
  number  =  1,
  pages   = "94--106",
  year    =  1997,
  doi     = "10.1080/08145857.1997.10415974"
}

@BOOK{Prout1969-tt,
  title     = "Fugue",
  author    = "Prout, Ebenezer",
  publisher = "Greenwood Press",
  year      =  1969,
  address   = "New York, NY"
}

@ARTICLE{Snyder1990-uu,
  title   = "Entropy as a measure of musical style: The influence of a priori
             assumptions",
  author  = "Snyder, John L",
  journal = "Music Theory Spectrum",
  volume  =  12,
  number  =  1,
  pages   = "121--160",
  year    =  1990
}

@ARTICLE{Babbitt1965-ka,
  title   = "The structure and function of musical theory: {I}",
  author  = "Babbitt, Milton",
  journal = "College Music Symposium",
  volume  =  5,
  pages   = "49--60",
  year    =  1965
}

@INPROCEEDINGS{Cox2010-yp,
  title     = "On the relationship between entropy and meaning in music: An
               exploration with recurrent neural networks",
  booktitle = "Proceedings of the Annual Meeting of the Cognitive Science
               Society",
  author    = "Cox, Greg",
  pages     = "429--434",
  year      =  2010,
  keywords  = "information; music cognition; neural networks"
}

@ARTICLE{Boon1995-up,
  title   = "Dynamical systems theory for music dynamics",
  author  = "Boon, Jean Pierre and Decroly, Olivier",
  journal = "Chaos: An Interdisciplinary Journal of Nonlinear Science",
  volume  =  5,
  number  =  3,
  pages   = "501--508",
  year    =  1995,
  arxivid = "chao-dyn/9411022v1"
}

@ARTICLE{Pinkerton1956-ah,
  title   = "Information theory and melody",
  author  = "Pinkerton, Richard C",
  journal = "Scientific American",
  volume  =  194,
  number  =  2,
  pages   = "77--86",
  year    =  1956,
  issn    = "0036-8733"
}

@ARTICLE{Christensen1988-fn,
  title   = "Carl Dahlhaus. Die Musiktheorie im 18. und 19. Jahrhundert:
             Grundz{\"u}ge einer Systematik",
  author  = "Christensen, Thomas",
  journal = "Music Theory Spectrum",
  volume  =  10,
  pages   = "127--137",
  year    =  1988
}

@INPROCEEDINGS{Kaliakatsos-Papakostas2014-sr,
  title     = "Harmony in the polyphonic songs of Epirus: Representation,
               statistical analysis and generation",
  booktitle = "4th International Workshop on Folk Music Analysis ({FMA})",
  author    = "Kaliakatsos-Papakostas, Maximos and Katsiavalos, Andreas and
               Tsougras, Costas and Cambouropoulos, Emilios",
  year      =  2014
}

@ARTICLE{Milne2011-iv,
  title   = "Modelling the similarity of pitch collections with expectation
             tensors",
  author  = "Milne, Andrew J and Sethares, William A and Laney, Robin and
             Sharp, David B",
  journal = "Journal of Mathematics \& Music. Mathematical and Computational
             Approaches to Music Theory, Analysis, Composition and Performance",
  volume  =  5,
  number  =  1,
  pages   = "1--20",
  year    =  2011,
  issn    = "1745-9737",
  doi     = "10.1080/17459737.2011.573678"
}

@ARTICLE{Sigtia2015-pn,
  title    = "A hybrid recurrent neural network for music transcription",
  author   = "Sigtia, Siddharth and Benetos, Emmanouil and
              Boulanger-Lewandowski, Nicolas and Weyde, Tillman and Garcez,
              Artur S D'avila and Dixon, Simon",
  journal  = "Proceedings of the ... IEEE International Conference on
              Acoustics, Speech, and Signal Processing / sponsored by the
              Institute of Electrical and Electronics Engineers Signal
              Processing Society. ICASSP",
  year     =  2015,
  keywords = "music transcription;neural networks;polyphony",
  issn     = "1520-6149",
  arxivid  = "1411.1623v1"
}

@BOOK{Eberlein1994-ak,
  title     = "Die Entstehung der tonalen Klangsyntax",
  author    = "Eberlein, Roland",
  publisher = "Peter Lang",
  year      =  1994,
  address   = "Frankfurt, Germany"
}

@INPROCEEDINGS{Anders2009-uu,
  title     = "A computational model that generalises Schoenberg's guidelines
               for favourable chord progressions",
  booktitle = "Proceedings of the Sound and Music Computing Conference",
  author    = "Anders, Torsten and Miranda, Eduardo R",
  pages     = "48--52",
  year      =  2009,
  address   = "Porto, Portugal"
}

@INPROCEEDINGS{Milne2010-ju,
  title     = "Tonal music theory: A psychoacoustic explanation?",
  booktitle = "Proceedings of the International Conference of Music Perception
               and Cognition 2010 ({ICMPC} 11)",
  author    = "Milne, Andrew J",
  year      =  2010
}

@ARTICLE{Milne2016-lg,
  title   = "Testing a spectral model of tonal affinity with microtonal
             melodies and inharmonic spectra",
  author  = "Milne, Andrew J and Laney, Robin and Sharp, David B",
  journal = "Musicae scientiae",
  volume  =  20,
  number  =  4,
  pages   = "465--494",
  year    =  2016,
  issn    = "1029-8649",
  doi     = "10.1177/1029864915622682"
}

@PHDTHESIS{Milne2013-wi,
  title   = "A computational model of the cognition of tonality",
  author  = "Milne, Andrew J",
  year    =  2013,
  address = "Milton Keynes, England",
  school  = "Unpublished doctoral dissertation, The Open University"
}

@ARTICLE{Milne2015-os,
  title    = "A spectral pitch class model of the probe tone data and scalic
              tonality",
  author   = "Milne, Andrew J and Laney, Robin and Sharp, David",
  journal  = "Music perception",
  volume   =  32,
  number   =  4,
  pages    = "364--393",
  year     =  2015,
  keywords = "1982; essler; fits; k rumhansl and k; microtonality; of twelve;
              perceived; pitch class similarity; probe; probe tone data;
              spectral; tonal hierarchies; tonality; tone data comprise the",
  issn     = "0730-7829",
  doi      = "10.1525/MP.2015.32.4.364"
}

@ARTICLE{Blacking1959-wf,
  title   = "Problems of pitch, pattern and harmony in the ocarina music of the
             Venda",
  author  = "Blacking, John",
  journal = "African Music",
  volume  =  2,
  number  =  2,
  pages   = "15--23",
  year    =  1959
}

@BOOK{Rameau1722-bw,
  title     = "Treatise on harmony",
  author    = "Rameau, Jean-Philippe",
  publisher = "Jean-Baptiste-Christophe Ballard",
  year      =  1722,
  address   = "Paris, France"
}

@BOOK{Schoenberg1978-ca,
  title     = "Theory of harmony",
  author    = "Schoenberg, Arnold",
  publisher = "University of California Press",
  year      =  1978,
  address   = "Berkeley and Los Angeles, CA"
}

@ARTICLE{Rahn1999-yg,
  title   = "Chinese harmony and contemporary non-tonal music theory",
  author  = "Rahn, Jay",
  journal = "Canadian University Music Review",
  volume  =  19,
  number  =  2,
  pages   = "115--124",
  year    =  1999,
  doi     = "10.7202/1014452ar"
}

@ARTICLE{Anders2011-wi,
  title   = "Constraint programming systems for modeling music theories and
             composition",
  author  = "Anders, Torsten and Miranda, Eduardo R",
  journal = "ACM Computing Surveys",
  volume  =  43,
  number  =  4,
  year    =  2011,
  doi     = "10.1145/1978802.1978809"
}

@PHDTHESIS{Milne2009-qj,
  title  = "A psychoacoustic model of harmonic cadences",
  author = "Milne, Andrew J",
  year   =  2009,
  school = "University of Jyv{\"a}skyl{\"a}"
}

@ARTICLE{Parncutt2011-hr,
  title   = "The tonic as triad: Key profiles as pitch salience profiles of
             tonic triads",
  author  = "Parncutt, Richard",
  journal = "Music perception",
  volume  =  28,
  number  =  4,
  pages   = "333--365",
  year    =  2011,
  issn    = "0730-7829"
}

@ARTICLE{Parncutt1999-ub,
  title    = "Tonality as implication-realisation",
  author   = "Parncutt, Richard and Vos, P In and Leman, M",
  abstract = "The implication-realisation concept may be applied to various
              aspects of tonal perception and syntax. Consider the following
              four asymmetries in relationships between successive tones and
              chords. First, successive pure tones spanning an octave in the
              central pitch range sound more similar when the interval falls
              than when it rises. Second, for harmonic complex tones, rising
              octaves sound more similar than falling. Third, in mainstream
              tonal music, root progressions between major and/or minor triads
              (with one tone in common) more frequently span falling perfect
              fifths than rising perfect fifths. Fourth, in pairs of
              major/minor triads (with two tones in common), falling thirds
              between roots outnumber rising thirds. All these phenomena may
              traced to pitches that are implied (as fundamentals of incomplete
              harmonic series) but not physically present in the sounds
              concerned. The strongest of these implied pitches are: one octave
              below the main pitch of a pure tone; one octave above the main
              pitch of a harmonic complex tone; and at third and fifth
              intervals below the conventional roots of major and minor triads.
              Another kind of implication-realisation effect applies at perfect
              or authentic cadences. Both the prevalence distribution of chroma
              in a passage of music in a major or minor key, and the
              pitch-salience distribution of the tonic triad, correlate closely
              with the corresponding key profile. The prevalence distribution
              of chroma in the previous music may thus be regarded as an
              implication that is realised by the tonic triad, encapsulating
              the entire distribution in a single sonority. 1",
  journal  = "Proceedings of Expert Meeting on Tonality Induction",
  number   = "March",
  pages    = "1--21",
  year     =  1999,
  keywords = "syntax asymmetries successive tones chords rising"
}

@INCOLLECTION{Eberlein1997-iy,
  title     = "A method of analysing harmony, based on interval patterns or
               ``Gestalten''",
  booktitle = "Music, Gestalt, and Computing: Studies in Cognitive and
               Systematic Musicology",
  author    = "Eberlein, Roland",
  editor    = "Leman, Marc",
  publisher = "Springer Verlag",
  pages     = "225--236",
  year      =  1997,
  address   = "Berlin, Germany"
}

@INCOLLECTION{Werts1997-ci,
  title     = "`Good', `fair', and `bad' chord progressions: A
               regression-analysis of some psychological chord progression data
               obtained in an experiment by J. Bharucha and C. Krumhansl",
  booktitle = "Music, Gestalt and Computing: Studies in Cognitive and
               Systematic Musicology",
  author    = "Werts, Daniel",
  editor    = "Leman, Marc",
  publisher = "Springer",
  pages     = "200--211",
  year      =  1997,
  address   = "Berlin, Germany"
}

@ARTICLE{Schneider2010-oo,
  title  = "Music Theory: Speculation, Reasoning, Experience. A Perspective
            from Systematic Musicology",
  author = "Schneider, Albert",
  year   =  2010
}

@INCOLLECTION{Toiviainen1997-hj,
  title     = "Optimizing self-organizing timbre maps: Two approaches",
  booktitle = "Music, Gestalt, and Computing: Studies in Cognitive and
               Systematic Musicology",
  author    = "Toiviainen, Petri",
  editor    = "Leman, Marc",
  publisher = "Springer-Verlag",
  pages     = "337--350",
  year      =  1997,
  address   = "Berlin, Germany",
  doi       = "10.1007/BFb0034102"
}

@ARTICLE{Dahlhaus2001-zk,
  title   = "Harmony",
  author  = "Dahlhaus, Carl and Anderson, Julian and Wilson, Charles and Cohn,
             Richard and Hyer, Brian",
  journal = "Grove Music Online",
  year    =  2001
}

@ARTICLE{Koelsch2011-lc,
  title    = "Toward a neural basis of music perception - a review and updated
              model",
  author   = "Koelsch, Stefan",
  abstract = "Music perception involves acoustic analysis, auditory memory,
              auditory scene analysis, processing of interval relations, of
              musical syntax and semantics, and activation of (pre)motor
              representations of actions. Moreover, music perception
              potentially elicits emotions, thus giving rise to the modulation
              of emotional effector systems such as the subjective feeling
              system, the autonomic nervous system, the hormonal, and the
              immune system. Building on a previous article (Koelsch and
              Siebel, 2005), this review presents an updated model of music
              perception and its neural correlates. The article describes
              processes involved in music perception, and reports EEG and fMRI
              studies that inform about the time course of these processes, as
              well as about where in the brain these processes might be
              located.",
  journal  = "Frontiers in psychology",
  volume   =  2,
  number   = "JUN",
  pages    = "1--20",
  year     =  2011,
  keywords = "Brain; EEG; ERAN; FMRI; Music; Semantics",
  issn     = "1664-1078",
  pmid     = "21713060",
  doi      = "10.3389/fpsyg.2011.00110"
}

@INCOLLECTION{Petroni1997-oe,
  title     = "Self-organizing neural nets and the perceptual origin of the
               circle of fifths",
  booktitle = "Music, Gestalt, and Computing: Studies in Cognitive and
               Systematic Musicology",
  author    = "Petroni, N C and Tricarico, M",
  editor    = "Leman, Marc",
  publisher = "Springer",
  pages     = "169--180",
  year      =  1997,
  address   = "Berlin, Germany"
}

@ARTICLE{Parncutt1996-nz,
  title   = "Praxis, Lehre, Wahrnehmung. Kritische Bemerkungen zu Roland
             Eberlein: Die Entstehung der tonalen Klangsyntax",
  author  = "Parncutt, Richard",
  journal = "Musiktheorie",
  volume  =  11,
  year    =  1996
}

@ARTICLE{Xu2005-es,
  title   = "Survey of clustering algorithms",
  author  = "Xu, Rui and Wunsch, II, Donald",
  journal = "IEEE transactions on neural networks / a publication of the IEEE
             Neural Networks Council",
  volume  =  16,
  number  =  3,
  pages   = "645--678",
  year    =  2005,
  issn    = "1045-9227"
}

@ARTICLE{Loui2005-uc,
  title    = "Effects of attention on the neural processing of harmonic syntax
              in Western music",
  author   = "Loui, Psyche and Grent-, Tineke and Torpey, Dana and Woldorff,
              Marty",
  volume   =  25,
  pages    = "678--687",
  year     =  2005,
  keywords = "auditory processing; event-related potential; harmonic
              expectation; music perception; selective attention",
  doi      = "10.1016/j.cogbrainres.2005.08.019"
}

@ARTICLE{Likas2003-rt,
  title    = "The global k -means clustering algorithm",
  author   = "Likas, Aristidis and Vlassis, Nikos and Verbeek, Jakob J",
  volume   =  36,
  pages    = "451--461",
  year     =  2003,
  keywords = "clustering; data mining; global optimization; k - d trees; k
              -means algorithm"
}

@ARTICLE{Andreopoulos2009-mp,
  title    = "A roadmap of clustering algorithms: Finding a match for a
              biomedical application",
  author   = "Andreopoulos, Bill and An, Aijun and Wang, Xiaogang and
              Schroeder, Michael",
  journal  = "Briefings in bioinformatics",
  volume   =  10,
  number   =  3,
  pages    = "297--314",
  year     =  2009,
  keywords = "bioinformatics; clustering; gene expression; interactome;
              network; protein",
  issn     = "1467-5463",
  doi      = "10.1093/bib/bbn058"
}

@INPROCEEDINGS{Talia2002-ms,
  title     = "Parallelism in knowledge discovery techniques",
  booktitle = "International Workshop on Applied Parallel Computing",
  author    = "Talia, Domenico",
  publisher = "Springer",
  pages     = "127--136",
  year      =  2002,
  address   = "Berlin, Germany"
}

@ARTICLE{Groll2014-bj,
  title    = "Variable selection for generalized linear mixed models by {L}
              1-penalized estimation",
  author   = "Groll, Andreas and Tutz, Gerhard",
  journal  = "Statistics and computing",
  number   = "August 2016",
  pages    = "137--154",
  year     =  2014,
  keywords = "generalized linear mixed model; gradient ascent; lasso; linear
              models; penalty",
  issn     = "0960-3174",
  doi      = "10.1007/s11222-012-9359-z"
}

@ARTICLE{Package2016-im,
  title  = "Package ` glmmLasso '",
  author = "Package, Type and Groll, Author Andreas",
  pages  = "14",
  year   =  2016
}

@BOOK{Kuhn2013-sj,
  title    = "Applied Predictive Modeling",
  author   = "Kuhn, Max and Johnson, Kjell",
  abstract = "When modeling discrete classes, the relative frequencies of the
              classes can have a significant impact on the effectiveness of the
              model. An imbalance occurs when one or more classes have very low
              proportions in the training data as compared to the other
              classes. Imbalance can be present in any data set or application,
              and hence, the practitioner should be aware of the implications
              of modeling this type of data. To illustrate the impacts and
              remedies for severe class imbalance, we present a case study
              example (Section 16.1) and the impact of class imbalance on
              performances measures (Section 16.2). Sections 16.3-16.6 describe
              approaches for handling imbalance using the existing data such as
              maximizing minority class accuracy, adjusting classification
              cut-offs or prior probabilities, or adjusting sample weights
              prior to model tuning. Handling imbalance can also be done
              through sophisticated up- or down-sampling methods (Section 16.7)
              or by applying costs to the classification errors (Section 16.8).
              In the Computing Section (16.9) we demonstrate how to implement
              these remedies in R. Finally, exercises are provided at the end
              of the chapter to solidify the concepts.",
  pages    = "1--595",
  year     =  2013,
  isbn     = "9781461468486",
  doi      = "10.1007/978-1-4614-6849-3"
}

@ARTICLE{Wagenmakers2012-gn,
  title    = "An agenda for purely confirmatory research",
  author   = "Wagenmakers, E-J and Wetzels, R and Borsboom, D and van der Maas,
              H L J and Kievit, R a",
  abstract = "The veracity of substantive research claims hinges on the way
              experimental data are collected and analyzed. In this article, we
              discuss an uncomfortable fact that threatens the core of
              psychology's academic enterprise: almost without exception,
              psychologists do not commit themselves to a method of data
              analysis before they see the actual data. It then becomes
              tempting to fine tune the analysis to the data in order to obtain
              a desired result---a procedure that invalidates the
              interpretation of the common statistical tests. The extent of the
              fine tuning varies widely across experiments and experimenters
              but is almost impossible for reviewers and readers to gauge. To
              remedy the situation, we propose that researchers preregister
              their studies and indicate in advance the analyses they intend to
              conduct. Only these analyses deserve the label ``confirmatory,''
              and only for these analyses are the common statistical tests
              valid. Other analyses can be carried out but these should be
              labeled ``exploratory.'' We illustrate our proposal with a
              confirmatory replication attempt of a study on extrasensory
              perception.",
  journal  = "Perspectives on psychological science: a journal of the
              Association for Psychological Science",
  volume   =  7,
  pages    = "627--633",
  year     =  2012,
  keywords = "bayesian hypothesis test; confirmatory experiments; esp; final;
              go all wonky; it makes the stats; results; starting hypothesis in
              your; wonky statistics; you cannot find your",
  issn     = "1745-6916",
  pmid     = "24449647",
  doi      = "10.1177/1745691612463078"
}

@ARTICLE{Calcagno2010-mw,
  title    = "glmulti : An {R} Package for Easy Automated Model Selection with
              ( Generalized ) Linear Models",
  author   = "Calcagno, Vincent and Mazancourt, Claire De",
  abstract = "We introduce glmulti , an R package for automated model selection
              and multi-model inference with glm and related functions. From a
              list of explanatory variables, the pro- vided function glmulti
              builds all possible unique models involving these variables and,
              optionally, their pairwise interactions. Restrictions can be
              speci ed for candidate models, by excluding speci c terms,
              enforcing marginality, or controlling model complexity. Mod- els
              are tted with standard R functions like glm . The n best models
              and their support (e.g., (Q)AIC, (Q)AICc, or BIC) are returned,
              allowing model selection and multi-model inference through
              standard R functions. The package is optimized for large
              candidate sets by avoiding memory limitation, facilitating
              parallelization and providing, in addition to exhaustive
              screening, a compiled genetic algorithm method. This article brie
              y presents the statistical framework and introduces the package,
              with applications to simulated and real data.",
  journal  = "Journal of statistical software",
  volume   =  34,
  number   =  12,
  pages    = "1--29",
  year     =  2010,
  keywords = "aic; bic; genetic algorithm; glm; marginality; rjava; step;
              variable selection",
  issn     = "1548-7660",
  doi      = "10.18637/jss.v034.i12"
}

@ARTICLE{Poulin-Charronnat2006-pe,
  title   = "Processing of musical syntax tonic versus subdominant: An
             event-related potential study",
  author  = "Poulin-Charronnat, B{\'e}n{\'e}dicte and Bigand, E and Koelsch,
             Stefan",
  journal = "Journal of cognitive neuroscience",
  volume  =  18,
  number  =  9,
  pages   = "1545--1554",
  year    =  2006,
  issn    = "0898-929X"
}

@ARTICLE{Muller2013-ar,
  title    = "Model Selection in Linear Mixed Models",
  author   = "M{\"u}ller, Samuel and Scealy, J L and Welsh, A H",
  abstract = "Linear mixed effects models are highly flexible in handling a
              broad range of data types and are therefore widely used in
              applications. A key part in the analysis of data is model
              selection, which often aims to choose a parsimonious model with
              other desirable properties from a possibly very large set of
              candidate statistical models. Over the last 5-10 years the
              literature on model selection in linear mixed models has grown
              extremely rapidly. The problem is much more complicated than in
              linear regression because selection on the covariance structure
              is not straightforward due to computational issues and boundary
              problems arising from positive semidefinite constraints on
              covariance matrices. To obtain a better understanding of the
              available methods, their properties and the relationships between
              them, we review a large body of literature on linear mixed model
              selection. We arrange, implement, discuss and compare model
              selection methods based on four major approaches: information
              criteria such as AIC or BIC, shrinkage methods based on penalized
              loss functions such as LASSO, the Fence procedure and Bayesian
              techniques.",
  journal  = "Statistical science: a review journal of the Institute of
              Mathematical Statistics",
  volume   =  28,
  number   =  2,
  pages    = "135--167",
  year     =  2013,
  keywords = "aic; and phrases; applied statistics; bayes factor; bic; cholesky
              decompo-; fence; information criteria; ingly widely used in; it
              is inter-; lasso; linear mixed model; model; selection; shrinkage
              methods; sition",
  issn     = "0883-4237",
  arxivid  = "1306.2427",
  doi      = "10.1214/12-STS410"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Turney2010-ry,
  title   = "★★★★★From Frequency to Meaning\_ Vector Space Models of
             Semantics（讲的非常好，但是我还只看了三分之一）.pdf",
  author  = "Turney, Peter D and Pantel, Patrick",
  volume  =  37,
  pages   = "141--188",
  year    =  2010,
  issn    = "1076-9757",
  arxivid = "1003.1141v1",
  doi     = "10.1613/jair.2934"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Baroni2010-tr,
  title    = "Nouns are vectors, adjectives are matrices: Representing
              adjective-noun constructions in semantic space",
  author   = "Baroni, Marco and Zamparelli, Roberto",
  abstract = "We propose an approach to adjective-noun composition (AN) for
              corpus-based distributional semantics that, building on insights
              from theoretical linguistics, represents nouns as vectors and
              adjectives as data-induced (linear) functions (encoded as
              matrices) over nominal vectors. Our model significantly
              out-performs the rivals on the task of reconstructing AN vectors
              not seen in training. A small post-hoc analysis further suggests
              that, when the model-generated AN vector is not similar to the
              corpus-observed AN vector, this is due to anomalies in the
              latter. We show more-over that our approach provides two novel
              ways to represent adjective meanings, alternative to its
              representation via corpus-based co-occurrence vectors, both
              outperforming the latter in an adjective clustering task.",
  journal  = "Proceedings of the 2010 Conference on …",
  number   = "October",
  pages    = "1183--1193",
  year     =  2010,
  issn     = "1941-6016",
  doi      = "10.4249/scholarpedia.3881"
}

@MISC{Leman_undated-ks,
  title  = "{IPEM} toolbox manual",
  author = "Leman, Marc and Lesaffre, Micheline and Tanghe, Koen"
}

@INPROCEEDINGS{Yu2017-yx,
  title  = "Towards deep interpretability ({Mus-Rover} {II)}: Learning
            hierarchical representations of tonal music",
  author = "Yu, Haizi",
  pages  = "1--13",
  year   =  2017
}

@INPROCEEDINGS{Chu2017-qn,
  title  = "Song from Pi: A musically plausible network for pop music
            generation",
  author = "Chu, Hang and Urtasun, Raquel and Fidler, Sanja",
  pages  = "1--9",
  year   =  2017
}

@INPROCEEDINGS{Heidl2016-vl,
  title  = "Tuning recurrent neural networks with reinforcement learning",
  author = "Heidl, W and Eitzinger, C and Gyimesi, M and Breitenecker, F and
            Gmbh, Profactor and Gmbh, Profactor",
  pages  = "1722--1728",
  year   =  2016,
  isbn   = "9783901608353"
}

@ARTICLE{Kartsaklis2012-ua,
  title   = "A unified sentence space for categorical
             distributional-compositional semantics: Theory and experiments",
  author  = "Kartsaklis, Dimitri and Sadrzadeh, Mehrnoosh and Pulman, Stephen",
  journal = "Coling-2012",
  number  = "December 2012",
  pages   = "549--558",
  year    =  2012
}

@ARTICLE{Socher2012-qw,
  title    = "Semantic Compositionality through Recursive {Matrix-Vector}
              Spaces",
  author   = "Socher, Richard and Huval, Brody and Manning, Christopher D and
              Ng, Andrew Y",
  abstract = "Single-word vector space models have been very successful at
              learning lexical informa- tion. However, they cannot capture the
              com- positional meaning of longer phrases, prevent- ing them from
              a deeper understanding of lan- guage. We introduce a recursive
              neural net- work (RNN) model that learns compositional vector
              representations for phrases and sen- tences of arbitrary
              syntactic type and length. Our model assigns a vector and a
              matrix to ev- ery node in a parse tree: the vector captures the
              inherent meaning of the constituent, while the matrix captures
              how it changes the mean- ing of neighboring words or phrases.
              This matrix-vector RNN can learn the meaning of operators in
              propositional logic and natural language. The model obtains state
              of the art performance on three different experiments: predicting
              fine-grained sentiment distributions of adverb-adjective pairs;
              classifying senti- ment labels of movie reviews and classifying
              semantic relationships such as cause-effect or topic-message
              between nouns using the syn- tactic path between them.",
  journal  = "Proceedings of the 2012 Joint Conference on Empirical Methods in
              Natural Language Processing and Computational Natural Language
              Learning",
  number   = "Mv",
  pages    = "1201--1211",
  year     =  2012
}

@ARTICLE{Mitchell2010-gb,
  title    = "Composition in distributional models of semantics",
  author   = "Mitchell, Jeff and Lapata, Mirella",
  abstract = "Vector-based models of word meaning have become increasingly
              popular in cognitive science. The appeal of these models lies in
              their ability to represent meaning simply by using distributional
              information under the assumption that words occurring within
              similar contexts are semantically similar. Despite their
              widespread use, vector-based models are typically directed at
              representing words in isolation, and methods for constructing
              representations for phrases or sentences have received little
              attention in the literature. This is in marked contrast to
              experimental evidence (e.g., in sentential priming) suggesting
              that semantic similarity is more complex than simply a relation
              between isolated words. This article proposes a framework for
              representing the meaning of word combinations in vector space.
              Central to our approach is vector composition, which we
              operationalize in terms of additive and multiplicative functions.
              Under this framework, we introduce a wide range of composition
              models that we evaluate empirically on a phrase similarity task.",
  journal  = "Cognitive science",
  volume   =  34,
  number   =  8,
  pages    = "1388--1429",
  year     =  2010,
  keywords = "compositionality; connectionism; distributional models; meaning
              representations; phrase similarity; semantic spaces",
  issn     = "0364-0213, 1551-6709",
  pmid     = "21564253",
  doi      = "10.1111/j.1551-6709.2010.01106.x"
}

@ARTICLE{Coecke2011-sw,
  title    = "Mathematical Foundations for a Compositional Distributional Model
              of Meaning",
  author   = "Coecke, Bob and Sadrzadeh, Mehrnoosh and Clark, Stephen",
  abstract = "We propose a mathematical framework for a unification of the
              distributional theory of meaning in terms of vector space models,
              and a compositional theory for grammatical types, for which we
              rely on the algebra of Pregroups, introduced by Lambek. This
              mathematical framework enables us to compute the meaning of a
              well-typed sentence from the meanings of its constituents.
              Concretely, the type reductions of Pregroups are `lifted' to
              morphisms in a category, a procedure that transforms meanings of
              constituents into a meaning of the (well-typed) whole.
              Importantly, meanings of whole sentences live in a single space,
              independent of the grammatical structure of the sentence. Hence
              the inner-product can be used to compare meanings of arbitrary
              sentences, as it is for comparing the meanings of words in the
              distributional model. The mathematical structure we employ admits
              a purely diagrammatic calculus which exposes howthe information
              flows between the words in a sentence in order to make up the
              meaning of the whole sentence. A variation of our `categorical
              model' which involves constraining the scalars of the vector
              spaces to the semiring of Booleans results in a Montague-style
              Boolean-valued semantics.",
  journal  = "Linguistic Analysis",
  volume   =  36,
  number   = "1-4",
  pages    = "345--384",
  year     =  2011,
  pmid     = "4849484414950127770",
  arxivid  = "1003.4394v1"
}

@ARTICLE{Leman2001-vf,
  title   = "Toolbox for perception-based music analysis. Concepts, demos and
             reference manual",
  author  = "Leman, M and Leasaffre, M and Tanghe, K",
  journal = "Institute for Psychoacoustics and Electronic Music (IPEM), Ghent
             University, Blandijnberg",
  volume  =  2,
  pages   = "9000",
  year    =  2001
}

@INPROCEEDINGS{Leman2001-pm,
  title     = "Introduction to the {IPEM} Toolbox for Perception-based Music
               Analysis",
  booktitle = "Conference Program and Abstracts of {SMPC} 2001 Kingston",
  author    = "Leman, Marc and Lesaffre, Micheline and Tanghe, Koen",
  abstract  = "The motivation for developing a toolbox for perception-based
               music analysis starts from the observation that much of the
               world music production (seen over different cultures and time
               periods) has no score representation, and that if a score
               representation is available, it still represents but a small
               percentage of what musical communication really is about. A
               sonological analysis of musical sounds may provide steps towards
               a better understanding of the components that contribute to
               musical information processing but is also insufficient in view
               of how humans deal with musical signals. Technology has
               revolutionized our conception of what kind of music research
               will be possible in the 21st Century. But it is the task of
               musicologists, in collaboration with other scientists, such as
               engineers, psychologists, and brain scientists, to make these
               dreams more concrete. Our basic motivation for developing this
               toolbox is a pragmatic one: if the musicology aims at
               understanding music as a social and cultural phenomenon embedded
               in the physical world and mediated through human faculties of
               perception, cognition, and processing of expressive
               communication, then new tools must be developed that allow a
               fully integrated approach. This paper introduces the main
               concepts and a state-of-the-art of the modules of the IPEM
               toolbox for perception-based music analysis. This toolbox
               represents a bottom-up approach to musical description taking
               human perception as the basis for musical feature extraction and
               higher-level conceptualization and representation. The IPEM
               toolbox provides a collection of MATLAB functions that allow
               dealing with different aspects of feature extraction as well as
               a global concept concerning perception-based music analysis.
               First we present the global internal representation framework.
               Then we sketch what we have in mind as a global picture and
               present the modules currently involved. Finally we describe some
               applications of the toolbox.",
  year      =  2001
}

@ARTICLE{Poulin-Charronnat2005-mc,
  title    = "Musical structure modulates semantic priming in vocal music",
  author   = "Poulin-Charronnat, B{\'e}n{\'e}dicte and Bigand, E and Madurell,
              Fran{\c c}ois and Peereman, Ronald",
  abstract = "It has been shown that harmonic structure may influence the
              processing of phonemes whatever the extent of participants'
              musical expertise [Bigand, E., Tillmann, B., Poulin, B., D'Adamo,
              D. A., \& Madurell, F. (2001). The effect of harmonic context on
              phoneme monitoring in vocal music. Cognition, 81, B11-B20]. The
              present study goes a step further by investigating how musical
              harmony may potentially interfere with the processing of words in
              vocal music. Eight-chord sung sentences were presented, their
              last word being either semantically related (La girafe a un tr??s
              grand cou, The giraffe has a very long neck) or unrelated to the
              previous linguistic context (La girafe a un tr??s grand pied, The
              giraffe has a very long foot). The target word was sung on a
              chord that acted either as a referential tonic chord or as a
              congruent but less referential subdominant chord. Participants
              performed a lexical decision task on the target word. A
              significant interaction was observed between semantic and
              harmonic relatedness suggesting that music modulates semantic
              priming in vocal music. Following Jones' dynamic attention
              theory, we argue that music can modulate semantic priming in
              vocal music, by modifying the allocation of attentional resource
              necessary for linguistic computation. ?? 2004 Elsevier B.V. All
              rights reserved.",
  journal  = "Cognition",
  volume   =  94,
  number   =  3,
  pages    = "B67--B78",
  year     =  2005,
  keywords = "Modularity; Musical expertise; Semantic and musical priming;
              Vocal music",
  issn     = "0010-0277",
  pmid     = "15617668",
  doi      = "10.1016/j.cognition.2004.05.003"
}

@ARTICLE{Poulin-Charronnat2005-qm,
  title   = "The influence of voice leading on harmonic priming",
  author  = "Poulin-Charronnat, B{\'e}n{\'e}dicte and Bigand, E and Madurell, F",
  journal = "Music perception",
  volume  =  22,
  number  =  4,
  pages   = "613--627",
  year    =  2005,
  issn    = "0730-7829, 0008-1256"
}

@MISC{Tillmann1998-ud,
  title    = "Effects of global and local contexts on harmonic expectancy",
  author   = "Tillmann, Barbara and Bigand, E and Pineau, Marion",
  abstract = "Several psycholinguistic studies have investigated the influence
              of local and global semantic contexts on word processing. The
              first aim of the present study was to examine local and global
              level contributions to harmonic priming. The second was to test a
              spreading-activation account of harmonic context effects
              (Bharucha, 1987). The expectations for the last chord (the
              target) of eight-chord sequences were varied by simultaneously
              manipulating the harmonic relationship of the target to the first
              six chords (global context) and to the seventh chord (local
              context). Human performances demonstrated that harmonic
              expectancies are derived from both the global and local levels of
              musical structure. Bharucha's connectionist model provides a
              possible account of local and global context effects. In
              isochronous chord sequences, harmonic priming seems to result
              from activation spreading via a schematic knowledge of tonal
              hierarchies.",
  journal  = "Music Perception",
  volume   =  16,
  number   =  1,
  pages    = "99--117",
  year     =  1998,
  issn     = "0730-7829",
  doi      = "10.2307/40285780"
}

@ARTICLE{Tillmann2005-fi,
  title    = "Implicit investigations of tonal knowledge in nonmusician
              listeners",
  author   = "Tillmann, Barbara",
  abstract = "By mere exposure to musical pieces in everyday life, Western
              listeners acquire sensitivity to the regularities of the tonal
              system and to the context dependency of musical sounds. This
              implicitly acquired tonal knowledge allows nonmusician listeners
              to perceive relationships among musical events and to develop
              expectations for future events that then influence the processing
              of these events. The musical priming paradigm is one method of
              the indirect investigation of listeners' tonal knowledge. It
              investigates the influence of a preceding context (with its
              musical structures and relationships) on the processing of a
              musical target event, without asking participants for direct
              evaluations. Behavioral priming data have provided evidence for
              facilitated processing of musically related events in comparison
              to unrelated and less-related events. The sensitivity of implicit
              investigations is further shown by I.R., a patient with severe
              amusia, showing spared implicit knowledge of music. Finally, the
              priming paradigm allows us to investigate the neural correlates
              of musical structure processing. Two fMRI studies reported the
              implication of inferior frontal regions in musical priming,
              contrasting related and unrelated events, as well as finer
              structural manipulations contrasting in-key events.",
  journal  = "Annals of the New York Academy of Sciences",
  volume   =  1060,
  pages    = "100--110",
  year     =  2005,
  issn     = "0077-8923",
  pmid     = "16597757",
  doi      = "10.1196/annals.1360.007"
}

@ARTICLE{Tekman1998-hb,
  title    = "Implicit knowledge versus psychoacoustic similarity in priming of
              chords",
  author   = "Tekman, Hasan G{\"u}rkan and Bharucha, Jamshed J",
  abstract = "A chord-priming paradigm was used to test predictions of a neural
              net model (MUSACT). The model makes a nonintuitive prediction:
              Following a prime chord, expectations for the target chord are
              based on psychoacoustic similarity at short stimulus onset
              asynchronies (SOAs) but on implicit knowledge of conventional
              relationships at longer SOAs. In a critical test, 2 targets were
              selected for each prime. One was more psychoacoustically similar
              to the prime, and the other was more closely related on the basis
              of convention. With an SOA of 50 ms, priming favored the
              psychoacoustically similar target; with SOAs of 500 ms and
              longer, the effect reversed, and priming favored conventional
              relatedness. The results underscore the limitations of models of
              harmony based on psychoacoustic factors alone. These studies
              demonstrate how neural net learning models that are appropriately
              constrained can be subject to strong empirical verification.
              (PsycINFO Database Record (c) 2012 APA, all rights reserved).
              (journal abstract)",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  24,
  number   =  1,
  pages    = "252--260",
  year     =  1998,
  issn     = "0096-1523",
  pmid     = "3615146",
  doi      = "10.1037/0096-1523.24.1.252"
}

@ARTICLE{Bigand2005-uf,
  title   = "Repetition priming: Is music special?",
  author  = "Bigand, E and Tillmann, B and Poulin-Charronnat, B and Manderlier,
             D",
  journal = "The Quarterly Journal of Experimental Psychology Section A",
  volume  =  58,
  number  =  8,
  pages   = "1347--1375",
  year    =  2005,
  issn    = "0272-4987",
  doi     = "10.1080/02724980443000601"
}

@ARTICLE{Bigand1997-hg,
  title    = "Global context effects on musical expectancy",
  author   = "Bigand, E and Pineau, Marion",
  abstract = "The effects of global harmonic contexts on expectancy formation
              were studied in a set of three experiments. Eight-chord sequences
              were presented to subjects. Expectations for the last chord were
              varied by manipulating the harmonic context created by the first
              six: in one context, the last chord was part of an authentic
              cadence (V-I), whereas in the other, it was a fourth harmonic
              degree following a full cadence (I-IV). Given this change in
              harmonic function, the last chord was assumed to be more expected
              in the former context, all the other local parameters being held
              constant. The effect of global context on expectancy formation
              was supported by the fact that subjects reported a lower degree
              of completion for sequences ending on an unexpected chord
              (Experiment 1), took longer to decide whether the last chord
              belonged to the sequence when the last chord was unexpected
              (Experiment 2), and took longer to decide whether the last chord
              was consonant or dissonant when it was unexpected (Experiment 3).
              These results are discussed with reference to current models of
              tonal cognition.",
  journal  = "Perception \& psychophysics",
  volume   =  59,
  number   =  7,
  pages    = "1098--1107",
  year     =  1997,
  issn     = "0031-5117",
  pmid     = "9360482",
  doi      = "10.3758/BF03205524"
}

@ARTICLE{Lathrop2016-vm,
  title    = "Item cloning variation and the impact on the parameters of
              response models",
  author   = "Lathrop, Quinn N and Cheng, Ying",
  journal  = "Psychometrika",
  volume   =  82,
  number   =  1,
  pages    = "245--263",
  year     =  2016,
  keywords = "MCMC; analyze this type of; can be used to; computer technology
              is increasingly; data and provides a; examinees responding to
              items; explanatory IRT; explanatory irt; inferences about both
              the; irt; item cloning; item response; item response theory;
              mcmc; multilevel IRT; multilevel irt; persons and the items;
              powerful framework to make; psychological data are often; theory;
              times the result of; used to",
  issn     = "0033-3123",
  doi      = "10.1007/s11336-016-9513-1"
}

@ARTICLE{Toiviainen2003-ys,
  title    = "Measuring and modeling real-time responses to music: The dynamics
              of tonality induction",
  author   = "Toiviainen, Petri and Krumhansl, Carol L",
  abstract = "We examined a variety of real-time responses evoked by a single
              piece of music, the organ Duetto BWV 805 by J S Bach. The primary
              data came from a concurrent probe-tone method in which the probe
              tone is sounded continuously with the music. Listeners judged how
              well the probe tone fit with the music at each point in time. The
              process was repeated for all probe tones of the chromatic scale.
              A self-organizing map (SOM) [Kohonen 1997 Self-organizing Maps
              (Berlin: Springer)] was used to represent the developing and
              changing sense of key reflected in these judgments. The SOM was
              trained on the probe-tone profiles for 24 major and minor keys
              (Krumhansl and Kessler 1982 Psychological Review 89 334-368).
              Projecting the concurrent probe-tone data onto the map showed
              changes both in the perceived keys and in their strengths. Two
              dynamic models of tonality induction were tested. Model 1 is
              based on pitch class distributions. Model 2 is based on the
              tone-transition distributions; it tested the idea that the order
              of tones might provide additional information about tonality.
              Both models contained dynamic components for characterizing pitch
              strength and creating pitch memory representations. Both models
              produced results closely matching those of the concurrent
              probe-tone data. Finally real-time judgments of tension were
              measured. Tension correlated with distance away from the
              predominant key in the direction of keys built on the dominant
              and supertonic tones, and also correlated with dissonance.",
  journal  = "Perception",
  volume   =  32,
  number   =  6,
  pages    = "741--766",
  year     =  2003,
  issn     = "0301-0066",
  pmid     = "12892434",
  doi      = "10.1068/p3312"
}

@ARTICLE{Bigand2003-hr,
  title   = "Sensory versus cognitive components in harmonic priming",
  author  = "Bigand, E and Poulin, B{\'e}n{\'e}dicte and Tillmann, Barbara and
             Madurell, F and Adamo, Daniel A D",
  journal = "Journal of experimental psychology. Human perception and
             performance",
  volume  =  29,
  number  =  1,
  pages   = "159--171",
  year    =  2003,
  issn    = "0096-1523",
  doi     = "10.1037/0096-1523.29.1.159"
}

@ARTICLE{Sigtia2016-nv,
  title   = "An end-to-end neural network for polyphonic music transcription",
  author  = "Sigtia, S and Benetos, E and Dixon, S",
  journal = "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
  volume  =  24,
  number  =  5,
  pages   = "927--939",
  year    =  2016
}

@ARTICLE{Raczynski2013-fz,
  title   = "Dynamic Bayesian networks for symbolic polyhonic pitch modeling",
  author  = "Raczy{\'n}ski, Stanis{\l}aw A and Vincent, Emmanuel and Sagayama,
             Shigeki",
  journal = "IEEE transactions on audio, speech, and language processing",
  volume  =  21,
  number  =  9,
  pages   = "1830--1840",
  year    =  2013,
  issn    = "1558-7916",
  doi     = "10.1109/TASL.2013.2258012"
}

@ARTICLE{Walder2016-ro,
  title    = "Modelling symbolic music: Beyond the piano roll",
  author   = "Walder, Christian",
  abstract = "In this paper, we consider the problem of probabilistically
              modelling symbolic music data. We introduce a representation
              which reduces polyphonic music to a univariate categorical
              sequence. In this way, we are able to apply state of the art
              natural language processing techniques, namely the long
              short-term memory sequence model. The representation we employ
              permits arbitrary rhythmic structure, which we assume to be
              given. We show that our model is effective on four out of four
              piano roll based benchmark datasets. We further improve our model
              by augmenting our training data set with transpositions of the
              original pieces through all musical keys, thereby convincingly
              advancing the state of the art on these benchmark problems. We
              also fit models to music which is unconstrained in its rhythmic
              structure, discuss the properties of this model, and provide
              musical samples which are more sophisticated than previously
              possible with this class of recurrent neural network sequence
              models. We also provide our newly preprocessed data set of non
              piano-roll music data.",
  journal  = "arXiv preprint arXiv:1606.01368",
  year     =  2016,
  keywords = "neural networks;polyphony",
  arxivid  = "1606.01368"
}

@INPROCEEDINGS{Boulanger-Lewandowski2012-eb,
  title     = "Modeling temporal dependencies in high-dimensional sequences:
               Application to polyphonic music generation and transcription",
  booktitle = "Proceedings of the 29th International Conference on Machine
               Learning ({ICML-12})",
  author    = "Boulanger-Lewandowski, Nicolas and Vincent, Pascal and Bengio,
               Yoshua",
  abstract  = "We investigate the problem of modeling symbolic sequences of
               polyphonic music in a completely general piano-roll
               representation. We introduce a probabilistic model based on
               distribution estimators conditioned on a recurrent neural
               network that is able to discover temporal dependencies in
               high-dimensional sequences. Our approach outperforms many
               traditional models of polyphonic music on a variety of realistic
               datasets. We show how our musical language model can serve as a
               symbolic prior to improve the accuracy of polyphonic
               transcription.",
  year      =  2012,
  address   = "Edinburgh, Scotland",
  keywords  = "music transcription;neural networks;polyphony",
  isbn      = "9781450312851"
}

@BOOK{Gordon1967-gx,
  title     = "A three-year longitudinal predictive validity study of the
               Musical Aptitude Profile",
  author    = "Gordon, Edwin E",
  publisher = "University of Iowa Press",
  year      =  1967,
  address   = "Iowa City, IA"
}

@ARTICLE{Gembris1997-gt,
  title   = "Historical phases in the definition of musicality",
  author  = "Gembris, H",
  journal = "Psychomusicology",
  volume  =  16,
  number  = "1-2",
  pages   = "17--25",
  year    =  1997
}

@BOOK{Van_der_Linden2000-wk,
  title     = "Computerized adaptive testing: Theory and practice",
  editor    = "van der Linden, Wim J and Glas, Gees A W",
  publisher = "Kluwer Academic",
  year      =  2000,
  address   = "Dordrecht, Netherlands"
}

@ARTICLE{Stanton1928-cp,
  title   = "Seashore measures of musical talent",
  author  = "Stanton, Hazel M",
  journal = "Psychological monographs",
  volume  =  39,
  number  =  2,
  pages   = "135--144",
  year    =  1928,
  issn    = "0096-9753"
}

@ARTICLE{Thompson1997-eu,
  title    = "Perceptual judgments of triads and dyads: Assessment of a
              psychoacoustic model",
  author   = "Thompson, William Forde and Parncutt, Richard",
  journal  = "Music perception",
  volume   =  14,
  number   =  3,
  pages    = "263--280",
  year     =  1997,
  keywords = "goodness of fit ratings octave-complex tones shepa",
  issn     = "0730-7829"
}

@ARTICLE{Sapp2007-vv,
  title    = "Computational chord-root identification in symbolic musical data:
              Rationale, methods, and applications",
  author   = "Sapp, C",
  abstract = "My aim here is to present a basic methodology for identifying the
              roots of in score data encoded in the Humdrum kern format. The
              overall process starts with an initial of the root based on lim-
              ited information from pitch alone, then refines the",
  journal  = "Computing in musicology",
  volume   =  15,
  pages    = "99--119",
  year     =  2007
}

@PHDTHESIS{Sears2016-fr,
  title  = "The Classical cadence as a closing schema: Learning, memory, \&
            perception",
  author = "Sears, David",
  year   =  2016,
  school = "McGill University, Montreal, Canada"
}

@ARTICLE{Paiement2009-yr,
  title   = "Probabilistic models for melodic prediction",
  author  = "Paiement, Jean-Fran{\c c}ois and Bengio, Samy and Eck, Douglas",
  journal = "Artificial intelligence",
  volume  =  173,
  number  =  14,
  pages   = "1266--1274",
  year    =  2009,
  issn    = "0004-3702",
  doi     = "10.1016/j.artint.2009.06.001"
}

@ARTICLE{Parncutt2000-zk,
  title   = "Tone profiles following short chord progressions: Top-down or
             bottom-up?",
  author  = "Parncutt, Richard and Bregman, A S",
  journal = "Music perception",
  volume  =  18,
  number  =  1,
  pages   = "25--57",
  year    =  2000,
  issn    = "0730-7829"
}

@ARTICLE{Parncutt1988-lo,
  title   = "Revision of Terhardt's psychoacoustical model of the root(s) of a
             musical chord",
  author  = "Parncutt, Richard",
  journal = "Music perception",
  volume  =  6,
  number  =  1,
  pages   = "65--93",
  year    =  1988,
  issn    = "0730-7829",
  doi     = "10.2307/40285416"
}

@ARTICLE{Maccallum2008-ox,
  title  = "{Real-Time} Analysis of Sensory Dissonance",
  author = "Maccallum, John and Einbond, Aaron",
  pages  = "203--211",
  year   =  2008
}

@ARTICLE{Cook2004-vo,
  title  = "A Psychophysical Model of Harmony Perception",
  author = "Cook, Norman D and Fujisawa, Takashi and Takami, Kazuaki",
  pages  = "493--496",
  year   =  2004
}

@ARTICLE{Bigand1999-pa,
  title   = "Perceiving musical tension in long chord sequences",
  author  = "Bigand, E and Parncutt, Richard",
  journal = "Psychological research",
  volume  =  62,
  pages   = "237--254",
  year    =  1999,
  issn    = "0340-0727"
}

@ARTICLE{Cook2006-iq,
  title    = "The psychophysics of harmony perception: Harmony is a three-tone
              phenomenon",
  author   = "Cook, Norman D and Fujisawa, Takashi",
  journal  = "Empirical musicology review: EMR",
  volume   =  1,
  number   =  2,
  pages    = "106--126",
  year     =  2006,
  keywords = "1877; and the widespread use; at least to helmholtz; create and
              measure musical; dissonance; harmony; honorable history going
              back; intervals and the influence; major mode; minor mode; of
              electronic techniques to; of music has an; of upper partials on;
              particularly since the 1960s; psychophysics; t he psychophysical
              study; tension; the; the perception of two-tone; tones with great
              precision"
}

@ARTICLE{Farbood2012-uj,
  title    = "A parametric, temporal model of musical tension",
  author   = "Farbood, Morwaread M",
  journal  = "Music perception",
  volume   =  29,
  number   =  4,
  pages    = "387--428",
  year     =  2012,
  keywords = "change perception; he aggregate experience of; listening to
              music; many disparate auditory; musical tension; requires the
              integration of; temporal dynamics; trend salience; web study",
  issn     = "0730-7829"
}

@ARTICLE{Snijders2001-gn,
  title    = "Asymptotic null distribution of person fit statistics with
              estimated person parameter",
  author   = "Snijders, Tom A B",
  abstract = "Abstract Person fit statistics are considered for dichotomous
              item response models. The asymptotic null distribution is derived
              for statistics which are linear in the item responses, and in
              which the ability parameter is replaced by an estimate. This
              allows the asymptotically correct standardization of linear
              person fit statistics with estimated ability parameter. The fact
              that the ability parameter is estimated usually decreases the
              asymptotic variance.",
  journal  = "Psychometrika",
  volume   =  66,
  number   =  3,
  pages    = "331--342",
  year     =  2001,
  keywords = "asymptotic approximations; item response theory; person fit",
  issn     = "0033-3123",
  doi      = "10.1007/BF02294437"
}

@ARTICLE{Yen1981-dr,
  title    = "Using simulation results to choose a latent trait model",
  author   = "Yen, W M",
  abstract = "A latent trait model goodness-of-fit statistic was defined, and
              its relationships to several other com monly used fit statistics
              were described. Simulation data were used to examine the behavior
              of these fit statistics under conditions similar to those found
              with real data. The simulation data were generated for 36
              pseudo-items and 1,000 simulees using three-, two-, and
              one-parameter logistic latent trait models. The data were
              analyzed using three-, two-, and one-parameter models.
              Between-model comparisons were made of the fit statistics, trait
              es timates, and item parameter estimates. The three generating
              models produced clearly different pat terns of results. The
              simulation results were com pared to results for real data
              involving seventh- and eighth-grade students' performance on
              eight achievement tests. The achievement test results ap peared
              most similar to the simulation results based on data generated
              with the three-parameter model. Some practical problems that can
              result from using an inappropriate model with multiple-choice
              tests are discussed.",
  journal  = "Applied psychological measurement",
  volume   =  5,
  number   =  2,
  pages    = "245--262",
  year     =  1981,
  issn     = "0146-6216",
  doi      = "10.1177/014662168100500212"
}

@ARTICLE{Kaliakatsos-Papakostas2016-bw,
  title    = "Learning and creating novel harmonies in diverse musical idioms:
              An adaptive modular melodic harmonisation system",
  author   = "Kaliakatsos-Papakostas, Maximos and Makris, Dimos and Tsougras,
              Costas and Cambouropoulos, Emilios",
  journal  = "Journal of Creative Music Systems",
  volume   =  1,
  number   =  1,
  year     =  2016,
  keywords = "computational creativity; harmonic learning; melodic
              harmonisation"
}

@ARTICLE{Warm1989-ti,
  title   = "Weighted likelihood estimation of ability in item response theory",
  author  = "Warm, T A",
  journal = "Psychometrika",
  volume  =  54,
  number  =  3,
  pages   = "427--450",
  year    =  1989,
  issn    = "0033-3123"
}

@ARTICLE{Ghahramani1997-mu,
  title    = "Factorial hidden Markov models",
  author   = "Ghahramani, Zoubin and Jordan, Michael I",
  abstract = "Hidden Markov models (HMMs) have proven to be one of the most
              widely used tools for learning probabilistic models of time
              series data. In an HMM, information about the past is conveyed
              through a single discrete variable---the hidden state. We discuss
              a generalization of HMMs in which this state is factored into
              multiple state variables and is therefore represented in a
              distributed manner. We describe an exact algorithm for inferring
              the posterior probabilities of the hidden state variables given
              the observations, and relate it to the forward--backward
              algorithm for HMMs and to algorithms for more general graphical
              models. Due to the combinatorial nature of the hidden state
              representation, this exact algorithm is intractable. As in other
              intractable systems, approximate inference can be carried out
              using Gibbs sampling or variational methods. Within the
              variational framework, we present a structured approximation in
              which the the state variables are decoupled, yielding a tractable
              algorithm for learning the parameters of the model. Empirical
              comparisons suggest that these approximations are efficient and
              provide accurate alternatives to the exact methods. Finally, we
              use the structured approximation to model Bach's chorales and
              show that factorial HMMs can capture statistical structure in
              this data set which an unconstrained HMM cannot.",
  journal  = "Machine learning",
  volume   =  29,
  pages    = "245--273",
  year     =  1997,
  keywords = "bayesian networks; em algorithm; graphical models; hidden markov
              models; mean field; time series",
  issn     = "0885-6125",
  pmid     = "505",
  doi      = "10.1023/A:1007425814087"
}

@ARTICLE{Zioga2016-rg,
  title     = "Musical training shapes neural responses to melodic and prosodic
               expectation",
  author    = "Zioga, Ioanna and Di Bernardi Luft, Caroline and Bhattacharya,
               Joydeep",
  journal   = "Brain research",
  publisher = "Elsevier",
  volume    =  1650,
  pages     = "267--282",
  year      =  2016,
  keywords  = "EEG; Expectation; Language; Musical training; Prosody",
  issn      = "0006-8993",
  doi       = "10.1016/j.brainres.2016.09.015"
}

@ARTICLE{Loyd1980-ln,
  title    = "Vertical equating using the Rasch model",
  author   = "Loyd, Brenda H and Hoover, H D",
  journal  = "Journal of Educational Measurement",
  volume   =  17,
  number   =  3,
  pages    = "179--193",
  month    =  sep,
  year     =  1980,
  keywords = "mean-mean equating",
  issn     = "0022-0655",
  doi      = "10.1111/j.1745-3984.1980.tb00825.x"
}

@ARTICLE{Magis2012-ww,
  title    = "A Didactic Presentation of Snijders's lz* Index of Person Fit
              With Emphasis on Response Model Selection and Ability Estimation",
  author   = "Magis, D and Raiche, G and Beland, S",
  abstract = "This paper focuses on two likelihood-based indices of person fit,
              the index lz and the Snijders's modified index l z*. The first
              one is commonly used in practical assessment of person fit,
              although its asymptotic standard normal distribution is not valid
              when true abilities are replaced by sample ability estimates. The
              l z* index is a generalization of l z, which corrects for this
              sampling variability. Surprisingly, it is not yet popular in the
              psychometric and educational assessment community. Moreover,
              there is some ambiguity about which type of item response model
              and ability estimation method can be used to compute the l z*
              index. The purpose of this article is to present the index l z*
              in a simple and didactic approach. Starting from the relationship
              between l z and l z*, we develop the framework according to the
              type of logistic item response theory (IRT) model and the
              likelihood-based estimators of ability. The practical calculation
              of l z* is illustrated by analyzing a real data set about
              language skill assessment. \copyright{} American Educational
              Research Association 2012.",
  journal  = "Journal of educational and behavioral statistics: a quarterly
              publication sponsored by the American Educational Research
              Association and the American Statistical Association",
  volume   =  37,
  number   =  1,
  pages    = "57--81",
  year     =  2012,
  issn     = "1076-9986",
  doi      = "10.3102/1076998610396894"
}

@ARTICLE{Tendeiro2015-nb,
  title  = "Package ` {PerFit} '",
  author = "Tendeiro, Maintainer Jorge N",
  year   =  2015
}

@ARTICLE{Drasgow1985-gc,
  title    = "Appropriateness measurement with polychotomous item response
              models and standardized indices",
  author   = "Drasgow, F and Levine, M V and Williams, E a",
  abstract = "Reports research that extends appropriateness measurement methods
              to examinees with moderately high nonresponse rates. These
              methods treat nonresponse as if it were a deliberate option
              choice and then attempt to measure the appropriateness of the
              pattern of option choices. Earlier studies used only the
              dichotomous pattern of ``right'' and ``not right'' answers. A
              general polychotomous model is introduced along with a technique
              called standardization, which is designed to reduce the observed
              confounding between measured appropriateness and ability. (17
              ref) ((c) 1997 APA/PsycINFO, all rights reserved)",
  journal  = "The British journal of mathematical and statistical psychology",
  volume   =  38,
  number   =  1,
  pages    = "67--86",
  year     =  1985,
  keywords = "*Item Response Theory; *Multiple Choice Testing Method; Human;
              extension of appropriateness measurement methods t",
  issn     = "0007-1102",
  doi      = "10.1111/j.2044-8317.1985.tb00817.x"
}

@ARTICLE{Egberink2010-vv,
  title    = "Detection of aberrant item score patterns in computerized
              adaptive testing: An empirical example using the {CUSUM}",
  author   = "Egberink, Iris J L and Meijer, Rob R and Veldkamp, Bernard P and
              Schakel, Lolle and Smid, Nico G",
  abstract = "The scalability of individual trait scores on a computerized
              adaptive test (CAT) was assessed through investigating the
              consistency of individual item score patterns. A sample of N=428
              persons completed a personality CAT as part of a career
              development procedure. To detect inconsistent item score
              patterns, we used a cumulative sum (CUSUM) procedure. Combined
              information from the CUSUM, other personality measures, and
              interviews showed that similar estimated trait values may have a
              different interpretation. Implications for computer-based
              assessment are discussed. ?? 2010 Elsevier Ltd.",
  journal  = "Personality and individual differences",
  volume   =  48,
  number   =  8,
  pages    = "921--925",
  year     =  2010,
  keywords = "Computerized adaptive testing; Person fit; Personality assessment",
  issn     = "0191-8869",
  doi      = "10.1016/j.paid.2010.02.023"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Van_Krimpen-Stoop2001-je,
  title    = "{CUSUM-Based} {Person-Fit} Statistics for Adaptive Testing",
  author   = "van Krimpen-Stoop, Edith M and Meijer, Rob R",
  abstract = "Item scores that do not fit an assumed item response theory model
              may cause the latent trait value to be inaccurately estimated.
              Several person-fit statistics for detecting nonfitting score
              patterns for paper-and-pencil tests have been proposed. In the
              context of computerized adaptive tests (CAT), the use of
              person-fit analysis has hardly been explored. Because it has been
              shown that the distribution of existing person-fit statistics is
              not applicable in a CAT, in this study new person-fit statistics
              are proposed and critical values for these statistics are derived
              from existing statistical theory. Statistics are proposed that
              are sensitive to runs of correct or incorrect item scores and are
              based on all items administered in a CAT or based on subsets of
              items, using observed and expected item scores and using
              cumulative sum (CUSUM) procedures. The theoretical and empirical
              distributions of the statistics are compared and detection rates
              are investigated. Results showed that the nominal and empirical
              Type I error rates were comparable for CUSUM procedures when the
              number of items in each subset and the number of measurement
              points were not too small. Detection rates of CUSUM procedures
              were superior to other fit statis­tics. Applications of the
              statistics are discussed.",
  journal  = "Journal of educational and behavioral statistics: a quarterly
              publication sponsored by the American Educational Research
              Association and the American Statistical Association",
  volume   =  26,
  number   =  2,
  pages    = "199--218",
  year     =  2001,
  keywords = "appropriateness measurement • computer adaptive te",
  issn     = "1076-9986",
  doi      = "10.3102/10769986026002199"
}

@ARTICLE{Armstrong2016-fs,
  title  = "{Model-Free} {CUSUM} Methods for Person Fit Author ( s ): Ronald
            {D} . Armstrong and Min Shi Source : Journal of Educational
            Measurement , Vol . 46 , No . 4 ( Winter 2009 ), pp . 408-428
            Published by : National Council on Measurement in Education Stable
            {URL} : h",
  author = "Armstrong, Ronald D and Shi, Min",
  volume =  46,
  number =  4,
  pages  = "408--428",
  year   =  2016
}

@ARTICLE{Tendeiro2012-dt,
  title    = "A {CUSUM} to Detect Person Misfit: A Discussion and Some
              Alternatives for Existing Procedures",
  author   = "Tendeiro, J N and Meijer, R R",
  abstract = "This article extends the work by Armstrong and Shi on CUmulative
              SUM (CUSUM) person-fit methodology. The authors present new
              theoretical considerations concerning the use of CUSUM person-fit
              statistics based on likelihood ratios for the purpose of
              detecting cheating and random guessing by individual test takers.
              According to the Neyman--Pearson Lemma, the optimality of such
              statistics relies on how accurately normal and aberrant behaviors
              are modeled. General and specific models for cheating and random
              guessing are investigated. The detection rates of several
              statistics are compared using simulated data. Results showed that
              the likelihood-based CUSUM statistics that use the proposed
              models for aberrant behavior performed better than some of the
              more commonly used statistics, especially for cheating behavior.",
  journal  = "Applied psychological measurement",
  volume   =  36,
  number   =  5,
  pages    = "420--442",
  year     =  2012,
  keywords = "aberrant behavior detection; achievement test-; cheating;
              cumulative sum; important in education and; item response theory
              model; likelihood; random guessing; ratio; test score validity
              is; the evaluation of individual",
  issn     = "0146-6216",
  doi      = "10.1177/0146621612446305"
}

@ARTICLE{Chalmers2015-ke,
  title  = "Multidimensional Item Response Theory Workshop in {R} ( Day 2 )",
  author = "Chalmers, Phil",
  number = "Day 2",
  year   =  2015
}

@ARTICLE{Chalmers2015-os,
  title  = "Multidimensional Item Response Theory Workshop in {R}",
  author = "Chalmers, Phil",
  year   =  2015
}

@MISC{Mullensiefen_undated-bc,
  title  = "How we become musically sophisticated: A gap in the literature and
            a new research perspective",
  author = "M{\"u}llensiefen, Daniel"
}

@ARTICLE{Leman2000-pq,
  title   = "An auditory model of the role of short-term memory in probe-tone
             ratings",
  author  = "Leman, Marc",
  journal = "Music perception",
  volume  =  17,
  number  =  4,
  pages   = "481--509",
  year    =  2000,
  issn    = "0730-7829"
}

@INPROCEEDINGS{Pearce2016-pv,
  title     = "Which perceptual properties of music drive genuine aesthetic
               musical experiences ?",
  booktitle = "{IAEA}",
  author    = "Pearce, Marcus T",
  year      =  2016
}

@ARTICLE{Koelsch2016-dc,
  title    = "Under the hood of statistical learning: A statistical {MMN}
              reflects the magnitude of transitional probabilities in auditory
              sequences",
  author   = "Koelsch, Stefan and Busch, Tobias and Jentschke, Sebastian and
              Rohrmeier, Martin",
  abstract = "Within the framework of statistical learning, many behavioural
              studies investigated the processing of unpredicted events.
              However, surprisingly few neurophysiological studies are
              available on this topic, and no statistical learning experiment
              has investigated electroencephalographic (EEG) correlates of
              processing events with different transition probabilities. We
              carried out an EEG study with a novel variant of the established
              statistical learning paradigm. Timbres were presented in
              isochronous sequences of triplets. The first two sounds of all
              triplets were equiprobable, while the third sound occurred with
              either low (10\%), intermediate (30\%), or high (60\%)
              probability. Thus, the occurrence probability of the third item
              of each triplet (given the first two items) was varied. Compared
              to high- probability triplet endings, endings with low and
              intermediate probability elicited an early anterior negativity
              that had an onset around 100 ms and was maximal at around 180 ms.
              This effect was larger for events with low than for events with
              intermediate probability. Our results reveal that, when
              predictions are based on statistical learning, events that do not
              match a prediction evoke an early anterior negativity, with the
              amplitude of this mismatch response being inversely related to
              the probability of such events. Thus, we report a statistical
              mismatch negativity (sMMN) that reflects statistical learning of
              transitional probability distributions that go beyond auditory
              sensory memory capabilities. Humans",
  journal  = "Scientific reports",
  volume   =  6,
  pages    = "1--11",
  year     =  2016,
  doi      = "10.1038/srep19741"
}

@PHDTHESIS{Conklin1990-lc,
  title  = "Prediction and entropy of music",
  author = "Conklin, Darrell",
  year   =  1990,
  school = "University of Calgary"
}

@INPROCEEDINGS{Mullensiefen2016-wv,
  title     = "What to expect from music psychology?",
  booktitle = "Humboldt Prize Presentation",
  author    = "M{\"u}llensiefen, Daniel",
  year      =  2016
}

@INPROCEEDINGS{Mullensiefen_undated-zq,
  title     = "Individual differences and cognitive music information retrieval",
  booktitle = "{CogMIR} 2016",
  author    = "M{\"u}llensiefen, Daniel"
}

@INPROCEEDINGS{Bas_de_Haas2008-dh,
  title     = "Tonal pitch step distance: A similarity measure for chord
               progressions",
  booktitle = "Proceedings of the International Conference on Music Information
               Retrieval ({ISMIR})",
  author    = "Bas de Haas, W and Veltkamp, Remco C",
  pages     = "51--56",
  year      =  2008,
  isbn      = "9780615248493"
}

@ARTICLE{Bas_de_Haas2013-dw,
  title    = "A geometrical distance measure for determining the similarity of
              musical harmony",
  author   = "Bas de Haas, W and Wiering, Frans and Veltkamp, Remco C",
  journal  = "International Journal of Multimedia Information Retrieval",
  volume   =  2,
  number   =  3,
  pages    = "189--202",
  year     =  2013,
  keywords = "b; by the netherlands organization; de haas is supported; for;
              harmony; music information retrieval; nwo-vidi grant 276-35-001;
              scientific research; similarity; step function; this article has;
              tonality; w",
  issn     = "2192-6611",
  doi      = "10.1007/s13735-013-0036-6"
}

@INCOLLECTION{Cambouropoulos2016-ex,
  title     = "The harmonic musical surface and two novel chord representation
               schemes",
  booktitle = "Computational Music Analysis",
  author    = "Cambouropoulos, Emilios",
  editor    = "Meredith, David",
  publisher = "Springer International Publishing",
  pages     = "31--56",
  year      =  2016,
  address   = "Cham, Switzerland",
  isbn      = "9783319259314"
}

@ARTICLE{Queiroz_undated-rc,
  title  = "Obtaining General Chord Types from Chroma Vectors",
  author = "Queiroz, Marcelo and Kaliakatsos-Papakostas, Maximos and
            Cambouropoulos, Emilios"
}

@ARTICLE{Pearce2010-mn,
  title    = "Melodic grouping in music information retrieval: New methods and
              applications",
  author   = "Pearce, Marcus T and M{\"u}llensiefen, Daniel and Wiggins, G A",
  abstract = "We introduce the MIR task of segmenting melodies into phrases,
              summarise the musicological and psychological background to the
              task and review existing computational methods before presenting
              a new model, IDyOM, for melodic segmentation based on statistical
              learning and information-dynamic analysis. The performance of the
              model is compared to several existing algorithms in predicting
              the annotated phrase boundaries in a large corpus of folk music.
              The results indicate that four algorithms produce acceptable
              results: one of these is the IDyOM model which performs much
              better than naive statistical models and approaches the
              performance of the best-performing rule-based models. Further
              slight performance improvement can be obtained by combining the
              output of the four algorithms in a hybrid model, although the
              performance of this model is moderate at best, leaving a great
              deal of room for improvement on this task.",
  journal  = "Advances in music information retrieval",
  pages    = "364--388",
  year     =  2010
}

@INPROCEEDINGS{Hansen2012-gr,
  title     = "Shannon entropy predicts perceptual uncertainty in the
               generation of melodic pitch expectations",
  booktitle = "Proceedings of the 12th International Conference on Music
               Perception and Cognition ({ICMPC}) and 8th Triennial Conference
               of the European Society for the Cognitive Sciences of Music
               ({ESCOM})",
  author    = "Hansen, N C and Pearce, Marcus T",
  pages     = "406--407",
  year      =  2012,
  issn      = "0096-1523",
  doi       = "10.1037/0096-1523.5.4.579"
}

@INPROCEEDINGS{Cameron2012-sc,
  title     = "Perception of Rhythmic Similarity in Reich's Clapping Music :
               Factors and Models",
  booktitle = "Proceedings of the 12th International Conference on Music
               Perception and Cognition ({ICMPC}) and 8th Triennial Conference
               of the European Society for the Cognitive Sciences of Music
               ({ESCOM})",
  author    = "Cameron, Daniel and Potter, Keith and Wiggins, G A and Pearce,
               Marcus T",
  pages     = "195--196",
  year      =  2012
}

@ARTICLE{Omigie2012-na,
  title     = "Tracking of pitch probabilities in congenital amusia",
  author    = "Omigie, Diana and Pearce, Marcus T and Stewart, Lauren",
  abstract  = "Auditory perception involves not only hearing a series of sounds
               but also making predictions about future ones. For typical
               listeners, these predictions are formed on the basis of
               long-term schematic knowledge, gained over a lifetime of
               exposure to the auditory environment. Individuals with a
               developmental disorder known as congenital amusia show marked
               difficulties with music perception and production. The current
               study investigated whether these difficulties can be explained,
               either by a failure to internalise the statistical regularities
               present in music, or by a failure to consciously access this
               information. Two versions of a melodic priming paradigm were
               used to probe participants' abilities to form melodic pitch
               expectations, in an implicit and an explicit manner. In the
               implicit version (Experiment 1), participants made speeded,
               forced-choice discriminations concerning the timbre of a cued
               target note. In the explicit version (Experiment 2),
               participants used a 1-7 rating scale to indicate the degree to
               which the pitch of the cued target note was expected or
               unexpected. Target notes were chosen to have high or low
               probability in the context of the melody, based on the
               predictions of a computational model of melodic expectation.
               Analysis of the data from the implicit task revealed a melodic
               priming effect in both amusic and control participants whereby
               both groups showed faster responses to high probability than low
               probability notes rendered in the same timbre as the context.
               However, analysis of the data from the explicit task revealed
               that amusic participants were significantly worse than controls
               at using explicit ratings to differentiate between high and low
               probability events in a melodic context. Taken together,
               findings from the current study make an important contribution
               in demonstrating that amusic individuals track melodic pitch
               probabilities at an implicit level despite an impairment,
               relative to controls, when required to make explicit judgments
               in this regard. However the unexpected finding that amusics
               nevertheless are able to use explicit ratings to distinguish
               between high and low probability notes (albeit not as well as
               controls) makes a similarly important contribution in revealing
               a sensitivity to musical structure that has not previously been
               demonstrated in these individuals. ?? 2012 Elsevier Ltd.",
  journal   = "Neuropsychologia",
  publisher = "Elsevier Ltd",
  volume    =  50,
  number    =  7,
  pages     = "1483--1493",
  year      =  2012,
  keywords  = "Congenital amusia; Conscious awareness; Expectations; Priming",
  issn      = "0028-3932",
  pmid      = "22414591",
  doi       = "10.1016/j.neuropsychologia.2012.02.034"
}

@ARTICLE{Whorley2013-bs,
  title    = "Harmonising Melodies: Why do we add the bass line first?",
  author   = "Whorley, Raymond Peter and Rhodes, Christophe and Wiggins, G A
              and Pearce, Marcus T",
  abstract = "We are taking an information theoretic approach to the question
              of the best way to harmonise melodies. Is it best to add the bass
              first, as has been traditionally the case? We describe software
              which uses statistical machine learning techniques to learn how
              to harmonise from a corpus of existing music. The software is
              able to perform the harmonisation task in various different ways.
              A performance comparison using the information theoretic measure
              cross-entropy is able to show that, indeed, the bass first
              approach appears to be best. We then use this overall strategy to
              investigate the performance of specialist models for the
              prediction of different musical attributes (such as pitch and
              note length) compared with single models which predict all
              attributes. We find that the use of specialist models affords a
              definite performance advantage. Final comparisons with a simpler
              model show that each has its pros and cons. Some harmonisations
              are presented which have been generated by some of the better
              performing models.",
  journal  = "International Conference on Computational Creativity",
  pages    = "79--86",
  year     =  2013
}

@INPROCEEDINGS{Agres2013-dc,
  title     = "An {Information-Theoretic} Account of Musical Expectation and
               Memory",
  booktitle = "Proceedings of the 35th Annual Conference of the Cognitive
               Science Society {CogSci} 2013",
  author    = "Agres, Kat and Abdallah, Samer and Pearce, Marcus T",
  pages     = "127--132",
  year      =  2013
}

@ARTICLE{Brattico2013-mb,
  title    = "The neuroaesthetics of music",
  author   = "Brattico, Elvira and Pearce, Marcus T",
  abstract = "The increasingly intensive study of music by neuroscientists over
              the past two decades has established\textbackslashnthe
              neurosciences of music as a subdiscipline of cognitive
              neuroscience, responsible for investigating
              the\textbackslashnneural basis for music perception, cognition,
              and emotion. In this endeavor, music perception
              and\textbackslashncognition have often been compared with
              language processing and understanding, while
              music-induced\textbackslashnemotions are compared with emotions
              induced by visual stimuli. Here, we review research that
              is\textbackslashnbeginning to define a new field of study called
              neuroaesthetics of music. According to this
              fresh\textbackslashnperspective, music is viewed primarily as an
              expressive art rather than as a cognitive domain. The
              goal\textbackslashnof this emerging field is to understand the
              neural mechanisms and structures involved in the
              perceptual,\textbackslashnaffective and cognitive processes that
              generate the three principal aesthetic responses: emotions,
              judgments, and preference. Although much is known about the
              frontotemporal brain mechanisms
              underlying\textbackslashnperceptual and cognitive musical
              processes, and about the limbic and paralimbic networks
              responsible for\textbackslashnmusical affect, there is a great
              deal of work to be done in understanding the neural chronometry
              and\textbackslashnstructures determining aesthetic responses to
              music. Research has only recently begun to delineate
              the\textbackslashnmodulatory effects of the listener, listening
              situation, and the properties of the music itself on a
              musical\textbackslashnaesthetic experience. This article offers a
              review and synthesis of our current understanding of
              the\textbackslashnperceptual, cognitive, and affective processes
              involved in an aesthetic musical experience and
              introduces\textbackslashna novel framework to coordinate future
              endeavors in an emerging field",
  journal  = "Psychology of Aesthetics, Creativity, and the Arts",
  volume   =  7,
  number   =  1,
  pages    = "48--61",
  year     =  2013,
  keywords = "auditory cortex; cognitive neuroscience; from neuroscience to
              neuroaesthetics; music; overture; pitch; rhythm",
  issn     = "1931-390X, 1931-3896",
  doi      = "10.1037/a0031624"
}

@ARTICLE{Omigie2013-cm,
  title     = "Electrophysiological correlates of melodic processing in
               congenital amusia",
  author    = "Omigie, Diana and Pearce, Marcus T and Williamson, Victoria J
               and Stewart, Lauren",
  abstract  = "Music listening involves using previously internalized
               regularities to process incoming musical structures. A condition
               known as congenital amusia is characterized by musical
               difficulties, notably in the detection of gross musical
               violations. However, there has been increasing evidence that
               individuals with the disorder show preserved musical ability
               when probed using implicit methods. To further characterize the
               degree to which amusic individuals show evidence of latent
               sensitivity to musical structure, particularly in the context of
               stimuli that are ecologically valid, electrophysiological
               recordings were taken from a sample of amusic and control
               participants as they listened to real melodies. To encourage
               them to pay attention to the music, participants were asked to
               detect occasional notes in a different timbre. Using a
               computational model of auditory expectation to identify points
               of varying levels of expectedness in these melodies (in units of
               information content (IC), a measure which has an inverse
               relationship with probability), ERP analysis investigated the
               extent to which the amusic brain differs from that of controls
               when processing notes of high IC (low probability) as compared
               to low IC ones (high probability). The data revealed a novel
               effect that was highly comparable in both groups: Notes with
               high IC reliably elicited a delayed P2 component relative to
               notes with low IC, suggesting that amusic individuals, like
               controls, found these notes more difficult to evaluate. However,
               notes with high IC were also characterized by an early frontal
               negativity in controls that was attenuated in amusic
               individuals. A correlation of this early negative effect with
               the ability to make accurate note expectedness judgments
               (previous data collected from a subset of the current sample)
               was shown to be present in typical individuals but compromised
               in individuals with amusia: a finding in line with evidence of a
               close relationship between the amplitude of such a response and
               explicit knowledge of musical deviance. \copyright{} 2013
               Elsevier Ltd.",
  journal   = "Neuropsychologia",
  publisher = "Elsevier",
  volume    =  51,
  number    =  9,
  pages     = "1749--1762",
  year      =  2013,
  keywords  = "Congenital amusia; Electroencephalography; Expectations;
               Explicit knowledge; Melodic processing",
  issn      = "0028-3932",
  pmid      = "23707539",
  doi       = "10.1016/j.neuropsychologia.2013.05.010"
}

@ARTICLE{Egermann2013-xl,
  title    = "Probabilistic models of expectation violation predict
              psychophysiological emotional responses to live concert music",
  author   = "Egermann, Hauke and Pearce, Marcus T and Wiggins, G A and
              McAdams, Stephen",
  abstract = "We present the results of a study testing the often-theorized
              role of musical expectations in inducing listeners' emotions in a
              live flute concert experiment with 50 participants. Using an
              audience response system developed for this purpose, we measured
              subjective experience and peripheral psychophysiological changes
              continuously. To confirm the existence of the link between
              expectation and emotion, we used a threefold approach. (1) On the
              basis of an information-theoretic cognitive model, melodic pitch
              expectations were predicted by analyzing the musical stimuli used
              (six pieces of solo flute music). (2) A continuous rating scale
              was used by half of the audience to measure their experience of
              unexpectedness toward the music heard. (3) Emotional reactions
              were measured using a multicomponent approach: subjective feeling
              (valence and arousal rated continuously by the other half of the
              audience members), expressive behavior (facial EMG), and
              peripheral arousal (the latter two being measured in all 50
              participants). Results confirmed the predicted relationship
              between high-information-content musical events, the violation of
              musical expectations (in corresponding ratings), and emotional
              reactions (psychologically and physiologically). Musical
              structures leading to expectation reactions were manifested in
              emotional reactions at different emotion component levels
              (increases in subjective arousal and autonomic nervous system
              activations). These results emphasize the role of musical
              structure in emotion induction, leading to a further
              understanding of the frequently experienced emotional effects of
              music.",
  journal  = "Cognitive, affective \& behavioral neuroscience",
  volume   =  13,
  number   =  3,
  pages    = "533--553",
  year     =  2013,
  keywords = "accompanied by activations in; computational modeling; emotion;
              expectation; learning; music; music has been shown;
              psychophysiology; several reaction components; statistical; that
              are; to induce emotional reactions",
  issn     = "1530-7026, 1531-135X",
  pmid     = "23605956",
  doi      = "10.3758/s13415-013-0161-y"
}

@ARTICLE{Whorley2013-gk,
  title   = "Multiple viewpoint systems: Time complexity and the construction
             of domains for complex musical viewpoints in the harmonization
             problem",
  author  = "Whorley, Raymond P and Wiggins, G A and Rhodes, Christophe and
             Pearce, Marcus T",
  journal = "Journal of New Music Research",
  volume  =  42,
  number  =  3,
  pages   = "237--266",
  year    =  2013,
  issn    = "0929-8215",
  doi     = "10.1080/09298215.2013.831457"
}

@ARTICLE{Bailes2013-kf,
  title    = "Music cognition as mental time travel",
  author   = "Bailes, Freya and Dean, Roger T and Pearce, Marcus T",
  abstract = "As we experience a temporal flux of events our expectations of
              future events change. Such expectations seem to be central to our
              perception of affect in music, but we have little understanding
              of how expectations change as recent information is integrated.
              When music establishes a pitch centre (tonality), we rapidly
              learn to anticipate its continuation. What happens when
              anticipations are challenged by new events? Here we show that
              providing a melodic challenge to an established tonality leads to
              progressive changes in the impact of the features of the stimulus
              on listeners' expectations. The results demonstrate that
              retrospective analysis of recent events can establish new
              patterns of expectation that converge towards probabilistic
              interpretations of the temporal stream. These studies point to
              wider applications of understanding the impact of information
              flow on future prediction and its behavioural utility.",
  journal  = "Scientific reports",
  volume   =  3,
  pages    = "2690",
  year     =  2013,
  keywords = "Acoustic Stimulation; Adolescent; Adult; Cognition; Female;
              Humans; Male; Mental Processes; Music; Music: psychology; Pitch
              Discrimination; Reaction Time; Young Adult",
  issn     = "2045-2322",
  pmid     = "24045614",
  doi      = "10.1038/srep02690"
}

@ARTICLE{Carrus2013-rz,
  title     = "Melodic pitch expectation interacts with neural responses to
               syntactic but not semantic violations",
  author    = "Carrus, Elisa and Pearce, Marcus T and Bhattacharya, Joydeep",
  abstract  = "Current behavioural and electrophysiological evidence suggests
               that music and language syntactic processing depends on at least
               partly shared neural resources. Existing studies using a
               simultaneous presentation paradigm are limited to the effects of
               violations of harmonic structure in Western tonal music on
               processing of single syntactic or semantic violations. Because
               melody is a universal property of music as it is emphasized also
               by non-western musical traditions, it is fundamental to
               investigate interactions between melodic expectation and
               language processing. The present study investigates the effect
               of melodically unexpected notes on neural responses elicited by
               linguistic violations. Sentences with or without a violation in
               the last word were presented on screen simultaneously with
               melodies whose last note had a high- or low-probability, as
               estimated by a computational model of melodic expectation.
               Violations in language could be syntactic, semantic or combined.
               The electroencephalogram (EEG) was recorded while participants
               occasionally responded to language stimuli. Confirming previous
               studies, low-probability notes elicited an enhanced N1 compared
               to high-probability notes. Further, syntactic violations
               elicited a left anterior negativity (LAN) and P600 component,
               and semantic violations elicited an N400. Combined violations
               elicited components which resembled neural responses to both
               syntactic and semantic incongruities. The LAN amplitude was
               decreased when language syntactic violations were presented
               simultaneously with low-probability notes compared to when they
               were presented with high-probability notes. The N400 was not
               influenced by the note-probability. These findings show support
               for the neural interaction between language and music
               processing, including novel evidence for melodic processing
               which can be incorporated in a computational framework of
               melodic expectation. \copyright{} 2012.",
  journal   = "Cortex; a journal devoted to the study of the nervous system and
               behavior",
  publisher = "Elsevier Srl",
  volume    =  49,
  number    =  8,
  pages     = "2186--2200",
  year      =  2013,
  keywords  = "EEG; ERP; Interaction; Language; Melody; Semantics; Syntax",
  issn      = "0010-9452",
  pmid      = "23141867",
  doi       = "10.1016/j.cortex.2012.08.024"
}

@INPROCEEDINGS{Cherla2013-fr,
  title     = "Learning distributed representations for multiple-viewpoint
               melodic prediction",
  booktitle = "14th International Society for Music Information Retrieval
               Conference ({ISMIR})",
  author    = "Cherla, S and Weyde, T and Garcez, A D'avila and Pearce, Marcus
               T",
  year      =  2013
}

@ARTICLE{Pearce2015-zw,
  title    = "{Age-Related} Patterns in Emotions Evoked by Music",
  author   = "Pearce, Marcus T and Halpern, Andrea R",
  abstract = "We presented older and younger nonmusician adult listeners with
              (mostly) unfamiliar excerpts of film music. All listeners rated
              their emotional reaction using the Geneva Emotional Music Scale 9
              (GEMS-9; Zentner, Grandjean, \& Scherer, 2008), and also rated
              familiarity and liking. The GEMS-9 was factor-analyzed into 3
              factors of Animacy, Valence, and Arousal. Although the 2 age
              groups liked the music equally well, and showed roughly the same
              pattern of responses to the different emotion categories, the
              younger group showed a wider range of emotional reactivity on all
              the factors. We found support for a type of positivity effect, in
              that older people found Happy music somewhat less happy than did
              younger people, but found Sad music much less sad than did
              younger people. Older people also rated Fearful music more
              positively than did younger people. We propose that the GEMS-9
              scale is an efficient and effective device to collect evoked
              emotion data for a wide age range of listeners. (PsycINFO
              Database Record (c) 2015 APA, all rights reserved)",
  journal  = "Psychology of Aesthetics, Creativity, and the Arts",
  volume   =  9,
  number   =  3,
  pages    = "No Pagination Specified",
  year     =  2015,
  keywords = "aging; and as; audiences; evoked emotion; gems; in the united;
              including particularly classical and; jazz; music; older adults
              are well; performers; proportion of concert; represented in
              musical audiences; they constitute a significant",
  doi      = "10.1037/a0039279"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gingras2015-rc,
  title    = "Linking Melodic Expectation to Expressive Performance Timing and
              Perceived Musical Tension",
  author   = "Gingras, Bruno and Pearce, Marcus T and Goodchild, Meghan and
              Dean, Roger T and Wiggins, G A and McAdams, Stephen",
  abstract = "This research explored the relations between the predictability
              of musical structure, expressive timing in performance, and
              listeners' perceived musical tension. Studies analyzing the
              influence of expressive timing on listeners' affective responses
              have been constrained by the fact that, in most pieces, the
              notated durations limit performers' interpretive freedom. To
              circumvent this issue, we focused on the unmeasured prelude, a
              semi-improvisatory genre without notated durations. In Experiment
              1, 12 professional harpsichordists recorded an unmeasured prelude
              on a harpsichord equipped with a MIDI console. Melodic
              expectation was assessed using a probabilistic model (IDyOM
              [Information Dynamics of Music]) whose expectations have been
              previously shown to match closely those of human listeners.
              Performance timing information was extracted from the MIDI data
              using a score−performance matching algorithm. Time-series
              analyses showed that, in a piece with unspecified note durations,
              the predictability of melodic structure measurably influenced
              tempo fluctuations in performance. In Experiment 2, another 10
              harpsichordists, 20 nonharpsichordist musicians, and 20
              nonmusicians listened to the recordings from Experiment 1 and
              rated the perceived tension continuously. Granger causality
              analyses were conducted to investigate predictive relations among
              melodic expectation, expressive timing, and perceived tension.
              Although melodic expectation, as modeled by IDyOM, modestly
              predicted perceived tension for all participant groups, neither
              of its components, information content or entropy, was Granger
              causal. In contrast, expressive timing was a strong predictor and
              was Granger causal. However, because melodic expectation was also
              predictive of expressive timing, our results outline a complete
              chain of influence from predictability of melodic structure via
              expressive performance timing to perceived musical tension.",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  42,
  number   =  4,
  pages    = "594--609",
  year     =  2015,
  keywords = "gaze; line of sight; subitizing; theory of mind; visual
              perspective taking",
  issn     = "0096-1523, 1939-1277",
  doi      = "10.1037/xhp0000141"
}

@ARTICLE{Barascud2016-hn,
  title    = "Brain responses in humans reveal ideal observer-like sensitivity
              to complex acoustic patterns",
  author   = "Barascud, Nicolas and Pearce, Marcus T and Griffiths, Timothy D
              and Friston, Karl J and Chait, Maria",
  abstract = "We use behavioral methods, magnetoencephalography, and functional
              MRI to investigate how human listeners discover temporal patterns
              and statistical regularities in complex sound sequences.
              Sensitivity to patterns is fundamental to sensory processing, in
              particular in the auditory system, because most auditory signals
              only have meaning as successions over time. Previous evidence
              suggests that the brain is tuned to the statistics of sensory
              stimulation. However, the process through which this arises has
              been elusive. We demonstrate that listeners are remarkably
              sensitive to the emergence of complex patterns within rapidly
              evolving sound sequences, performing on par with an ideal
              observer model. Brain responses reveal online processes of
              evidence accumulation-dynamic changes in tonic activity precisely
              correlate with the expected precision or predictability of
              ongoing auditory input-both in terms of deterministic
              (first-order) structure and the entropy of random sequences.
              Source analysis demonstrates an interaction between primary
              auditory cortex, hippocampus, and inferior frontal gyrus in the
              process of discovering the regularity within the ongoing sound
              sequence. The results are consistent with precision based
              predictive coding accounts of perceptual inference and provide
              compelling neurophysiological evidence of the brain's capacity to
              encode high-order temporal structure in sensory signals.",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  113,
  number   =  5,
  pages    = "E616--E625",
  year     =  2016,
  issn     = "0027-8424",
  pmid     = "26787854",
  doi      = "10.1073/pnas.1508523113"
}

@ARTICLE{Hansen2016-iy,
  title    = "Nonlinear changes in the rhythm of European art music:
              Quantitative support for historical musicology",
  author   = "Hansen, Niels Chr and Sadakata, Makiko and Pearce, Marcus T",
  journal  = "Music perception",
  volume   =  33,
  number   =  4,
  pages    = "414--431",
  year     =  2016,
  keywords = "french composers; historical musicology; language; npvi;
              presented an approach; properties of their music; rhythm; the
              authors who originated; this research endeavor recently",
  issn     = "0730-7829",
  doi      = "10.1525/MP.2016.33.4.414"
}

@ARTICLE{Dean2016-ts,
  title    = "Algorithmically-generated Corpora that use Serial Compositional
              Principles Can Contribute to the Modeling of Sequential Pitch
              Structure in Non-tonal Music",
  author   = "Dean, Roger T and Pearce, Marcus T",
  volume   =  11,
  number   =  1,
  pages    = "27--46",
  year     =  2016,
  keywords = "idyom; improvisation; information content; non-tonal; serial
              music"
}

@INPROCEEDINGS{Pearce2006-pz,
  title     = "The information dynamics of melodic boundary detection",
  booktitle = "Proceedings of the Ninth International Conference on Music
               Perception and Cognition",
  author    = "Pearce, Marcus T and Wiggins, G A",
  abstract  = "Many published models of perceived grouping structure in music
               are inspired by Gestalt psychology, associating grouping
               boundaries with discontinuities or changes in various dimensions
               of the musical surface. We examine a complementary approach
               based on information dynamics in melody perception according to
               which boundaries are perceived at points of expectancy violation
               and predictive uncertainty. We discuss empirical evidence for
               and against the two theories, consider how they relate to one
               another and suggest methods for further empirical investigation
               and development of the information dynamics approach.",
  pages     = "860--867",
  year      =  2006,
  keywords  = "boundary perception; expectation; gestalt rules; grouping
               structure; information dynamics; melody perception;
               segmentation; statistical learning",
  isbn      = "9788873951551"
}

@ARTICLE{Socher_undated-vr,
  title  = "Learning Continuous Phrase Representations and Syntactic Parsing
            with Recursive Neural Networks",
  author = "Socher, Richard and Manning, Christopher D and Ng, Andrew Y",
  pages  = "1--9"
}

@ARTICLE{Terdalkar2008-uw,
  title  = "Parsing with Compositional Vector Grammars",
  author = "Terdalkar, Hrishikesh",
  number = "August",
  year   =  2008
}

@ARTICLE{Le2014-oc,
  title    = "The {Inside-Outside} Recursive Neural Network model for
              Dependency Parsing",
  author   = "Le, Phong and Zuidema, Willem",
  abstract = "We propose the first implementation of an infinite-order
              generative dependency model. The model is based on a new
              recursive neural network architecture, the Inside-Outside
              Recursive Neural Network. This architecture allows information to
              flow not only bottom-up, as in traditional recursive neural
              networks, but also top-down. This is achieved by computing
              content as well as context representations for any constituent,
              and letting these rep-resentations interact. Experimental
              re-sults on the English section of the Uni-versal Dependency
              Treebank show that the infinite-order model achieves a
              per-plexity seven times lower than the tradi-tional third-order
              model using counting, and tends to choose more accurate parses in
              k-best lists. In addition, reranking with this model achieves
              state-of-the-art unla-belled attachment scores and unlabelled
              exact match scores.",
  journal  = "Proceedings of the 2014 Conference on Empirical Methods in
              Natural Language Processing (EMNLP)",
  pages    = "729--739",
  year     =  2014
}

@ARTICLE{Rohrmeier2015-vp,
  title    = "Principles of structure building in music, language and animal
              song",
  author   = "Rohrmeier, Martin A and Zuidema, Willem and Wiggins, G A and
              Scharff, Constance",
  abstract = "Human language, music and a variety of animal vocalizations
              constitute ways of sonic communication that exhibit remarkable
              structural complexity. While the complexities of language and
              possible parallels in animal communication have been discussed
              intensively, reflections on the complexity of music and animal
              song, and their comparisons, are underrepresented. In some ways,
              music and animal songs are more comparable to each other than to
              language as propositional semantics cannot be used as indicator
              of communicative success or wellformedness, and notions of
              grammaticality are less easily defined. This review brings
              together accounts of the principles of structure building in
              music and animal song. It relates them to corresponding models in
              formal language theory, the extended Chomsky hierarchy (CH), and
              their probabilistic counterparts. We further discuss common
              misunderstandings and shortcomings concerning the CH and suggest
              ways to move beyond. We discuss language, music and animal song
              in the context of their function and motivation and further
              integrate problems and issues that are less commonly addressed in
              the context of language, including continuous event spaces,
              features of sound and timbre, representation of temporality and
              interactions of multiple parallel feature streams. We discuss
              these aspects in the light of recent theoretical, cognitive,
              neuroscientific and modelling research in the domains of music,
              language and animal song.",
  journal  = "Philosophical transactions of the Royal Society of London. Series
              B, Biological sciences",
  volume   =  370,
  number   =  1664,
  year     =  2015,
  keywords = "cognition; computational biology; neuroscience",
  issn     = "0962-8436, 1471-2970",
  pmid     = "25646520",
  doi      = "10.1098/rstb.2014.0097"
}

@ARTICLE{Koelsch2013-wk,
  title    = "Processing of hierarchical syntactic structure in music",
  author   = "Koelsch, Stefan and Rohrmeier, Martin A and Torrecuso, Renzo and
              Jentschke, Sebastian",
  abstract = "Hierarchical structure with nested nonlocal dependencies is a key
              feature of human language and can be identified theoretically in
              most pieces of tonal music. However, previous studies have argued
              against the perception of such structures in music. Here, we show
              processing of nonlocal dependencies in music. We presented
              chorales by J. S. Bach and modified versions in which the
              hierarchical structure was rendered irregular whereas the local
              structure was kept intact. Brain electric responses differed
              between regular and irregular hierarchical structures, in both
              musicians and nonmusicians. This finding indicates that, when
              listening to music, humans apply cognitive processes that are
              capable of dealing with long-distance dependencies resulting from
              hierarchically organized syntactic structures. Our results reveal
              that a brain mechanism fundamental for syntactic processing is
              engaged during the perception of music, indicating that
              processing of hierarchical structure with nested nonlocal
              dependencies is not just a key component of human language, but a
              multidomain capacity of human cognition.",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  110,
  number   =  38,
  pages    = "15443--15448",
  year     =  2013,
  keywords = "Acoustic Stimulation; Adult; Cognition; Cognition: physiology;
              Electroencephalography; Female; Humans; Male; Models; Music;
              Music: psychology; Psycholinguistics; Psychological",
  issn     = "0027-8424, 1091-6490",
  pmid     = "24003165",
  doi      = "10.1073/pnas.1300272110"
}

@INPROCEEDINGS{Hedges2011-ol,
  title  = "Exploring Rameau and beyond: A corpus study of root progression
            theories",
  author = "Hedges, Thomas and Rohrmeier, Martin A",
  year   =  2011,
  issn   = "0717-6163",
  doi    = "10.1007/978-3-642-21590-2\_27"
}

@ARTICLE{Kuhn2008-qg,
  title    = "Learning non-local dependencies",
  author   = "Kuhn, Gustav and Dienes, Zolt{\'a}n",
  abstract = "This paper addresses the nature of the temporary storage buffer
              used in implicit or statistical learning. Kuhn and Dienes [Kuhn,
              G., \& Dienes, Z. (2005). Implicit learning of nonlocal musical
              rules: implicitly learning more than chunks. Journal of
              Experimental Psychology-Learning Memory and Cognition, 31(6)
              1417-1432] showed that people could implicitly learn a musical
              rule that was solely based on non-local dependencies. These
              results seriously challenge models of implicit learning that
              assume knowledge merely takes the form of linking adjacent
              elements (chunking). We compare two models that use a buffer to
              allow learning of long distance dependencies, the Simple
              Recurrent Network (SRN) and the memory buffer model. We argue
              that these models - as models of the mind - should not be
              evaluated simply by fitting them to human data but by determining
              the characteristic behaviour of each model. Simulations showed
              for the first time that the SRN could rapidly learn non-local
              dependencies. However, the characteristic performance of the
              memory buffer model rather than SRN more closely matched how
              people came to like different musical structures. We conclude
              that the SRN is more powerful than previous demonstrations have
              shown, but it's flexible learned buffer does not explain people's
              implicit learning (at least, the affective learning of musical
              structures) as well as fixed memory buffer models do.
              \copyright{} 2007 Elsevier B.V. All rights reserved.",
  journal  = "Cognition",
  volume   =  106,
  number   =  1,
  pages    = "184--206",
  year     =  2008,
  keywords = "Artificial grammar learning; Chunks; Implicit learning; Memory
              buffer model; Non-local dependencies; Simple Recurrent Network;
              Statistical learning",
  issn     = "0010-0277",
  pmid     = "17343839",
  doi      = "10.1016/j.cognition.2007.01.003"
}

@ARTICLE{Toiviainen1998-wz,
  title    = "Timbre similarity: Convergence of neural, behavioral, and
              computational approaches",
  author   = "Toiviainen, Petri and Tervaniemi, Mari and Louhivuori, Jukka and
              Saher, Marieke and Huotilainen, Minna and N{\"a}{\"a}t{\"a}nen,
              Risto",
  abstract = "Compared the degree of similarity of timbre representations as
              observed with brain recordings, behavioral studies, and computer
              simulations. To this end, the electrical brain activity of 9 Ss
              (aged 20-31 yrs) was recorded while they were repetitively
              presented with 5 sounds differing in timbre. Ss read
              simultaneously so that their attention was not focused on the
              sounds. The brain activity was quantified in terms of a
              change-specific mismatch negativity component. Thereafter, the Ss
              were asked to judge the similarity of all pairs along a 5-step
              scale. A computer simulation was made by 1st training a Kohonen
              self-organizing map with a large set of instrumental sounds. The
              map was then tested with the experimental stimuli, and the
              distance between the most active artificial neurons was measured.
              The results of these methods are highly similar, suggesting that
              timbre representations reflected in behavioral measures
              correspond to neural activity, both as measured directly and as
              simulated in self-organizing neural network models. (PsycINFO
              Database Record (c) 2004 APA, all rights reserved)",
  journal  = "Music perception",
  volume   =  16,
  number   =  2,
  pages    = "223--241",
  year     =  1998,
  keywords = "20-31 yr olds; Female; Human; Male; Music Perception; Stimulus
              Similarity; degree of similarity of timbre representations",
  issn     = "0730-7829"
}

@ARTICLE{Lari1990-dt,
  title   = "The estimation of stochastic context-free grammars using the
             inside-out algorithm",
  author  = "Lari, K and Young, S J",
  journal = "Computer speech \& language",
  volume  =  4,
  number  = "September",
  pages   = "35--56",
  year    =  1990,
  issn    = "0885-2308",
  doi     = "10.1016/0885-2308(90)90022-X"
}

@ARTICLE{Jonaitis2009-qb,
  title    = "Learning harmony: The role of serial statistics",
  author   = "Jonaitis, Erin Mcmullen and Saffran, Jenny R",
  abstract = "How do listeners learn about the statistical regularities
              underlying musical harmony? In traditional Western music, certain
              chords predict the occurrence of other chords: Given a particular
              chord, not all chords are equally likely to follow. In
              Experiments 1 and 2, we investigated whether adults make use of
              statistical information when learning new musical structures.
              Listeners were exposed to a novel musical system containing
              phrases generated using an artificial grammar. This new system
              contained statistical structure quite different from Western
              tonal music. Our results suggest that learners take advantage of
              the statistical patterning of chords to acquire new musical
              structures, similar to learning processes previously observed for
              language learning.",
  journal  = "Cognitive science",
  volume   =  33,
  number   =  5,
  pages    = "951--968",
  year     =  2009,
  keywords = "Language acquisition; Learning; Music; Syntax",
  issn     = "0364-0213",
  pmid     = "21585492",
  doi      = "10.1111/j.1551-6709.2009.01036.x"
}

@ARTICLE{Ponsford1999-pv,
  title    = "Statistical learning of harmonic movement",
  author   = "Ponsford, Dan and Wiggins, G A and Mellish, Chris",
  abstract = "We explore the application of statistical techniques, borrowed
              from natural language processing, to music. A probabilistic
              method is used to capture and generalise from the local harmonic
              movement of a corpus of seventeenth-century dance music. The
              probabilistic grammars so generated are then used for experiments
              in generation (composition). The corpus is preprocessed in a
              novel way, automatically converting the harmonies into a normal
              form to capture the underlying harmonic similarities between
              pieces. It is then automatically marked up with constituent
              boundaries (beginnings and ends of pieces, phrases and bars), to
              enable the learning process to capture some of the higher-level
              structure of the music. The experiment is promising, and a sample
              of the results are given. We discuss the limitations of the
              approach, and how they might be overcome.",
  journal  = "Journal of New Music Research",
  volume   =  28,
  number   =  2,
  pages    = "150--177",
  year     =  1999,
  issn     = "0929-8215",
  doi      = "10.1076/jnmr.28.2.150.3115"
}

@ARTICLE{Rohrmeier2014-ew,
  title     = "Modelling unsupervised online-learning of artificial grammars:
               Linking implicit and statistical learning",
  author    = "Rohrmeier, Martin A and Cross, Ian",
  abstract  = "Humans rapidly learn complex structures in various domains.
               Findings of above-chance performance of some untrained control
               groups in artificial grammar learning studies raise questions
               about the extent to which learning can occur in an untrained,
               unsupervised testing situation with both correct and incorrect
               structures. The plausibility of unsupervised online-learning
               effects was modelled with n-gram, chunking and simple recurrent
               network models. A novel evaluation framework was applied, which
               alternates forced binary grammaticality judgments and subsequent
               learning of the same stimulus. Our results indicate a strong
               online learning effect for n-gram and chunking models and a
               weaker effect for simple recurrent network models. Such findings
               suggest that online learning is a plausible effect of
               statistical chunk learning that is possible when ungrammatical
               sequences contain a large proportion of grammatical chunks. Such
               common effects of continuous statistical learning may underlie
               statistical and implicit learning paradigms and raise
               implications for study design and testing methodologies. ?? 2014
               Elsevier Inc.",
  journal   = "Consciousness and cognition",
  publisher = "Elsevier Inc.",
  volume    =  27,
  number    =  1,
  pages     = "155--167",
  year      =  2014,
  keywords  = "Artificial grammar learning; Competitive chunking; Computational
               modelling; Implicit learning; Incidental learning; N-gram model;
               Online learning; Simple recurrent network; Statistical learning;
               Unsupervised learning",
  issn      = "1053-8100, 1090-2376",
  pmid      = "24905545",
  doi       = "10.1016/j.concog.2014.03.011"
}

@INCOLLECTION{Cleeremans2008-ac,
  title     = "Computational models of implicit learning",
  booktitle = "The Cambridge handbook of computational psychology",
  author    = "Cleeremans, Axel and Dienes, Zolt{\'a}n",
  editor    = "Sun, Ron",
  abstract  = "(From the chapter) Implicit learning is the process through
               which one becomes sensitive to certain regularities in the
               environment: (1) without trying to learn regularities, (2)
               without knowing that one is learning regularities, and (3) in
               such a way that the resulting knowledge is unconscious. Over the
               last twenty years, the field of implicit learning has come to
               embody ongoing questioning about three fundamental issues in the
               cognitive sciences: (1) consciousness (how one should
               conceptualize and measure the relationships between conscious
               and unconscious cognition); (2) mental representation (in
               particular, the complex issue of abstraction); and (3)
               modularity and the architecture of the cognitive system (whether
               one should think of implicit and explicit learning as being
               subtended by separable systems of the brain or not).
               Computational modeling plays a central role in addressing these
               issues. (PsycINFO Database Record (c) 2009 APA, all rights
               reserved)",
  publisher = "Cambridge University Press",
  pages     = "396--421",
  year      =  2008,
  address   = "Cambridge, England",
  isbn      = "9780521674102, 9780521857413"
}

@INPROCEEDINGS{Rohrmeier2012-ty,
  title     = "Comparing feature-based models of harmony",
  booktitle = "Proceedings of the 9th International Symposium on Computer Music
               Modeling and Retrieval ({CMMR})",
  author    = "Rohrmeier, Martin A and Graepel, Thore",
  abstract  = "Predictive processing is a fundamental process in music cog-
               nition. While there are a number of predictive models of melodic
               struc- ture, fewer approaches exist for harmony/chord
               prediction. This paper compares the predictive performance of
               n-gram, HMM, autoregressive HMMs as well as feature-based (or
               multiple-viewpoint) n-gram and Dy- namic Bayesian Network Models
               of harmony, which used a basic set of duration and mode
               features. The evaluation was performed using a hand-selected
               corpus of Jazz standards. Multiple-viewpoint n-gram mod- els
               yield strong results and outperform plain HMM models. However,
               feature-based DBNs outperform n-gram models and HMMs when incor-
               porating the mode feature, but perform worse when duration is
               added to the models. Results suggest that the DBNs provide a
               promising route to modelling tonal harmony.",
  pages     = "357--370",
  year      =  2012,
  address   = "London, UK",
  keywords  = "cognitive modelling; dynamic bayesian networks; graphical
               models; harmony; model comparison; music; n gram models"
}

@INCOLLECTION{Irvine2002-kf,
  title     = "The foundations of item generation for mass testing",
  booktitle = "Item generation for test development",
  author    = "Irvine, Sidney H",
  editor    = "Irvine, Sidney H and Kyllonen, P C",
  publisher = "Routledge",
  pages     = "3--34",
  year      =  2002,
  address   = "Abingdon, England"
}

@BOOK{Gierl2012-an,
  title     = "Automatic Item Generation: Theory and Practice",
  editor    = "Gierl, M J and Haladyna, Thomas M",
  publisher = "Routledge",
  year      =  2012,
  address   = "New York, NY"
}

@PHDTHESIS{Morgan2011-ae,
  title  = "Nonword item generation: Predicting item difficulty in nonword
            repetition",
  author = "Morgan, Gareth",
  year   =  2011,
  school = "Arizona State University"
}

@BOOK{Baker2004-zy,
  title     = "Item Response Theory: Parameter estimation techniques",
  author    = "Baker, F B and Kim, S-H",
  publisher = "Marcel Dekker",
  year      =  2004,
  address   = "New York, NY"
}

@ARTICLE{Peretz2003-tj,
  title   = "Varieties of musical disorders",
  author  = "Peretz, I and Champod, A S and Hyde, K",
  journal = "Annals of the New York Academy of Sciences",
  volume  =  999,
  number  =  1,
  pages   = "58--75",
  year    =  2003,
  issn    = "0077-8923"
}

@ARTICLE{Sanfilippo2016-dq,
  title  = "Conference report: The Third Nordoff Robbins Plus Conference
            `Exploring music in therapeutic and community settings'",
  author = "Sanfilippo, Katie Rose and Spiro, Neta",
  pages  = "1--5",
  year   =  2016
}

@ARTICLE{Harrison2016-hh,
  title    = "Modelling melodic discrimination tests: Descriptive and
              explanatory approaches",
  author   = "Harrison, Peter M C and Musil, J J and M{\"u}llensiefen, D",
  abstract = "Melodic discrimination tests have been used for many years to
              assess individual differences in musical abilities. These tests
              are usually analysed using classical test theory. However,
              classical test theory is not well suited for optimizing test
              efficiency or for investigating construct validity. This paper
              addresses this problem by applying modern item response modelling
              techniques to three melodic discrimination tests. First,
              descriptive item response modelling is used to develop a short
              melodic discrimination test from a larger item pool. The
              resulting test meets the test-theoretic assumptions of a Rasch
              (1960) item response model and possesses good concurrent and
              convergent validity as well as good testing efficiency. Second,
              an explicit cognitive model of melodic discrimination is used to
              generate hypotheses relating item difficulty to structural item
              features such as melodic complexity, similarity, and tonalness.
              These hypotheses are then tested on response data from three
              melodic discrimination tests (n=317) using explanatory item
              response modelling. Results indicate that item difficulty is
              predicted by melodic complexity and melodic similarity,
              consistent with the proposed cognitive model. This provides
              useful evidence for construct validity. This paper therefore
              demonstrates the benefits of item response modelling both for
              efficient test construction and for test validity.",
  journal  = "Journal of New Music Research",
  volume   =  45,
  number   =  3,
  pages    = "265--280",
  year     =  2016,
  keywords = "[item response modelling; melodic discrimination",
  issn     = "0929-8215",
  doi      = "10.1080/09298215.2016.1197953"
}

@BOOK{Meredith2016-gh,
  title     = "Computational music analysis",
  editor    = "Meredith, David",
  abstract  = "This book provides an in-depth introduction and overview of
               current research in computational music analysis. Its seventeen
               chapters, written by leading researchers, collectively represent
               the diversity as well as the technical and philosophical
               sophistication of the work being done today in this intensely
               interdisciplinary field. A broad range of approaches are
               presented, employing techniques originating in disciplines such
               as linguistics, information theory, information retrieval,
               pattern recognition, machine learning, topology, algebra and
               signal processing. Many of the methods described draw on
               well-established theories in music theory and analysis, such as
               Forte's pitch-class set theory, Schenkerian analysis, the
               methods of semiotic analysis developed by Ruwet and Nattiez, and
               Lerdahl and Jackendoff's Generative Theory of Tonal Music. The
               book is divided into six parts, covering methodological issues,
               harmonic and pitch-class set analysis, form and
               voice-separation, grammars and hierarchical reduction, motivic
               analysis and pattern discovery and, finally, classification and
               the discovery of distinctive patterns. As a detailed and
               up-to-date picture of current research in computational music
               analysis, the book provides an invaluable resource for
               researchers, teachers and students in music theory and analysis,
               computer science, music information retrieval and related
               disciplines. It also provides a state-of-the-art reference for
               practitioners in the music technology industry.",
  publisher = "Springer",
  year      =  2016,
  address   = "New York, NY",
  isbn      = "9783319259314",
  doi       = "10.1007/978-3-319-25931-4"
}

@ARTICLE{Dietterich1998-yh,
  title    = "Approximate statistical tests for comparing supervised
              classification learning algorithms",
  author   = "Dietterich, Thomas G",
  abstract = "This article reviews ve approximate statistical tests for
              determining whether one learning algorithm outperforms another on
              a particular learn- ing task. These tests are compared
              experimentally to determine their prob- ability of incorrectly
              detecting a difference when no difference exists (type I error).
              Two widely used statistical tests are shown to have high
              probability of type I error in certain situations and should
              never be used: a test for the difference of two proportions and a
              paired-differences t test based on taking several random
              train-test splits. A third test, a paired- differences t test
              based on 10-fold cross-validation, exhibits somewhat elevated
              probability of type I error. A fourth test, McNemar's test, is
              shown to have low type I error. The fth test is a new test, 5
              \pounds{} 2 cv, based on ve iterations of twofold
              cross-validation. Experiments show that this test also has
              acceptable type I error. The article also measures the power
              (ability to detect algorithm differences when they do exist) of
              these tests. The cross-validated t test is the most powerful. The
              5 \pounds{}2 cv test is shown to be slightly more powerful than
              McNemar's test. The choice of the best test is determined by the
              computational cost of running the learning algorithm. For
              algorithms that can be executed only once, Mc- Nemar's test is
              the only test with acceptable type I error. For algorithms that
              can be executed 10 times, the 5 \pounds{} 2 cv test is
              recommended, because it is slightly more powerful and because it
              directly measures variation due to the choice of training set.",
  journal  = "Neural computation",
  volume   =  10,
  number   =  7,
  pages    = "1895--1923",
  year     =  1998,
  issn     = "0899-7667",
  pmid     = "9744903",
  doi      = "10.1162/089976698300017197"
}

@INPROCEEDINGS{Bouckaert2003-qp,
  title     = "Choosing between two learning algorithms based on calibrated
               tests",
  booktitle = "Proceedings of the 20th International Conference on Machine
               Learning",
  author    = "Bouckaert, Remco R",
  abstract  = "Designing a hypothesis test to determine the best of two machine
               learning algorithms with only a small data set available is not
               a sim- ple task. Many popular tests suffer from low power (5x2
               cv [2]), or high Type I er- ror (Weka's 10x10 cross validation
               [11]). Fur- thermore, many tests show a low level of
               replicability, so that tests performed by dif- ferent scientists
               with the same pair of algo- rithms, the same data sets and the
               same hy- pothesis test still may present different re- sults. We
               show that 5x2 cv, resampling and 10 fold cv suffer from low
               replicability. The main complication is due to the need to use
               the data multiple times. As a conse- quence, independence
               assumptions for most hypothesis tests are violated. In this
               paper, we pose the case that reuse of the same data causes the
               effective degrees of freedom to be much lower than theoretically
               expected. We show how to calibrate the effective degrees of
               freedom empirically for various tests. Some tests are not
               calibratable, indicating another flaw in the design. However the
               ones that are calibratable all show very similar behav- ior.
               Moreover, the Type I error of those tests is on the mark for a
               wide range of circum- stances, while they show a power and
               replica- bility that is a considerably higher than cur- rently
               popular hypothesis tests.",
  pages     = "51--58",
  year      =  2003,
  keywords  = "American Association for Artificial Intelligence.; Compilation
               copyright \copyright{}2003",
  isbn      = "9781577351894",
  doi       = "10.1145/1015330.1015338"
}

@ARTICLE{Ozer1999-hg,
  title    = "A survey of new product evaluation models",
  author   = "Ozer, Muammer",
  abstract = "New product development is a dynamic and lengthy process ranging
              from idea generation through product launch. It is quite
              important that product managers evaluate the viability of a new
              product at every stage of its development. Previous literature
              provides a large number of models that can be used to evaluate
              new products at different stages of the new product development
              process. These models vary with respect to their objectives,
              applicability to different products, data requirements, suitable
              environments and time frames, and diagnostics. This article
              presents a critical review of the models with an emphasis on
              these factors. The article also outlines other emerging methods
              that companies are using today. It concludes with managerial and
              research implications.",
  journal  = "Journal of Product Innovation Management",
  volume   =  16,
  number   =  1,
  pages    = "77--94",
  year     =  1999,
  issn     = "0737-6782"
}

@ARTICLE{Kyauk2012-qb,
  title  = "Predicting Song Popularity",
  author = "Kyauk, Edric and Park, Edwin and Pham, James",
  pages  = "2012",
  year   =  2012
}

@INCOLLECTION{Bishop2003-ck,
  title     = "Bayesian regression and classification",
  booktitle = "Advances in Learning Theory: Methods, Models and Applications",
  author    = "Bishop, Christopher M and Tipping, Michael E",
  editor    = "Suykens, J A K and Horvath, I and Basu, S and Micchelli, C and
               Vandewalle, J",
  abstract  = "In recent years Bayesian methods have become widespread in many
               domains including computer vision, signal processing,
               information retrieval and genome data analysis. The availability
               of fast computers allows the required computations to be
               performed in reasonable time, and thereby makes the benefits of
               a Bayesian treatment accessible to an ever broadening range of
               applications. In this tutorial we give an overview of the
               Bayesian approach to pattern recognition in the context of
               simple regression and classification problems. We then describe
               in detail a specific Bayesian model for regression and
               classification called the Relevance Vector Machine. This
               overcomes many of the limitations of the widely used Support
               Vector Machine, while retaining the highly desirable property of
               sparseness.",
  publisher = "IOS Press",
  volume    =  190,
  pages     = "267--285",
  year      =  2003,
  address   = "Amsterdam, The Netherlands",
  keywords  = "Bayes; Relevance vector machine; Support vector machine",
  issn      = "1387-6694",
  isbn      = "9781586033415",
  doi       = "10.1002/acs.744"
}

@ARTICLE{Caruana1997-ud,
  title    = "Multitask learning",
  author   = "Caruana, R",
  abstract = "Abstract. Multitask Learning is an approach to inductive transfer
              that improves generalization by using the domain information
              contained in the training signals of related tasks as an
              inductive bias. It does this by learning tasks in parallel while
              using a shared representation; what is learned for each task can
              help other tasks be learned better. This paper reviews prior work
              on MTL, presents new evidence that MTL in backprop nets discovers
              task relatedness without the need of supervisory signals, and
              presents new results for MTL with k-nearest neighbor and kernel
              regression. In this paper we demonstrate multitask learning in
              three domains. We explain how multitask learning works, and show
              that there are many opportunities for multitask learning in real
              domains. We present an algorithm and results for multitask
              learning with case-based methods like k-nearest neighbor and
              kernel regression, and sketch an algorithm for multitask learning
              in decision trees. Because multitask learning works, can be
              applied to many different kinds of domains, and can be used with
              different learning algorithms, we conjecture there will be many
              opportunities for its use on real-world problems.",
  journal  = "Machine learning",
  volume   =  75,
  pages    = "41--75",
  year     =  1997,
  keywords = "backpropagation; generalization; inductive transfer; k-nearest
              neighbor; kernel; multitask learning; parallel transfer;
              regression; supervised learning",
  issn     = "0885-6125, 1557-9964",
  pmid     = "20421687",
  doi      = "10.1109/TCBB.2010.22"
}

@TECHREPORT{Revelle2016-jg,
  title  = "Package `psych'",
  author = "Revelle, William",
  year   =  2016
}

@INPROCEEDINGS{Titov2008-dc,
  title     = "Modeling online reviews with multi-grain topic models",
  booktitle = "Proceeding of the 17th international conference on the World
               Wide Web ({WWW})",
  author    = "Titov, Ivan and McDonald, Ryan",
  abstract  = "In this paper we present a novel framework for extracting the
               ratable aspects of objects from online user reviews. Extracting
               such aspects is an important challenge in automatically mining
               product opinions from the web and in generating opinion-based
               summaries of user reviews [18, 19, 7, 12, 27, 36, 21]. Our
               models are based on extensions to standard topic modeling
               methods such as LDA and PLSA to induce multi-grain topics. We
               argue that multi-grain models are more appropriate for our task
               since standard models tend to produce topics that correspond to
               global properties of objects (e.g., the brand of a product type)
               rather than the aspects of an object that tend to be rated by a
               user. The models we present not only extract ratable aspects,
               but also cluster them into coherent topics, e.g., waitress and
               bartender are part of the same topic staff for restaurants. This
               differentiates it from much of the previous work which extracts
               aspects through term frequency analysis with minimal clustering.
               We evaluate the multi-grain models both qualitatively and
               quantitatively to show that they improve significantly upon
               standard topic models.",
  year      =  2008,
  keywords  = "LDA; Multi-grained Topic Models; Ratable aspects; Review data;
               Topic model; aspects; sliding window",
  isbn      = "9781605580852",
  doi       = "10.1145/1367497.1367513"
}

@TECHREPORT{Olsson2009-eo,
  title       = "A literature survey of active machine learning in the context
                 of natural language processing",
  author      = "Olsson, Fredrik",
  abstract    = "Active learning is a supervised machine learning technique in
                 which the learner is in control of the data used for learning.
                 That control is utilized by the learner to ask an oracle,
                 typically a human with extensive knowledge of the domain at
                 hand, about the classes of the instances for which the model
                 learned so far makes unreliable predictions. The active
                 learning process takes as input a set of labeled examples, as
                 well as a larger set of unlabeled examples, and produces a
                 classifier and a relatively small set of newly labeled data.
                 The overall goal is to create as good a classifier as
                 possible, without having to mark-up and supply the learner
                 with more data than necessary. The learning process aims at
                 keeping the human annotation effort to a minimum, only asking
                 for advice where the training utility of the result of such a
                 query is high. Active learning has been successfully applied
                 to a number of natural language processing tasks, such as,
                 information extraction, named entity recognition, text
                 categorization, part-of-speech tagging, parsing, and word
                 sense disambiguation. This report is a literature survey of
                 active learning from the perspective of natural language
                 processing.",
  pages       = "134--138",
  institution = "Swedish Institute of Computer Science",
  year        =  2009,
  keywords    = "active learning; ing; literature survey; machine learning;
                 natural language process-",
  issn        = "1100-3154"
}

@ARTICLE{Mathys2016-iu,
  title    = "What drives the market popularity of celebrities? A longitudinal
              analysis of consumer interest in film stars",
  author   = "Mathys, Juliane and Burmester, Alexa B and Clement, Michel",
  abstract = "The economic value of celebrity brands is heavily influenced by
              their ability to generate large-scale consumer interest. We
              develop a comprehensive framework for the drivers of celebrities'
              market popularity (in terms of consumer interest generated by
              celebrities) including variables related to actors, movies, and
              actor--movie fit. To test the framework, Internet search
              histories are examined for 161 film stars over the course of more
              than 6years (January 2004--June 2010). In particular, we test
              three hypotheses. First, with regard to actor-related variables,
              we do not find support for the postulated inverted U-shaped
              effect from the frequency of movie appearances on the market
              popularity of film stars (H1). Rather, the results indicate a
              monotone and positive relationship between a film star's
              frequency of movie appearances and consumer interest in the film
              star. Second, with respect to movie-related factors, the findings
              indicate that both positive and negative abnormal movie revenues
              increase the popularity of film stars (H2). Third, concerning
              variables related to actor--movie fit, the results support the
              hypothesized U-shaped effect from actor--movie fit on the market
              popularity of film stars (H3). On a managerial level, this study
              provides insights for film stars on how to enhance their market
              popularity by increasing the frequency of their movie appearances
              and by selecting films that are likely to generate abnormal
              revenues and have a certain fit with their image.",
  journal  = "International Journal of Research in Marketing",
  volume   =  33,
  number   =  2,
  pages    = "428--448",
  year     =  2016,
  issn     = "0167-8116",
  doi      = "10.1016/j.ijresmar.2015.09.003"
}

@ARTICLE{Strobl2000-qp,
  title     = "The Dynamics of Chart Success in the {U.K}. {Pre-Recorded}
               Popular Music Industry",
  author    = "Strobl, Eric A and Tucker, Clive",
  journal   = "Journal of Cultural Economics",
  publisher = "Kluwer Academic Publishers",
  volume    =  24,
  number    =  2,
  pages     = "113--134",
  year      =  2000,
  issn      = "0885-2545",
  doi       = "10.1023/A:1007601402245"
}

@ARTICLE{Meng1992-oh,
  title   = "Comparing correlated correlation coefficients",
  author  = "Meng, Xiao-Li and Rosenthal, Robert and Rubin, Donald B",
  journal = "Psychological bulletin",
  volume  =  111,
  number  =  1,
  pages   = "172--175",
  year    =  1992,
  issn    = "0033-2909",
  doi     = "10.1037/0033-2909.111.1.172"
}

@TECHREPORT{Diedenhofen2016-lu,
  title  = "Package `cocor'",
  author = "Diedenhofen, Birk",
  year   =  2016
}

@ARTICLE{Bunn1991-bn,
  title   = "Interaction of judgemental and statistical forecasting methods:
             Issues and analysis",
  author  = "Bunn, Derek and Wright, George",
  journal = "Management science",
  volume  =  37,
  number  =  5,
  pages   = "501--518",
  year    =  1991,
  issn    = "0025-1909"
}

@BOOK{Venables2002-vf,
  title     = "Modern Applied Statistics with {S}",
  author    = "Venables, W N and Ripley, B D",
  publisher = "Springer",
  edition   = "Fourth",
  year      =  2002,
  address   = "New York, NY"
}

@TECHREPORT{Kuhn2014-af,
  title    = "A short introduction to the caret package",
  author   = "Kuhn, Max",
  abstract = "The caret package (short for classification and regression
              training) contains functions to streamline the model training
              process for complex regression and classification problems. The
              package utilizes a number of R packages but tries not to load
              them all at package start-up1. The package ``suggests'' field
              includes 20 packages. caret loads packages as needed and assumes
              that they are installed.",
  pages    = "1--10",
  year     =  2014,
  keywords = "caret"
}

@TECHREPORT{Southworth2015-vh,
  title  = "Package `gbm': Generalized Boosted Regression Models",
  author = "Southworth, Harry",
  year   =  2015
}

@BOOK{Leskovec2014-zt,
  title     = "Mining of massive datasets",
  author    = "Leskovec, Jure and Rajaraman, Anand and Ullman, Jeffrey D",
  publisher = "Cambridge University Press",
  year      =  2014,
  address   = "Cambridge, England"
}

@ARTICLE{Liaw2002-qg,
  title    = "Classification and regression by randomForest",
  author   = "Liaw, Andy and Wiener, Matthew",
  abstract = "Recently there has been a lot of interest in ``ensemble
              learning'' --- methods that generate many classifiers and
              aggregate their results. Two well-known methods are boosting
              (see, e.g., Shapire et al., 1998) and bagging Breiman (1996) of
              classification trees. In boosting, successive trees give extra
              weight to points incorrectly predicted by earlier predictors. In
              the end, a weighted vote is taken for prediction. In bagging,
              successive trees do not depend on earlier trees --- each is
              independently constructed using a bootstrap sample of the data
              set. In the end, a simple majority vote is taken for prediction.",
  journal  = "R news",
  volume   =  2,
  number   =  3,
  pages    = "18--22",
  year     =  2002
}

@TECHREPORT{James2016-vg,
  title  = "Package {`RMySQL'}",
  author = "James, David",
  year   =  2016
}

@ARTICLE{Karatzoglou2004-bo,
  title    = "kernlab -- An {S4} package for kernel methods in {R}",
  author   = "Karatzoglou, Alexandros and Smola, Alex and Hornik, Kurt and
              Zeileis, Achim",
  abstract = "kernlab is an extensible package for kernel-based machine
              learning methods in R. It takes advantage of R's new S4 object
              model and provides a framework for creating and using
              kernel-based algorithms. The package contains dot product
              primitives (kernels), implementations of support vector machines
              and the relevance vector machine, Gaussian processes, a ranking
              algorithm, kernel PCA, kernel CCA, and a spectral clustering
              algorithm. Moreover it provides a general purpose quadratic
              programming solver, and an incomplete Cholesky decomposition
              method.",
  journal  = "Journal of statistical software",
  volume   =  11,
  number   =  9,
  pages    = "1--20",
  year     =  2004,
  keywords = "clus-; kernel methods; quadratic programming; ranking; support
              vector machines",
  issn     = "1548-7660",
  pmid     = "16631469",
  doi      = "10.1016/j.csda.2009.09.023"
}

@ARTICLE{Bunton1997-pz,
  title   = "Semantically motivated improvements for {PPM} variants",
  author  = "Bunton, Suzanne",
  journal = "Computer Journal",
  volume  =  40,
  number  = "2/3",
  pages   = "76--93",
  year    =  1997,
  issn    = "0010-4620",
  doi     = "10.1093/comjnl/40.2\_and\_3.76"
}

@INPROCEEDINGS{Marton2005-xm,
  title     = "On compression-based text classification",
  booktitle = "Proceedings of the 27th European Conference on Information
               Retrieval",
  author    = "Marton, Yuval and Wu, Ning and Hellerstein, Lisa",
  pages     = "300--314",
  year      =  2005
}

@PHDTHESIS{Bunton1996-hx,
  title   = "On-line stochastic processes in data compression",
  author  = "Bunton, Suzanne",
  year    =  1996,
  address = "Seattle, WA",
  school  = "University of Washington"
}

@INPROCEEDINGS{Shkarin2002-br,
  title     = "{PPM}: One step to practicality",
  booktitle = "Data Compression Conference Proceedings",
  author    = "Shkarin, D",
  abstract  = "PPM is one of the most promising lossless data compression
               algorithms using Markov source model of order D. Its main
               essence is the coding of a new (in the given context) symbol in
               one of inner nodes of the context tree; a sequence of the
               special escape symbols is used to describe this node. In
               reality, the majority of symbols is encoded in inner nodes and
               the Markov model becomes rather conventional. In spite of the
               fact that the PPM algorithm achieves the best results in
               comparison with others, it is used rarely in practical
               applications due to its high computational complexity. This
               paper is devoted to the PPM algorithm implementation that has a
               complexity comparable with widespread practical compression
               schemes based on LZ77, LZ78 and BWT algorithms. This scheme has
               been proposed by Shkarin (see Problems of Information
               Transmission, vol.34, no.3, p.44-54, 2001) and named PPM with
               information inheritance (PPMII).",
  pages     = "202--211",
  year      =  2002,
  keywords  = "Chromium; Data compression",
  issn      = "1068-0314",
  isbn      = "9780769514772",
  doi       = "10.1109/DCC.2002.999958"
}

@BOOK{Chiang2003-cb,
  title     = "Statistical methods of analysis",
  author    = "Chiang, Chin Long",
  publisher = "World Scientific Publishing",
  year      =  2003,
  address   = "Singapore"
}

@INPROCEEDINGS{Willems1993-jd,
  title     = "Context tree weighting: A sequential universal source coding
               procedure for {FSMX} sources",
  booktitle = "International Symposium on Information Theory, Proceedings",
  author    = "Willems, Frans M J and Shtarkov, Y M and Tjalkens, Tj J",
  pages     = "59",
  year      =  1993
}

@ARTICLE{Willems1998-pa,
  title   = "The {Context-Tree} Weighting Method: Extensions",
  author  = "Willems, Frans M J",
  journal = "IEEE transactions on information theory / Professional Technical
             Group on Information Theory",
  volume  =  44,
  number  =  2,
  pages   = "792--798",
  year    =  1998,
  issn    = "0018-9448"
}

@ARTICLE{Jiang1992-oh,
  title   = "Word-based dynamic algorithms for data compression",
  author  = "Jiang, J and Jones, S",
  journal = "Communications, Speech and Vision",
  volume  =  139,
  pages   = "582--586",
  year    =  1992,
  issn    = "0956-3776",
  doi     = "10.1049/ip-i-2.1992.0078"
}

@TECHREPORT{Mikolov2012-yb,
  title  = "Subword language modeling with neural networks",
  author = "Mikolov, Tom{\'a}{\v s} and Sutskever, I and Deoras, A and Le, H S
            and Kombrink, S and Cernocky, J",
  year   =  2012
}

@PHDTHESIS{Volf2002-gw,
  title  = "Weighting techniques in data compression theory and algorithms",
  author = "Volf, P",
  year   =  2002,
  school = "Technische Universiteit Eindhoven"
}

@INPROCEEDINGS{Mikolov2011-xa,
  title     = "Strategies for training large scale neural network language
               models",
  booktitle = "2011 {\{IEEE\}} Workshop on Automatic Speech Recognition and
               Understanding, {\{ASRU\}} 2011, Proceedings",
  author    = "Mikolov, Tom{\'a}{\v s} and Deoras, Anoop and Povey, Daniel and
               Burget, Luk{\'a}{\v s} and {\v C}ernock{\'y}, Jan",
  abstract  = "We describe how to effectively train neural network based
               language models on large data sets. Fast convergence during
               training and better overall performance is observed when the
               training data are sorted by their relevance. We introduce
               hash-based implementation of a maximum entropy model, that can
               be trained as a part of the neural network model. This leads to
               significant reduction of computational complexity. We achieved
               around 10\% relative reduction of word error rate on English
               Broadcast News speech recognition task, against large 4-gram
               model trained on 400M tokens.",
  pages     = "196--201",
  year      =  2011,
  isbn      = "9781467303675",
  doi       = "10.1109/ASRU.2011.6163930"
}

@ARTICLE{Mahoney2005-el,
  title    = "Adaptive weighing of context models for lossless data compression",
  author   = "Mahoney, Matthew V",
  abstract = "Until recently the state of the art in lossless data compression
              was prediction by partial match (PPM). A PPM model estimates the
              next-symbol probability distribution by combining statistics from
              the longest matching contiguous contexts in which each symbol
              value is found. We introduce a context mixing model which
              improves on PPM by allowing contexts which are arbitrary
              functions of the history. Each model independently estimates a
              probability and confidence that the next bit of data will be 0 or
              1. Predictions are combined by weighted averaging. After a bit is
              arithmetic coded, the weights are adjusted along the cost
              gradient in weight space to favor the most accurate models.
              Context mixing compressors, as implemented by the open source PAQ
              project, are now top ranked on several independent benchmarks.",
  journal  = "Florida Institute of Technology Melbourne, USA",
  volume   = "CS-2005-16",
  pages    = "1--6",
  year     =  2005
}

@ARTICLE{Begleiter2004-ql,
  title    = "On prediction using variable order Markov models",
  author   = "Begleiter, Ron and El-Yaniv, Ran and Yona, Golan",
  abstract = "This paper is concerned with algorithms for prediction of
              discrete sequences over a finite alphabet, using variable order
              Markov models. The class of such algorithms is large and in
              principle includes any lossless compression algorithm. We focus
              on six prominent prediction algorithms, including Context Tree
              Weighting (CTW), Prediction by Partial Match (PPM) and
              Probabilistic Suffix Trees (PSTs). We discuss the properties of
              these algorithms and compare their performance using real life
              sequences from three domains: proteins, English text and music
              pieces. The comparison is made with respect to prediction quality
              as measured by the average log-loss. We also compare
              classification algorithms based on these predictors with respect
              to a number of large protein classification tasks. Our results
              indicate that a ``decomposed '' CTW (a variant of the CTW
              algorithm) and PPM outperform all other algorithms in sequence
              prediction tasks. Somewhat surprisingly, a different algorithm,
              which is a modification of the Lempel-Ziv compression algorithm,
              significantly outperforms all algorithms on the protein
              classification problems. 1.",
  journal  = "The journal of artificial intelligence research",
  volume   =  22,
  pages    = "385--421",
  year     =  2004,
  issn     = "1076-9757",
  doi      = "10.1613/jair.1491"
}

@INPROCEEDINGS{Mikolov2012-xz,
  title     = "Context dependent recurrent neural network language model",
  booktitle = "{IEEE} Workshop on Spoken Language Technology ({SLT})",
  author    = "Mikolov, Tomas and Zweig, Geoffrey",
  abstract  = "Recurrent neural network language models (RNNLMs) have recently
               demonstrated state-of-the-art performance across a variety of
               tasks. In this paper, we improve their performance by providing
               a contextual real-valued input vector in association with each
               word. This vector is used to convey contextual information about
               the sentence being modeled. By performing Latent Dirichlet
               Allocation using a block of preceding text, we achieve a
               topic-conditioned RNNLM. This approach has the key advantage of
               avoiding the data fragmentation associated with building
               multiple topic models on different data subsets. We report
               perplexity results on the Penn Treebank data, where we achieve a
               new state-of-the-art.We further apply the model to the Wall
               Street Journal speech recognition task, where we observe
               improvements in word-error-rate.",
  pages     = "234--239",
  year      =  2012,
  keywords  = "Latent Dirichlet Allocation; language modelling; recurrent
               neural networks; topic models",
  isbn      = "9781467351263",
  doi       = "10.1109/SLT.2012.6424228"
}

@INPROCEEDINGS{Sundermeyer2013-og,
  title     = "Comparison of feedforward and recurrent neural network language
               models",
  booktitle = "{\{ICASSP\}}, {\{IEEE} \}International Conference on Acoustics,
               Speech and Signal Processing - Proceedings",
  author    = "Sundermeyer, M and Oparin, I and Gauvain, J L and Freiberg, B
               and Schluter, R and Ney, H",
  abstract  = "Research on language modeling for speech recognition has
               increasingly focused on the application of neural networks. Two
               competing concepts have been developed: On the one hand,
               feedforward neural networks representing an n-gram approach, on
               the other hand recurrent neural networks that may learn context
               dependencies spanning more than a fixed number of predecessor
               words. To the best of our knowledge, no comparison has been
               carried out between feedforward and state-of-the-art recurrent
               networks when applied to speech recognition. This paper analyzes
               this aspect in detail on a well-tuned French speech recognition
               task. In addition, we propose a simple and efficient method to
               normalize language model probabilities across different
               vocabularies, and we show how to speed up training of recurrent
               neural networks by parallelization. \copyright{} 2013 IEEE.",
  pages     = "8430--8434",
  year      =  2013,
  keywords  = "Automatic speech recognition; feedforward neural networks;
               recurrent neural networks",
  issn      = "1520-6149",
  isbn      = "9781479903566",
  doi       = "10.1109/ICASSP.2013.6639310"
}

@ARTICLE{Witten1998-zb,
  title  = "Text mining: A new frontier for lossless compression",
  author = "Witten, Ian H and Bray, Zane and Mahoui, Malika and Teahan, Bill",
  year   =  1998
}

@INCOLLECTION{Crocker2005-sq,
  title     = "Probabilistic grammars as models of gradience in language
               processing",
  booktitle = "Gradience in Grammar: Generative Perspectives",
  author    = "Crocker, Matthew W and Keller, Frank",
  editor    = "Fanselow, G and F{\'e}ry, C and Vogel, R and Schlesewsky, M",
  publisher = "Oxford University Press",
  pages     = "227--245",
  year      =  2005,
  address   = "Oxford, England",
  keywords  = "Gradience; Grammaticality; Language processing; Probabilistic
               grammar; Psycholinguistics; Sentence processing"
}

@INPROCEEDINGS{Clark2013-lv,
  title     = "Towards a statistical model of grammaticality",
  booktitle = "Proceedings of the 35th Annual Conference of the Cognitive
               Science Society",
  author    = "Clark, Alexander and Giorgolo, Gianluca and Lappin, Shalom",
  pages     = "2064--2069",
  year      =  2013
}

@INPROCEEDINGS{Tetreault2008-ob,
  title     = "The ups and downs of preposition error detection in {ESL}
               writing",
  booktitle = "Proceedings of the 22nd International Conference on
               Computational Linguistics (Coling 2008)",
  author    = "Tetreault, Joel R and Chodorow, Martin",
  abstract  = "In this paper we describe a methodology for detecting
               preposition errors in the writ- ing of non-native English
               speakers. Our system performs at 84\% precision and close to
               19\% recall on a large set of stu- dent essays. In addition, we
               address the problem of annotation and evaluation in this domain
               by showing how current ap- proaches of using only one rater can
               skew system evaluation. We present a sampling approach to
               circumvent some of the issues that complicate evaluation of
               error detec- tion systems.",
  pages     = "865--872",
  year      =  2008,
  isbn      = "9781905593446",
  doi       = "10.3115/1599081.1599190"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Han2006-zy,
  title    = "Detecting errors in English article usage by non-native speakers",
  author   = "Han, Na-Rae and Chodorow, Martin and Leacock, Claudia",
  abstract = "One of the most diﬃcult challenges faced by non-native speakers
              of English is mastering the system of English articles. We
              trained a maximum entropy classiﬁer to select among a/an, the, or
              zero article for noun phrases (NPs), based on a set of features
              extracted from the local context of each. When the classiﬁer was
              trained on 6 million NPs, its performance on published text was
              about 83\% correct. We then used the classiﬁer to detect article
              errors in the TOEFL essays of native speakers of Chinese,
              Japanese, and Russian. These writers made such errors in about
              one out of every eight NPs, or almost once in every three
              sentences. The classiﬁer's agreement with human annotators was
              85\% (kappa = 0.48) when it selected among a/an, the, or zero
              article. Agreement was 89\% (kappa = 0.56) when it made a binary
              (yes/no) decision about whether the NP should have an article.
              Even with these levels of overall agreement, precision and recall
              in error detection were only 0.52 and 0.80, respectively.
              However, when the classiﬁer was allowed to skip cases where its
              conﬁdence was low, precision rose to 0.90, with 0.40 recall.
              Additional improvements in performance may require features that
              reﬂect general knowledge to handle phenomena such as indirect
              prior reference. In August 2005, the classiﬁer was deployed as a
              component of Educational Testing Service's Criterion S M Online
              Writing Evaluation Service.",
  journal  = "Natural Language Engineering",
  volume   =  12,
  number   =  2,
  pages    = "115--129",
  year     =  2006,
  issn     = "1351-3249",
  doi      = "10.1017/S1351324906004190"
}

@ARTICLE{Kennington2012-vq,
  title    = "Suffix Trees as Language Models",
  author   = "Kennington, Casey Redd and Kay, Martin and Friedrich, Annemarie",
  abstract = "Suffix trees are data structures that can be used to index a
              corpus. In this paper, we explore how some properties of suffix
              trees naturally provide the functionality of an n-gram language
              model with variable n. We explain how we leverage these
              properties of suffix trees for our Suffix Tree Language Model
              (STLM) implementation and explain how a suffix tree implicitly
              contains the data needed for n-gram language modeling. We also
              discuss the kinds of smoothing techniques appropriate to such a
              model. We then show that our STLM implementation is competitive
              when compared to the state-of-the-art language model SRILM
              (Stolcke, 2002) in statistical machine translation (SMT)
              experiments.",
  journal  = "Proceedings of the Eight International Conference on Language
              Resources and Evaluation (LREC). Istanbul, Turkey",
  number   = "February 2012",
  pages    = "446--453",
  year     =  2012,
  keywords = "language model; machine translation; suffix tree"
}

@ARTICLE{Dellarocas2008-ok,
  title   = "Exploring the value of online product reviews in forecasting
             sales: The case of motion pictures",
  author  = "Dellarocas, Chrysanthos and Zhang, Xiaoquan and Awad, Neveen F",
  journal = "Journal of Interactive Marketing",
  volume  =  21,
  number  =  4,
  pages   = "23--45",
  year    =  2008
}

@PHDTHESIS{Kulkarni2010-uo,
  title  = "Using online search data to forecast new product sales",
  author = "Kulkarni, Gauri M",
  year   =  2010,
  school = "University of Maryland, College Park"
}

@ARTICLE{Yu2012-xw,
  title    = "Mining online reviews for predicting sales performance: A case
              study in the movie domain",
  author   = "Yu, Xiaohui and Liu, Yang and Huang, Xiangji and An, Aijun",
  abstract = "Posting reviews online has become an increasingly popular way for
              people to express opinions and sentiments toward the products
              bought or services received. Analyzing the large volume of online
              reviews available would produce useful actionable knowledge that
              could be of economic values to vendors and other interested
              parties. In this paper, we conduct a case study in the movie
              domain, and tackle the problem of mining reviews for predicting
              product sales performance. Our analysis shows that both the
              sentiments expressed in the reviews and the quality of the
              reviews have a significant impact on the future sales performance
              of products in question. For the sentiment factor, we propose
              Sentiment PLSA (S-PLSA), in which a review is considered as a
              document generated by a number of hidden sentiment factors, in
              order to capture the complex nature of sentiments. Training an
              S-PLSA model enables us to obtain a succinct summary of the
              sentiment information embedded in the reviews. Based on S-PLSFA,
              we propose ARSA, an Autoregressive Sentiment-Aware model for
              sales prediction. We then seek to further improve the accuracy of
              prediction by considering the quality factor, with a focus on
              predicting the quality of a review in the absence of
              user-supplied indicators, and present ARSQA, an Autoregressive
              Sentiment and Quality Aware model, to utilize sentiments and
              quality for predicting product sales performance. Extensive
              experiments conducted on a large movie data set confirm the
              effectiveness of the proposed approach.",
  journal  = "IEEE transactions on knowledge and data engineering",
  volume   =  24,
  number   =  4,
  pages    = "720--734",
  year     =  2012,
  keywords = "Review mining; prediction; sentiment analysis",
  issn     = "1041-4347",
  doi      = "10.1109/TKDE.2010.269"
}

@INPROCEEDINGS{Dellarocas2004-br,
  title     = "Exploring the value of online reviews to organizations:
               Implications for revenue forecasting and planning",
  booktitle = "Icis 2004 Proceedings",
  author    = "Dellarocas, Chrysanthos and Awad, Neveen F and Zhang, Xiaoquan",
  abstract  = "Despite the widespread popularity of online opinion forums among
               consumers, the business value that such systems bring to
               organizations has, so far, remained an unanswered question. This
               paper addresses this question by studying the value of online
               movie ratings in forecasting motion picture revenues. First, we
               conduct a survey where a nationally representative sample of
               subjects who do not rate movies online is asked to rate a number
               of recent movies. Their ratings exhibit high correlation with
               online ratings for the same movies. We thus provide evidence for
               the claim that online ratings can be considered as a useful
               proxy for word-of-mouth about movies. Inspired by the Bass model
               of product diffusion, we then develop a motion picture
               revenue-forecasting model that incorporates the impact of both
               publicity and word of mouth on a movies revenue trajectory.
               Using our model, we derive notably accurate predictions of a
               movies total revenues from statistics of user reviews posted on
               Yahoo! Movies during the first week of a new movies release. The
               results of our work provide encouraging evidence for the value
               of publicly available online forum information to firms for
               real-time forecasting and competitive analysis.",
  year      =  2004,
  issn      = "1094-9968",
  doi       = "10.1002/dir.20087"
}

@ARTICLE{Navarro2001-yh,
  title    = "A guided tour to approximate string matching",
  author   = "Navarro, Gonzalo",
  abstract = "We survey the current techniques to cope with the problem of
              string matching allowing errors. This is becoming a more and more
              relevant issue for many fast growing areas such as information
              retrieval and computational biology. We focus on online
              searching, explaining the problem and its relevance, its
              statistical behavior, its history and current developments, and
              the central ideas of the algorithms and their complexities. We
              present a number of experiments to compare the performance of the
              different algorithms and show which are the best choices
              according to each case. We conclude with some future work
              directions and open problems.",
  journal  = "ACM Computing Surveys",
  volume   =  33,
  number   =  1,
  pages    = "31--88",
  year     =  2001,
  issn     = "0360-0300",
  doi      = "10.1145/375360.375365"
}

@ARTICLE{Levandowsky1971-mo,
  title   = "Distance between sets",
  author  = "Levandowsky, M and Winter, D",
  journal = "Nature",
  volume  =  234,
  number  =  5323,
  pages   = "34--35",
  year    =  1971,
  issn    = "0028-0836"
}

@MISC{Lisacek2000-ye,
  title    = "Algorithms on Strings, Trees and Sequences",
  author   = "Lisacek, Frederique",
  abstract = "Describes a range of string problems in computer science and
              molecular biology and the algorithms developed to solve them.",
  journal  = "Computers \& Chemistry",
  volume   =  24,
  number   =  1,
  pages    = "135--137",
  year     =  2000,
  issn     = "0097-8485",
  isbn     = "9780511574931",
  doi      = "10.1016/S0097-8485(00)80014-5"
}

@ARTICLE{Davis-Stober2014-ur,
  title   = "When is a crowd wise?",
  author  = "Davis-Stober, Clintin P and Budescu, David V and Dana, Jason and
             Broomell, S B",
  journal = "Decisions",
  volume  =  1,
  number  =  2,
  pages   = "1--4",
  year    =  2014
}

@INPROCEEDINGS{Schenk2009-lk,
  title     = "Crowdsourcing: What can be outsourced to the crowd, and why?",
  booktitle = "Workshop on Open Source Innovation",
  author    = "Schenk, Eric and Guittard, Claude",
  abstract  = "Why should a firm outsource certain activities in countries
               where labor is inexpensive, when by using the Internet, firms
               are a mouse click away from an eclectic, university educated,
               population ready to invest in intellectually stimulating
               projects for little or no remuneration The word Crowdsourcing a
               compound contraction of Crowd and Outsourcing, was used by Howe
               in order to define outsourcing to the crowd. Beyond cost,
               benefits for the company can be substantial. It can externalize
               the risk of failure and it only pays for products or services
               that meet its expectations. The aim of this paper is to
               characterize Crowdsourcing from a management science
               perspective. Our approach is mainly theoretical, although we
               rely on extensive illustrations. First we discuss the definition
               of Crowdsourcing, and provide examples that illustrate the
               diversity of Crowdsourcing practices. Then, we present
               similarities and differences between Crowdsourcing and
               established theories (Open Innovation, User Innovation) and a
               phenomenon that has inspired many studies in Economics and
               Management, Open Source Software. Our goal is to avoid future
               misunderstandings and to show that Crowdsourcing is a concept
               per se. Finally, we propose and illustrate a typology of
               Crowdsourcing practices based on two criteria: the integrative
               or selective nature of the process and the type of tasks that
               are crowdsourced (routine, complex and creative tasks). In
               either case, the client firm seeks to mobilize external
               competencies. Relying upon the crowd can be an adequate method,
               because of its unique characteristics that are fostered by the
               Internet.",
  pages     = "1--29",
  year      =  2009,
  address   = "Strasbourg, France",
  keywords  = "Crowdsourcing; Open Source: Open Innovation; User Innovation;
               Web 2.0"
}

@ARTICLE{Estelles_Arolas2012-zs,
  title   = "Towards an integrating crowdsourcing definition",
  author  = "Estelles Arolas, E and Gonz{\'a}lez-Ladr{\'o}n-De-Guevara, F",
  journal = "Journal of Information Science and Engineering",
  volume  =  32,
  number  =  2,
  pages   = "189--200",
  year    =  2012,
  issn    = "1016-2364, 0165-5515"
}

@ARTICLE{Servan-Schreiber2004-vg,
  title    = "Prediction markets: Does money matter?",
  author   = "Servan-Schreiber, Emile and Wolfers, Justin and Pennock, David M
              and Galebach, Brian",
  abstract = "The accuracy of prediction markets has been documented both for
              markets based on real money and those based on play money. To
              test how much extra accuracy can be obtained by using real money
              versus play money, we set up a real?world online experiment
              pitting the predictions of TradeSports.com (real money) against
              those of NewsFutures.com (play money) regarding American Football
              outcomes during the 2003?2004 NFL season. As expected, both types
              of markets exhibited significant predictive powers, and
              remarkable performance compared to individual humans. But,
              perhaps surprisingly, the play?money markets performed as well as
              the real?money markets. We speculate that this result reflects
              two opposing forces: real?money markets may better motivate
              information discovery while play?money markets may yield more
              efficient information aggregation. The accuracy of prediction
              markets has been documented both for markets based on real money
              and those based on play money. To test how much extra accuracy
              can be obtained by using real money versus play money, we set up
              a real?world online experiment pitting the predictions of
              TradeSports.com (real money) against those of NewsFutures.com
              (play money) regarding American Football outcomes during the
              2003?2004 NFL season. As expected, both types of markets
              exhibited significant predictive powers, and remarkable
              performance compared to individual humans. But, perhaps
              surprisingly, the play?money markets performed as well as the
              real?money markets. We speculate that this result reflects two
              opposing forces: real?money markets may better motivate
              information discovery while play?money markets may yield more
              efficient information aggregation.",
  journal  = "Electronic Markets",
  volume   =  14,
  number   =  3,
  pages    = "243--251",
  year     =  2004,
  keywords = "forecasts; newsfutures; play-money; prediction markets;
              tradesports",
  issn     = "1019-6781",
  pmid     = "17320118",
  doi      = "10.1080/1019678042000245254"
}

@INPROCEEDINGS{Thiesing1997-oz,
  title  = "Sales forecasting using neural networks",
  author = "Thiesing, Frank M and Vornberger, Oliver",
  volume =  4,
  year   =  1997
}

@ARTICLE{Spann2003-eb,
  title    = "Internet-based virtual stock markets for business forecasting",
  author   = "Spann, Martin and Skiera, Bernd",
  abstract = "The application of Internet-based virtual stock markets (VSMs) is
              an additional approach that can be used to predict short- and
              medium-term market developments.The basic concept involves
              bringing a group of participants together via the Internet and
              allowing them to trade shares of virtual stocks.These stocks
              represent a bet on the outcome of future mar- ket situations, and
              their value depends on the realization of these market
              situations.In this process, a VSM elicits and aggregates the
              assessments of its participants concerning future market
              developments.The aim of this article is to evaluate the potential
              use and the different design possibilities as well as the
              forecast accuracy and performance of VSMs compared to expert
              predictions for their application to business forecasting.After
              introducing the basic idea of using VSMs for business
              forecasting, we discuss the different design possibilities for
              such VSMs.In three real-world applications, we analyze the
              feasibility and forecast accuracy of VSMs, compare the
              performance of VSMs to expert predictions, and propose a new
              valid- ity test for VSM forecasts.Finally, we draw conclusions
              and provide suggestions for future research.",
  journal  = "Management science",
  volume   =  49,
  number   = "January 2015",
  pages    = "1310--1326",
  year     =  2003,
  issn     = "0025-1909",
  pmid     = "11190955",
  doi      = "10.1287/mnsc.49.10.1310.17314"
}

@UNPUBLISHED{Chen2002-av,
  title    = "Information aggregation mechanisms: concept, design and field
              implementation",
  author   = "Chen, K Y and Plott, C R",
  journal  = "California Institute of Technology Social Science Working Paper",
  number   = "April",
  year     =  2002,
  keywords = "Alpha"
}

@ARTICLE{Ho2007-et,
  title   = "New product blockbusters: The magic and science of prediction
             markets",
  author  = "Ho, Teck-Hua and Chen, Kay-Yut",
  journal = "California management review",
  volume  =  50,
  number  =  1,
  pages   = "144--158",
  year    =  2007,
  issn    = "0008-1256",
  doi     = "10.2307/41166420"
}

@INPROCEEDINGS{Peter2012-nu,
  title     = "{ARIMA} vs. {ARIMAX} -- which approach is better to analyze and
               forecast macroeconomic time series?",
  booktitle = "Proceedings of 30th International Conference Mathematical
               Methods in Economics",
  author    = "Peter, {\v D} and Silvia, Pastorekov{\'a}",
  pages     = "136--140",
  year      =  2012
}

@ARTICLE{Tian2014-nb,
  title    = "Pre-release sales forecasting: A model-driven context feature
              extraction approach",
  author   = "Tian, C H and Wang, Y and Mo, W T and Huang, F C and Dong, W S
              and Huang, J",
  abstract = "Social media can be a potential data source in new product
              pre-release sales forecasting. However, the relationship is not
              straightforward because sales volume is the result of the
              interaction between different context entities. To reveal the
              important hidden dimensions from the structural relationships
              between context entities, we propose a model-driven feature
              extraction approach. Based on the semantic entity relationship
              model, middle-level features can be automatically generated
              through predefined primitive features with respect to typical
              structural relationships. Then, spatio-temporal analytics is
              applied in feature selection for sales forecasting models. The
              proposed technical approach is verified in movie box-office
              forecasting for a leading cinema chain in China.",
  journal  = "IBM Journal of Research and Development",
  volume   =  58,
  number   = "5/6",
  pages    = "8:1--8:13",
  year     =  2014,
  keywords = "China; Context modeling; Feature extraction; Forecasting; Market
              research; Motion pictures; Sales and marketing; Semantics; Social
              network services",
  issn     = "0018-8646",
  doi      = "10.1147/JRD.2014.2344531"
}

@MISC{Kotz2003-ns,
  title    = "{IEEE} Xplore {Full-Text} {PDF}",
  author   = "K{\"o}tz, Benjamin and Schaepman, Michael and Morsdorf, Felix and
              Bowyer, Paul and Itten, Klaus and Allg{\"o}wer, Britta",
  abstract = "Abstract--- A concept has been developed for a nextgeneration
              integrated countermeasure architecture to detect improvised
              explosive devices hidden on people or left behind in unstructured
              crowds. The work is part of the Standoff Technology Integration
              and ... \textbackslashn",
  journal  = "Geoscience and Remote Sensing Symposium, 2003. IGARSS '03.
              Proceedings. 2003 IEEE International",
  volume   =  4,
  pages    = "2869--2871",
  year     =  2003,
  isbn     = "9780780364950",
  doi      = "10.1109/NOMS.2002.1015622"
}

@BOOK{Hamilton1994-eb,
  title     = "Time series analysis",
  author    = "Hamilton, J D",
  publisher = "Princeton University Press",
  year      =  1994,
  address   = "Princeton, NJ"
}

@ARTICLE{Frank2003-aa,
  title    = "Forecasting women's apparel sales using mathematical modeling",
  author   = "Frank, Celia and Garg, Ashish and Raheja, Amar and Sztandera, Les",
  journal  = "International Journal of Clothing Science and Technology",
  volume   =  15,
  number   =  2,
  pages    = "107--125",
  year     =  2003,
  keywords = "abstract traditionally; apparel; ar; are more; are used for
              forecasting; auto-; computing; environment where the sales;
              forecasting; future sales only on; like moving average; ma;
              modelling; or combinations of them; regression; sales; since
              these models predict; statistical time series methods; the basis
              of previous; they fail in an; time series",
  issn     = "0955-6222",
  doi      = "10.1108/09556220310470097"
}

@BOOK{Pankratz1983-ty,
  title     = "Forecasting with univariate {Box-Jenkins} models: Concepts and
               cases",
  author    = "Pankratz, Alan",
  publisher = "John Wiley \& Sons",
  year      =  1983,
  address   = "Oxford, England"
}

@ARTICLE{Holt2004-ow,
  title    = "Forecasting seasonals and trends by exponentially weighted moving
              averages",
  author   = "Holt, Charles C",
  abstract = "The paper provides a systematic development of the forecasting
              expressions for exponential weighted moving averages. Methods for
              series with no trend, or additive or multiplicative trend are
              examined. Similarly, the methods cover non-seasonal, and seasonal
              series with additive or multiplicative error structures. The
              paper is a reprinted version of the 1957 report to the Office of
              Naval Research (ONR 52) and is being published here to provide
              greater accessibility. ?? 2004 Published by Elsevier B.V. on
              behalf of International Institute of Forecasters.",
  journal  = "International journal of forecasting",
  volume   =  20,
  number   =  1,
  pages    = "5--10",
  year     =  2004,
  keywords = "Exponential smoothing; Forecasting; Local seasonals; Local trends",
  issn     = "0169-2070",
  pmid     = "21272410",
  doi      = "10.1016/j.ijforecast.2003.09.015"
}

@BOOK{Gardner2006-wh,
  title    = "Exponential smoothing: The state of the art -- Part {II}",
  author   = "Gardner, E S",
  abstract = "In Gardner [Gardner, E. S., Jr. (1985). Exponential smoothing:
              The state of the art. Journal of Forecasting, 4, 1--28], I
              reviewed the research in exponential smoothing since the original
              work by Brown and Holt. This paper brings the state of the art up
              to date. The most important theoretical advance is the invention
              of a complete statistical rationale for exponential smoothing
              based on a new class of state-space models with a single source
              of error. The most important practical advance is the development
              of a robust method for smoothing damped multiplicative trends. We
              also have a new adaptive method for simple smoothing, the first
              such method to demonstrate credible improved forecast accuracy
              over fixed-parameter smoothing. Longstanding confusion in the
              literature about whether and how to renormalize seasonal indices
              in the Holt--Winters methods has finally been resolved. There has
              been significant work in forecasting for inventory control,
              including the development of new predictive distributions for
              total lead-time demand and several improved versions of Croston's
              method for forecasting intermittent time series. Regrettably,
              there has been little progress in the identification and
              selection of exponential smoothing methods. The research in this
              area is best described as inconclusive, and it is still difficult
              to beat the application of a damped trend to every time series.",
  volume   =  22,
  pages    = "637--666",
  year     =  2006,
  keywords = "arima; comparative methods; discount weighted; evaluation;
              exponential smoothing; identification; intermittent demand;
              inventory control; invertibility; kernel; model selection;
              prediction intervals; regression; stability; state-space models;
              time series",
  issn     = "0169-2070",
  isbn     = "9787137434946",
  doi      = "10.1016/j.ijforecast.2006.03.005"
}

@ARTICLE{Liu2013-ov,
  title  = "Sales Forecasting for Fashion Retailing Service Industry : A Review
            Sales Forecasting for Fashion Retailing Service Industry : A Review",
  author = "Liu, Na and Choi, Tsan-Ming and Hui, Chi-Leung and Ng, Sau-Fun",
  volume =  2013,
  pages  = "1--23",
  year   =  2013
}

@ARTICLE{Sun2008-ri,
  title    = "Sales forecasting using extreme learning machine with
              applications in fashion retailing",
  author   = "Sun, Zhan-Li and Choi, Tsan-Ming and Au, Kin-Fan and Yu, Yong",
  abstract = "Sales forecasting is a challenging problem owing to the
              volatility of demand which depends on many factors. This is
              especially prominent in fashion retailing where a versatile sales
              forecasting system is crucial. This study applies a novel neural
              network technique called extreme learning machine (ELM) to
              investigate the relationship between sales amount and some
              significant factors which affect demand (such as design factors).
              Performances of our models are evaluated by using real data from
              a fashion retailer in Hong Kong. The experimental results
              demonstrate that our proposed methods outperform several sales
              forecasting methods which are based on backpropagation neural
              networks. \copyright{} 2008 Elsevier B.V. All rights reserved.",
  journal  = "Decision support systems",
  volume   =  46,
  number   =  1,
  pages    = "411--419",
  year     =  2008,
  keywords = "Artificial neural network; Backpropagation neural networks;
              Decision support system; Extreme learning machine; Fashion sales
              forecasting",
  issn     = "0167-9236",
  doi      = "10.1016/j.dss.2008.07.009"
}

@ARTICLE{Fildes2008-tk,
  title    = "Forecasting and operational research: a review",
  author   = "Fildes, R and Nikolopoulos, K and Crone, S F and Syntetos,
              Argyrios",
  abstract = "From its foundation, operational research (OR) has made many
              substantial contributions to practical forecasting in
              organizations. Equally, researchers in other disciplines have
              influenced forecasting practice. Since the last survey articles
              in JORS, forecasting has developed as a discipline with its own
              journals. While the effect of this increased specialization has
              been a narrowing of the scope of OR's interest in forecasting,
              research from an OR perspective remains vigorous. OR has been
              more receptive than other disciplines to the specialist research
              published in the forecasting journals, capitalizing on some of
              their key findings. In this paper, we identify the particular
              topics of OR interest over the past 25 years. After a brief
              summary of the current research in forecasting methods, we
              examine those topic areas that have grabbed the attention of OR
              researchers: computationally intensive methods and applications
              in operations and marketing. Applications in operations have
              proved particularly important, including the management of
              inventories and the effects of sharing forecast information
              across the supply chain. The second area of application is
              marketing, including customer relationship management using data
              mining and computer-intensive methods. The paper concludes by
              arguing that the unique contribution that OR can continue to make
              to forecasting is through developing models that link the
              effectiveness of new forecasting methods to the organizational
              context in which the models will be applied. The benefits of
              examining the system rather than its separate components are
              likely to be substantial.",
  journal  = "The Journal of the Operational Research Society",
  volume   =  59,
  number   =  1,
  pages    = "1150--1172",
  year     =  2008,
  keywords = "HB Economic Theory; HD Industries. Land use. Labor",
  issn     = "0160-5682",
  doi      = "10.1057/palgrave.jors.2602597"
}

@ARTICLE{Lawrence2006-mf,
  title    = "Judgmental forecasting: A review of progress over the last 25
              years",
  author   = "Lawrence, Michael and Goodwin, Paul and O'Connor, Marcus and
              {\"O}nkal, Dilek",
  abstract = "The past 25 years has seen phenomenal growth of interest in
              judgemental approaches to forecasting and a significant change of
              attitude on the part of researchers to the role of judgement.
              While previously judgement was thought to be the enemy of
              accuracy, today judgement is recognised as an indispensable
              component of forecasting and much research attention has been
              directed at understanding and improving its use. Human judgement
              can be demonstrated to provide a significant benefit to
              forecasting accuracy but it can also be subject to many biases.
              Much of the research has been directed at understanding and
              managing these strengths and weaknesses. An indication of the
              explosion of research interest in this area can be gauged by the
              fact that over 200 studies are referenced in this review. ?? 2006
              International Institute of Forecasters.",
  journal  = "International journal of forecasting",
  volume   =  22,
  number   =  3,
  pages    = "493--518",
  year     =  2006,
  keywords = "Domain knowledge; Forecasting; Improving judgement forecasts;
              Judgement; Prediction intervals; Probability forecasts; Review",
  issn     = "0169-2070",
  doi      = "10.1016/j.ijforecast.2006.03.007"
}

@ARTICLE{Ivanov2009-sk,
  title    = "Using prediction markets to harness collective wisdom for
              forecasting",
  author   = "Ivanov, Aleksandar",
  abstract = "The article focuses on the use of prediction markets (PM) method
              in generating sales forecasts. It notes that under the said
              method, forecast is represented by the price of a virtual stock.
              Moreover, to arrive at a good PM forecast, it suggests to
              consider participants who are knowledgeable about what to
              forecast",
  journal  = "Journal of Business Forecasting Methods and Systems",
  volume   =  28,
  number   =  3,
  pages    = "9--14",
  year     =  2009,
  issn     = "0278-6087"
}

@ARTICLE{Morwitz2007-nb,
  title    = "When do purchase intentions predict sales?",
  author   = "Morwitz, Vicki G and Steckel, Joel H and Gupta, Alok",
  abstract = "Marketing managers routinely use purchase intentions to predict
              sales. The purpose of this paper is to identify the factors
              associated with an increased or decreased correlation between
              purchase intentions and actual purchasing. Using two studies, we
              examine the data collected from a wide range of different
              settings which reflect the real world diversity in how intentions
              studies are conducted. The results indicate that intentions are
              more correlated with purchases: 1) for existing products than for
              new ones; 2) for durable goods than for non-durable goods; 3) for
              short than for long time horizons; 4) when respondents are asked
              to provide intentions to purchase specific brands or models than
              when they are asked to provide intentions to buy at the product
              category level; 5) when purchases are measured in terms of trial
              rates than when they are measured in terms of total market sales;
              and 6) when purchase intentions are collected in a comparative
              mode than when they are collected monadically. ?? 2007
              International Institute of Forecasters.",
  journal  = "International journal of forecasting",
  volume   =  23,
  number   =  3,
  pages    = "347--364",
  year     =  2007,
  keywords = "Marketing research; Meta-analysis; Purchase intentions; Sales
              forecasting",
  issn     = "0169-2070",
  doi      = "10.1016/j.ijforecast.2007.05.015"
}

@ARTICLE{Armstrong2000-xj,
  title    = "Sales forecasts for existing consumer products and services: Do
              purchase intentions contribute to accuracy?",
  author   = "Armstrong, J Scott and Morwitz, Vicki G",
  abstract = "Purchase intentions are routinely used to forecast sales of
              existing products and services. While past studies have shown
              that intentions are predictive of sales, they have only examined
              the absolute accuracy of intentions, not their accuracy relative
              to other forecasting methods. For example, no research has been
              able to demonstrate that intentions-based forecasts can improve
              upon a simple extrapolation of past sales trends. We examined the
              relative accuracy of four methods that forecast sales from
              intentions.We tested these methods using four data sets involving
              different products and time horizons; one of French automobile
              sales, two of US automobile sales, and one of US wireless
              services. For all four products and time horizons, each of the
              four intentions-based forecasting methods was more accurate than
              an extrapolation of past sales. Combinations of these forecasting
              methods using equal weights lead to even greater accuracy, with
              error rates about one-third lower than extrapolations of past
              sales. Thus, it appears that purchase intentions can provide
              better forecasts than a simple extrapolation of past sales
              trends. While the evidence from the current study contradicts the
              findings of an earlier study, the consistency of the results in
              our study suggest that intentions are a valuable input to sales
              forecasts. {\'O} 2000 Elsevier Science B.V. All rights reserved.",
  journal  = "International journal of forecasting",
  volume   =  16,
  pages    = "383--397",
  year     =  2000,
  keywords = "combining; expectations; extrapolation; intentions; purchase
              probabilities",
  issn     = "0169-2070",
  doi      = "10.1016/S0169-2070(00)00058-3"
}

@ARTICLE{Urban1996-fj,
  title    = "Premarket Forecasting of {Really-New} Products",
  author   = "Urban, Glen L and Weinberg, Bruce D and Hauser, John R",
  abstract = "The authors illustrate how a firm can face the challenge of
              forecasting consumer reaction for a really-new product. For the
              case of an electric vehicle, the authors describe how one firm
              combines managerial judgment and state-of-the-art market
              measurement to determine whether (1) the really-new product would
              be a viable business venture at its target launch date, (2) the
              firm should plan for improvements in technology that would reduce
              price and/or increase benefits enough so that the business
              venture would be profitable, or (3) the firm should stop
              development. The new market measurement system combines existing
              methods with a multimedia virtual-buying environment that
              conditions respondents for future situations, simulates user
              experience, and encourages consumers to actively search for
              information on the product. The authors comment on the advantages
              and disadvantages of the methodology and summarize the lessons
              they have learned from this application.",
  journal  = "Journal of marketing",
  volume   =  60,
  number   =  1,
  pages    = "47--60",
  year     =  1996,
  issn     = "0022-2429",
  doi      = "10.2307/1251887"
}

@ARTICLE{Warshaw1980-gj,
  title   = "Predicting purchase and other behaviors from general and
             contextually specific intentions",
  author  = "Warshaw, Paul R",
  journal = "JMR, Journal of marketing research",
  volume  =  17,
  number  =  1,
  pages   = "26--33",
  year    =  1980,
  issn    = "0022-2437"
}

@ARTICLE{Sanders2003-bn,
  title   = "Forecasting software in practice: Use, satisfaction, and
             performance",
  author  = "Sanders, Nada R and Manrodt, Karl B",
  journal = "Interfaces",
  volume  =  33,
  number  =  5,
  pages   = "90--93",
  year    =  2003,
  issn    = "0092-2102"
}

@ARTICLE{Fildes2007-os,
  title   = "Against your better judgement? How organizations can improve their
             use of management judgement in forecasting",
  author  = "Fildes, Robert and Goodwin, Paul",
  journal = "Interfaces",
  volume  =  37,
  number  =  6,
  pages   = "570--576",
  year    =  2007,
  issn    = "0092-2102"
}

@INCOLLECTION{Rowe2001-ux,
  title     = "Expert opinions in forecasting: The role of the Delphi technique",
  booktitle = "Principles of Forecasting",
  author    = "Rowe, Gene and Wright, George",
  editor    = "Armstrong, J Scott",
  publisher = "Springer US",
  pages     = "125--144",
  year      =  2001,
  address   = "Boston: Kluwer Academic Publishers",
  keywords  = "delphi; expertise; interacting groups; statistical groups"
}

@ARTICLE{Gallimore2004-qv,
  title   = "Expert judgement in the processes of commercial property market
             forecasting",
  author  = "Gallimore, Paul and McAllister, Patrick",
  journal = "Journal of Property Research",
  volume  =  21,
  number  =  4,
  pages   = "337--360",
  year    =  2004,
  issn    = "0959-9916",
  doi     = "10.1080/09599910500163157"
}

@ARTICLE{Armstrong2006-aa,
  title    = "Findings from evidence-based forecasting: Methods for reducing
              forecast error",
  author   = "Armstrong, J Scott",
  abstract = "Empirical comparisons of reasonable approaches provide evidence
              on the best forecasting procedures to use under given conditions.
              Based on this evidence, I summarize the progress made over the
              past quarter century with respect to methods for reducing
              forecasting error. Seven well-established methods have been shown
              to improve accuracy: combining forecasts and Delphi help for all
              types of data; causal modeling, judgmental bootstrapping and
              structured judgment help with cross-sectional data; and causal
              models and trend-damping help with time series data. Promising
              methods for cross-sectional data include damped causality,
              simulated interaction, structured analogies, and judgmental
              decomposition; for time series data, they include segmentation,
              rule-based forecasting, damped seasonality, decomposition by
              causal forces, damped trend with analogous data, and damped
              seasonality. The testing of multiple hypotheses has also revealed
              methods where gains are limited: these include data mining,
              neural nets, and Box-Jenkins methods. Multiple hypotheses tests
              should be conducted on widely used but relatively untested
              methods such as prediction markets, conjoint analysis, diffusion
              models, and game theory. ?? 2006 International Institute of
              Forecasters.",
  journal  = "International journal of forecasting",
  volume   =  22,
  number   =  3,
  pages    = "583--598",
  year     =  2006,
  keywords = "Box-Jenkins; Causal forces; Causal models; Combining forecasts;
              Complex series; Conjoint analysis; Contrary series; Damped
              seasonality; Damped trend; Data mining; Delphi; Diffusion; Game
              theory; Judgmental decomposition; Multiple hypotheses; Neural
              nets; Prediction markets; Rule-based forecasting; Segmentation;
              Simulated interaction; Structured analogies",
  issn     = "0169-2070",
  doi      = "10.1016/j.ijforecast.2006.04.006"
}

@INCOLLECTION{Macgregor2001-pg,
  title     = "Decomposition for judgmental forecasting and estimation",
  booktitle = "Principles of Forecasting: A handbook for Researchers and
               Practitioners",
  author    = "Macgregor, Donald G",
  editor    = "Armstrong, J Scott",
  abstract  = "Forecasters often need to estimate uncertain quantities, but
               with limited time and resources. Decomposition is a method for
               dealing with such problems by breaking down (decomposing) the
               estimation task down into a set of components that can be more
               readily estimated, and then combining the component estimates to
               produce a target estimate. Estimators can effectively apply
               decomposition to either multiplicative or segmented forecasts,
               though multiplicative decomposition is especially sensitive to
               correlated errors in component values. Decomposition is most
               used for highly uncertain estimates, such as ones having a large
               numerical value (e.g., millions or more) or quantities in an
               unfamiliar metric. When possible, multiple estimations should be
               used and the results aggregated. In addition, multiple
               decompositions can be applied to the same estimation problem and
               the results resolved into a single estimate. Decomposition
               should be used only when the estimation can make component
               estimates more accurately or more confidently than the target
               estimate.",
  publisher = "Kluwer Academic Publishers",
  pages     = "1--14",
  year      =  2001,
  address   = "Norwell, MA",
  keywords  = "algorithmic decomposition; judgmental forecasting; numerical
               estimation",
  isbn      = "9780306476303"
}

@ARTICLE{Mccarthy2006-bb,
  title    = "The evolution of sales forecasting management: A 20-year
              longitudinal study of forecasting practices",
  author   = "Mccarthy, Teresa M and Davis, Donna F and Golicic, Susan L and
              Mentzer, John T",
  abstract = "This paper presents results of a survey designed to discover how
              sales fore- casting management practices have changed over the
              past 20 years as com- pared to findings reported by Mentzer and
              Cox (1984) and Mentzer and Kahn (1995). An up-to-date overview of
              empirical studies on forecasting practice is also presented.
              Aweb-based survey of forecasting executives was employed to
              explore trends in forecasting management, familiarity,
              satisfaction, usage, and accuracy among companies in a variety of
              industries. Results revealed decreased familiarity with
              forecasting techniques, and decreased levels of fore- cast
              accuracy. Implications for managers and suggestions for future
              research are presented. Copyright",
  journal  = "Journal of forecasting",
  volume   =  25,
  number   =  5,
  pages    = "303--324",
  year     =  2006,
  keywords = "Accuracy; Familiarity; Forecasting management; Forecasting
              techniques; Satisfaction",
  issn     = "0277-6693",
  doi      = "10.1002/for.989"
}

@ARTICLE{Nenni2013-gu,
  title    = "Demand forecasting in the fashion industry: A review",
  author   = "Nenni, Maria Elena and Giustiniano, Luca and Pirolo, Luca",
  journal  = "International Journal of Engineering Business Management",
  volume   =  5,
  number   = "SPL.ISSUE",
  year     =  2013,
  keywords = "Demand forecasting; Fashion; Supply",
  issn     = "1847-9790",
  doi      = "10.5772/56840"
}

@ARTICLE{Lee2014-lj,
  title    = "Pre-launch new product demand forecasting using the Bass model: A
              statistical and machine learning-based approach",
  author   = "Lee, Hakyeon and Kim, Sang Gook and Park, Hyun Woo and Kang,
              Pilsung",
  abstract = "This study proposes a novel approach to the pre-launch
              forecasting of new product demand based on the Bass model and
              statistical and machine learning algorithms. The Bass model is
              used to explain the diffusion process of products while
              statistical and machine learning algorithms are employed to
              predict two Bass model parameters prior to launch. Initially, two
              types of databases (DBs) are constructed: a product attribute DB
              and a product diffusion DB. Taking the former as inputs and the
              latter as outputs, single prediction models are developed using
              six regression algorithms, on the basis of which an ensemble
              prediction model is constructed in order to enhance predictive
              power. The experimental validation shows that most single
              prediction models outperform the conventional analogical method
              and that the ensemble model improves prediction accuracy further.
              Based on the developed models, an illustrative example of 3D TV
              is provided. \copyright{} 2013 Elsevier Inc.",
  journal  = "Technological forecasting and social change",
  volume   =  86,
  number   = "July",
  pages    = "49--64",
  year     =  2014,
  keywords = "Bass model; Ensemble; Machine learning; Multivariate linear
              regression; Pre-launch forecasting",
  issn     = "0040-1625",
  doi      = "10.1016/j.techfore.2013.08.020"
}

@ARTICLE{Hann_undated-lt,
  title  = "Forecasting the Sales of Music Albums : A Functional Data Analysis
            of Demand and Supply Side {P2P} Data",
  author = "Hann, Il-Horn and Oh, Joohee and James, Gareth",
  pages  = "1--31"
}

@ARTICLE{Lee2003-se,
  title    = "A Bayesian model for prelaunch sales forecasting of recorded
              music",
  author   = "Lee, Jonathan and Boatwright, Peter and Kamakura, Wagner a",
  abstract = "The purpose of this study is to obtain sales forecasts for a new
              album before it is introduced. A hierarchical Bayesian model is
              developed based on a logistic diffusion process. It allows for
              the generalization of various adoption patterns out of discrete
              data and can be applied in a situation where the eventual number
              of adopters is unknown. Using sales of previous albums along with
              information known prior to the launch of a new album, the model
              constructs informed priors, yielding prelaunch sales forecasts,
              which are out-of-sample predictions. In the context of new
              product forecasting before introduction, the information is
              limited to the relevant background characteristics of a new
              album. Knowing only the general attributes of a new album, the
              meta-analytic approach proposed here provides an informed prior
              on the dynamics of duration, the effects of marketing variables,
              and the unknown market potential. As new data become available,
              weekly sales forecasts and market size are revised and updated.
              This approach is illustrated using weekly sales data of albums
              that appeared in Billboard's Top 200 albums chart from January
              1994 to December 1995.",
  journal  = "Management science",
  volume   =  49,
  number   =  2,
  pages    = "179--196",
  year     =  2003,
  keywords = "forecasting,empirical generalization,hierarchical",
  issn     = "0025-1909",
  pmid     = "9224843",
  doi      = "10.1287/mnsc.49.2.179.12744"
}

@ARTICLE{Williams2016-hm,
  title   = "Forecasting elections",
  author  = "Williams, Leighton Vaughan and Reade, James J",
  journal = "Journal of forecasting",
  volume  =  35,
  pages   = "308--328",
  year    =  2016,
  issn    = "0277-6693",
  doi     = "10.1002/for.2377"
}

@ARTICLE{Armstrong1980-nj,
  title    = "The seer-sucker theory: the value of experts in forecasting",
  author   = "Armstrong, J Scott",
  abstract = "People are willing to pay heavily for expert advice. Economists
              are consulted to tell us how the economy will change, stock
              analysts are paid large salaries to forecast the earnings of
              various companies, and political experts command large fees to
              tell our leaders what the future holds. The available evidence,
              however, implies that this money is poorly spent. But because few
              people pay attention to this evidence, I have come up with what I
              call the ``seersucker theory'': ``No matter how much evidence
              exists that seers do not exist, suckers will pay for the
              existence of seers.'' One would expect experts to have reliable
              information for predicting change and to be able to utilize the
              information effectively. However, expertise beyond a minimal
              level is of little value in fore casting change. This conclusion
              is both surprising and useful, and its implication is clear:
              Don't hire the best expert, hire the cheapest expert.",
  journal  = "Technology review",
  volume   =  82,
  number   =  7,
  pages    = "16--24",
  year     =  1980,
  issn     = "0040-1692"
}

@ARTICLE{Powdthavee2012-zz,
  title    = "Why Do People Pay for Useless Advice? Implications of Gambler's
              and {Hot-Hand} Fallacies in {False-Expert} Setting",
  author   = "Powdthavee, Nattavudh and Riyanto, Yohanes E",
  abstract = "We investigated experimentally whether people can be induced to
              believe in a non-existent expert, and subsequently pay for what
              can only be described as transparently useless advice about
              future chance events. Consistent with the theoretical predictions
              made by Rabin (2002) and Rabin and Vayanos (2010), we show
              empirically that the answer is yes and that the size of the error
              made systematically by people is large.",
  journal  = "SSRN eLibrary",
  number   =  6557,
  year     =  2012,
  keywords = "expert; gambler's fallacy; hot-hand; random streak",
  doi      = "10.2139/ssrn.2066980"
}

@UNPUBLISHED{Green2012-hl,
  title       = "Demand forecasting: Evidence-based methods",
  author      = "Green, Kesten C and Armstrong, J Scott",
  series      = "Monash Econometrics and Business Statistics Working Papers",
  institution = "Monash University, Department of Econometrics and Business
                 Statistics",
  year        =  2012
}

@BOOK{Tetlock2005-it,
  title     = "Expert political judgment: How good is it? How can we know?",
  author    = "Tetlock, P E",
  publisher = "Princeton University Press",
  year      =  2005,
  address   = "Princeton, NJ"
}

@ARTICLE{Southorn2016-na,
  title   = "Great expectations: The past, present and future of prediction",
  author  = "Southorn, Graham",
  journal = "Significance. Statistics Making Sense",
  volume  =  13,
  number  =  2,
  pages   = "14--19",
  year    =  2016,
  issn    = "1740-9705, 1740-9713",
  doi     = "10.1111/j.1740-9713.2016.00895.x"
}

@ARTICLE{Mellers2015-rr,
  title    = "Identifying and cultivating superforecasters as a method of
              improving probabilistic predictions",
  author   = "Mellers, B and Stone, E and Murray, T and Minster, A and
              Rohrbaugh, N and Bishop, M and Chen, E and Baker, J and Hou, Y
              and Horowitz, M and Ungar, L and Tetlock, P",
  abstract = "Across a wide range of tasks, research has shown that people make
              poor probabilistic predictions of future events. Recently, the
              U.S. Intelligence Community sponsored a series of forecasting
              tournaments designed to explore the best strategies for
              generating accurate subjective probability estimates of
              geopolitical events. In this article, we describe the winning
              strategy: culling off top performers each year and assigning them
              into elite teams of superforecasters. Defying expectations of
              regression toward the mean 2 years in a row, superforecasters
              maintained high accuracy across hundreds of questions and a wide
              array of topics. We find support for four mutually reinforcing
              explanations of superforecaster performance: (a) cognitive
              abilities and styles, (b) task-specific skills, (c) motivation
              and commitment, and (d) enriched environments. These findings
              suggest that superforecasters are partly discovered and partly
              created--- and that the high-performance incentives of
              tournaments highlight aspects of human judgment that would not
              come to light in laboratory paradigms focused on typical
              performance.",
  journal  = "Perspectives on psychological science: a journal of the
              Association for Psychological Science",
  volume   =  10,
  number   =  3,
  pages    = "267--281",
  year     =  2015,
  keywords = "expertise; forecasts; predictions; probability training; teams",
  issn     = "1745-6916",
  pmid     = "25987508",
  doi      = "10.1177/1745691615577794"
}

@ARTICLE{Galton1907-cb,
  title   = "Vox populi",
  author  = "Galton, Francis",
  journal = "Nature",
  volume  =  75,
  number  =  7,
  pages   = "450--451",
  year    =  1907,
  issn    = "0028-0836"
}

@ARTICLE{Dawes1989-sq,
  title   = "Clinical versus actuarial judgment",
  author  = "Dawes, Robyn M and Faust, David and Meehl, Paul E",
  journal = "Science",
  volume  =  243,
  number  =  4899,
  pages   = "1668--1674",
  year    =  1989,
  issn    = "0036-8075"
}

@ARTICLE{Humes2005-ln,
  title    = "Measures of working memory, sequence learning, and speech
              recognition in the elderly",
  author   = "Humes, Larry E and Floyd, Shari S",
  abstract = "This study describes the measurement of 2 cognitive functions,
              working-memory capacity and sequence learning, in 2 groups of
              listeners: young adults with normal hearing and elderly adults
              with impaired hearing. The measurement of these 2 cognitive
              abilities with a unique, nonverbal technique capable of auditory,
              visual, and auditory-visual stimulation, patterned after the
              Simon memory game, is described. The use of simple, easily
              understood items in the test sequences enabled the measurement of
              these cognitive abilities in older listeners with no apparent
              impact of age-related hearing loss on the cognitive measures.
              Age-related cognitive deficits were observed for all 3 modes of
              stimulation and in both working-memory capacity and
              sequence-learning ability. The age-related deficits appeared to
              be greatest, however, for the sequence-learning task. Although it
              was hypothesized that there might be an association between an
              individual's performance on these cognitive tasks and his or her
              performance on various measures of speech recognition, such an
              association generally was not observed.",
  journal  = "Journal of speech, language, and hearing research: JSLHR",
  volume   =  48,
  pages    = "224--235",
  year     =  2005,
  issn     = "1092-4388",
  pmid     = "15938066",
  doi      = "10.1044/1092-4388(2005/016)"
}

@ARTICLE{Conway2010-ik,
  title     = "Implicit statistical learning in language processing: Word
               predictability is the key",
  author    = "Conway, Christopher M and Bauernschmidt, Althea and Huang, Sean
               S and Pisoni, David B",
  abstract  = "Fundamental learning abilities related to the implicit encoding
               of sequential structure have been postulated to underlie
               language acquisition and processing. However, there is very
               little direct evidence to date supporting such a link between
               implicit statistical learning and language. In three experiments
               using novel methods of assessing implicit learning and language
               abilities, we show that sensitivity to sequential structure - as
               measured by improvements to immediate memory span for
               structurally-consistent input sequences - is significantly
               correlated with the ability to use knowledge of word
               predictability to aid speech perception under degraded listening
               conditions. Importantly, the association remained even after
               controlling for participant performance on other cognitive
               tasks, including short-term and working memory, intelligence,
               attention and inhibition, and vocabulary knowledge. Thus, the
               evidence suggests that implicit learning abilities are essential
               for acquiring long-term knowledge of the sequential structure of
               language - i.e., knowledge of word predictability - and that
               individual differences on such abilities impact speech
               perception in everyday situations. These findings provide a new
               theoretical rationale linking basic learning phenomena to
               specific aspects of spoken language processing in adults, and
               may furthermore indicate new fruitful directions for
               investigating both typical and atypical language development. ??
               2009 Elsevier B.V. All rights reserved.",
  journal   = "Cognition",
  publisher = "Elsevier B.V.",
  volume    =  114,
  number    =  3,
  pages     = "356--371",
  year      =  2010,
  keywords  = "Implicit learning; Individual differences; Language processing;
               Speech perception; Statistical learning; Word predictability",
  issn      = "0010-0277",
  pmid      = "19922909",
  doi       = "10.1016/j.cognition.2009.10.009"
}

@ARTICLE{Hodgetts2012-xf,
  title     = "Similarity-based asymmetries in perceptual matching",
  author    = "Hodgetts, Carl J and Hahn, Ulrike",
  abstract  = "Asymmetries, where response times differ depending on the order
               of two stimuli, have been widely used to explore fundamental
               aspects of perceptual processing. Given how much is made of
               asymmetries in the study of perception there has been
               surprisingly little research into the cognitive mechanisms that
               may underlie why comparing two objects in isolation depends on
               the order of presentation. In visual search, for example,
               asymmetries are typically attributed to fundamental processing
               characteristics as opposed to the inherent relation between two
               stimuli. However, one possible explanation for asymmetries found
               in perceptual processing is that similarity is important in the
               task and it is similarity itself that is asymmetric. In the
               current paper, we use a stimulus set for which the
               transformational account of similarity predicts asymmetries
               based on differences in transformational complexity. Using the
               fine-grained measure of reaction time we show that directional
               differences in transformation distance successfully predict
               asymmetries in the speed of matching two stimuli in sequence.
               The results are discussed in relation to the role of
               transformations in perceptual identification more generally, and
               how transformations could be revealing about how objects are
               compared in other experimental contexts where objects are
               compared directionally (e.g., visual search). ?? 2012 Elsevier
               B.V.",
  journal   = "Acta psychologica",
  publisher = "Elsevier B.V.",
  volume    =  139,
  number    =  2,
  pages     = "291--299",
  year      =  2012,
  keywords  = "Asymmetry; Mental representation; Perceptual matching;
               Similarity; Transformations",
  issn      = "0001-6918",
  pmid      = "22305350",
  doi       = "10.1016/j.actpsy.2011.12.003"
}

@ARTICLE{Pisoni2002-ar,
  title    = "Some new findings on learning, memory and cognitive processes in
              deaf children following cochlear implantation",
  author   = "Pisoni, David B and Cleary, Miranda",
  abstract = "In recent years, cochlear implant (CI) technology has advanced
              substantially. Deaf children can now be provided with an
              electrical signal that codes sound input to facilitate spoken
              language learning. However, a great deal of variability has been
              observed in the audiological outcome measures obtained from
              pediatric CI recipients. Deaf children who have received CIs
              often lag substantially behind their normal hearing (NH) peers on
              a wide range of speech and language measures. Many factors
              contribute to this variability in performance, including age of
              implantation, amount of speech therapy, cognitive information
              processing factors, such as working memory span, as well as
              numerous linguistic factors. An important fundamental linguistic
              skill that plays a critical role in later language development is
              novel word learning, the ability to map the sound patterns of
              spoken words onto their physical referents. This paper describes
              an experimental procedure that was developed to investigate the
              word-learning skills of deaf children who have received CIs and
              reports some preliminary findings obtained from 2- to 5-year-old
              CI users. Each child was presented with a set of Beanie BabiesTM
              and a set of associated labels for their names using interactive
              play scenarios. After training, the children's receptive and
              expressive knowledge of the new names was tested both immediately
              after exposure and then following a 2-hour delay. Pediatric CI
              users performed more poorly than age-matched NH children on both
              receptive and expressive word-learning tests. Both groups of
              children showed retention of the new names from immediate to
              delayed testing conditions for words that were previously known
              by the children. However, additional analyses of the deaf
              children's response revealed that they performed more poorly
              after a delay on both receptive and expressive tests when the
              words were unfamiliar to them before coming into the laboratory.
              Our findings on novel word learning suggest that although
              pediatric CI users may have impaired and/or delayed phonological
              processing skills their long-term memory for familiar spoken
              words that they are able to perceive and encode appears to be
              similar to NH children. Implications of these findings for
              receptive and expressive language development in this clinical
              population are discussed.",
  journal  = "Research on spoken language processing: Progress report no. 25
              (2001-2002)",
  volume   =  25,
  number   =  25,
  pages    = "4--34",
  year     =  2002,
  keywords = "Children; Cochlear Implant; HL; Location (United States); M -
              Word Learning"
}

@ARTICLE{Karpicke2004-ky,
  title    = "Using immediate memory span to measure implicit learning",
  author   = "Karpicke, Jeffrey D and Pisoni, David B",
  abstract = "To avoid some conceptual and methodological pitfalls found in
              traditional artificial grammar learning tasks, we developed a new
              method of measuring implicit learning using immediate memory
              span. Subjects were presented with sequences generated by an
              artificial grammar and were asked to reproduce the patterns by
              pressing buttons on a response box. After exposure to these
              sequences, subjects showed selective improvement in immediate
              memory span for novel sequences governed by the same grammar.
              Individual differences in implicit learning covaried with
              measures of auditory digit span. Subjects with greater immediate
              memory processing capacity were better able to learn and
              subsequently exploit the information available in grammatical
              sequences. Our results are consistent with a detailed episodic
              coding framework in which implicit learning occurs as an
              incidental by-product of explicit task performance. Although
              subjects encode highly detailed information about specific
              instances, they use different aspects of this information to
              accomplish different task-specific demands.",
  journal  = "Memory \& cognition",
  volume   =  32,
  number   =  6,
  pages    = "956--964",
  year     =  2004,
  issn     = "0090-502X",
  doi      = "10.3758/BF03196873"
}

@ARTICLE{Tierney2008-pu,
  title   = "Effects of early musical experience on auditory sequence memory",
  author  = "Tierney, Adam T and Bergeson-Dana, Tonya R and Pisoni, David B",
  journal = "Empirical musicology review: EMR",
  volume  =  3,
  number  =  4,
  pages   = "178--186",
  year    =  2008
}

@ARTICLE{Bigand2014-td,
  title    = "Empirical evidence for musical syntax processing? Computer
              simulations reveal the contribution of auditory short-term memory",
  author   = "Bigand, E and Delb{\'e}, Charles and Poulin-Charronnat,
              B{\'e}n{\'e}dicte and Leman, Marc and Tillmann, Barbara",
  abstract = "During the last decade, it has been argued that (1) music
              processing involves syntactic representations similar to those
              observed in language, and (2) that music and language share
              similar syntactic-like processes and neural resources. This claim
              is important for understanding the origin of music and language
              abilities and, furthermore, it has clinical implications. The
              Western musical system, however, is rooted in psychoacoustic
              properties of sound, and this is not the case for linguistic
              syntax. Accordingly, musical syntax processing could be
              parsimoniously understood as an emergent property of auditory
              memory rather than a property of abstract processing similar to
              linguistic processing. To support this view, we simulated
              numerous empirical studies that investigated the processing of
              harmonic structures, using a model based on the accumulation of
              sensory information in auditory memory. The simulations revealed
              that most of the musical syntax manipulations used with
              behavioral and neurophysiological methods as well as with
              developmental and cross-cultural approaches can be accounted for
              by the auditory memory model. This led us to question whether
              current research on musical syntax can really be compared with
              linguistic processing. Our simulation also raises methodological
              and theoretical challenges to study musical syntax while
              disentangling the confounded low-level sensory influences. In
              order to investigate syntactic abilities in music comparable to
              language, research should preferentially use musical material
              with structures that circumvent the tonal effect exerted by
              psychoacoustic properties of sounds.",
  journal  = "Frontiers in systems neuroscience",
  volume   =  8,
  year     =  2014,
  keywords = "auditory short-term memory; expectancy; modeling; musical brain;
              musical syntax",
  issn     = "1662-5137",
  pmid     = "24936174",
  doi      = "10.3389/fnsys.2014.00094"
}

@ARTICLE{Nosofsky1991-kj,
  title    = "Stimulus bias, asymmetric similarity, and classification",
  author   = "Nosofsky, Robert M",
  abstract = "This article proposes that patterns of proximity data that have
              been characterized in terms of ``asymmetric similarity'' may be
              alternatively characterized in terms of differential ``bias.''
              Bias is a characteristic pertaining to an individual object, as
              opposed to similarity, which is a relation between two objects.
              It is proposed that biases can be stimulus based as well as
              response based, and numerous examples are provided. Part 1 of the
              article reviews an additive similarity and bias model proposed by
              Holman (1979, Journal of Mathematical Psychology, 20, 1-15),
              which generalizes various extant models that have successfully
              characterized asymmetric proximities. Part 1 then discusses
              relations between asymmetric proximities and differences in
              self-proximities, and also discusses multidimensional scaling
              models that are supplemented with stimulus bias terms. Part 2 of
              the article reviews and integrates a variety of phenomena in the
              perceptual classification literature involving asymmetries that
              can be characterized in terms of symmetric similarity together
              with differential stimulus bias. Part 3 provides examples of
              limitations of the additive similarity and bias model. A main
              thesis of the article is that models of proximity and
              classification data that incorporate properties of the individual
              stimulus may not always require recourse to the positing of
              asymmetric similarities. ?? 1991.",
  journal  = "Cognitive psychology",
  volume   =  23,
  number   =  1,
  pages    = "94--140",
  year     =  1991,
  issn     = "0010-0285",
  doi      = "10.1016/0010-0285(91)90004-8"
}

@ARTICLE{Battauz2015-hx,
  title    = "{equateIRT}: An {R} Package for {IRT} Test Equating",
  author   = "Battauz, Michela",
  journal  = "Journal of statistical software",
  volume   =  68,
  number   =  7,
  pages    = "1--22",
  year     =  2015,
  keywords = "bisector; chain; equating; equating coefficients; irt; rasch
              model; standard errors",
  issn     = "1548-7660",
  doi      = "10.18637/jss.v068.i07"
}

@ARTICLE{Weeks2010-zd,
  title    = "plink: An {R} Package for Linking {Mixed-Format} Tests Using
              {IRT-Based} Methods",
  author   = "Weeks, Jonathan P",
  abstract = "The R package plink has been developed to facilitate the linking
              of mixed-format tests for multiple groups under a common item
              design using unidimensional and multidimen- sional IRT-based
              methods. This paper presents the capabilities of the package in
              the context of the unidimensional methods. The package supports
              nine unidimensional item response models (the Rasch model, 1PL,
              2PL, 3PL, graded response model, partial credit and generalized
              partial credit model, nominal response model, and multiple-choice
              model) and four separate calibration linking methods (mean/sigma,
              mean/mean, Haebara, and Stocking-Lord). It also includes
              functions for importing item and/or ability parameters from
              common IRT software, conducting IRT true-score and observed-score
              equating, and plotting item response curves and parameter
              comparison plots.",
  journal  = "Journal of statistical software",
  volume   =  35,
  number   =  12,
  pages    = "1--33",
  year     =  2010,
  keywords = "chain linking; item response theory; mixed-format tests; r;
              separate calibration",
  issn     = "1548-7660"
}

@ARTICLE{Zivic2013-el,
  title    = "Perceptual basis of evolving Western musical styles",
  author   = "Zivic, Pablo H Rodriguez and Shifres, Favio and Cecchi, Guillermo
              A",
  abstract = "The brain processes temporal statistics to predict future events
              and to categorize perceptual objects. These statistics, called
              expectancies, are found in music perception, and they span a
              variety of different features and time scales. Specifically,
              there is evidence that music perception involves strong
              expectancies regarding the distribution of a melodic interval,
              namely, the distance between two consecutive notes within the
              context of another. The recent availability of a large Western
              music dataset, consisting of the historical record condensed as
              melodic interval counts, has opened new possibilities for
              data-driven analysis of musical perception. In this context, we
              present an analytical approach that, based on cognitive theories
              of music expectation and machine learning techniques, recovers a
              set of factors that accurately identifies historical trends and
              stylistic transitions between the Baroque, Classical, Romantic,
              and Post-Romantic periods. We also offer a plausible
              musicological and cognitive interpretation of these factors,
              allowing us to propose them as data-driven principles of melodic
              expectation.",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  110,
  number   =  24,
  pages    = "10034--10038",
  year     =  2013,
  issn     = "0027-8424, 1091-6490",
  pmid     = "23716669",
  doi      = "10.1073/pnas.1222336110"
}

@ARTICLE{Amazon_Web_Services2011-hq,
  title    = "Amazon Elastic Compute Cloud (Amazon {EC2})",
  author   = "{Amazon Web Services}",
  abstract = "Amazon EC2s simple web service interface allows you to obtain and
              configure capacity with minimal friction.",
  journal  = "Amazon Web Services LLC",
  volume   =  2010,
  year     =  2011,
  arxivid  = "1105.1408v1"
}

@ARTICLE{Savage2015-rp,
  title    = "Statistical universals reveal the structures and functions of
              human music",
  author   = "Savage, Patrick E and Brown, Steven and Sakai, Emi and Currie,
              Thomas E",
  abstract = "Music has been called ``the universal language of mankind.'' Al-
              though contemporary theories of music evolution often invoke
              various musical universals, the existence of such universals has
              been disputed for decades and has never been empirically demon-
              strated. Here we combine a music-classification scheme with sta-
              tistical analyses, including phylogenetic comparative methods, to
              examine a well-sampled global set of 304 music recordings. Our
              analyses reveal no absolute universals but strong support for
              many statistical universals that are consistent across all nine
              geo- graphic regions sampled. These universals include 18 musical
              fea- tures that are common individually as well as a network of
              10 features that are commonly associated with one another. They
              span not only features related to pitch and rhythm that are often
              cited as putative universals but also rarely cited domains
              including per- formance style and social context. These
              cross-cultural structural reg- ularities of human music may
              relate to roles in facilitating group coordination and cohesion,
              as exemplified by the universal tendency to sing, play percussion
              instruments, and dance to simple, repetitive music in groups. Our
              findings highlight the need for scientists study- ing music
              evolution to expand the range of musical cultures and musical
              features under consideration. The statistical universals we
              identified represent important candidates for future
              investigation.",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  112,
  number   =  29,
  pages    = "8987--8992",
  year     =  2015,
  keywords = "Culture: evolution Culture: phylogenetics; Culture: universals;
              Ethnography: music; Ethnomusicology; Evolution: cultural",
  issn     = "0027-8424",
  pmid     = "26124105",
  doi      = "10.1073/pnas.1414495112"
}

@ARTICLE{Hansen2014-es,
  title    = "Predictive uncertainty in auditory sequence processing",
  author   = "Hansen, Niels Chr and Pearce, Marcus T",
  abstract = "Previous studies of auditory expectation have focused on the
              expectedness perceived by listeners retrospectively in response
              to events. In contrast, this research examines predictive
              uncertainty-a property of listeners' prospective state of
              expectation prior to the onset of an event. We examine the
              information-theoretic concept of Shannon entropy as a model of
              predictive uncertainty in music cognition. This is motivated by
              the Statistical Learning Hypothesis, which proposes that
              schematic expectations reflect probabilistic relationships
              between sensory events learned implicitly through exposure. Using
              probability estimates from an unsupervised, variable-order Markov
              model, 12 melodic contexts high in entropy and 12 melodic
              contexts low in entropy were selected from two musical
              repertoires differing in structural complexity (simple and
              complex). Musicians and non-musicians listened to the stimuli and
              provided explicit judgments of perceived uncertainty (explicit
              uncertainty). We also examined an indirect measure of uncertainty
              computed as the entropy of expectedness distributions obtained
              using a classical probe-tone paradigm where listeners rated the
              perceived expectedness of the final note in a melodic sequence
              (inferred uncertainty). Finally, we simulate listeners'
              perception of expectedness and uncertainty using computational
              models of auditory expectation. A detailed model comparison
              indicates which model parameters maximize fit to the data and how
              they compare to existing models in the literature. The results
              show that listeners experience greater uncertainty in
              high-entropy musical contexts than low-entropy contexts. This
              effect is particularly apparent for inferred uncertainty and is
              stronger in musicians than non-musicians. Consistent with the
              Statistical Learning Hypothesis, the results suggest that
              increased domain-relevant training is associated with an
              increasingly accurate cognitive model of probabilistic structure
              in music.",
  journal  = "Frontiers in psychology",
  volume   =  5,
  year     =  2014,
  keywords = "Auditory cognition; Entropy; Expectation; Information theory;
              Melody; Music; Statistical learning",
  issn     = "1664-1078",
  pmid     = "25295018",
  doi      = "10.3389/fpsyg.2014.01052"
}

@ARTICLE{Reips2012-xe,
  title    = "Using the internet to Collect Data",
  author   = "Reips, Ulf-Dietrich",
  abstract = "This chapter shows the major steps in collecting data on the
              Internet. The first section, Internet-Based Research, narrates
              the short history of Internet-based data-collection methods in
              psychological research, describes their characteristics, and
              presents a systematic overview of the four basic types of
              methods. Some notions about planning Internet based research lead
              to the second section, Generating a Web Experiment. The section
              describes an example and provides the reader with the opportunity
              to become active and experience Internet-based data-collection
              methods by creating and conducting a web experiment in a
              step-by-step fashion. The example introduces the important
              concepts of client-side versus server-side processing and
              illustrates a number of important techniques. The third section,
              Pretesting, emphasizes the need to take extra care in preparing
              the materials and procedure and evaluating their usability.
              Useful procedures in pretesting of Internet-based data collection
              are introduced, and the section explains how these procedures
              prevent methodological problems. In the fourth section,
              Recruitment, the pros and cons of various ways of attracting
              participants to Internet based studies are explained, concluding
              with the use of games as research environments on the Internet.
              The Data Analysis section explains a number of important issues
              such as raw data preservation, paradata, inclusion criteria, and
              technical variance. Furthermore, the section introduces several
              specific methods, including log file analysis. The concluding
              section looks at future trends and the continuing evolution of
              Internet-based methods and their use in behavioral and social
              research. (PsycINFO Database Record (c) 2013 APA, all rights
              reserved)",
  journal  = "APA handbook of research methods in psychology: Research designs:
              Quantitative, qualitative, neuropsychological, and biological",
  volume   =  2,
  pages    = "291--310",
  year     =  2012,
  doi      = "10.1037/XXXXX.XXX"
}

@ARTICLE{Schon2011-pp,
  title    = "Musical expertise and statistical learning of musical and
              linguistic structures",
  author   = "Sch{\"o}n, Daniele and Fran{\c c}ois, Cl{\'e}ment",
  journal  = "Frontiers in psychology",
  volume   =  2,
  number   = "July",
  pages    = "1--9",
  year     =  2011,
  keywords = "according to rules that; allow the generation of; articulated
              sys-; both highly complex and; both involve the combination;
              language and music are; music and language processing; musical e;
              musical expertise; of a small number; of elements; statistical
              learning; tems; unlimited numbers; word segmentation",
  issn     = "1664-1078",
  doi      = "10.3389/fpsyg.2011.00167"
}

@ARTICLE{Francois2014-ml,
  title    = "Neural sensitivity to statistical regularities as a fundamental
              biological process that underlies auditory learning: The role of
              musical practice",
  author   = "Fran{\c c}ois, Cl{\'e}ment and Sch{\"o}n, Daniele",
  abstract = "There is increasing evidence that humans and other nonhuman
              mammals are sensitive to the statistical structure of auditory
              input. Indeed, neural sensitivity to statistical regularities
              seems to be a fundamental biological property underlying auditory
              learning. In the case of speech, statistical regularities play a
              crucial role in the acquisition of several linguistic features,
              from phonotactic to more complex rules such as morphosyntactic
              rules. Interestingly, a similar sensitivity has been shown with
              non-speech streams: sequences of sounds changing in frequency or
              timbre can be segmented on the sole basis of conditional
              probabilities between adjacent sounds. We recently ran a set of
              cross-sectional and longitudinal experiments showing that merging
              music and speech information in song facilitates stream
              segmentation and, further, that musical practice enhances
              sensitivity to statistical regularities in speech at both neural
              and behavioral levels. Based on recent findings showing the
              involvement of a fronto-temporal network in speech segmentation,
              we defend the idea that enhanced auditory learning observed in
              musicians originates via at least three distinct pathways:
              enhanced low-level auditory processing, enhanced
              phono-articulatory mapping via the left Inferior Frontal Gyrus
              and Pre-Motor cortex and increased functional connectivity within
              the audio-motor network. Finally, we discuss how these data
              predict a beneficial use of music for optimizing speech
              acquisition in both normal and impaired populations. \copyright{}
              2013 Elsevier B.V.",
  journal  = "Hearing research",
  volume   =  308,
  number   = "September",
  pages    = "122--128",
  year     =  2014,
  issn     = "0378-5955, 1878-5891",
  pmid     = "24035820",
  doi      = "10.1016/j.heares.2013.08.018"
}

@ARTICLE{Francois2010-bs,
  title    = "Learning of musical and linguistic structures: comparing
              event-related potentials and behavior",
  author   = "Francois, Cl{\'e}ment and Sch{\"o}n, Daniele",
  abstract = "To learn a new language, it is necessary for the learner to
              succeed in segmenting the continuous stream of sounds into
              significant units. Previous behavioral studies have shown that it
              is possible to segment a language or musical stream based only on
              probabilities of occurrence between adjacent syllables/tones.
              Here we used a sung language and tested participants' learning of
              both linguistic and musical structures while recording
              electroencephalography. Although behavioral results showed
              learning of the linguistic structure only, event-related
              potential results for both dimensions showed a negative component
              sensitive to the degree of familiarity of items. We discuss this
              component as an index of lexical search, also pointing to the
              greater sensitivity of the event-related potentials compared to
              the behavioral responses.",
  journal  = "Neuroreport",
  volume   =  21,
  number   = "April 2016",
  pages    = "928--932",
  year     =  2010,
  keywords = "event-related potentials; language; music; n400; segmentation;
              song; statistical learning",
  issn     = "0959-4965",
  pmid     = "20697301",
  doi      = "10.1097/WNR.0b013e32833ddd5e"
}

@ARTICLE{Hajjem_undated-eb,
  title    = "Mixed Effects Regression Trees for Clustered Data",
  author   = "Hajjem, A and Larocque, D and Bellavance, F",
  volume   =  1,
  pages    = "1--2",
  keywords = "algo-; based methods; clustered data; em; expectation;
              maximization; mixed effects; tree"
}

@ARTICLE{Graves2013-vo,
  title    = "Generating sequences with recurrent neural networks",
  author   = "Graves, Alex",
  abstract = "This paper shows how Long Short-term Memory recurrent neural
              networks can be used to generate complex sequences with
              long-range structure, simply by predicting one data point at a
              time. The approach is demonstrated for text (where the data are
              discrete) and online handwriting (where the data are
              real-valued). It is then extended to handwriting synthesis by
              allowing the network to condition its predictions on a text
              sequence. The resulting system is able to generate highly
              realistic cursive handwriting in a wide variety of styles.",
  journal  = "arXiv preprint arXiv:1308.0850",
  pages    = "1--43",
  year     =  2013,
  arxivid  = "1308.0850v5"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Jones2015-ln,
  title  = "Exploratory Data Analysis using Random Forests ∗",
  author = "Jones, Zachary and Linder, Fridolin",
  year   =  2015
}

@ARTICLE{Zenatti1975-pu,
  title    = "Melodic memory tests: A comparison of normal children and mental
              defectives",
  author   = "Zenatti, Arlette",
  journal  = "Journal of Research in Music Education",
  volume   =  23,
  number   =  1,
  pages    = "41--52",
  year     =  1975,
  keywords = "and mental defectives in; audiovisual ability; aural
              discrimination; formance of normal children; learning theory;
              melodic; mem-; ory; physical characteristics; psychological
              characteristics; research was a comparative; students; study of
              the per-; the subject of this; theory",
  issn     = "0022-4294",
  doi      = "10.2307/3345202"
}

@ARTICLE{Messick1995-na,
  title    = "Validity of psychological assessment: Validation of inferences
              from persons' responses and performances as scientific inquiry
              into score meaning",
  author   = "Messick, Samuel",
  abstract = "The traditional conception of validity divides it into three
              separate and substitutable types: content, criterion, and
              construct validities. This view is fragmented and incomplete,
              especially because it fails to take into account both evidence of
              the value implications of score meaning as a basis for action and
              the social consequences of score use. The new unified concept of
              validity interrelates these issues as fundamental aspects of a
              more comprehensive theory of construct validity that addresses
              both score meaning and social values in test interpretation and
              test use. That is, unified validity integrates considerations of
              content, criteria, and consequences into a construct framework
              for the empirical testing of rational hypotheses about score
              meaning and theoretically relevant relationships, including those
              of an applied and a scientific nature. Six distinguishable
              aspects of construct validity are highlighted as a means of
              addressing central issues implicit in the notion of validity as a
              unified concept. These are content, substantive, structural,
              generalizability, external, and consequential aspects of
              construct validity. In effect, these six aspects function as
              general validity criteria or standards for all educational and
              psychological measurement, including performance assessments,
              which are discussed in some detail because of their increasing
              emphasis in educational and employment settings.",
  journal  = "The American psychologist",
  volume   =  50,
  number   =  9,
  pages    = "741--749",
  year     =  1995,
  keywords = "Construct Validity; Criteria; Educational Assessment; Hypothesis
              Testing; Matrices; Psychological Testing; Scores; Statistical
              Inference; Test Use; Validity",
  issn     = "0003-066X",
  pmid     = "244",
  doi      = "10.1037/0003-066X.50.9.741"
}

@BOOK{Carroll1993-yw,
  title     = "Human cognitive abilities: A survey of factor-analytic studies",
  author    = "Carroll, J B",
  publisher = "Cambridge University Press",
  year      =  1993,
  address   = "New York, NY"
}

@BOOK{Gulliksen1950-gi,
  title     = "Theory of mental tests",
  author    = "Gulliksen, H",
  publisher = "Wiley",
  year      =  1950,
  address   = "New York, NY"
}

@ARTICLE{Novick1966-tb,
  title    = "The axioms and principal results of classical test theory",
  author   = "Novick, Melvin R",
  abstract = "Following an approach due to Guttman the axioms of the classical
              test theory model are shown to be derivable as constructions from
              a specified sampling rule and from the assumption that the
              observed score of an arbitrarily specified or randomly selected
              person may be considered as an observation of a random variable
              having finite and positive variance. Without further assumption
              the reliability of a test is defined. Parallel measurements are
              then independently defined, and the concept of replication is
              explicated. The derived axioms of the classical test theory model
              are then stated in a refined form of Woodbury's stochastic
              process notation, and the basic results of this model are
              derived. The assumptions of experimental independence,
              homogeneity of error distribution, and conditional independence
              are related to the classical model and to each other. Finally, a
              brief sketch of some stronger models assuming the independence of
              error and true scores or the existence of higher-order moments of
              error distributions or those making specific distributional
              assumptions is given.",
  journal  = "Journal of mathematical psychology",
  volume   =  3,
  number   =  1,
  pages    = "1--18",
  year     =  1966,
  issn     = "0022-2496",
  doi      = "10.1016/0022-2496(66)90002-2"
}

@ARTICLE{Boltz1991-ve,
  title    = "Some structural determinants of melody recall",
  author   = "Boltz, M",
  abstract = "Sophisticated musicians were asked to recall, using musical
              notation, a set of unfamiliar folk tunes that varied in rhythmic
              structure and referents of tonality. The results showed that
              memory was facilitated by tonic triad members marking phrase
              endings, but only when their presence was highlighted by a
              corresponding pattern of temporal accents. Conversely, recall
              significantly declined when tonal information was either absent
              or obscured by rhythmic structure. Error analyses further
              revealed that the retention of overall pitch contour and
              information at phrase ending points varied as a function of these
              manipulations. The results are discussed in terms of a framework
              that links the acts of perceiving and remembering to a common
              attentional scheme.",
  journal  = "Memory \& cognition",
  volume   =  19,
  number   =  3,
  pages    = "239--251",
  year     =  1991,
  issn     = "0090-502X",
  pmid     = "1861610",
  doi      = "10.3758/BF03211148"
}

@ARTICLE{Andersen1973-cu,
  title   = "A goodness of fit test for the Rasch model",
  author  = "Andersen, Erling B",
  journal = "Psychometrika",
  volume  =  38,
  number  =  1,
  pages   = "123--140",
  year    =  1973,
  issn    = "0033-3123"
}

@MISC{Wechsler2011-jb,
  title     = "Wechsler Abbreviated Scale of Intelligence {II}",
  author    = "Wechsler, D",
  publisher = "Psychological Corporation",
  year      =  2011,
  address   = "San Antonio, Tex"
}

@BOOK{Bond2015-wc,
  title     = "Applying the Rasch model: Fundamental measurement in the human
               sciences",
  author    = "Bond, Trevor G and Fox, Christine M",
  publisher = "Routledge",
  year      =  2015,
  address   = "New York, NY"
}

@ARTICLE{Kuhnis2012-lz,
  title    = "Musicianship boosts perceptual learning of pseudoword-chimeras:
              An electrophysiological approach",
  author   = "K{\"u}hnis, J{\"u}rg and Elmer, Stefan and Meyer, Martin and
              J{\"a}ncke, Lutz",
  abstract = "A vast amount of previous work has consistently revealed that
              professional music training is associated with functional and
              structural alterations of auditory-related brain regions.
              Meanwhile, there is also an increasing array of evidence, which
              shows that musicianship facilitates segmental, as well as
              supra-segmental aspects of speech processing. Based on this
              evidence, we addressed a novel research question, namely whether
              professional music training has an influence on the perceptual
              learning of speech sounds. In the context of an EEG experiment,
              we presented auditory pseudoword-chimeras, manipulated in terms
              of spectral- or envelope-related acoustic information, to a group
              of professional musicians and non-musicians. During EEG
              measurements, participants were requested to assign the
              auditory-presented pseudoword-chimeras to one out of four
              visually presented templates. As expected, both groups showed
              behavioural learning effects during the time course of the
              experiment. These learning effects were associated with an
              increase in accuracy, a decrease in reaction time, as well as a
              decrease in the P2-like microstate duration in both groups.
              Notably, the musicians showed an increased learning performance
              compared to the controls during the first two runs of the
              spectral condition. This perceptual learning effect, which varies
              as a function of musical expertise, was reflected by a reduction
              of the P2-like microstate duration. Results may mirror transfer
              effects from musical training to the processing of spectral
              information in speech sounds. Hence, this study provides first
              evidence for a relationship between changes in microstates,
              musical expertise, and perceptual verbal learning mechanisms.",
  journal  = "Brain topography",
  volume   =  26,
  number   =  1,
  pages    = "110--125",
  year     =  2012,
  keywords = "Auditory chimeras; EEG; Microstates; Musical expertise;
              Perceptual learning; Plasticity; Topographical pattern analysis",
  issn     = "0896-0267",
  pmid     = "22736323",
  doi      = "10.1007/s10548-012-0237-y"
}

@ARTICLE{Mehr2016-tf,
  title    = "For 5-month-old infants, melodies are social",
  author   = "Mehr, Samuel A and Song, L A and Spelke, E S",
  journal  = "Psychological science",
  volume   =  27,
  number   =  4,
  pages    = "1--16",
  year     =  2016,
  keywords = "13; 14; 15; 17; 1991; brown; human universal; infant development;
              memory; music; music is a putative; open data; open materials;
              received 10; revision accepted 12; social cognition; that is",
  issn     = "0956-7976",
  pmid     = "26917211",
  doi      = "10.1177/0956797615626691"
}

@ARTICLE{Kuhnis2013-oq,
  title    = "The encoding of vowels and temporal speech cues in the auditory
              cortex of professional musicians: An {EEG} study",
  author   = "K{\"u}hnis, J{\"u}rg and Elmer, Stefan and Meyer, Martin and
              J{\"a}ncke, Lutz",
  abstract = "Here, we applied a multi-feature mismatch negativity (MMN)
              paradigm in order to systematically investigate the neuronal
              representation of vowels and temporally manipulated CV syllables
              in a homogeneous sample of string players and non-musicians.
              Based on previous work indicating an increased sensitivity of the
              musicians' auditory system, we expected to find that musically
              trained subjects will elicit increased MMN amplitudes in response
              to temporal variations in CV syllables, namely voice-onset time
              (VOT) and duration. In addition, since different vowels are
              principally distinguished by means of frequency information and
              musicians are superior in extracting tonal (and thus frequency)
              information from an acoustic stream, we also expected to provide
              evidence for an increased auditory representation of vowels in
              the experts. In line with our hypothesis, we could show that
              musicians are not only advantaged in the pre-attentive encoding
              of temporal speech cues, but most notably also in processing
              vowels. Additional ``just noticeable difference'' measurements
              suggested that the musicians' perceptual advantage in encoding
              speech sounds was more likely driven by the generic
              constitutional properties of a highly trained auditory system,
              rather than by its specialisation for speech representations per
              se. These results shed light on the origin of the often reported
              advantage of musicians in processing a variety of speech sounds.
              \copyright{} 2013 Elsevier Ltd.",
  journal  = "Neuropsychologia",
  volume   =  51,
  number   =  8,
  pages    = "1608--1618",
  year     =  2013,
  keywords = "Auditory-system; EEG; Mismatch negativity; Musical expertise;
              Plasticity; Semi-artificial consonant-vowel syllables;
              Spectro-temporal speech processing",
  issn     = "0028-3932",
  pmid     = "23664833",
  doi      = "10.1016/j.neuropsychologia.2013.04.007"
}

@ARTICLE{Mehr2013-to,
  title    = "Two randomized trials provide no consistent evidence for
              nonmusical cognitive benefits of brief preschool music enrichment",
  author   = "Mehr, Samuel A and Schachner, Adena and Katz, Rachel C and
              Spelke, Elizabeth S",
  abstract = "Young children regularly engage in musical activities, but the
              effects of early music education on children's cognitive
              development are unknown. While some studies have found
              associations between musical training in childhood and later
              nonmusical cognitive outcomes, few randomized controlled trials
              (RCTs) have been employed to assess causal effects of music
              lessons on child cognition and no clear pattern of results has
              emerged. We conducted two RCTs with preschool children
              investigating the cognitive effects of a brief series of music
              classes, as compared to a similar but non-musical form of arts
              instruction (visual arts classes, Experiment 1) or to a
              no-treatment control (Experiment 2). Consistent with typical
              preschool arts enrichment programs, parents attended classes with
              their children, participating in a variety of developmentally
              appropriate arts activities. After six weeks of class, we
              assessed children's skills in four distinct cognitive areas in
              which older arts-trained students have been reported to excel:
              spatial-navigational reasoning, visual form analysis, numerical
              discrimination, and receptive vocabulary. We initially found that
              children from the music class showed greater spatial-navigational
              ability than did children from the visual arts class, while
              children from the visual arts class showed greater visual form
              analysis ability than children from the music class (Experiment
              1). However, a partial replication attempt comparing music
              training to a no-treatment control failed to confirm these
              findings (Experiment 2), and the combined results of the two
              experiments were negative: overall, children provided with music
              classes performed no better than those with visual arts or no
              classes on any assessment. Our findings underscore the need for
              replication in RCTs, and suggest caution in interpreting the
              positive findings from past studies of cognitive effects of music
              instruction.",
  journal  = "PloS one",
  volume   =  8,
  number   =  12,
  pages    = "1--12",
  year     =  2013,
  issn     = "1932-6203",
  pmid     = "24349171",
  doi      = "10.1371/journal.pone.0082007"
}

@ARTICLE{Hu2013-jd,
  title     = "Language aptitude for pronunciation in advanced second language
               (L2) learners: Behavioural predictors and neural substrates",
  author    = "Hu, Xiaochen and Ackermann, Hermann and Martin, Jason A and Erb,
               Michael and Winkler, Susanne and Reiterer, Susanne M",
  abstract  = "Individual differences in second language (L2) aptitude have
               been assumed to depend upon a variety of cognitive and
               personality factors. Especially, the cognitive factor
               phonological working memory has been conceptualised as language
               learning device. However, strong associations between
               phonological working memory and L2 aptitude have been previously
               found in early-stage learners only, not in advanced learners.
               The current study aimed at investigating the behavioural and
               neurobiological predictors of advanced L2 learning. Our
               behavioural results showed that phonetic coding ability and
               empathy, but not phonological working memory, predict L2
               pronunciation aptitude in advanced learners. Second, functional
               neuroimaging revealed this behavioural trait to be correlated
               with hemodynamic responses of the cerebral network of speech
               motor control and auditory-perceptual areas. We suggest that the
               acquisition of L2 pronunciation aptitude is a dynamic process,
               requiring a variety of neural resources at different processing
               stages over time. ?? 2012 Elsevier Inc.",
  journal   = "Brain and language",
  publisher = "Elsevier Inc.",
  volume    =  127,
  number    =  3,
  pages     = "366--376",
  year      =  2013,
  keywords  = "Empathy; Individual differences; Language aptitude; Phonological
               working memory; Pronunciation; Second language acquisition",
  issn      = "0093-934X",
  pmid      = "23273501",
  doi       = "10.1016/j.bandl.2012.11.006"
}

@ARTICLE{Teahan2003-ez,
  title    = "Using compression-based language models for text categorization",
  author   = "Teahan, W J and Harper, D J",
  abstract = "Text categorization is the problem of assigning text to any of a
              set of pre-specified categories. It is useful in indexing
              documents for later retrieval, as a stage in natural language
              processing systems, for content analysis, and in many other
              roles. We with to use language models developed for text
              compression as the basis of a text categorization scheme and
              potentially for other applications in IR (although the later will
              not be discussed here). The motivation for using these models is
              that they are well grounded in information theory, and that they
              also have proven performance at many IR-related tasks such as
              word segmentation, text mining, language/dialect identification
              and authorship ascription.",
  journal  = "Language Modeling for Information Retrieval",
  volume   =  13,
  pages    = "141--165",
  year     =  2003
}

@ARTICLE{Cilibrasi2005-um,
  title    = "Clustering by compression",
  author   = "Cilibrasi, Rudi and Vit{\'a}nyi, P M B",
  abstract = "We present a new method for clustering based on compression. The
              method does not use subject-specific features or background
              knowledge, and works as follows: First, we determine a
              parameter-free, universal, similarity distance, the normalized
              compression distance or NCD, computed from the lengths of
              compressed data files (singly and in pairwise concatenation).
              Second, we apply a hierarchical clustering method. The NCD is not
              restricted to a specific application area, and works across
              application area boundaries. A theoretical precursor, the
              normalized information distance, co-developed by one of the
              authors, is provably optimal. However, the optimality comes at
              the price of using the noncomputable notion of Kolmogorov
              complexity. We propose axioms to capture the real-world setting,
              and show that the NCD approximates optimality. To extract a
              hierarchy of clusters from the distance matrix, we determine a
              dendrogram (ternary tree) by a new quartet method and a fast
              heuristic to implement it. The method is implemented and
              available as public software, and is robust under choice of
              different compressors. To substantiate our claims of universality
              and robustness, we report evidence of successful application in
              areas as diverse as genomics, virology, languages, literature,
              music, handwritten digits, astronomy, and combinations of objects
              from completely different domains, using statistical, dictionary,
              and block sorting compressors. In genomics, we presented new
              evidence for major questions in Mammalian evolution, based on
              whole-mitochondrial genomic analysis: the Eutherian orders and
              the Marsupionta hypothesis against the Theria hypothesis.",
  journal  = "IEEE transactions on information theory / Professional Technical
              Group on Information Theory",
  volume   =  51,
  number   =  4,
  pages    = "1523--1545",
  year     =  2005,
  keywords = "Heterogenous data analysis; Hierarchical unsupervised clustering;
              Kolmogorov complexity; Normalized compression distance;
              Parameter-free data mining; Quartet tree method; Universal
              dissimilarity distance",
  issn     = "0018-9448",
  pmid     = "1412045",
  arxivid  = "cs/0312044",
  doi      = "10.1109/TIT.2005.844059"
}

@ARTICLE{Chen2004-lv,
  title    = "Shared information and program plagiarism detection",
  author   = "Chen, Xin and Francia, Brent and Li, Ming and McKinnon, Brian and
              Seker, Amit",
  abstract = "A fundamental question in information theory and in computer
              science is how to measure similarity or the amount of shared
              information between two sequences. We have proposed a metric,
              based on Kolmogorov complexity, to answer this question and have
              proven it to be universal. We apply this metric in measuring the
              amount of shared information between two computer programs, to
              enable plagiarism detection. We have designed and implemented a
              practical system SID (Software Integrity Diagnosis system) that
              approximates this metric by a heuristic compression algorithm.
              Experimental results demonstrate that SID has clear advantages
              over other plagiarism detection systems. SID system server is
              online at http://software.bioinformatics.uwaterloo.ca/SID/.",
  journal  = "IEEE transactions on information theory / Professional Technical
              Group on Information Theory",
  volume   =  50,
  number   =  7,
  pages    = "1545--1551",
  year     =  2004,
  keywords = "Kolmogorov complexity; Program plagiarism detection; Shared
              information",
  issn     = "0018-9448",
  doi      = "10.1109/TIT.2004.830793"
}

@ARTICLE{Embretson1983-ou,
  title    = "Construct validity: Construct representation versus nomothetic
              span",
  author   = "Embretson, Susan E",
  abstract = "Presents a new approach to construct validation research:
              construct modeling. A paradigm shift from functionalism to
              structuralism in psychology permits 2 types of research to be
              separated. Construct representation is concerned with identifying
              the theoretical mechanisms that underlie responses, such as
              information processes, strategies, and knowledge stores. Three
              approaches to assessing construct representation are presented:
              (1) mathematical modeling, particularly as used in cognitive
              psychology; (2) psychometric modeling, as exemplified by latent
              trait modeling; and (3) multicomponent latent trait modeling.
              Nomothetic span is concerned with the network of relationships of
              a test score with other variables. These 2 types of construct
              validation research address different issues and require
              different types of data. For each type of construct validation
              research, appropriate methods and quantitative models are
              presented to test a priori hypotheses about construct validity.
              Examples are presented, and the construct modeling approach is
              compared with both the traditional psychometric approach and the
              information-processing approach to establishing theoretical
              mechanisms in performance. (41 ref) (PsycINFO Database Record (c)
              2012 APA, all rights reserved)",
  journal  = "Psychological bulletin",
  volume   =  93,
  number   =  1,
  pages    = "179--197",
  year     =  1983,
  issn     = "0033-2909",
  doi      = "10.1037/0033-2909.93.1.179"
}

@ARTICLE{Kang2006-vt,
  title    = "{PPChecker}: Plagiarism Pattern Checker in Document Copy
              Detection",
  author   = "Kang, Namoh and Gelbukh, Alexander and Han, San Yong",
  abstract = "Nowadays, most of documents are produced in digital format, in
              which they can be easily accessed and copied. Document copy
              detection is a very important tool for protecting the author's
              copyright. We present PPChecker, a document copy detection system
              based on plagiarism pattern checking. PPChecker calculates the
              amount of data copied from the original document to the query
              document, based on linguistically-motivated plagiarism patterns.
              Experiments performed on CISI document collection show that
              PPChecker produces better decision information for document copy
              detection than existing systems.",
  journal  = "Proceedings of the 9th international conference on Text, Speech
              and Dialogue",
  volume   = "LNAI (4188",
  number   = "Dcd",
  pages    = "661--667",
  year     =  2006,
  issn     = "0302-9743",
  doi      = "10.100711846406\_83"
}

@ARTICLE{Lyon2001-wm,
  title    = "Detecting short passages of similar text in large document
              collections",
  author   = "Lyon, C and Malcolm, J and Dickerson, B",
  abstract = "This paper presents a statistical method for finger- printing
              text. In a large collection of independently written documents
              each text is associated with a fin- gerprint which should be
              different from all the oth- ers. If fingerprints are too close
              then it is suspected that passages of copied or similar text
              occur in two documents. Our method exploits the characteris- tic
              distribution of word trigrams, and measures to determine
              similarity are based on set theoretic prin- ciples. The system
              was developed using a corpus of broadcast news reports and has
              been successfully used to detect plagiarism in students' work. It
              can find small sections that are similar as well as those that
              are identical. The method is very simple and effective, but seems
              not to have been used before",
  journal  = "Proceedings of the 2011 Conference on Empirical Methods in
              Natural Language Processing (EMNLP 2001)",
  pages    = "118--125",
  year     =  2001,
  doi      = "10.1.1.7.2630"
}

@ARTICLE{Sonntag2004-px,
  title   = "Assessing the quality of natural language text data",
  author  = "Sonntag, Daniel",
  journal = "GI Jahrestagung",
  volume  =  1,
  pages   = "259--263",
  year    =  2004
}

@INPROCEEDINGS{Heilman2014-rp,
  title     = "Predicting grammaticality on an ordinal scale",
  booktitle = "Proceedings of the 52nd Annual Meeting of the Association for
               Computational Linguistics (Short Papers)",
  author    = "Heilman, Michael and Tetreault, Joel and Cahill, Aoife and
               Madnani, Nitin and Lopez, Melissa and Mulholland, Matthew",
  abstract  = "Automated methods for identifying whether sentences are
               grammatical have various potential applications (e.g., machine
               translation, automated essay scoring, computer-assisted language
               learning). In this work, we construct a statistical model of
               grammaticality using various linguistic features (e.g., mis-
               spelling counts, parser outputs, n-gram language model scores).
               We also present a new publicly available dataset of learner
               sentences judged for grammaticality on an ordinal scale. In
               evaluations, we compare our system to the one from Post (2011)
               and find that our approach yields state-of-the-art performance.
               1",
  pages     = "174--180",
  year      =  2014,
  address   = "Baltimore, Maryland, USA",
  isbn      = "9781937284732"
}

@INCOLLECTION{Alzahrani2008-xd,
  title     = "Plagiarism detection techqniues",
  booktitle = "Databases and Text Processing Applications",
  author    = "Alzahrani, Salha Mohammed and Salim, Naomie",
  pages     = "58",
  year      =  2008,
  isbn      = "9789835206313"
}

@ARTICLE{Yerra2005-eo,
  title    = "A {Sentence-Based} Copy Detection Approach",
  author   = "Yerra, Rajiv and Ng, Yiu-Kai",
  abstract = "Web documents that are either partially or completely du-plicated
              in content are easily found on the Internet these days. Not only
              these documents create redundant information on the Web, which
              take longer to filter unique information and cause additional
              storage space, but they also degrade the efficiency of Web
              information retrieval. In this paper, we present a sentence-based
              copy detection approach on Web doc-uments, which determines the
              existence of overlapped portions of any two given Web documents
              and graphically displays the locations of (semanti-cally the)
              same sentences detected in the documents. Two sentences are
              treated as either the same or different according to the degree
              of simi-larity of the sentences computed by using either the
              three least-frequent 4-gram approach or the fuzzy-set information
              retrieval (IR) approach. Experimental results show that the
              fuzzy-set IR approach outperforms the three least-frequent 4-gram
              approach in our copy detection approach, which handles wide range
              of documents in different subject areas and does not require
              static word lists.",
  pages    = "557--570",
  year     =  2005
}

@INCOLLECTION{Schmidt2003-nw,
  title     = "Item Response Theory and measuring abilities",
  booktitle = "Handbook of Psychology: Research Methods in Psychology",
  author    = "Schmidt, Karen M and Embretson, Susan E",
  editor    = "Schinka, John A and Velicer, Wayne F and Weiner, Irving B",
  publisher = "John Wiley \& Sons",
  pages     = "429--446",
  year      =  2003,
  address   = "Hoboken, NJ"
}

@ARTICLE{Cook2014-qn,
  title    = "A Rogue Dream : Automatically Generating Meaningful Content For
              Games",
  author   = "Cook, Michael and Colton, Simon",
  journal  = "Experimental Artificial Intelligence in Games: Papers from the
              AIIDE Workshop",
  number   = "Yu",
  pages    = "2--7",
  year     =  2014,
  keywords = "AAAI Technical Report WS-14-16"
}

@ARTICLE{Llano2014-bp,
  title    = "Towards the Automatic Generation of Fictional Ideas for Games",
  author   = "Llano, Maria Teresa and Cook, Michael and Guckelsberger,
              Christian and Colton, Simon",
  journal  = "Proceedings of the 1st AIIDE Workshop on Experimental AI for
              Games",
  pages    = "35--41",
  year     =  2014,
  keywords = "AAAI Technical Report WS-14-16"
}

@ARTICLE{Cook2013-ia,
  title    = "Mechanic miner: Reflection-driven game mechanic discovery and
              level design",
  author   = "Cook, Michael and Colton, Simon and Raad, Azalea and Gow, Jeremy",
  abstract = "We introduce Mechanic Miner, an evolutionary system for
              discovering simple two-state game mechanics for puzzle platform
              games. We demonstrate how a reflection-driven generation
              technique can use a simulation of gameplay to select good
              mechanics, and how the simulation-driven process can be inverted
              to produce challenging levels specific to a generated mechanic.
              We give examples of levels and mechanics generated by the system,
              summarise a small pilot study conducted with example levels and
              mechanics, and point to further applications of the technique,
              including applications to automated game design.",
  journal  = "Lecture notes in computer science",
  volume   = "7835 LNCS",
  pages    = "284--293",
  year     =  2013,
  keywords = "automated game design; game mechanics; platform games",
  issn     = "0302-9743",
  doi      = "10.1007/978-3-642-37192-9-29"
}

@ARTICLE{Escoffier2008-ah,
  title    = "The tonal function of a task-irrelevant chord modulates speed of
              visual processing",
  author   = "Escoffier, N and Tillmann, Barbara",
  abstract = "Harmonic priming studies have provided evidence that musical
              expectations influence sung phoneme monitoring, with facilitated
              processing for phonemes sung on tonally related (expected) chords
              in comparison to less-related (less-expected) chords [Bigand,
              Tillmann, Poulin, D'Adamo, and Madurell (2001). The effect of
              harmonic context on phoneme monitoring in vocal music. Cognition,
              81, B11-B20]. This tonal relatedness effect has suggested two
              interpretations: (a) processing of music and language interact at
              some level of processing; and (b) tonal functions of chords
              influence task performance via listeners' attention. Our study
              investigated these hypotheses by exploring whether the effect of
              tonal relatedness extends to the processing of visually presented
              syllables (Experiments 1 and 2) and geometric forms (Experiments
              3 and 4). For Experiments 1-4, visual target identification was
              faster when the musical background fulfilled listeners'
              expectations (i.e., a related chord was played simultaneously).
              In Experiment 4, the addition of a baseline condition (i.e.,
              without an established tonal center) further showed that the
              observed difference was due to a facilitation linked to the
              related chord and not to an inhibition or disruption caused by
              the less-related chord. This outcome suggests the influence of
              musical structures on attentional mechanisms and that these
              mechanisms are shared between auditory and visual modalities. The
              implications for research investigating neural correlates shared
              by music and language processing are discussed. \copyright{} 2007
              Elsevier B.V. All rights reserved.",
  journal  = "Cognition",
  volume   =  107,
  number   =  3,
  pages    = "1070--1083",
  year     =  2008,
  keywords = "Attention; Audiovisual interaction; Music and language; Musical
              priming",
  issn     = "0010-0277",
  pmid     = "18076873",
  doi      = "10.1016/j.cognition.2007.10.007"
}

@ARTICLE{Park1988-so,
  title    = "Random number generators: good ones are hard to find",
  author   = "Park, Stephen K and Miller, Keith W",
  abstract = "Practical and theoretical issues are presented concerning the
              design, implementation, and use of a good, minimal standard
              random number generator that will port to virtually all systems.",
  journal  = "Communications of the ACM",
  volume   =  31,
  number   =  10,
  pages    = "1192--1201",
  year     =  1988,
  issn     = "0001-0782",
  doi      = "10.1145/63039.63042"
}

@MISC{Blizzard2016-dn,
  title        = "Blizzard Entertainment: Legacy games",
  author       = "{Blizzard}",
  year         =  2016,
  howpublished = "\url{http://us.blizzard.com/en-us/games/legacy/}"
}

@TECHREPORT{Entertainment_Software_Association2015-ga,
  title  = "Essential facts about the computer and video game industry",
  author = "{Entertainment Software Association}",
  year   =  2015,
  issn   = "0894-4393"
}

@BOOK{Brathwaite2009-ut,
  title     = "Challenges for game designers",
  author    = "Brathwaite, Brenda and Schreiber, Ian",
  publisher = "Charles River Media",
  year      =  2009,
  address   = "Boston, MA",
  keywords  = "board game; game design; game studies; video game",
  isbn      = "9781584505808"
}

@MISC{Aversa2015-nk,
  title        = "Procedural Contents Generation",
  author       = "Aversa, Davide",
  year         =  2015,
  howpublished = "\url{http://www.davideaversa.it/wp-content/uploads/2015/06/Procedural-Contents-Generation.pdf}"
}

@ARTICLE{Hendrixx2011-el,
  title   = "Procedural content generation for games: A survey",
  author  = "Hendrixx, Mark and Meijer, Sebastiaan and van der Velden, Joeri
             and Iosup, Alexandru",
  journal = "ACM Transactions on Multimedia Computing, Communications and
             Applications",
  volume  =  23,
  number  =  2,
  pages   = "158--171",
  year    =  2011
}

@MISC{Takatsuki2007-vt,
  title        = "Cost headache for game developers",
  booktitle    = "{BBC} News",
  author       = "Takatsuki, Yo",
  year         =  2007,
  howpublished = "\url{http://news.bbc.co.uk/1/hi/business/7151961.stm}"
}

@ARTICLE{Iosup2010-zu,
  title    = "{POGGI}: Generating Puzzle Instances for Online Games on Grid
              Infrastructures",
  author   = "Iosup, Alexandru",
  journal  = "Concurrency and computation: practice \& experience",
  volume   =  23,
  number   =  2,
  pages    = "1--15",
  year     =  2010,
  keywords = "game content generation; grid computing; mmog; puzzle; resource
              management",
  issn     = "1532-0626"
}

@ARTICLE{Hewgill2004-dw,
  title    = "Procedural {3D} texture synthesis using genetic programming",
  author   = "Hewgill, Adam and Ross, B J",
  abstract = "The automatic synthesis of procedural textures for 3D surfaces
              using genetic pro- gramming is investigated. Genetic algorithms
              employ a search strategy inspired by Darwinian natural evolution.
              Genetic programming uses genetic algorithms on tree structures,
              which are interpretable as computer programs or mathematical
              formulae. We use a texture generation language as a target
              language for genetic programming, and then use it to evolve
              textures having particular characteristics of interest. The
              texture generation language used here includes operators useful
              for texture creation, for example, mathematical operators, and
              colour and noise functions. In order to be practical for 3D model
              rendering, the language includes primitives that access surface
              information for the point being rendered, such as coordinates
              values, normal vectors, and surface gradients. A variety of
              experiments successfully generated pro- cedural textures that
              displayed visual characteristics similar to the target textures
              used during training. Key",
  journal  = "Computers \& graphics",
  volume   =  28,
  number   = "April",
  pages    = "1--25",
  year     =  2004,
  keywords = "evolution; genetic programming; procedural textures",
  issn     = "0097-8493",
  doi      = "10.1016/j.cag.2004.04.012"
}

@ARTICLE{Rhoades1992-xa,
  title    = "Real-time procedural textures",
  author   = "Rhoades, John and Turk, Greg and Bell, Andrew and State, Andrei
              and Neumann, Ulrich and Varshney, Amitabh",
  abstract = "We describe a software system on the Pixel-Planes 5 graphics
              engine that displays user-defined antialiased procedural textures
              at rates of about 30 frames per second for use in real- time
              graphics applications. Our system allows a user to create
              textures that can modulate both diffuse and specular color, the
              sharpness of specular highlights, the amount of transparency and
              the surface normals of an object. We describe a texture editor
              that allows a user to interactively create and edit procedural
              textures. Antialiasing is essential for real-time textures, and
              in this paper we present some techniques for antialiasing
              procedural textures. Another direction we are exploring is the
              use of dynamic textures, which are functions of time or
              orientation. Examples of textures we have generated include a
              translucent fire texture that waves and flickers and an animated
              water texture that shows the use of both environment mapping and
              normal perturbation (bump mapping).",
  journal  = "Proceedings of the 1992 symposium on Interactive 3D graphics -
              SI3D '92",
  pages    = "95--100",
  year     =  1992,
  issn     = "0097-8930",
  doi      = "10.1145/147156.147171"
}

@ARTICLE{Kelly2006-lg,
  title    = "A survey of procedural techniques for city generation",
  author   = "Kelly, George and McCabe, Hugh",
  abstract = "The computer game industry requires a skilled workforce and this
              combined with the complexity of modern games, means that
              production costs are extremely high. One of the most time
              consuming aspects is the creation of game geometry, the virtual
              world which the players inhabit. Procedural techniques have been
              used within computer graphics to create natural textures,
              simulate special effects and generate complex natural models
              including trees and waterfalls. It is these procedural techniques
              that we intend to harness to generate geometry and textures
              suitable for a game situated in an urban environment. Procedural
              techniques can provide many benefits for computer graphics
              applications when the correct algorithm is used. An overview of
              several commonly used procedural techniques including fractals,
              L-systems, Perlin noise, tiling systems and cellular basis is
              provided. The function of each technique and the resulting output
              they create are discussed to better understand their
              characteristics, benefits and relevance to the city generation
              problem. City generation is the creation of an urban area which
              necessitates the creation of buildings, situated along streets
              and arranged in appropriate patterns. Some research has already
              taken place into recreating road network patterns and generating
              buildings that can vary in function and architectural style. We
              will study the main body of existing research into procedural
              city generation and provide an overview of their implementations
              and a critique of their functionality and results. Finally we
              present areas in which further research into the generation of
              cities is required and outline our research goals for city
              generation.",
  journal  = "ITB Journal of Science",
  pages    = "87--130",
  year     =  2006,
  issn     = "1978-3043"
}

@ARTICLE{Hyun2009-bj,
  title    = "The comparison of visual working memory representations with
              perceptual inputs",
  author   = "Hyun, Joo-Seok and Woodman, Geoffrey F and Vogel, Edward K and
              Hollingworth, Andrew and Luck, Steven J",
  abstract = "The human visual system can notice differences between memories
              of previous visual inputs and perceptions of new visual inputs,
              but the comparison process that detects these differences has not
              been well characterized. In this study, the authors tested the
              hypothesis that differences between the memory of a stimulus
              array and the perception of a new array are detected in a manner
              that is analogous to the detection of simple features in visual
              search tasks. That is, just as the presence of a task-relevant
              feature in visual search can be detected in parallel, triggering
              a rapid shift of attention to the object containing the feature,
              the presence of a memory-percept difference along a task-relevant
              dimension can be detected in parallel, triggering a rapid shift
              of attention to the changed object. Supporting evidence was
              obtained in a series of experiments in which manual reaction
              times, saccadic reaction times, and event-related potential
              latencies were examined. However, these experiments also showed
              that a slow, limited-capacity process must occur before the
              observer can make a manual change detection response.",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  35,
  number   =  4,
  pages    = "1140--1160",
  year     =  2009,
  keywords = "comparison; few hundred milli-; human visual system consists; it
              is often useful; most lasting only a; primarily of a; saccades;
              seconds; separated by blinks and; series of static snapshots; the
              input to the; to; visual search; visual short-term memory; visual
              working memory",
  issn     = "0096-1523",
  pmid     = "19653755",
  doi      = "10.1037/a0015019"
}

@BOOK{Garner1974-gu,
  title     = "The processing of information and structure",
  author    = "Garner, W R",
  publisher = "Erlbaum",
  year      =  1974,
  address   = "Hillsdale, NJ"
}

@INCOLLECTION{Bartlett1993-lb,
  title     = "Tonal structure of melodies",
  booktitle = "Psychology and music: The understanding of melody and rhythm",
  author    = "Bartlett, James C",
  editor    = "Tighe, Thomas J and Dowling, W Jay",
  publisher = "Lawrence Erlbaum Associates, Inc.",
  pages     = "39--62",
  year      =  1993,
  address   = "New York, NY"
}

@ARTICLE{Knecht2003-bg,
  title    = "Music expertise and memory: The relationship between music
              expertise and memory of music patterns, within various degrees of
              contextual constraint",
  author   = "Knecht, Melissa Gerber",
  abstract = "The present study investigated the relationship between expertise
              in one's principal instrument and memory performance achievement
              of various aural melodic patterns, constructed in such a manner
              as to reflect three degrees of contextual constraint. Music
              patterns ranged from random music approximations (zero-order) to
              music patterns generated from systematically increased degrees of
              contextual constraint, simulating classical Western tonal music
              (second- and third-order music approxima- tions). Participants
              were selected from those who play viola in the Chicago Symphony
              and the Toledo Symphony (experts) and in two high school
              orchestras (novices). Two tests were designed by the investigator
              to assess the respondents' ability to replicate music patterns in
              a listen--imitate format. Results indicated that for the
              approximations to classical Western tonal music (second- and
              third-order) there was a great difference between the expert and
              novice violists. The experts showed a superior performance.
              However, for the zero-order or random music approximations, there
              was little difference between the two research groups.
              Introduction",
  journal  = "Music Education Research",
  volume   =  5,
  number   =  3,
  pages    = "227--242",
  year     =  2003,
  issn     = "1461-3808",
  doi      = "10.1080/1461380032000126328"
}

@ARTICLE{Taylor1983-iq,
  title   = "Strategies in memory for short melodies: An extension of Otto
             Ortmann's 1933 study",
  author  = "Taylor, Jack A and Pembrook, Randall G",
  journal = "Psychomusicology",
  volume  =  3,
  number  =  1,
  pages   = "16--35",
  year    =  1983
}

@ARTICLE{Oura1988-cc,
  title   = "Memory for melodies among subjects differing in age and experience
             in music",
  author  = "Oura, Yoko and Hatano, Giyoo",
  journal = "Psychology of Music",
  volume  =  16,
  pages   = "91--109",
  year    =  1988,
  issn    = "1059-6011"
}

@ARTICLE{Hannon2005-ii,
  title    = "Infants use meter to categorize rhythms and melodies:
              Implications for musical structure learning",
  author   = "Hannon, Erin E and Johnson, Scott P",
  abstract = "Little is known about whether infants perceive meter, the
              underlying temporal structure of music. We employed a habituation
              paradigm to examine whether 7-month-old infants could categorize
              rhythmic and melodic patterns on the basis of the underlying
              meter, which was implied from event and accent frequency of
              occurrence. In Experiment 1, infants discriminated duple and
              triple classes of rhythm on the basis of implied meter.
              Experiment 2 replicated this result while controlling for
              rhythmic grouping structure, confirming that infants perceived
              metrical structure despite occasional ambiguities and conflicting
              group structure. In Experiment 3, infants categorized melodies on
              the basis of contingencies between metrical position and pitch.
              Infants presented with metrical melodies detected reversals of
              pitch/meter contingencies, while infants presented with
              non-metrical melodies showed no preference. Results indicate that
              infants can infer meter from rhythmic patterns, and that they may
              use this metrical structure to bootstrap their knowledge
              acquisition in music learning. ?? 2004 Elsevier Inc. All rights
              reserved.",
  journal  = "Cognitive psychology",
  volume   =  50,
  number   =  4,
  pages    = "354--377",
  year     =  2005,
  keywords = "Bootstrapping; Development; Music and speech; Pattern perception;
              Rhythm and meter; Statistical learning",
  issn     = "0010-0285",
  pmid     = "15893524",
  doi      = "10.1016/j.cogpsych.2004.09.003"
}

@ARTICLE{Bharucha1986-ds,
  title    = "Disrupting the isochrony underlying rhythm: An asymmetry in
              discrimination",
  author   = "Bharucha, Jamshed J and Pryor, John H",
  abstract = "Recognition memory for equitone sequences was tested as a
              function of whether the pattern of stimulus onsets mapped easily
              onto an isochronous grid (rhythmic) or did not (disrupted). In a
              same-different task, discrimination between a rhythmic sequence
              and its disrupted variant was better when the rhythmic sequence
              was presented first and the disrupted variant second than vice
              versa. Analogous effects have been obtained for melodies and
              chord sequences as a function of tonal structure, and for text as
              a function of semantic and pragmatic coherence. In each do- main,
              discrimination between coherent sequences and anomalous variants
              is better when the coherent version is presented first.",
  journal  = "Perception \& psychophysics",
  volume   =  40,
  number   =  3,
  pages    = "137--141",
  year     =  1986,
  keywords = "Adult; Humans; Memory; Mental Recall; Pitch Perception; Time
              Perception",
  issn     = "0031-5117",
  pmid     = "3774495",
  doi      = "10.3758/bf03203008"
}

@ARTICLE{Handel1992-rg,
  title    = "The differentiation of rhythmic structure",
  author   = "Handel, S",
  abstract = "Listeners judged whether two five-tone nonmetric rhythms were the
              same or different. Each rhythm was presented one, two, or four
              times to study the process of perceptual differentiation. The
              results indicated that the listeners perceived these rhythms in
              terms of the grouping of the tones, and not in terms of the
              timing between the groups. Two rhythms that had the same
              perceptual grouping were judged as being identical, even if the
              timing between the groups was different. The perception of the
              groupings of tones developed gradually. If each rhythm was
              presented only once, then the listeners had only a global
              percept, focused on groups (runs) of three elements, and often
              judged two different rhythms as being identical. If the rhythms
              were presented two or four times, then the grouping of the tones
              became more differentiated and the listeners were less likely to
              judge different patterns as being identical. Thus, perception of
              auditory rhythmic structure appears to follow the same
              developmental process as the perception of visual spatial
              structure.",
  journal  = "Perception \& psychophysics",
  volume   =  52,
  number   =  5,
  pages    = "497--507",
  year     =  1992,
  keywords = "Adult; Attention; Auditory Perception; Humans; Individuality;
              Pitch Perception; Reaction Time; Time Perception",
  issn     = "0031-5117",
  pmid     = "1437482",
  doi      = "10.3758/BF03206711"
}

@ARTICLE{Pick1988-zb,
  title   = "Children's perception of certain musical properties: Scale and
             contour",
  author  = "Pick, Anne D and Palmer, Caroline F and Hennessy, Beth L and Unze,
             Marsha G and Jones, Rebecca K and Richardson, Rose Mae",
  journal = "Journal of experimental child psychology",
  volume  =  45,
  pages   = "28--51",
  year    =  1988,
  issn    = "0022-0965"
}

@ARTICLE{Van_Egmond2016-qw,
  title  = "Linked references are available on {JSTOR} for this article : Notes
            \& Comment Factors in the Recognition of Transposed Melodies : A
            Comment on Takeuchi \& H{\"u}lse {REN{\'E}} {VAN} {EGMOND} \&
            {DIRK-JAN} {POVEL}",
  author = "Van Egmond, Ren{\'e} and Povel, Dirk-Jan",
  volume =  12,
  number =  1,
  pages  = "137--142",
  year   =  2016
}

@ARTICLE{Takeuchi1992-na,
  title   = "Key-distance effects in melody recognition reexamined",
  author  = "Takeuchi, Annie H and Hulse, Stewart H",
  journal = "Music perception",
  volume  =  10,
  number  =  1,
  pages   = "1--23",
  year    =  1992,
  issn    = "0730-7829"
}

@ARTICLE{Semal1996-la,
  title    = "Speech versus nonspeech in pitch memory",
  author   = "Semal, C and Demany, L and Ueda, K and Hall{\'e}, P a",
  abstract = "The memory trace of the pitch sensation induced by a standard
              tone (S) can be strongly degraded by subsequently intervening
              sounds (I). Deutsch [Science 168, 1604-1605 (1970)] suggested
              that the degradation is much weaker when the I sounds are words
              than when they are tones. In Deutsch's study, however, the pitch
              relations between S and the I words were not controlled. The
              first experiment reported here was similar to that of Deutsch
              except that the speech and nonspeech stimuli used as I sounds
              were matched in pitch. The speech stimuli were monosyllabic words
              derived from recordings of a real voice, whereas the nonspeech
              stimuli were harmonic complex tones with a flat spectral profile.
              These two kinds of I sound were presented at a variable pitch
              distance (delta-pitch) from the S tone. In a same/different
              paradigm, S had to be compared with a tone presented 6 s later;
              this comparison tone could be either identical to S or shifted in
              pitch by +/- 75 cents. The nature of the I sounds (spoken words
              versus tones) affected discrimination performance, but markedly
              less than did delta-pitch. Performance was better when
              delta-pitch was large than when it was small, for the speech as
              well as nonspeech I sounds. In a second experiment, the S sounds
              and comparison sounds were spoken words instead of tones. The
              differences to be detected were restricted to shifts in
              fundamental frequency (and thus pitch), the other acoustic
              attributes of the words being left unchanged. Again,
              discrimination performance was positively related to delta-pitch.
              This time, the nature of the I sounds (words versus tones) had no
              significant effect. Overall, the results suggest that, in
              auditory short-term memory, the pitch of speech sounds is not
              stored differently from the pitch of nonspeech sounds.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  100,
  number   = "2 Pt 1",
  pages    = "1132--1140",
  year     =  1996,
  keywords = "Humans; Memory; Pitch Perception; Random Allocation; Short-Term;
              Sound Spectrography; Speech",
  issn     = "0001-4966",
  pmid     = "8759966",
  doi      = "10.1121/1.416298"
}

@ARTICLE{Schulze2011-dx,
  title    = "Neuroarchitecture of verbal and tonal working memory in
              nonmusicians and musicians",
  author   = "Schulze, Katrin and Zysset, Stefan and Mueller, Karsten and
              Friederici, Angela D and Koelsch, Stefan",
  abstract = "Working memory (WM) for auditory information has been thought of
              as a unitary system, but whether WM for verbal and tonal
              information relies on the same or different functional
              neuroarchitectures has remained unknown. This fMRI study examines
              verbal and tonal WM in both nonmusicians (who are trained in
              speech, but not in music) and highly trained musicians (who are
              trained in both domains). The data show that core structures of
              WM are involved in both tonal and verbal WM (Broca's area,
              premotor cortex, pre-SMA/SMA, left insular cortex, inferior
              parietal lobe), although with significantly different structural
              weightings, in both nonmusicians and musicians. Additionally,
              musicians activated specific subcomponents only during verbal
              (right insular cortex) or only during tonal WM (right globus
              pallidus, right caudate nucleus, and left cerebellum). These
              results reveal the existence of two WM systems in musicians: A
              phonological loop supporting rehearsal of phonological
              information, and a tonal loop supporting rehearsal of tonal
              information. Differences between groups for tonal WM, and between
              verbal and tonal WM within musicians, were mainly related to
              structures involved in controlling, programming and planning of
              actions, thus presumably reflecting differences in action-related
              sensorimotor coding of verbal and tonal information.",
  journal  = "Human brain mapping",
  volume   =  32,
  number   =  5,
  pages    = "771--783",
  year     =  2011,
  keywords = "Auditory processing; Functional plasticity; Language; Music;
              Working memory",
  issn     = "1065-9471",
  pmid     = "20533560",
  doi      = "10.1002/hbm.21060"
}

@ARTICLE{Koelsch2009-qr,
  title    = "Functional architecture of verbal and tonal working memory: An
              {fMRI} study",
  author   = "Koelsch, Stefan and Schulze, Katrin and Sammler, Daniela and
              Fritz, Thomas and M??ller, Karsten and Gruber, Oliver",
  abstract = "This study investigates the functional architecture of working
              memory (WM) for verbal and tonal information during rehearsal and
              articulatory suppression. Participants were presented with
              strings of four sung syllables with the task to remember either
              the pitches (tonal information) or the syllables (verbal
              information). Rehearsal of verbal, as well as of tonal
              information activated a network comprising ventrolateral premotor
              cortex (encroaching Broca's area), dorsal premotor cortex, the
              planum temporale, inferior parietal lobe, the anterior insula,
              subcortical structures (basal ganglia and thalamus), as well as
              the cerebellum. The topography of activations was virtually
              identical for the rehearsal of syllables and pitches, showing a
              remarkable overlap of the WM components for the rehearsal of
              verbal and tonal information. When the WM task was performed
              under articulatory suppression, activations in those areas
              decreased, while additional activations arose in anterior
              prefrontal areas. These prefrontal areas might contain additional
              storage components of verbal and tonal WM that are activated when
              auditory information cannot be rehearsed. As in the rehearsal
              conditions, the topography of activations under articulatory
              suppression was nearly identical for the verbal as compared to
              the tonal task. Results indicate that both the rehearsal of
              verbal and tonal information, as well as storage of verbal and
              tonal information relies on strongly overlapping neuronal
              networks. These networks appear to partly consist of
              sensorimotor-related circuits which provide resources for the
              representation and maintenance of information, and which are
              remarkably similar for the production of speech and song.",
  journal  = "Human brain mapping",
  volume   =  30,
  number   =  3,
  pages    = "859--873",
  year     =  2009,
  keywords = "Music; Pitch; Verbal; Working memory",
  issn     = "1065-9471",
  pmid     = "18330870",
  doi      = "10.1002/hbm.20550"
}

@ARTICLE{Gaab2003-wi,
  title    = "The effect of musicianship on pitch memory in performance matched
              groups",
  author   = "Gaab, Nadine and Schlaug, Gottfried",
  abstract = "We compared brain activation patterns between musicians and
              non-musicians (matched in performance score) while they performed
              a pitch memory task (using a sparse temporal sampling fMRI
              method). Both groups showed bilateral activation of the superior
              temporal, supramarginal, posterior middle and inferior frontal
              gyrus, and superior parietal lobe. Musicians showed more right
              temporal and supramarginal gyrus activation while non-musicians
              had more right primary and left secondary auditory cortex
              activation. Since both groups' performance were matched, these
              results probably indicate processing differences between groups
              that are possibly related to musical training. Non-musicians rely
              more on brain regions important for pitch discrimination while
              musicians prefer to use brain regions specialized in short-term
              memory and recall to perform well in this pitch memory task.",
  journal  = "Neuroreport",
  volume   =  14,
  number   =  18,
  pages    = "2291--2295",
  year     =  2003,
  keywords = "auditory cortex; fmri; music; pitch memory; supramarginal gyrus",
  issn     = "0959-4965",
  pmid     = "14663178",
  doi      = "10.1097/00001756-200312190-00001"
}

@ARTICLE{Deutsch1970-ze,
  title    = "Tones and numbers: Specificity of interference in immediate
              memory",
  author   = "Deutsch, D",
  abstract = "Recognition of the pitch of a tone was severely disrupted by the
              incorporation of six other tones during a 5-second retention
              interval, even though the intervening tones could be ignored.
              However, the requirement to recall six numbers spoken at equal
              loudness during the identical retention interval produced only a
              minimum decrement in the same pitch-recognition task. Further,
              the requirement to remember the tone produced no decrement in
              recall of the numbers. It is concluded that immediate memory for
              pitch is subject to a large interference effect which is highly
              specific in nature and which is not due to some limitation in
              general short-term memory capacity or to a distraction of
              attention.",
  journal  = "Science",
  volume   =  168,
  number   =  3939,
  pages    = "1604--1605",
  year     =  1970,
  issn     = "0036-8075",
  pmid     = "5420547",
  doi      = "10.1126/science.168.3939.1604"
}

@ARTICLE{Schulze2012-pe,
  title   = "Working memory for tonal and atonal sequences during a forward and
             backward recognition task",
  author  = "Schulze, Katrin and Dowling, W Jay and Tillmann, Barbara",
  journal = "Music perception",
  volume  =  29,
  number  =  3,
  pages   = "255--267",
  year    =  2012,
  issn    = "0730-7829"
}

@INCOLLECTION{Edworthy1983-lj,
  title     = "Towards a contour-pitch continuum theory of memory for melodies",
  booktitle = "The acquisition of symbolic skills",
  author    = "Edworthy, Judy",
  publisher = "Springer",
  pages     = "263--271",
  year      =  1983,
  address   = "New York, NY"
}

@ARTICLE{Croonen1989-ds,
  title   = "Tonality, tonal scheme, and contour in delayed recognition of tone
             sequences",
  author  = "Croonen, W L M and Kop, P F M",
  journal = "Music perception",
  volume  =  7,
  number  =  1,
  pages   = "49--67",
  year    =  1989,
  issn    = "0730-7829"
}

@ARTICLE{Magne2016-bu,
  title     = "Speech rhythm sensitivity and musical aptitude: {ERPs} and
               individual differences",
  author    = "Magne, Cyrille and Jordan, Deanna K and Gordon, Reyna L",
  abstract  = "This study investigated the electrophysiological markers of
               rhythmic expectancy during speech percep-tion. In addition,
               given the large literature showing overlaps between cognitive
               and neural resources recruited for language and music, we
               considered a relation between musical aptitude and individual
               dif-ferences in speech rhythm sensitivity. Twenty adults were
               administered a standardized assessment of musical aptitude, and
               EEG was recorded as participants listened to sequences of four
               bisyllabic words for which the stress pattern of the final word
               either matched or mismatched the stress pattern of the
               pre-ceding words. Words with unexpected stress patterns elicited
               an increased fronto-central mid-latency negativity. In addition,
               rhythm aptitude significantly correlated with the size of the
               negative effect eli-cited by unexpected iambic words, the least
               common type of stress pattern in English. The present results
               suggest shared neurocognitive resources for speech rhythm and
               musical rhythm.",
  journal   = "Brain and language",
  publisher = "Elsevier Inc.",
  volume    = "153-154",
  pages     = "13--19",
  year      =  2016,
  keywords  = "ERPs; Expectancy; Music; Musical aptitude; Speech meter",
  issn      = "0093-934X, 1090-2155",
  doi       = "10.1016/j.bandl.2016.01.001"
}

@ARTICLE{Ross2016-hl,
  title   = "Dissociating Prediction Failure: Considerations from Music
             Perception",
  author  = "Ross, S and Hansen, N C",
  journal = "Journal of Neuroscience",
  volume  =  36,
  number  =  11,
  pages   = "3103--3105",
  year    =  2016,
  issn    = "0270-6474",
  doi     = "10.1523/JNEUROSCI.0053-16.2016"
}

@ARTICLE{Fujii2013-ic,
  title    = "The Harvard Beat Assessment Test ({H-BAT)}: a battery for
              assessing beat perception and production and their dissociation",
  author   = "Fujii, Shinya and Schlaug, Gottfried",
  abstract = "Humans have the abilities to perceive, produce, and synchronize
              with a musical beat, yet there are widespread individual
              differences. To investigate these abilities and to determine if a
              dissociation between beat perception and production exists, we
              developed the Harvard Beat Assessment Test (H-BAT), a new battery
              that assesses beat perception and production abilities. H-BAT
              consists of four subtests: (1) music tapping test (MTT), (2) beat
              saliency test (BST), (3) beat interval test (BIT), and (4) beat
              finding and interval test (BFIT). MTT measures the degree of
              tapping synchronization with the beat of music, whereas BST, BIT,
              and BFIT measure perception and production thresholds via
              psychophysical adaptive stair-case methods. We administered the
              H-BAT on thirty individuals and investigated the performance
              distribution across these individuals in each subtest. There was
              a wide distribution in individual abilities to tap in synchrony
              with the beat of music during the MTT. The degree of
              synchronization consistency was negatively correlated with
              thresholds in the BST, BIT, and BFIT: a lower degree of
              synchronization was associated with higher perception and
              production thresholds. H-BAT can be a useful tool in determining
              an individual's ability to perceive and produce a beat within a
              single session.",
  journal  = "Frontiers in human neuroscience",
  volume   =  7,
  pages    = "1--16",
  year     =  2013,
  keywords = "battery; beat; beat-deafnes; beat-deafness; dissociation; meter;
              rhythm; synchronization",
  issn     = "1662-5161",
  pmid     = "24324421",
  doi      = "10.3389/fnhum.2013.00771"
}

@INCOLLECTION{Bamberger2016-wj,
  title     = "Action and symbol: An essential tension",
  booktitle = "Mathemusical Conversations",
  author    = "Bamberger, Jeanne",
  editor    = "Chew, E and Assayag, G and Smith, J B L",
  year      =  2016
}

@INPROCEEDINGS{Yang2015-sr,
  title     = "Mathematical thought and empirical approaches in higher
               education in music",
  booktitle = "Mathemusical Conversations",
  author    = "Yang, Jian",
  year      =  2015
}

@ARTICLE{Lampe2007-gy,
  title   = "Integrating Interactive Learning Experiences into Augmented Toy
             Environments",
  author  = "Lampe, Matthias and Hinske, Steve",
  journal = "Wortkshop on Pervasive Learning",
  pages   = "1--9",
  year    =  2007
}

@INPROCEEDINGS{Hinske2009-mk,
  title     = "Kingdom of the Knights",
  booktitle = "Proceedings of the 8th International Conference on Interaction
               Design and Children - {IDC} '09",
  author    = "Hinske, Steve and Lampe, Matthias and Yuill, Nicola and Price,
               Sara and Langheinrich, Marc",
  year      =  2009,
  isbn      = "9781605583952",
  doi       = "10.1145/1551788.1551829"
}

@ARTICLE{Magerkurth2005-nz,
  title    = "Pervasive games: bringing computer entertainment back to the real
              world",
  author   = "Magerkurth, Carsten and Cheok, Adrian David and Mandryk, Regan L
              and Nilsen, Trond",
  abstract = "This article gives an introduction and overview of the field of
              pervasive gaming, an emerging genre in which traditional,
              real-world games are augmented with computing functionality, or,
              depending on the perspective, purely virtual computer
              entertainment is brought back to the real world.The field of
              pervasive games is diverse in the approaches and technologies
              used to create new and exciting gaming experiences that profit by
              the blend of real and virtual game elements. We explicitly look
              at the pervasive gaming sub-genres of smart toys, affective
              games, tabletop games, location-aware games, and augmented
              reality games, and discuss them in terms of their benefits and
              critical issues, as well as the relevant technology base.",
  journal  = "Computers in Entertainment",
  volume   =  3,
  number   =  3,
  pages    = "1--19",
  year     =  2005,
  issn     = "1544-3574",
  doi      = "10.1145/1077246.1077257"
}

@ARTICLE{Whitton2011-uh,
  title    = "Game engagement theory and adult learning",
  author   = "Whitton, Nicola",
  abstract = "One of the benefits of computer game--based learning is the
              ability of certain types of game to engage and motivate learners.
              However, theories of learning and engagement, particularly in the
              sphere of higher education, typically fail to consider gaming
              engage- ment theory. In this article, the author examines the
              principles of engagement from games designed for entertainment,
              applies these principles to the design of learning activities,
              and presents a model of learning engagement. The article examines
              litera- ture on computer games and engagement, draws together the
              findings from a series of interviews, and applies these in an
              educational context. The author hypothesizes five factors that
              contribute to engagement with a learning activity and provides an
              example of the use of these factors in practice. The article
              concludes by considering further potential applications of the
              model.",
  journal  = "Simulation \& gaming",
  volume   =  42,
  number   =  5,
  pages    = "596--609",
  year     =  2011,
  keywords = "adult learning; challenge; control; engagement; flow; game-based
              learning; higher education; immersion; interest; purpose",
  issn     = "1046-8781",
  doi      = "10.1177/1046878110378587"
}

@ARTICLE{Shaer2009-as,
  title   = "Tangible User Interfaces: Past, Present, and Future Directions",
  author  = "Shaer, Orit",
  journal = "Foundations and Trends\textregistered{} in Human--Computer
             Interaction",
  volume  =  3,
  number  = "1-2",
  pages   = "1--137",
  year    =  2009,
  issn    = "1551-3955",
  doi     = "10.1561/1100000026"
}

@ARTICLE{Antle2009-sg,
  title     = "What the body knows: Exploring the benefits of embodied
               metaphors in hybrid physical digital environments",
  author    = "Antle, Alissa N and Corness, Greg and Droumeva, Milena",
  abstract  = "A recent trend in ubiquitous computing is the development of new
               forms of interfaces, which rely on embodied interaction. We
               focus on the definition of embodiment that refers to the ways in
               which abstract concepts rely on metaphorical extensions of
               embodied schemata shaped by processes below the level of
               conscious awareness as explored by Lakoff and Johnson [Lakoff,
               G., Johnson, M., 1980. Metaphors We Live By. Chicago Press,
               Chicago, IL, USA]. Our inquiry focuses on understanding the role
               embodied metaphors may play in supporting people to understand
               the possibilities for physical interaction in augmented spaces.
               We explore this issue through the development and evaluation of
               an interactive audio environment. We instantiate metaphor theory
               by using embodied schemata as the basis for the interactional
               metaphor that relates full-body input actions to audio output
               responses. We demonstrate and explore the benefits of this
               approach through a comparative experiment in which adults and
               children learn to use our audio environment. The results from
               our experiment indicated that embodied metaphors improve
               usability however, other factors including discoverability,
               perceivability of feedback and duplicity of structural
               isomorphism may mediate these metaphor-based benefits. We have
               generalized our main findings as a set of suggestions for the
               design of embodied style interfaces that rely on physical
               interaction. ?? 2008 Elsevier B.V. All rights reserved.",
  journal   = "Interacting with computers",
  publisher = "Elsevier B.V.",
  volume    =  21,
  number    = "1-2",
  pages     = "66--75",
  year      =  2009,
  keywords  = "Audio environments; Augmented environments; Embodied
               interaction; Metaphor; Physical interaction",
  issn      = "0953-5438",
  doi       = "10.1016/j.intcom.2008.10.005"
}

@ARTICLE{Howard-Jones2009-oj,
  title    = "Uncertainty and engagement with learning games",
  author   = "Howard-Jones, Paul A and Demetriou, Skevi",
  abstract = "Uncertainty may be an important component of the motivation
              provided by learning games, especially when associated with
              gaming rather than learning. Three studies are reported that
              explore the influence of gaming uncertainty on engagement with
              computer- based learning games. In the first study, children
              (10--11 years) played a simple maths quiz. Participants chose
              their preferred reward for a correct answer prior to seeing each
              question. They could either receive a single point or toss an
              animated coin to receive 2 points for heads or none for tails. A
              preference for the uncertain option was revealed and this
              increased during the quiz. The second study explored the
              discourse around learning when pairs of participants (13--14
              years) competed against the computer in a science quiz. Progress
              depended on the acquisition of facts but also on the outcomes of
              throwing dice. Discourse was characterized by a close
              intermingling of learning and gaming talk without salient
              problematic constructions regarding fairness when losing points
              due to gaming uncertainty. A final experiment explored whether,
              in this type of game, the uncertainty provided by the gaming
              component could influence players' affective response to the
              learning component. Electrodermal activity (EDA) of 16 adults was
              measured while they played the quiz with and without the element
              of chance provided by the dice. Results showed EDA when answering
              questions was increased by inclusion of gaming uncertainty.
              Findings are discussed in terms of the potential benefits of
              combining gaming uncertainty with learning and directions for
              further research in this area are outlined. (PsycINFO Database
              Record (c) 2012 APA, all rights reserved) (journal abstract)",
  journal  = "Instructional Science",
  volume   =  37,
  number   =  6,
  pages    = "519--536",
  year     =  2009,
  keywords = "Games; Learning; Motivation; Uncertainty",
  issn     = "0020-4277",
  doi      = "10.1007/s11251-008-9073-6"
}

@INPROCEEDINGS{Hinske2008-mw,
  title     = "Towards guidelines for designing augmented toy environments",
  booktitle = "Proceedings of the 7th {ACM} conference on Designing interactive
               systems - {DIS} '08",
  author    = "Hinske, Steve and Langheinrich, Marc and Lampe, Matthias",
  abstract  = "Combining interactive technology with traditional toys promises
               to significantly enhance the educational value of children's
               play. Designing such augmented toy environments, however,
               requires designers to take both the traditional, technology-less
               nature of the toy, and the novel interactive aspects of the
               newly accessible virtual environment into account. This article
               attempts to present a unified set of guidelines for the design
               and implementation of augmented toy environments, drawing upon
               existing literature in traditional and educational toy and game
               design, as well as our own experiences in building mixed reality
               game environments. We also offer practical advice on the use of
               these guidelines by reporting on our own augmented toy
               environment for young children, called the Augmented Knight's
               Castle, which encourages learning about the Middle Ages in a
               playful way.",
  pages     = "78--87",
  year      =  2008,
  keywords  = "augmented toy environments; design guidelines; interactive
               systems; mixed; pervasive computing; reality",
  isbn      = "9781605580029",
  doi       = "10.1145/1394445.1394454"
}

@ARTICLE{Livingstone2010-cr,
  title    = "Changing musical emotion: A computational rule system for
              modifying score and performance",
  author   = "Livingstone, Steven R and Muhlberger, Ralf and Brown, Andrew R
              and Thompson, William F",
  abstract = "Composers and performers communicate emotional intentions through
              the control of basic musical features such as pitch, loudness,
              and articulation. The extent to which emotion can be controlled
              by software through the systematic manipulation of these features
              has not been fully examined. To address this, we present CMERS, a
              Computational Music Emotion Rule System for the real-time control
              of musical emotion that modifies features at both the score level
              and the performance level. In Experiment 1, 20 participants
              continuously rated the perceived emotion of works each modified
              to express happy, sad, angry, tender, and normal. Intended
              emotion was identified correctly at 78\%, with valence and
              arousal significantly shifted regardless of the works' original
              emotions. Existing systems developed for expressive performance,
              such as Director Musices (DM), focus on modifying features of
              performance. To study emotion more broadly, CMERS modifies
              features of both score and performance. In Experiment 2, 18
              participants rated music works modified by CMERS and DM to
              express five emotions. CMERS's intended emotion was correctly
              identified at 71\%, DM at 49\%. CMERS achieved significant shifts
              in valence and arousal, DM in arousal only. These results suggest
              that features of the score are important for controlling valence.
              The effects of musical training on emotional identification
              accuracy are also discussed.",
  journal  = "Computer Music Journal",
  volume   =  34,
  number   =  1,
  pages    = "41--64",
  year     =  2010,
  issn     = "0148-9267",
  doi      = "10.1162/comj.2010.34.1.41"
}

@INPROCEEDINGS{Huang2012-sg,
  title     = "Fast emotion detection from {EEG} using asymmetric spatial
               filtering",
  booktitle = "2012 {IEEE} International Conference on Acoustics, Speech and
               Signal Processing ({ICASSP})",
  author    = "Huang, Dong and Zhang, Haihong and Ang, Kaikeng and Guan, Cuntai
               and Pan, Yaozhang and Wang, Chuanchu and Yu, Juanhong",
  abstract  = "The injection of emotional intelligence in human-computer
               interfaces is necessary for computer applications to appear
               intelligent when interacting with people. With the recent de-
               velopment of brain imaging techniques and brain-computer
               interfaces, computers can actually take a look inside users'
               head to observe their emotional states. This paper presents an
               EEG-based emotion detection system which detects emo- tional
               states based on short EEG segments of 1s. A novel fea- ture
               extraction algorithm termed asymmetric spatial filtering is
               proposed to extract features from high dimensional EEG data. The
               effectiveness of the proposed method is tested for two types of
               emotion detection problems on data from five subjects.",
  pages     = "589--592",
  year      =  2012,
  issn      = "1520-6149",
  isbn      = "9781467300469",
  doi       = "10.1109/ICASSP.2012.6287952"
}

@ARTICLE{Farbood2004-ra,
  title   = "Hyperscore: A graphical sketchpad for novice composers",
  author  = "Farbood, Mary and Pasztor, Egon and Jennings, Kevin",
  journal = "IEEE computer graphics and applications",
  volume  =  24,
  number  =  1,
  pages   = "50--54",
  year    =  2004,
  issn    = "0272-1716"
}

@INPROCEEDINGS{Dixon2005-te,
  title     = "The ``Air Worm'': An interface for real-time manipulation of
               expressive music performance",
  booktitle = "Proceedings of the 2005 International Computer Music Conference
               ({ICMC2005})",
  author    = "Dixon, Simon and Goebl, Werner and Widmer, Gerhard",
  abstract  = "Expressive performance of traditional Western music is a complex
               phenomenon which is mastered by few, and yet appreciated by
               many. In this paper we explore various ways of interacting with
               expressive performances using methods that are accessible to
               non-expert music-lovers. A digital theremin is used as an input
               device, and users can control the two most important expressive
               parame- ters, tempo and loudness, during playback of an audio or
               MIDI file. Several modes of operation are possible: the Air Worm
               builds on previous work in performance vi- sualisation, where
               the tempo is displayed on the horizontal axis and loudness on
               the vertical axis in a two-dimensional animation; the Air Tapper
               uses a conducting metaphor where the beat is given by the
               minimum vertical point in a quasi-periodic trajectory; and the
               Mouse-Worm allows users without a theremin to use a standard
               input device as controller.",
  year      =  2005,
  doi       = "10.1.1.1.3452"
}

@ARTICLE{Aho2014-pv,
  title   = "Model selection for ecologists: the worldviews of {AIC} and {BIC}",
  author  = "Aho, Ken and Derryberry, Dewayne and Peterson, Teri",
  journal = "Ecology",
  volume  =  95,
  number  =  3,
  pages   = "631--636",
  year    =  2014,
  issn    = "0012-9658"
}

@INPROCEEDINGS{Roy2013-er,
  title     = "Enforcing Meter in {Finite-Length} Markov Sequences",
  booktitle = "Proc. 27th {AAAI} Conference on Artificial Intelligence",
  author    = "Roy, Pierre and Pachet, Fran{\c c}ois",
  year      =  2013,
  isbn      = "9781577356158"
}

@BOOK{Amabile1996-kt,
  title     = "Creativity in context",
  author    = "Amabile, T M",
  publisher = "Westview Press",
  year      =  1996,
  address   = "Boulder, CO"
}

@ARTICLE{Frieler2006-ok,
  title    = "Generalized N-gram Measures for Melodic Similarity",
  author   = "Frieler, Klaus",
  abstract = "In this paper we propose three generalizations of well-known
              N-gram approaches for measuring similarity of single-line
              melodies. In a former paper we compared around 50 similarity
              measures for melodies with empirical data from music
              psychological experiments. Similarity measures based on edit
              distances and N-grams always showed the best results for
              different contexts. This paper aims at a generalization of N-gram
              measures that can combine N-gram and other similarity measures in
              a fairly general way.",
  pages    = "289--298",
  year     =  2006,
  doi      = "10.1007/3-540-34416-0\_31"
}

@ARTICLE{Mullensiefen2006-bm,
  title   = "The Simile algorithms documentation 0 . 3",
  author  = "M{\"u}llensiefen, Daniel and Frieler, Klaus",
  journal = "Simile",
  year    =  2006
}

@INCOLLECTION{Marsden2000-nd,
  title     = "Music, intelligence and artificiality",
  booktitle = "Readings in Music and Artificial Intelligence",
  author    = "Marsden, A",
  publisher = "Harwood Academic Publishers",
  pages     = "15--28",
  year      =  2000,
  address   = "Amsterdam, The Netherlands"
}

@ARTICLE{Watkins1985-wb,
  title    = "Scale, key, and contour in the discrimination of tuned and
              mistuned approximations to melody",
  author   = "Watkins, Anthony J",
  journal  = "Perception \& psychophysics",
  volume   =  37,
  number   =  4,
  pages    = "275--285",
  year     =  1985,
  keywords = "Humans; Music; Pitch Discrimination; Psychoacoustics",
  issn     = "0031-5117",
  pmid     = "4034344",
  doi      = "10.3758/BF03211349"
}

@ARTICLE{Bartlett1988-cz,
  title   = "Scale structure and similarity of melodies",
  author  = "Bartlett, James C and Dowling, W Jay",
  journal = "Music perception",
  volume  =  5,
  number  =  3,
  pages   = "285--314",
  year    =  1988,
  issn    = "0730-7829"
}

@ARTICLE{Ritchie2007-pw,
  title    = "Some empirical criteria for attributing creativity to a computer
              program",
  author   = "Ritchie, Graeme",
  abstract = "Over recent decades there has been a growing interest in the
              question of whether computer programs are capable of genuinely
              creative activity. Although this notion can be explored as a
              purely philosophical debate, an alternative perspective is to
              consider what aspects of the behaviour of a program might be
              noted or measured in order to arrive at an empirically supported
              judgement that creativity has occurred. We sketch out, in general
              abstract terms, what goes on when a potentially creative program
              is constructed and run, and list some of the relationships (for
              example, between input and output) which might contribute to a
              decision about creativity. Specifically, we list a number of
              criteria which might indicate interesting properties of a
              program's behaviour, from the perspective of possible creativity.
              We go on to review some ways in which these criteria have been
              applied to actual implementations, and some possible improvements
              to this way of assessing creativity.",
  journal  = "Minds and Machines",
  volume   =  17,
  number   =  1,
  pages    = "67--99",
  year     =  2007,
  keywords = "AI methodology; Assessing output; Computational creativity;
              Empirical criteria; Generating artefacts",
  issn     = "0924-6495",
  doi      = "10.1007/s11023-007-9066-2"
}

@ARTICLE{Binsted1994-jw,
  title    = "An implemented model of punning riddles",
  author   = "Binsted, Kim and Ritchie, Graeme",
  abstract = "In this paper, we discuss a model of simple question-answer
              punning, implemented in a program, JAPE, which generates riddles
              from humour-independent lexical entries. The model uses two main
              types of structure: schemata, which determine the relationships
              between key words in a joke, and templates, which produce the
              surface form of the joke. JAPE succeeds in generating pieces of
              text that are recognizably jokes, but some of them are not very
              good jokes. We mention some potential improvements and
              extensions, including post-production heuristics for ordering the
              jokes according to quality.",
  pages    = "6",
  year     =  1994,
  arxivid  = "cmp-lg/9406022"
}

@ARTICLE{Binsted1996-mg,
  title    = "Machine humour: An implemented model of puns",
  author   = "Binsted, Kim",
  abstract = "This thesis describes a formal model of a subtype of humour, and
              the implementation of that model in a program that generates
              jokes of that subtype. Although there is a great deal of
              literature on humour in general, very little formal work has been
              done on puns, and none has been implemented. All current
              linguistic theories of humour are over-general and not
              falsifiable. Our model, which is specific, formal, implemented
              and evaluated, makes a significant contribution to the field.
              Punning riddles are our chosen subtype of verbal humour, for
              several reasons. They are very common, they exhibit certain
              regular structures and mechanisms, and they have been studied
              previously by linguists. Our model is based on our extensive
              analysis of large numbers of punning riddles, taken from
              children's joke books. The implementation of the model, JAPE
              (Joke Analysis and Production Engine), generates punning riddles,
              from a humour independent lexicon. Pun generation requires much
              less world knowledge than pun comprehension, making it feasible
              for implementation. To support our claim that all of JAPE's
              output is punning riddles, we conducted an evaluatory experiment.
              We took JAPE texts, human-generated texts, nonsense non-jokes and
              sensible non-jokes, and asked joke experts to evaluate them. For
              jok e experts, we used 8-11 year old children, since
              psychological research suggests that this age group enjoys, and
              can recognize, punning riddles better than other age groups. The
              results showed that JAPE's output texts are, in fact,
              recognizably jokes.The evaluation showed that our model
              adequately describes a significant subtype of verbal humour. We
              believe that this model can now be expanded to cover puns in
              general, as well as other types of linguistic humour.",
  pages    = "198",
  year     =  1996,
  keywords = "Machine humour; puns"
}

@ARTICLE{Pease2011-tk,
  title    = "On impact and evaluation in computational creativity: A
              discussion of the Turing test and an alternative proposal",
  author   = "Pease, A and Colton, S",
  abstract = "Computational Creativity is the AI subfield in which we study how
              to build computational models of creative thought in science and
              the arts. From an engineering perspective, it is desirable to
              have concrete measures for assessing the progress made from one
              version of a program to another, or for comparing and contrasting
              different software systems for the same creative task. We
              describe the Turing Test and versions of it which have been used
              in order to measure progress in Computational Creativity. We show
              that the versions proposed thus far lack the important aspect of
              interaction, without which much of the power of the Turing Test
              is lost. We argue that the Turing Test is largely inappropriate
              for the purposes of evaluation in Computational Creativity, since
              it attempts to homogenise creativity into a single (human) style,
              does not take into account the importance of background and
              contextual information for a creative act, encourages
              superficial, uninteresting advances in front-ends, and rewards
              creativity which adheres to a certain style over that which
              creates something which is genuinely novel. We further argue that
              although there may be some place for Turing-style tests for
              Computational Creativity at some point in the future, it is
              currently untenable to apply any defensible version of the Turing
              Test. As an alternative to Turing-style tests, we introduce two
              descriptive models for evaluating creative software, the FACE
              model which describes creative acts performed by software in
              terms of tuples of generative acts, and the IDEA model which
              describes how such creative acts can have an impact upon an ideal
              audience, given ideal information about background knowledge and
              the software development process. While these models require
              further study and elaboration, we believe that they can be
              usefully applied to current systems as well as guiding further
              development of creative systems.",
  journal  = "AISB 2011: Computing and Philosophy",
  pages    = "15--22",
  year     =  2011
}

@ARTICLE{Colton2008-fr,
  title    = "Creativity Versus the Perception of Creativity in Computational
              Systems",
  author   = "Colton, Simon",
  abstract = "We add to the discussion of how to assess the creativ- ity of
              programs which generate artefacts such as poems, theorems,
              paintings, melodies, etc. To do so, we first review some existing
              frameworks for assessing artefact generation programs. Then,
              drawing on our experience of building both a mathematical
              discovery system and an automated painter, we argue that it is
              not appro- priate to base the assessment of a system on its
              output alone, and that the way it produces artefacts also needs
              to be taken into account. We suggest a simple frame- work within
              which the behaviour of a program can be categorised and described
              which may add to the per- ception of creativity in the system.",
  journal  = "Proceedings of the AAAI Spring Symposium on Creative Systems",
  number   = "Colton 2002",
  pages    = "14--20",
  year     =  2008,
  keywords = "Technical Report SS-08-03"
}

@ARTICLE{Abel1972-wt,
  title   = "Duration discrimination of noise and tone bursts",
  author  = "Abel, Sharon M",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  51,
  number  = "4B",
  pages   = "1219--1223",
  year    =  1972,
  issn    = "0001-4966"
}

@ARTICLE{Tillmann2011-li,
  title    = "Fine-grained pitch processing of music and speech in congenital
              amusia",
  author   = "Tillmann, Barbara and Rusconi, Elena and Traube, Caroline and
              Butterworth, Brian and Umilt{\`a}, Carlo and Peretz, Isabelle",
  abstract = "Congenital amusia is a lifelong disorder of music processing that
              has been ascribed to impaired pitch perception and memory. The
              present study tested a large group of amusics (n=17) and provided
              evidence that their pitch deficit affects pitch processing in
              speech to a lesser extent: Fine-grained pitch discrimination was
              better in spoken syllables than in acoustically matched tones.
              Unlike amusics, control participants performed fine-grained pitch
              discrimination better for musical material than for verbal
              material. These findings suggest that pitch extraction can be
              influenced by the nature of the material (music vs speech), and
              that amusics' pitch deficit is not restricted to musical
              material, but extends to segmented speech events.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  130,
  number   =  6,
  pages    = "4089--4096",
  year     =  2011,
  keywords = "Auditory Perceptual Disorders; Auditory Perceptual Disorders:
              physiopathology; Case-Control Studies; Humans; Music; Pitch
              Discrimination; Pitch Discrimination: physiology; Speech
              Perception; Speech Perception: physiology",
  issn     = "0001-4966, 1520-8524",
  pmid     = "22225063",
  doi      = "10.1121/1.3658447"
}

@ARTICLE{Jesteadt1977-lq,
  title    = "Frequency discrimination as a function of frequency and sensation
              level",
  author   = "Jesteadt, W and Wier, C C and Green, D M",
  abstract = "Intensity discrimination was measured for pulsed sinusoids of
              various frequencies (2008000 Hz) and sensation levels (580 dB).
              The data for all frequencies were fitted by a single function,
              DeltaI/I=0.463 (I/I0)0.072, where I0 is intensity at threshold, I
              is the intensity of the tone, and DeltaI is the increment needed
              to obtain 71\% correct in a two-interval forced-choice adaptive
              procedure. The form of this function is in good agreement with
              data reported in comparable studies but differs markedly from the
              data reported by Riesz Phys. Rev. 31, 867875 (1928). An analysis
              of the actual values of DeltaI/I reported in the other studies
              indicates a range larger than would be predicted on the basis of
              individual differences among observers in this study. The data
              are also discussed differences among observers in this study. The
              data are also discussed in terms of the predictions of current
              theoretical models.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  61,
  number   =  1,
  pages    = "169--177",
  year     =  1977,
  issn     = "0001-4966",
  pmid     = "833368",
  doi      = "10.1121/1.381278"
}

@ARTICLE{Tyler1983-av,
  title    = "Frequency resolution and discrimination of constant and dynamic
              tones in normal and hearing-impaired listeners",
  author   = "Tyler, R S and Wood, E J and Fernandes, M",
  abstract = "Frequency resolution and three tasks of frequency discrimination
              were measured at 500 and 4000 Hz in 12 normal and 12
              hearing-impaired listeners. A three-interval, two-alternative
              forced-choice procedure was used. Frequency resolution was
              measured with an abbreviated psychoacoustical tuning curve.
              Frequency discrimination was measured for (1) a fixed-frequency
              standard and target, (2) a fixed-frequency standard and a
              frequency-transition target, and (3) frequency-transition
              standard and a frequency-transition target. The 50-ms frequency
              transitions had the same final frequency as the standards, but
              the initial frequency was lowered to obtain about 79\%
              discrimination performance. There was a strong relationship
              between poor frequency resolution and elevated pure-tone
              thresholds, but only a very weak relationship between poor
              frequency discrimination and elevated pure-tone thresholds.
              Several hearing-impaired listeners had normal discrimination
              performance together with pure-tone thresholds of 80-90 dB HL. A
              slight correlation was found between word recognition and
              frequency discrimination, but a detailed comparison of the
              phonetic errors and either the frequency-discrimination or
              frequency-resolution tasks failed to suggest any consistent
              interdependencies. These results are consistent with previous
              work that has suggested that frequency resolution and frequency
              discrimination are independent processes.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  74,
  number   =  4,
  pages    = "1190--1199",
  year     =  1983,
  issn     = "0001-4966",
  pmid     = "6643841",
  doi      = "10.1121/1.390043"
}

@ARTICLE{Kishon-Rabin2001-bw,
  title    = "Pitch discrimination: Are professional musicians better than
              non-musicians?",
  author   = "Kishon-Rabin, L and Amir, O and Vexler, Y and Zaltz, Y",
  abstract = "Musicians are typically considered to exhibit exceptional
              auditory skills. Only few studies, however, have substantiated
              this in basic psychoacoustic tasks. The purpose of the present
              investigation was to expand our knowledge on basic auditory
              abilities of musicians compared to non-musicians. Specific goals
              were: (1) to compare frequency discrimination thresholds
              (difference limen for frequency [DLF]) of non-musical pure tones
              in controlled groups of professional musicians and non-musicians;
              (2) to relate DLF performance to musical background; and (3) to
              compare DLF thresholds obtained with two threshold estimation
              procedures: 2- and 3- interval forced choice procedures (2IFC and
              3IFC). Subjects were 16 professional musicians and 14
              non-musicians. DLFs were obtained for three frequencies (0.25, 1
              and 1.5 kHz) using the 3IFC adaptive procedure, and for one
              frequency (1 kHz) also using the 2IFC. Three threshold estimates
              were obtained for each frequency, procedure and subject. The
              results of the present study support five major findings: (a)
              mean DLFs for musicians were approximately half the values of the
              non-musicians; (b) significant learning for both groups during
              the three threshold estimations; (c) classical musicians
              performed better than those with contemporary musical background;
              (d) performance was influenced by years of musical experience;
              and (e) both groups showed better DLF in a 2IFC paradigm compared
              to the 3IFC. These data highlight the importance of short-term
              training on an auditory task, auditory memory and factors related
              to musical background (such as musical genre and years of
              experience) on auditory performance.",
  journal  = "Journal of basic and clinical physiology and pharmacology",
  volume   =  12,
  number   = "2 Suppl",
  pages    = "125--143",
  year     =  2001,
  issn     = "0792-6855",
  pmid     = "11605682",
  doi      = "10.1515/JBCPP.2001.12.2.125"
}

@ARTICLE{Murtaugh2014-fd,
  title   = "In defense of {P} values",
  author  = "Murtaugh, Paul A",
  journal = "Ecology",
  volume  =  95,
  number  =  3,
  pages   = "611--617",
  year    =  2014,
  issn    = "0012-9658"
}

@ARTICLE{Halpern1982-hg,
  title   = "Duration discrimination in a series of rhythmic events",
  author  = "Halpern, Andrea R and Darwin, C J",
  journal = "Perception \& psychophysics",
  volume  =  31,
  number  =  1,
  pages   = "86--89",
  year    =  1982,
  issn    = "0031-5117",
  pmid    = "7070941",
  doi     = "10.3758/BF03206204"
}

@ARTICLE{Schellenberg1994-ot,
  title   = "Frequency ratios and the perception of tone patterns",
  author  = "Schellenberg, E Glenn and Trehub, S E",
  journal = "Psychonomic bulletin \& review",
  volume  =  1,
  number  =  2,
  pages   = "191--201",
  year    =  1994,
  issn    = "1069-9384"
}

@ARTICLE{Schellenberg1989-je,
  title   = "Natural musical intervals: Evidence from infant listeners",
  author  = "Schellenberg, E Glenn and Trehub, Sandra E",
  journal = "Psychological science",
  volume  =  7,
  number  =  5,
  pages   = "5--19",
  year    =  1989,
  issn    = "0956-7976"
}

@ARTICLE{Richter2006-uh,
  title    = "What Is Wrong With {ANOVA} and Multiple Regression? Analyzing
              Sentence Reading Times With Hierarchical Linear Models",
  author   = "Richter, Tobias",
  abstract = "Most reading time studies using naturalistic texts yield data
              sets characterized by a multilevel structure: Sentences (sentence
              level) are nested within persons (person level). In contrast to
              analysis of variance and multiple regression techniques, hierar-
              chical linear models take the multilevel structure of reading
              time data into account. They provide methods to estimate variance
              components and to model the influence of predictor variables on
              different levels as well as cross-level interactions between
              these predictors. This article gives a brief introduction to the
              method and proposes practical guidelines for its application to
              reading time data, including a discussion of power issues and the
              scaling of predictor variables. The basic principles of model
              building and hypothesis testing are illustrated with original
              data from a reading time study with naturalistic texts. In",
  journal  = "Discourse processes",
  volume   =  41,
  number   =  3,
  pages    = "221--250",
  year     =  2006,
  keywords = "2006; 221; 250; 3; 41; and multiple regression; anova; copyright;
              course processes; inc; lawrence erlbaum associates; what is wrong
              with",
  issn     = "0163-853X",
  doi      = "10.1207/s15326950dp4103\_1"
}

@ARTICLE{Widmer1992-dl,
  title   = "Qualitative perception modeling and intelligent musical learning",
  author  = "Widmer, Gerhard",
  journal = "Computer Music Journal",
  volume  =  16,
  number  =  2,
  pages   = "51--68",
  year    =  1992
}

@INPROCEEDINGS{Gillick2009-rh,
  title     = "Learning jazz grammars",
  booktitle = "Proceedings of the 6th Sound and Music Computing Conference",
  author    = "Gillick, Jon and Tang, Kevin and Keller, Robert M",
  pages     = "125--130",
  year      =  2009
}

@ARTICLE{Steedman1984-iv,
  title   = "A generative grammar for jazz chord sequences",
  author  = "Steedman, Mark J",
  journal = "Music perception",
  volume  =  2,
  number  =  1,
  pages   = "52--77",
  year    =  1984,
  issn    = "0730-7829"
}

@ARTICLE{Chemillier2004-il,
  title    = "Toward a formal study of jazz chord sequences generated by
              Steedman's grammar",
  author   = "Chemillier, M",
  abstract = "This paper shows how to generate jazz chord sequences
              incrementally using Steedman's grammar by taking advantage of
              some formal properties. We point out the specific role played by
              particular chord sequences called ``cadential sequences''. By
              precompiling them, one could improve the implementation of
              Steedman's grammar in a real-time improvisation system, and make
              it more reactive to the inputs of the user.",
  journal  = "Soft Computing",
  volume   =  8,
  number   =  9,
  pages    = "617--622",
  year     =  2004,
  keywords = "Chord sequence; Formal grammar; Harmonic substitution;
              Improvisation; Jazz; Real-time; Rewrite rule",
  issn     = "1432-7643",
  doi      = "10.1007/s00500-004-0386-3"
}

@INPROCEEDINGS{Keller2007-hq,
  title     = "A grammatical approach to automatic improvisation",
  booktitle = "4th Sound and Music Computing Conference",
  author    = "Keller, Robert M and Morrison, David R",
  abstract  = "We describe an approach to the automatic generation of
               convincing jazz melodies using probabilistic grammars. Uses of
               this approach include a software tool for assisting a soloist in
               the creation of a jazz solo over chord progressions. The method
               also shows promise as a means of automatically improvising
               complete solos in real-time. Our approach has been implemented
               and demonstrated in a free software tool.",
  pages     = "330--337",
  year      =  2007,
  keywords  = "a grammar can be; and linguistics; as it occurs in; computer
               science; context-free grammar; educational software;
               improvisation; jazz; melody generator; probabilistic
               context-free grammar; then we show how; used",
  isbn      = "9789606608759"
}

@ARTICLE{Fernandez2013-mp,
  title    = "{AI} methods in algorithmic composition: A comprehensive survey",
  author   = "Fern{\'a}ndez, Jose David and Vico, Francisco",
  abstract = "Algorithmic composition is the partial or total automation of the
              process of music composition by using computers. Since the 1950s,
              different computational techniques related to Artificial
              Intelligence have been used for algorithmic composition,
              including grammatical representations, probabilistic methods,
              neural networks, symbolic rule-based systems, constraint
              programming and evolutionary algorithms. This survey aims to be a
              comprehensive account of research on algorithmic composition,
              presenting a thorough view of the field for researchers in
              Artificial Intelligence.",
  journal  = "The journal of artificial intelligence research",
  volume   =  48,
  pages    = "513--582",
  year     =  2013,
  issn     = "1076-9757",
  arxivid  = "1402.0585",
  doi      = "10.1613/jair.3908"
}

@INPROCEEDINGS{Wright2003-pq,
  title     = "{OpenSound} Control: State of the art 2003",
  booktitle = "Proceedings of the 2003 Conference on New Interfaces for Musical
               Expression ({NIME-03})",
  author    = "Wright, Matthew and Freed, Adrian and Momeni, Ali",
  abstract  = "OpenSound Control (``OSC'') is a protocol for communication
               among computers, sound synthesizers, and other multimedia
               devices that is optimized for modern networking technology. OSC
               has achieved wide use in the field of computer-based new
               interfaces for musical expression for wide-area and local-area
               networked distributed music systems, inter-process
               communication, and even within a single application.",
  pages     = "153--159",
  year      =  2003,
  isbn      = "9780771706042"
}

@ARTICLE{Reas2006-zk,
  title    = "Processing: Programming for the media arts",
  author   = "Reas, Casey and Fry, Ben",
  abstract = "Processing is a programming language and environment built for
              the media arts communities. It is created to teach fundamentals
              of computer programming within the media arts context and to
              serve as a software sketchbook. It is used by students, artists,
              designers, architects, and researchers for learning, prototyping,
              and production. This essay discusses the ideas underlying the
              software and presents its relationship to open source software
              and the idea of software literacy. Additionally, Processing is
              discussed in relation to education and online communities.",
  journal  = "AI and Society",
  volume   =  20,
  number   =  4,
  pages    = "526--538",
  year     =  2006,
  keywords = "Authoring tools; Education; Online communities; Software;
              Software literacy",
  issn     = "0951-5666",
  doi      = "10.1007/s00146-006-0050-9"
}

@ARTICLE{Chew2012-yp,
  title   = "About time: Strategies of performance revealed in graphs",
  author  = "Chew, Elaine",
  journal = "Visions of Research in Music Education",
  volume  =  20,
  number  =  1,
  year    =  2012
}

@BOOK{Cope2005-bd,
  title     = "Computer models of musical creativity",
  author    = "Cope, David",
  publisher = "MIT Press",
  year      =  2005,
  address   = "Cambridge, MA"
}

@ARTICLE{Seddon2005-wb,
  title    = "Modes of communication during jazz improvisation",
  author   = "Seddon, Frederick A",
  abstract = "This study investigated modes of communication adopted by six
              student jazz musicians during rehearsal and performance. Six
              one-hour rehearsal sessions and a performance were observed and
              videotaped for analysis. Results revealed six modes of
              communication that formed two main categories, verbal and
              non-verbal, each containing three distinct modes of
              communication: instruction, cooperation and collaboration.
              Non-verbal collaborative\textbackslashr\textbackslashnmode
              displayed empathetic attunement, which is a vehicle for
              empathetic creativity. Empathetic creativity is a theoretical
              concept proposed by the author based on the concept of empathetic
              intelligence (Arnold, 2003, 2004). Practical applications of
              empathetic creativity are discussed with reference to music
              education, focusing on evaluation of individual contribution to
              group creative performances.",
  journal  = "British Journal of Music Education",
  volume   =  22,
  number   =  1,
  pages    = "47--61",
  year     =  2005,
  keywords = "ML3508 Jazz; ML430 Composition and performance; MT68
              Improvisation. Accompaniment. Transposition",
  issn     = "0265-0517",
  pmid     = "200959724",
  doi      = "10.1017/S0265051704005984"
}

@INPROCEEDINGS{Dannenberg1997-ii,
  title     = "A machine learning approach to musical style recognition",
  booktitle = "Proceedings of the 1997 International Computer Music Conference",
  author    = "Dannenberg, Roger B and Thom, Belinda and Watson, David",
  abstract  = "Much of the work on perception and understanding of music by
               computers has focused on low-level perceptual features such as
               pitch and tempo. Our work demonstrates that machine learning can
               be used to build effective style classifiers for interactive
               performance systems. We also present an analysis explaining why
               these techniques work so well when hand-coded approaches have
               consistently failed. We also describe a reliable real-time
               performance style classifier.",
  pages     = "344--347",
  year      =  1997,
  doi       = "10.1.1.46.527"
}

@INPROCEEDINGS{Chai2001-dh,
  title     = "Folk music classification using hidden Markov models",
  booktitle = "Proceedings of the International Conference on Artificial
               Intelligence",
  author    = "Chai, W and Vercoe, B",
  abstract  = "Automatic music classification is essential for implementing
               efficient music information retrieval systems; meanwhile, it may
               shed light on the process of human's music perception. This
               paper describes our work on the classification of folk music
               from different countries based on their monophonic melodies
               using hidden Markov models. Music corpora of Irish, German and
               Austrian folk music in various symbolic formats were used as the
               data set. Different representations and HMM structures were
               tested and compared. The classification performances achieved
               75\%, 77\% and 66\% for 2-way classifications and 63\% for 3-way
               classification using 6-state left-right HMM with the interval
               representation in the experiment. This shows that the melodies
               of folk music do carry some statistical features to distinguish
               them. We expect that the result will improve if we use a more
               discriminable data set and the approach should be applicable to
               other music classification tasks and acoustic musical signals.
               Furthermore, the results suggest to us a new way to think about
               musical style similarity.",
  year      =  2001,
  keywords  = "hidden markov model; music classification; music perception",
  doi       = "10.1.1.68.206"
}

@ARTICLE{Chew2013-ht,
  title    = "Conceptual and experiential representations of tempo: Effects on
              expressive performance comparisons",
  author   = "Chew, Elaine and Callender, Clifton",
  journal  = "Lecture notes in computer science",
  volume   =  7937,
  pages    = "76--87",
  year     =  2013,
  keywords = "expressive performance; music analysis; performance time;
              representation; score time; tempo",
  issn     = "0302-9743",
  doi      = "10.1007/978-3-642-39357-0\_6"
}

@ARTICLE{Cooper1978-di,
  title    = "Hierarchical coding in speech timing",
  author   = "Cooper, William E and Paccia, Jeanne M and Lapointe, Steven G",
  abstract = "The analysis of syllable and pause durations in speech production
              can provide information about the properties of a speaker's
              grammatical code. The present study was conducted to reveal
              aspects of this code by analyzing syllable and pause durations in
              structurally ambiguous sentences. In Experiments 1-6, acoustical
              measurements were made for a key syllabic segment and a following
              pause for 10 or more speakers. Each of six structural
              ambiguities, previously unrelated, involved a grammatical
              relation between the constituent following the pause and one of
              two possible constituents preceding the pause. The results showed
              lengthening of the syllabic segments and pauses for the reading
              in which the constituent following the pause was hierarchically
              dominated by the higher of the two possible preceding
              constituents in a syntactic representation. The effects were also
              observed, to a lesser extent, when the structurally ambiguous
              sentences were embedded in disambiguating paragraph contexts
              (Experiment 7). The results show that a single hierarchical
              principle can provide a unified account of speech timing effects
              for a number of otherwise unrelated ambiguities. This principle
              is superior to a linear alternative and provides specific
              inferences about hierarchical relations among syntactic
              constituents in speech coding. ?? 1978.",
  journal  = "Cognitive psychology",
  volume   =  10,
  number   =  2,
  pages    = "154--177",
  year     =  1978,
  issn     = "0010-0285",
  doi      = "10.1016/0010-0285(78)90012-9"
}

@ARTICLE{Harrison_undated-vc,
  title  = "Modelling melodic discrimination with formal models of similarity
            and complexity",
  author = "Harrison, Peter M C and M{\"u}llensiefen, Daniel"
}

@ARTICLE{Misyak2012-om,
  title    = "Statistical learning and language: An individual differences
              study",
  author   = "Misyak, Jennifer B and Christiansen, Morten H",
  abstract = "Although statistical learning and language have been assumed to
              be intertwined, this the- oretical presupposition has rarely been
              tested empirically. The present study investigates the
              relationship between statistical learning and language using a
              within-subject design embedded in an individual-differences
              framework. Participants were administered sep- arate statistical
              learning tasks involving adjacent and nonadjacent dependencies,
              along with a language comprehension task and a battery of other
              measures assessing verbal working memory, short-term memory,
              vocabulary, reading experience, cognitive mo- tivation, and fluid
              intelligence. Strong interrelationships were found among
              statistical learning, verbal working memory, and language
              comprehension. However, when the effects of all other factors
              were controlled for, performance on the two statistical learn-
              ing tasks was the only predictor for comprehending relevant types
              of natural language sentences.",
  journal  = "Language learning",
  volume   =  62,
  number   =  1,
  pages    = "302--331",
  year     =  2012,
  keywords = "Artificial grammar; Cognitive motivation; Fluid intelligence;
              Individual differences; Language comprehension; Lexical
              knowledge; Memory span; Statistical learning; Verbal working
              memory",
  issn     = "0023-8333",
  doi      = "10.1111/j.1467-9922.2010.00626.x"
}

@ARTICLE{Misyak2010-dt,
  title    = "On-line individual differences in statistical learning predict
              language processing",
  author   = "Misyak, Jennifer B and Christiansen, Morten H and Tomblin, J
              Bruce",
  abstract = "Considerable individual differences in language ability exist
              among normally developing children and adults. Whereas past
              research have attributed such differences to variations in verbal
              working memory or experience with language, we test the
              hypothesis that individual differences in statistical learning
              may be associated with differential language performance. We
              employ a novel paradigm for studying statistical learning
              on-line, combining a serial-reaction time task with artificial
              grammar learning. This task offers insights into both the
              timecourse of and individual differences in statistical learning.
              Experiment 1 charts the micro-level trajectory for statistical
              learning of nonadjacent dependencies and provides an on-line
              index of individual differences therein. In Experiment 2, these
              differences are then shown to predict variations in participants'
              on-line processing of long-distance dependencies involving
              center-embedded relative clauses. The findings suggest that
              individual differences in the ability to learn from experience
              through statistical learning may contribute to variations in
              linguistic performance.",
  journal  = "Frontiers in psychology",
  volume   =  1,
  number   = "SEP",
  pages    = "0--9",
  year     =  2010,
  keywords = "Artificial grammar; Individual differences; Language processing;
              Relative clauses; Serial-reaction time; Statistical learning",
  issn     = "1664-1078",
  pmid     = "21833201",
  doi      = "10.3389/fpsyg.2010.00031"
}

@ARTICLE{Reber1991-ls,
  title    = "Implicit and explicit learning: Individual differences and {IQ}",
  author   = "Reber, a S and Walkenfeld, F F and Hernstadt, R",
  abstract = "We explored the degree to which individual differences in
              performance were observed in a group of subjects who worked with
              two different tasks: one implicit and one explicit. The implicit
              task was a standard artificial grammar-learning task; the
              explicit was a series-completion problem-solving task.
              Substantial individual differences were found between subjects on
              the explicit task; relatively small individual differences were
              found on the implicit task. Moreover, performance on the explicit
              task correlated strongly with intelligence quotient, but
              performance on the implicit task did not. Data from previous
              experiments were also found to be in agreement with these
              results. The findings are presented in the context of a general
              theory of implicit learning proposed recently by Reber (1989a, in
              press) that derives from considerations of the evolution of
              cognitive processes. This evolutionary model argues that
              unconscious, implicit induction systems are evolutionarily older
              and antedate conscious, explicit learning processes, and that
              this antiquity carries with it particular patterns of function
              that differentiate implicit processes from explicit processes.",
  journal  = "Journal of experimental psychology. Learning, memory, and
              cognition",
  volume   =  17,
  number   =  5,
  pages    = "888--896",
  year     =  1991,
  issn     = "0278-7393",
  pmid     = "1834770",
  doi      = "10.1037/0278-7393.17.5.888"
}

@ARTICLE{Hourcade2010-ab,
  title    = "Pointassist for older adults",
  author   = "Hourcade, Juan Pablo and Nguyen, Christopher M and Perry, Keith B
              and Denburg, Natalie L",
  abstract = "Perceptual, cognitive and motor deficits cause many older adults
              to have difficulty conducting pointing tasks on computers. Many
              strategies have been discussed in the HCI community to aid older
              adults and others in pointing tasks. We present a different
              approach in PointAssist, software that aids in pointing tasks by
              analyzing the characteristics of sub- movements, detecting when
              users have difficulty pointing, and triggering a precision mode
              that slows the speed of the cursor in those cases. PointAssist is
              designed to help maintain pointing skills, runs as a background
              process working with existing software, is not vulnerable to
              clusters of targets or targets in the way, and does not modify
              the visual appearance or the feel of user interfaces. There is
              evidence from a prior study that PointAssist helps young children
              conduct pointing tasks. In this paper, we present a study
              evaluating PointAssist with twenty older adults (ages 66-88). The
              study participants benefited from greater accuracy when using
              PointAssist, when compared to using the ``enhance pointer
              precision'' option in Windows XP. In addition, we provide
              evidence of correlations between neuropsychological measures,
              pointing performance, and PointAssist detecting pointing
              difficulty.",
  journal  = "Proceedings of the 28th international conference on Human factors
              in computing systems - CHI '10",
  pages    = "1115",
  year     =  2010,
  keywords = "accuracy; assistive technologies; older adults; pointing",
  doi      = "10.1145/1753326.1753494"
}

@ARTICLE{Raffle2010-gj,
  title    = "Family story play: reading with young children (and elmo) over a
              distance",
  author   = "Raffle, Hayes and Spasojevic, Mirjana and Ballagas, Rafael and
              Revelle, Glenda and Horii, Hiroshi and Follmer, Sean and Go,
              Janet and Reardon, Emily and Mori, Koichi and Kaye, Joseph",
  abstract = "We introduce Family Story Play, a system that supports
              grandparents to read books together with their grandchildren over
              the Internet. Family Story Play is designed to improve
              communication across generations and over a distance, and to
              support parents and grandparents in fostering the literacy
              development of young children. The interface encourages active
              child participation in the book reading experience by combining a
              paper book, a sensor-enhanced frame, video conferencing
              technology, and video content of a Sesame Street Muppet (Elmo).
              Results with users indicate that Family Story Play improves child
              engagement in long-distance communication and increases the
              quality of interaction between young children and distant
              grandparents. Additionally, Family Story Play encourages dialogic
              reading styles that are linked with literacy development.
              Ultimately, reading with Family Story Play becomes a creative
              shared activity that suggests a new kind of collaborative story
              telling.",
  journal  = "Proceedings of the 28th international conference on Human factors
              in computing systems - CHI '10",
  pages    = "1583",
  year     =  2010,
  doi      = "10.1145/1753326.1753563"
}

@ARTICLE{Chetty2011-lz,
  title    = "Why is my internet slow?: making network speeds visible",
  author   = "Chetty, Marshini and Haslem, David and Baird, Andrew",
  abstract = "With widespread broadband adoption, more households report
              experiencing sub-optimal speeds. Not only are slow speeds
              frustrating, they may indicate consumers are not receiving the
              services they are paying for from their internet service
              providers. Yet, determining the speed and source of slow-downs is
              difficult because few tools exist for broadband management. We
              report on results of a field trial with 10 households using a
              visual network probe designed to address these problems. We
              describe the results of the study and provide design implications
              for future tools. More importantly, we argue that tools like this
              can educate and empower consumers by making broadband speeds and
              sources of slow-downs more visible.",
  journal  = "Proceedings of the SIGCHI Conference on Human Factors in
              Computing Systems. ACM.",
  pages    = "1889--1898",
  year     =  2011,
  doi      = "10.1145/1978942.1979217"
}

@ARTICLE{Ramachandran2010-gt,
  title    = "Mobile-izing health workers in rural India",
  author   = "Ramachandran, D and Canny, J and Das, P D and Cutrell, E",
  abstract = "Researchers have long been interested in the potential of ICTs to
              enable positive change in developing regions communities. In
              these environments, ICT interventions often fail because
              political, social and cultural forces work against the changes
              ICTs entail. We argue that familiar uses of ICTs for information
              services in these contexts are less potent than their use for
              persuasion and motivation in order to facilitate change. We focus
              on India's rural maternal health system where health workers are
              employed in villages to persuade pregnant women to utilize health
              services. Health workers face challenges due to resistance to
              change in the village, and because of their limited education,
              training and status. These factors appear to reduce the
              motivation of health workers and impair their performance. For
              two months, we deployed short videos on mobile phones designed to
              persuade village women and motivate health workers. We also asked
              health workers to record their own videos. While our results are
              preliminary, they show evidence that the creation and use of
              videos did help (1) engage village women in dialogue, (2) show
              positive effects toward health worker motivation and learning,
              and (3) motivate key community influencers to participate in
              promoting the health workers. 2010 ACM.",
  journal  = "CHI ... conference proceedings / Conference on Human Factors in
              Computing Systems. CHI Conference",
  volume   =  3,
  pages    = "1889--1898",
  year     =  2010,
  keywords = "developing regions; health; health care; health services; health
              systems; human engineering; ictd; information services; mobile
              devices; mobile phones; mobile telecommunication systems;
              motivation; persuasion; positive changes; positive effects;
              pregnant woman; qualitative research; research; resistance
              change; telephone; telephone sets; use video",
  doi      = "10.1145/1753326.1753610"
}

@BOOK{Quinlan1993-wo,
  title     = "C4.5: Programs for machine learning",
  author    = "Quinlan, J R",
  publisher = "Morgan Kaufmann",
  year      =  1993,
  address   = "San Mateo, CA"
}

@ARTICLE{Temperley1999-ap,
  title   = "Modeling meter and harmony: A preference-rule approach",
  author  = "Temperley, David and Sleator, Daniel",
  journal = "Computer Music Journal",
  volume  =  23,
  number  =  1,
  pages   = "10--27",
  year    =  1999
}

@ARTICLE{Herremans2015-bj,
  title    = "Generating structured music for bagana using quality metrics
              based on Markov models",
  author   = "Herremans, D and Weisser, S",
  journal  = "Expert systems with applications",
  volume   =  42,
  number   =  21,
  pages    = "7424--7435",
  year     =  2015,
  keywords = "2000 msc; 60j20; 60j22; 62p99; 68t20; 90c27; 90c59; bagana; cac;
              combinatorial optimization; computer aided composition; markov
              models; markov processes; metaheuristics; music; variable
              neighborhood search; vns",
  issn     = "0957-4174"
}

@ARTICLE{Herremans2013-yb,
  title    = "Composing fifth species counterpoint music with a variable
              neighborhood search algorithm",
  author   = "Herremans, D and S{\"o}rensen, K",
  abstract = "In this paper, a variable neighborhood search (VNS) algorithm is
              developed and analyzed that can generate fifth species
              counterpoint fragments. The existing species counterpoint rules
              are quantified and form the basis of the objective function used
              by the algorithm. The VNS developed in this research is a local
              search metaheuristic that starts from a randomly generated
              fragment and gradually improves this solution by changing one or
              two notes at a time. An in-depth statistical analysis reveals the
              significance as well as the optimal settings of the parameters of
              the VNS. The algorithm has been implemented in a user-friendly
              software environment called Optimuse. Optimuse allows a user to
              input basic characteristics such as length, key and mode. Based
              on this input, a fifth species counterpoint fragment is generated
              by the system that can be edited and played back immediately.
              \copyright{} 2013 Elsevier Ltd. All rights reserved.",
  journal  = "Expert systems with applications",
  volume   =  40,
  number   =  16,
  pages    = "6427--6437",
  year     =  2013,
  keywords = "Combinatorial optimization; Computer aided composing;
              Metaheuristics; Variable neighborhood search",
  issn     = "0957-4174",
  doi      = "10.1016/j.eswa.2013.05.071"
}

@ARTICLE{Chuan2011-wl,
  title   = "Generating and evaluating musical harmonizations that emulate
             style",
  author  = "Chuan, Ching-Hua and Chew, Elaine",
  journal = "Computer Music Journal",
  volume  =  35,
  number  =  4,
  pages   = "64--82",
  year    =  2011,
  issn    = "0148-9267",
  doi     = "10.1162/COMJ\_a\_00091"
}

@ARTICLE{Barolsky2007-vu,
  title   = "The performer as analyst",
  author  = "Barolsky, Daniel",
  journal = "Music theory online",
  volume  =  13,
  number  =  1,
  year    =  2007
}

@ARTICLE{Leech-Wilkinson2015-fi,
  title   = "Cortot's Berceuse",
  author  = "Leech-Wilkinson, Daniel",
  journal = "Music Analysis",
  volume  =  34,
  number  =  3,
  pages   = "335--363",
  year    =  2015,
  issn    = "0262-5245",
  doi     = "10.1111/musa.12054"
}

@INPROCEEDINGS{Verfaille2005-sh,
  title     = "Perceptual evaluation of vibrato models",
  booktitle = "Proceedings of the Conference on Interdisciplinary Musicology
               ({CIM05})",
  author    = "Verfaille, Vincent and Guastavino, Catherine and Depalle,
               Philippe",
  abstract  = "We promote a clearer definition of vibrato(Seashore, 1932),
               based on a review of various vibrato features. We also propose a
               generalised vibrato effect generator that includes spectral
               envelope modulation, and a frequency-dependent hysteresis
               behaviour. We then investigate the influence of spectral
               envelope modulation on perceived quality with a double-blind
               ran- domized ABcomparison task. Eight participants listened
               to12pairs of sounds with vibrato matched for loudness. Each pair
               included one sound with constant average spectral envelope
               (identical amplitude modulation over all frequencies) and one
               with modulated spectral enve- lope (frequency dependent
               amplitude modulation). Participants were asked to choose which
               version sounded the most natural. The statistical analysis
               revealed a significant preference for sounds with modulated
               spectral envelope (p<0.001). Our results highlight the need to
               consider spectral envelope modulation for vibrato modelling.",
  year      =  2005
}

@INCOLLECTION{Kirke2013-hf,
  title     = "Guide to computing for expressive music performance",
  booktitle = "Guide to computing for expressive music performance",
  author    = "Kirke, Alexis and Miranda, Eduardo Reck",
  publisher = "Springer",
  pages     = "1--47",
  year      =  2013,
  address   = "London, England"
}

@BOOK{Kirke2013-xi,
  title  = "Guide to computing for expressive music performance",
  author = "Kirke, Alexis and Miranda, Eduardo Reck",
  year   =  2013,
  isbn   = "9781447141228",
  doi    = "10.1007/978-1-4471-4123-5"
}

@ARTICLE{Gabrielsson2003-tg,
  title    = "Music performance research at the millennium",
  author   = "Gabrielsson, Alf",
  abstract = "Empirical research on music performance has increased consider-
              ably during recent decades. This article updates the review of
              the research up to 1995 published by the current author in 1999.
              Covering about 200 papers from 1995 up to 2002, this article
              confirms the impression that music performance research is in a
              very active stage. As in the previous review, the majority of
              papers are on measurement of performance, but there is a rapidly
              increasing number of contributions concerning models of
              performance, performance plan- ning and practice. Although fewer
              in number, there are also many new contribu- tions within each of
              the remaining areas of performance research analysed in this
              review",
  journal  = "Psychology of Music",
  volume   =  31,
  number   =  3,
  pages    = "221--272",
  year     =  2003,
  issn     = "0305-7356",
  doi      = "10.1177/03057356030313002"
}

@ARTICLE{Palmer1999-al,
  title  = "Music Performance",
  author = "Palmer, Caroline",
  year   =  1999
}

@ARTICLE{Schellenberg1997-un,
  title    = "Simplifying the {Implication-Realisation} model of melodic
              expectancy",
  author   = "Schellenberg, E Glenn",
  abstract = "Results from previous investigations indicate that the
              implication-realization (IR) model (Narmour, 1990) of expectancy
              in melody may be overspecified and more complex than necessary.
              Indeed, Schellenberg's (1996) revised model, with two fewer
              predictor variables, improved predictive accuracy compared with
              the original model. A reanalysis of data reported by Cuddy and
              Lunney (1995) provided similar results. When the principles of
              the IR model were submitted to a principal-components analysis, a
              solution containing three orthogonal (uncorrelated) factors
              retained the accuracy of the model but was inferior to the
              revised model. A separate principal-components analysis of the
              predictors of the revised model yielded a two-factor solution
              that did not compromise the revised model's predictive power.
              Consequently, an even simpler model of melodic expectancy was
              derived. These results provide further evidence that redundancy
              in the IR model can be eliminated without loss of predictive
              accuracy.",
  journal  = "Music perception",
  volume   =  14,
  number   =  3,
  pages    = "295--318",
  year     =  1997,
  issn     = "0730-7829"
}

@ARTICLE{Tillmann2010-da,
  title    = "Auditory expectations for newly acquired structures",
  author   = "Tillmann, Barbara and Poulin-Charronnat, B{\'e}n{\'e}dicte",
  abstract = "Our study investigated whether newly acquired auditory structure
              knowledge allows listeners to develop perceptual expectations for
              future events. For that aim, we introduced a new experimental
              approach that combines implicit learning and priming paradigms.
              Participants were first exposed to structured tone sequences
              without being told about the underlying artificial grammar. They
              then made speeded judgements on a perceptual feature of target
              tones in new sequences (i.e., in-tune/out-of-tune judgements).
              The target tones respected or violated the structure of the
              artificial grammar and were thus supposed to be expected or
              unexpected. In this priming task, grammatical tones were
              processed faster and more accurately than ungrammatical ones.
              This processing advantage was observed for an experimental group
              performing a memory task during the exposure phase, but was not
              observed for a control group, which was lacking the exposure
              phase (Experiment 1). It persisted when participants realized an
              in-tune/out-of-tune detection task during exposure (Experiment
              2). This finding suggests that the acquisition of new structure
              knowledge not only influences grammaticality judgements on entire
              sequences (as previously shown in implicit learning research),
              but allows developing perceptual expectations that influence
              single event processing. It further promotes the priming paradigm
              as an implicit access to acquired artificial structure knowledge.",
  journal  = "The Quarterly journal of experimental psychology",
  volume   =  63,
  number   =  8,
  pages    = "1646--1664",
  year     =  2010,
  issn     = "0033-555X, 1747-0218",
  pmid     = "20175025",
  doi      = "10.1080/17470210903511228"
}

@ARTICLE{Schellenberg1996-il,
  title    = "Expectancy in melody: Tests of the implication-realization model",
  author   = "Schellenberg, E Glenn",
  abstract = "The implication-realization model's description of tone-to-tone
              expectancies for continuations of melodies was examined. The
              model's predictions for expectancies are described with a small
              number of principles specified precisely in terms of interval
              size and direction of pitch. These principles were quantified and
              used to predict the data from three experiments in which
              listeners were required to judge how well individual test tones
              continued melodic fragments. The model successfully predicted
              listeners judgments across different musical styles (British and
              Chinese folk songs and Webern Lieder), regardless of the extent
              of listeners' musical training (Experiments 1 and 2) or whether
              they were born and raised in China or the U.S.A. (Experiment 3).
              For each experiment, however, the collinearity of the model's
              predictors indicated that a simplified version of the model might
              predict the data equally well. Indeed, a revised and simplified
              model did not result in a loss of predictive power for any of the
              three experiments. Convergent evidence was provided in a
              reanalysis of data reported by Carlsen (1981) and Unyk and
              Carlsen (1987), whose listeners were required to sing
              continuations to two-tone stimuli. Thus, these findings indicate
              that the implication-realization model is over-specified. The
              consistency that was found across experimental tasks, musical
              styles, and listeners raises the possibility, however, that the
              revised version of the model may withstand the original model's
              claims of universality.",
  journal  = "Cognition",
  volume   =  58,
  number   =  1,
  pages    = "75--125",
  year     =  1996,
  issn     = "0010-0277",
  pmid     = "8808327",
  doi      = "10.1016/0010-0277(95)00665-6"
}

@INPROCEEDINGS{Kaneshiro2015-hb,
  title     = "Neuroimaging Methods for Music Information Retrieval: Current
               Findings and Future Prospects",
  booktitle = "16th International Society for Music Information Retrieval
               Conference ({ISMIR'15})",
  author    = "Kaneshiro, Blair and Dmochowski, Jacek P",
  abstract  = "Over the past decade and a half, music information re- trieval
               (MIR) has grown into a robust, cross-disciplinary field spanning
               a variety of research domains. Collabo- rations between MIR and
               neuroscience researchers, how- ever, are still rare, and to date
               only a few studies using approaches from one domain have
               successfully reached an audience in the other. In this paper, we
               take an initial step toward bridging these two fields by
               reviewing studies from the music neuroscience literature, with
               an emphasis on imaging modalities and analysis techniques that
               might be of practical interest to the MIR community. We show
               that certain approaches currently used in a neuroscientific
               setting align with those used in MIR research, and discuss
               implications for potential areas of future research. We ad-
               ditionally consider the impact of disparate research objec-
               tives between the two fields, and how such a discrepancy may
               have hindered cross-discipline output thus far. It is hoped that
               a heightened awareness of this literature will foster
               interaction and collaboration between MIR and neu- roscience
               researchers, leading to advances in both fields that would not
               have been achieved independently.",
  pages     = "538--544",
  year      =  2015
}

@ARTICLE{Stober2015-hp,
  title    = "Towards Music Imagery Information Retrieval: Introducing the
              {OpenMIIR} Dataset of {EEG} Recordings from Music Perception and
              Imagination",
  author   = "Stober, Sebastian and Sternin, Avital and Owen, Adrian M and
              Grahn, Jessica A",
  abstract = "Music imagery information retrieval (MIIR) systems may one day be
              able to recognize a song from only our thoughts. As
              asteptowardssuchtechnology, wearepresentinga public domain
              dataset of electroencephalography (EEG) recordings taken during
              music perception and imagination.We acquired this data during an
              ongoing study that so far comprises 10 subjects listening to and
              imagining 12 short music fragments
              --each7--16slong--takenfromwell-knownpieces. These stimuli were
              selected from different genres and systematically vary
              alongmusical dimensions such asmeter, tempo and the presence of
              lyrics. This way, various retrieval scenarios can be addressed
              and the success of classifying based on specific dimensions can
              be tested. The dataset is aimed to enable music information
              retrieval researchers interested in these new MIIR challenges to
              easily test and adapt their existing approaches for music
              analysis like fingerprinting, beat tracking, or tempo estimation
              on EEG data.",
  journal  = "16th International Society for Music Information Retrieval
              Conference (ISMIR'15)",
  pages    = "763--769",
  year     =  2015
}

@ARTICLE{Friberg2002-tl,
  title   = "Swing ratios and ensemble timing in jazz performance: Evidence for
             a common rhythmic pattern",
  author  = "Friberg, Anders and Sundstr{\"o}m, Andreas",
  journal = "Music Perception: An Interdisciplinary Journal",
  volume  =  19,
  number  =  3,
  pages   = "333--349",
  year    =  2002
}

@INPROCEEDINGS{Collier1996-vk,
  title     = "The swing rhythm in jazz",
  booktitle = "Proceedings of the 4th International Conference on Music
               Perception and Cognition",
  author    = "Collier, G and Collier, J",
  editor    = "Pennycook, B and Costa-Giomi, E",
  publisher = "McGill University",
  pages     = "477--480",
  year      =  1996,
  address   = "Montreal, Canada"
}

@ARTICLE{Widmer2002-ox,
  title    = "Machine discoveries: A few simple, robust local expression
              principles",
  author   = "Widmer, Gerhard",
  abstract = "The paper presents a new approach to discovering general rules of
              expressive music performance from real performance data via
              inductive machine learning. A new learning algorithm is briey
              presented, and then an experiment with a very large data set
              (performances of 13 Mozart piano sonatas) is described. The new
              learning algorithm succeeds in discovering some extremely simple
              and general principles of musical performance (at the level of
              individual notes), in the form of categorical prediction rules.
              These rules turn out to be very robust and general: when tested
              on performances by a dierent pianist and even on music of a
              dierent style (Chopin), they exhibit a surprisingly high degree
              of predictive accuracy.",
  journal  = "Journal of New Music Research",
  volume   =  31,
  number   =  1,
  pages    = "37--50",
  year     =  2002,
  issn     = "0929-8215",
  doi      = "10.1076/jnmr.31.1.37.8103"
}

@INPROCEEDINGS{Widmer2000-pr,
  title     = "Large-scale induction of expressive performance rules: First
               quantitative results",
  booktitle = "Proceedings of the International Computer Music Conference
               ({ICMC'2000})",
  author    = "Widmer, Gerhard",
  abstract  = "The paper presents rst experimental results of a research
               project that aims at identifying basic principles of expressive
               music performance with the help of machine learning methods.
               Various learning algorithms were applied to a large collection
               of real performance data (recordings of 13 Mozart sonatas by a
               skilled pianist) in order to induce general categorical
               expression rules for tempo, dynamics, and articulation.
               Preliminary results show that the algorithms can indeedfi nd
               some structure in the data. It also turns out that meter and
               global tempo have a strong inuence on expression patterns.
               Finally, we briefly describe an experiment that demonstrates how
               machine learning can be used to study and possibly resolve some
               specialized questions. 1 Introduction In this paper, we present
               rst quantitative results of a long-term research project that
               aims at identifying and studying basic principles of expressive
               music performance with the help of Articial Intelligence (in
               partic...",
  publisher = "International Computer Music Association",
  pages     = "344--347",
  year      =  2000,
  address   = "San Francisco, CA"
}

@ARTICLE{Honing2008-ab,
  title    = "Swing once more: Relating timing and tempo in expert jazz
              drumming",
  author   = "Honing, Henkjan and Bas de Haas, W",
  journal  = "Music Perception: An Interdisciplinary Journal",
  volume   =  25,
  number   =  5,
  pages    = "471--476",
  year     =  2008,
  keywords = "drumming; jazz; music performance"
}

@INPROCEEDINGS{Widmer2001-sf,
  title     = "Discovering strong principles of expressive music performance
               with the {PLCG} rule learning strategy",
  booktitle = "Proceedings of the 11th European Conference on Machine Learning
               ({ECML'01})",
  author    = "Widmer, Gerhard",
  abstract  = "We present a new rule learning algorithm named PLCG -- a kind of
               ensemble learning method -- that can find simple, robust partial
               theories (sets of classification rules) in complex data where
               neither high coverage nor high precision can be expected. The
               motivating application problem comes from an interdisciplinary
               research project that aims at discovering fundamental principles
               of expressive music performance from large amounts of complex
               real-world data (measurements of actual performances by concert
               pianists). It is shown that PLCG succeeds in finding some
               suprisingly simple and robust performance principles, some of
               which represent truly novel and musically meaningful
               discoveries. A more systematic experiment shows that PLCG learns
               significantly simpler theories than more direct approaches to
               rule learning, while striking a compromise between coverage and
               precision.",
  publisher = "Springer Verlag",
  pages     = "552--563",
  year      =  2001,
  address   = "Berlin, Germany",
  issn      = "1611-3349"
}

@ARTICLE{Widmer2003-so,
  title    = "Playing Mozart by analogy: Learning multi-level timing and
              dynamics strategies",
  author   = "Widmer, Gerhard and Tobudic, Asmir",
  abstract = "The article describes basic research in the area of machine
              learning and musical expression. A first step towards automatic
              induction of multi-level models of expressive performance
              (currently only tempo and dynamics) from real performances by
              skilled pianists is presented. The goal is to learn to apply
              sensible tempo and dynamics ?shapes? at various levels of the
              hierarchical musical phrase structure. We propose a general
              method for decomposing given expression curves into elementary
              shapes at different levels, and for separating phrase-level
              expression patterns from local, note-level ones. We then present
              a hybrid learning system that learns to predict, via two
              different learning algorithms, both note-level and phrase-level
              expressive patterns, and combines these predictions into complex
              composite expression curves for new pieces. Experimental results
              indicate that the approach is generally viable; however, we also
              discuss a number of severe limitations that still need to be
              overcome in order to arrive at truly musical machine-generated
              performances.\textbackslashnThe article describes basic research
              in the area of machine learning and musical expression. A first
              step towards automatic induction of multi-level models of
              expressive performance (currently only tempo and dynamics) from
              real performances by skilled pianists is presented. The goal is
              to learn to apply sensible tempo and dynamics ?shapes? at various
              levels of the hierarchical musical phrase structure. We propose a
              general method for decomposing given expression curves into
              elementary shapes at different levels, and for separating
              phrase-level expression patterns from local, note-level ones. We
              then present a hybrid learning system that learns to predict, via
              two different learning algorithms, both note-level and
              phrase-level expressive patterns, and combines these predictions
              into complex composite expression curves for new pieces.
              Experimental results indicate that the approach is generally
              viable; however, we also discuss a number of severe limitations
              that still need to be overcome in order to arrive at truly
              musical machine-generated performances.",
  journal  = "Journal of New Music Research",
  volume   =  32,
  number   =  3,
  pages    = "259--268",
  year     =  2003,
  issn     = "0929-8215",
  doi      = "10.1076/jnmr.32.3.259.16860"
}

@ARTICLE{Banse1996-vl,
  title   = "Acoustic profiles in vocal emotion expression",
  author  = "Banse, Rainer and Scherer, Klaus R",
  journal = "Journal of personality and social psychology",
  volume  =  70,
  number  =  3,
  pages   = "614--636",
  year    =  1996,
  issn    = "0022-3514"
}

@ARTICLE{Scherer2001-rt,
  title    = "Emotion Inferences from Vocal Expression Correlate Across
              Languages and Cultures",
  author   = "Scherer, Klaus R and Banse, R and Wallbott, H G",
  abstract = "Whereas the perception of emotion from facial expression has been
              extensively studied cross-culturally, little is known about
              judges' ability to infer emotion from vocal cues. This article
              reports the results from a study conducted in nine countries in
              Europe, the United States, and Asia on vocal emotion portrayals
              of anger, sadness, fear, joy, and neutral voice as produced by
              professional German actors. Data showan overall accuracy of 66\%
              across all emotions and countries. Although accuracywas
              substantially better than chance, there were sizable differences
              ranging from74\%in Germany to52\%in Indonesia.However, patterns
              of confusion were very similar across all countries. These data
              suggest the existence of similar inference rules from vocal
              expression across cultures. Generally, accuracy decreased with
              increasing language dissimilarity from German in spite of the use
              of language-free speech samples. It is concluded that culture-
              and language- specific paralinguistic patterns may influence the
              decoding process.",
  journal  = "Journal of cross-cultural psychology",
  volume   =  32,
  number   =  1,
  pages    = "76--92",
  year     =  2001,
  issn     = "0022-0221",
  pmid     = "616",
  doi      = "10.1177/0022022101032001009"
}

@INPROCEEDINGS{Enos2006-ag,
  title     = "A framework for eliciting emotional speech: Capitalizing on the
               actor's process",
  booktitle = "{LREC} 2006 Workshop on Emotional Corpora",
  author    = "Enos, Frank and Hirschberg, Julia",
  abstract  = "This paper offers an approach and a theoretical framework for
               eliciting emotional speech using actors. The framework is
               developed by connecting the goal-based model of emo- tion
               proposed by Abelson [1], the work of appraisal theo- rists, and
               an approach to the actor's technical process widely used in the
               professional theater and taught in modern con- servatories. In
               doing so, we hope to address some of the difficulties currently
               encountered in the use of acted speech in emotion research.",
  pages     = "1--4",
  year      =  2006,
  keywords  = "emotion; emotional speech; experiment; prosody"
}

@INPROCEEDINGS{Campbell2000-zi,
  title     = "Databases of emotional speech",
  booktitle = "{ISCA} Workshop on Speech and Emotions, Newcastle, North Ireland",
  author    = "Campbell, Nick",
  abstract  = "This paper presents a personal view of some the problems facing
               speech technologists in the study of emotional speech. It
               describes some databases that are currently being used, and
               points out that the majority of them use actors to reproduce
               the\textbackslashnemotions, thereby possibly falsely
               representing the true characteristics of emotion in speech.
               Databases of real emotional speech, on the other hand, present
               serious ethical and moral problems, since the nature of their
               contents must, by definition, reveal personal and intimate
               details about the speakers.",
  pages     = "34--38",
  year      =  2000
}

@ARTICLE{Bolger2013-su,
  title     = "Rhythm implicitly affects temporal orienting of attention across
               modalities",
  author    = "Bolger, Deirdre and Trost, Wiebke and Sch{\"o}n, Daniele",
  journal   = "Acta psychologica",
  publisher = "Elsevier B.V.",
  volume    =  142,
  number    =  2,
  pages     = "238--244",
  year      =  2013,
  keywords  = "Attention; Entrainment; Implicit orienting; Meter; Temporal
               structure",
  issn      = "0001-6918",
  doi       = "10.1016/j.actpsy.2012.11.012"
}

@PHDTHESIS{Chai2005-pg,
  title  = "Automated analysis of musical structure",
  author = "Chai, W",
  year   =  2005,
  school = "Massachusetts Institute of Technology"
}

@INPROCEEDINGS{Abdallah2005-rr,
  title     = "Theory and evaluation of a Bayesian music structure extractor",
  booktitle = "Proceedings of the 6th International Conference on Music
               Information Retrieval",
  author    = "Abdallah, Samer and Noland, Katy and Sandler, Mark and Casey,
               Michael and Rhodes, Christophe",
  year      =  2005,
  keywords  = "audio; boundary; segmentation; structure"
}

@INPROCEEDINGS{Aucouturier2001-cz,
  title     = "Segmentation of musical signals using hidden Markov models",
  booktitle = "Proceedings of the 110th Audio Engineering Society Convention",
  author    = "Aucouturier, J and Sandler, M",
  year      =  2001,
  address   = "Amsterdam, The Netherlands"
}

@INPROCEEDINGS{Logan2000-dx,
  title     = "Music summarization using key phrases",
  booktitle = "Proceedings of {IEEE} International Conference on Acoustics,
               Speech, and Signal Processing",
  author    = "Logan, B and Chu, Stephen",
  abstract  = "Mycotoxins are small (MW approximately 700), toxic chemical
               products formed as secondary metabolites by a few fungal species
               that readily colonise crops and contaminate them with toxins in
               the field or after harvest. Ochratoxins and Aflatoxins are
               mycotoxins of major significance and hence there has been
               significant research on broad range of analytical and detection
               techniques that could be useful and practical. Due to the
               variety of structures of these toxins, it is impossible to use
               one standard technique for analysis and/or detection. Practical
               requirements for high-sensitivity analysis and the need for a
               specialist laboratory setting create challenges for routine
               analysis. Several existing analytical techniques, which offer
               flexible and broad-based methods of analysis and in some cases
               detection, have been discussed in this manuscript. There are a
               number of methods used, of which many are lab-based, but to our
               knowledge there seems to be no single technique that stands out
               above the rest, although analytical liquid chromatography,
               commonly linked with mass spectroscopy is likely to be popular.
               This review manuscript discusses (a) sample pre-treatment
               methods such as liquid-liquid extraction (LLE), supercritical
               fluid extraction (SFE), solid phase extraction (SPE), (b)
               separation methods such as (TLC), high performance liquid
               chromatography (HPLC), gas chromatography (GC), and capillary
               electrophoresis (CE) and (c) others such as ELISA. Further
               currents trends, advantages and disadvantages and future
               prospects of these methods have been discussed.",
  pages     = "749--752",
  year      =  2000,
  address   = "Istanbul, Turkey",
  issn      = "0717-6163",
  isbn      = "9780874216561",
  pmid      = "15003161",
  doi       = "10.1007/s13398-014-0173-7.2"
}

@BOOK{Schenker1969-iq,
  title     = "Five graphic music analyses",
  author    = "Schenker, H",
  publisher = "Dover",
  year      =  1969,
  address   = "New York, NY"
}

@BOOK{Temperley2004-js,
  title     = "The cognition of basic musical structures",
  author    = "Temperley, D",
  publisher = "MIT Press",
  year      =  2004,
  address   = "Cambridge, MA"
}

@INPROCEEDINGS{Peeters2009-vs,
  title     = "Is music structure annotation multi-dimensional? A proposal for
               robust local music annotation",
  booktitle = "Proceedings of the 3rd International Workshop on Learning
               Semantics of Audio Signals",
  author    = "Peeters, Geoffroy and Deruty, Emmanuel",
  editor    = "Baumann, Stephan and Burred, Juan Jos{\'e} and N{\"u}rnberger,
               Andreas and Stober, Sebastian",
  pages     = "75--90",
  year      =  2009,
  isbn      = "9783940961389"
}

@INPROCEEDINGS{Paulus2006-xg,
  title     = "Music structure analysis by finding repeated parts",
  booktitle = "Proceedings of the 1st {ACM} workshop on Audio and music
               computing multimedia - {AMCMM} '06",
  author    = "Paulus, Jouni and Klapuri, Anssi",
  pages     = "59--68",
  year      =  2006,
  keywords  = "cost func-; music structure; search algorithm; segmentation;
               structure analysis; structure comparison; tion",
  isbn      = "9781595935014",
  doi       = "10.1145/1178723.1178733"
}

@BOOK{Lerdahl1983-xy,
  title     = "A generative theory of tonal music",
  author    = "Lerdahl, F and Jackendoff, R",
  publisher = "MIT Press",
  year      =  1983,
  address   = "Cambridge, MA"
}

@ARTICLE{Lange2006-jb,
  title    = "Orienting attention to points in time improves stimulus
              processing both within and across modalities",
  author   = "Lange, Kathrin and R{\"o}der, Brigitte",
  abstract = "Spatial attention affects the processing of stimuli of both a
              task-relevant and a task-irrelevant modality. The present study
              investigated if similar cross-modal effects exist when attention
              is oriented to a point in time. Short (600 msec) and long (1,200
              msec) empty intervals, marked by a tactile onset and an auditory
              or a tactile offset marker, were presented. In each block, the
              participants had to attend one interval and one modality.
              Event-related potentials (ERPs) to auditory and tactile offset
              markers of attended as compared to unattended intervals were
              characterized by an enhancement of early negative deflections of
              the auditory and somatosensory ERPs (audition, 100-140 msec;
              touch, 130-180 msec) when audition or touch was task relevant,
              respectively. Similar effects were found for auditory stimuli
              when touch was task relevant. An additional reaction time
              experiment revealed faster responses to both auditory and tactile
              stimuli at the attended as compared to the unattended point in
              time, irrespective of which modality was primary. Both behavioral
              and ERP data show that attention can be focused on a point in
              time, which results in a more efficient processing of auditory
              and tactile stimuli. The ERP data further suggest that a relative
              enhancement at perceptual processing stages contributes to the
              processing advantage for temporally attended stimuli. The
              existence of cross-modal effects of temporal attention underlines
              the importance of time as a feature for binding input across
              different modalities.",
  journal  = "Journal of cognitive neuroscience",
  volume   =  18,
  number   =  5,
  pages    = "715--729",
  year     =  2006,
  issn     = "0898-929X",
  pmid     = "16768372",
  doi      = "10.1162/jocn.2006.18.5.715"
}

@ARTICLE{McAuley2014-gp,
  title    = "Attentional entrainment and perceived event duration",
  author   = "McAuley, J Devin and Fromboluti, Elisa Kim",
  abstract = "This study considered the contribution of dynamic attending
              theory (DAT) and attentional entrainment to systematic
              distortions in perceived event duration. Three experiments were
              conducted using an auditory oddball paradigm, in which listeners
              judged the duration of a deviant (oddball) stimulus embedded
              within a series of identical (standard) stimuli. To test for a
              role of attentional entrainment in perceived oddball duration,
              oddballs were presented at either temporally expected (on time)
              or unexpectedly early or late time points relative to
              extrapolation of the context rhythm. Consistent with involvement
              of attentional entrainment in perceived duration, duration
              judgements about the oddball were least distorted when the
              oddball occurred on time with respect to the entrained rhythm,
              whereas durations of early and late oddballs were perceived to be
              shorter and longer, respectively. This pattern of results was
              independent of the absolute time interval preceding the oddball.
              Moreover, as expected, an irregularly timed sequence context
              weakened observed differences between oddballs with on-time and
              late onsets. Combined with other recent work on the role of
              temporal preparation in duration distortions, the present
              findings allot at least a portion of the oddball effect to
              increased attention to events that are more expected, rather than
              on their unexpected nature per se.",
  journal  = "Philosophical transactions of the Royal Society of London. Series
              B, Biological sciences",
  volume   =  369,
  number   =  1658,
  pages    = "20130401--",
  year     =  2014,
  issn     = "0962-8436, 1471-2970",
  pmid     = "25385779",
  doi      = "10.1098/rstb.2013.0401"
}

@ARTICLE{McAuley1998-fe,
  title    = "Effect of deviations from temporal expectations on tempo
              discrimination of isochronous tone sequences",
  author   = "McAuley, J D and Kidd, G R",
  abstract = "The effect of deviations from temporal expectations on tempo
              discrimination was studied in 3 experiments using isochronous
              auditory sequences. Temporal deviations consisted of advancing or
              delaying the onset of a comparison pattern relative to an
              ``expected'' onset, defined by an extension of the periodicity of
              a preceding standard pattern. An effect of onset condition was
              most apparent when responses to faster and slower comparison
              patterns were analyzed separately and onset conditions were
              mixed. Under these conditions, early onsets produced more
              ``faster'' judgments and lower thresholds for tempo increases,
              and late onsets produced more ``slower'' judgments and lower
              thresholds for tempo decreases. In another experiment, pattern
              tempo had a similar effect: Fast tempos led to lower thresholds
              for tempo increases and slow tempos led to lower thresholds for
              tempo decreases. Findings support oscillator-based approaches to
              time discrimination.",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  24,
  number   =  6,
  pages    = "1786--1800",
  year     =  1998,
  issn     = "0096-1523, 0001-4966",
  pmid     = "9861723",
  doi      = "10.1121/1.417584"
}

@ARTICLE{Miller2005-np,
  title    = "Tempo sensitivity in isochronous tone sequences: The
              multiple-look model revisited",
  author   = "Miller, Nathaniel S and McAuley, J Devin",
  abstract = "Factors affecting tempo sensitivity in isochronous tone sequences
              were investigated in two experiments. Participants listened to
              tones in sequence conditions in which the number of time
              intervals in isochronous standard and comparison sequences was
              varied, and they were asked to judge the tempo of the comparison
              relative to the standard. When the duration of the standard
              interval was held constant, tempo sensitivity was affected by the
              number of comparison intervals, but not by the number of standard
              intervals. In contrast, when the duration of the standard
              interval was varied randomly from trial to trial, tempo
              sensitivity was affected by the number of intervals in both
              sequences. The present findings are discussed in the context of a
              generalized multiple-look model that posits independent
              contributions of both sequences to tempo sensitivity.
              Quantitative model fits suggest that the relative contribution of
              the number of the standard intervals to tempo thresholds depends
              on (1) the availability of a stable long-term referent for the
              standard tempo and (2) a priori knowledge about the number of
              standard intervals.",
  journal  = "Perception \& psychophysics",
  volume   =  67,
  number   =  7,
  pages    = "1150--1160",
  year     =  2005,
  keywords = "Auditory Perception; Humans; Models; Periodicity; Reaction Time;
              Statistical; Time Perception",
  issn     = "0031-5117",
  pmid     = "16502837"
}

@ARTICLE{McAuley2003-nx,
  title    = "Modeling effects of rhythmic context on perceived duration: a
              comparison of interval and entrainment approaches to
              short-interval timing",
  author   = "McAuley, J Devin and Jones, Mari Riess",
  abstract = "Relative merits of interval and entrainment conceptions of the
              internal clock were assessed within a common theoretical
              framework by 4 time-judgment experiments. The timing of tone
              onsets marking the beginning and ending of standard and
              comparison time intervals relative to a context rhythm were
              manipulated: onsets were on time, early, or late relative to the
              implied rhythm, and 2 distinct accuracy patterns emerged. A
              quadratic ending profile indicated best performance when the
              standard ended on time and worst performance when it was early or
              late, whereas a flat beginning profile (Experiments 1-3)
              indicated uniform performance for the 3 expectancy conditions.
              Only in Experiment 4, in which deviations from expected onset
              times were large, did significant effects of beginning times
              appear in time-discrimination thresholds and points of subjective
              equality. Findings are discussed in the context of theoretical
              assumptions about clock resetting, the representation of time,
              and independence of successive time intervals.",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  29,
  number   =  6,
  pages    = "1102--1125",
  year     =  2003,
  issn     = "0096-1523",
  pmid     = "14640833",
  doi      = "10.1037/0096-1523.29.6.1102"
}

@ARTICLE{Barnes2000-gu,
  title    = "Expectancy, attention, and time",
  author   = "Barnes, R and Jones, M R",
  abstract = "Seven experiments examine the influence of contextual timing
              manipulations on prospective time judgments. Subjects judged
              durations of standard vs comparison time intervals in the context
              of a preceding induction (context) sequence. In some experiments,
              the rate of the induction sequence was systematically manipulated
              relative to the range of to-be-judged standard time intervals; in
              others, the induction sequence was omitted. Time judgments were
              strongly influenced by the rate of an induction sequence with
              best performance occurring when the standard time interval ended
              as expected, given context rate. An expectancy profile, in the
              form of an inverted U, indicated that time estimation accuracy
              declined systematically as a standard interval differed from a
              context rate. A similar expectancy profile emerged when the
              context rate was based on a harmonic subdivision (one-half) of an
              expected standard interval. Results are discussed in terms of
              various stimulus-based models of prospective time judgments,
              including those which appeal to attentional periodicities and
              entrainment.",
  journal  = "Cognitive psychology",
  volume   =  41,
  number   =  3,
  pages    = "254--311",
  year     =  2000,
  issn     = "0010-0285",
  pmid     = "11032658",
  doi      = "10.1006/cogp.2000.0738"
}

@ARTICLE{Lange2009-bt,
  title     = "Brain correlates of early auditory processing are attenuated by
               expectations for time and pitch",
  author    = "Lange, Kathrin",
  journal   = "Brain and cognition",
  publisher = "Elsevier Inc.",
  volume    =  69,
  number    =  1,
  pages     = "127--137",
  year      =  2009,
  issn      = "0278-2626",
  doi       = "10.1016/j.bandc.2008.06.004"
}

@ARTICLE{Andreou2011-nl,
  title     = "The role of temporal regularity in auditory segregation",
  author    = "Andreou, Lefkothea Vasiliki and Kashino, Makio and Chait, Maria",
  abstract  = "The idea that predictive modelling and extraction of
               regularities plays a pivotal role in auditory segregation has
               recently attracted considerable attention. The present study
               investigated the effect of one basic form of regularity,
               rhythmic regularity, on auditory stream segregation. We departed
               from the classic streaming paradigm and developed a new
               stimulus, Rand-AB, consisting of two, concurrently presented,
               temporally uncorrelated, tone sequences (with frequencies A and
               B). To evaluate segregation, we used an objective measure of the
               extent to which listeners are able to selectively attend to one
               of the sequences in the presence of the other. Performance was
               quantified on a difficult pattern detection task which involves
               detecting a rarely occurring pattern of amplitude modulation
               applied to three consecutive A or B tones. In all cases the
               attended sequence was temporally irregular (with a random
               inter-tone-interval (ITI) between 100 and 400 ms) and the
               regularity status of the competing sequence was set to one of
               four conditions: (1) random ITI between 100 and 400 ms (2)
               isochronous with ITI = 400 ms. (3) isochronous with ITI = 250 ms
               (equal to the mean rate of the attended sequence) (4)
               isochronous with ITI = 100 ms. For a frequency separation of 2
               (but not 4) semi tones we observed improved performance in
               conditions (3) and (4) relative to (1), suggesting that stream
               segregation is facilitated when the distracter sequence is
               temporally regular, but that the effect of temporal regularity
               as a cue for segregation is limited to relatively fast rates and
               to situations where frequency separation is insufficient for
               segregation. These findings provide new evidence to support
               models of streaming that involve segregation based on the
               formation of predictive models. ?? 2011 Elsevier B.V.",
  journal   = "Hearing research",
  publisher = "Elsevier B.V.",
  volume    =  280,
  number    = "1-2",
  pages     = "228--235",
  year      =  2011,
  issn      = "0378-5955",
  pmid      = "21683778",
  doi       = "10.1016/j.heares.2011.06.001"
}

@ARTICLE{Boltz1993-if,
  title    = "The generation of temporal and melodic expectancies during
              musical listening",
  author   = "Boltz, M G",
  abstract = "When listening to a melody, we are often able to anticipate not
              only what tonal intervals will occur next but also when in time
              these will appear. The experiments reported here were carried out
              to investigate what types of structural relations support the
              generation of temporal expectancies in the context of a melody
              recognition task. The strategy was to present subjects with a set
              of folk tunes in which temporal accents (i.e., notes with a
              prolonged duration) always occurred in the first half of a
              melody, so that expectancies, if generated, could carry over to
              an isochronous sequence of notes in the latter half of the
              melody. The ability to detect deviant pitch changes in the final
              variation as a function of rhythmic context was then evaluated.
              Accuracy and reaction time data from Experiment 1 indicated that
              expectancy formation jointly depends on an invariant periodicity
              of temporal accentuation and the attentional highlighting of
              certain melodic relations (i.e., phrase ending points). In
              Experiment 2, once these joint expectancies were generated, the
              temporal dimension had a greater facilitating effect upon melody
              recognition than did the melodic one. These results are discussed
              in terms of their implications for the perceptual processing of
              musical events.",
  journal  = "Perception \& psychophysics",
  volume   =  53,
  number   =  6,
  pages    = "585--600",
  year     =  1993,
  issn     = "0031-5117",
  pmid     = "8332426",
  doi      = "10.3758/BF03211736"
}

@ARTICLE{Devergie2010-qm,
  title    = "Effect of rhythmic attention on the segregation of interleaved
              melodies",
  author   = "Devergie, Aymeric and Grimault, Nicolas and Tillmann, Barbara and
              Berthommier, Fr{\'e}d{\'e}ric",
  abstract = "As previously suggested, attention may increase segregation via
              enhancement and suppression sensory mechanisms. To test this
              hypothesis, we proposed an interleaved melody paradigm with two
              rhythm conditions applied to familiar target melodies and
              unfamiliar distractor melodies sharing pitch and timbre
              properties. When rhythms of both target and distractor were
              irregular, target melodies were identified above chance level. A
              sensory enhancement mechanism guided by listeners' knowledge may
              have helped to extract targets from the interleaved sequence.
              When the distractor was rhythmically regular, performance was
              increased, suggesting that the distractor may have been
              suppressed by a sensory suppression mechanism.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  128,
  number   = "July 2010",
  pages    = "EL1--L7",
  year     =  2010,
  issn     = "0001-4966",
  pmid     = "20649182",
  doi      = "10.1121/1.3436498"
}

@ARTICLE{Rimmele2012-eq,
  title     = "Age-related changes in the use of regular patterns for auditory
               scene analysis",
  author    = "Rimmele, Johanna and Schr{\"o}ger, Erich and Bendixen, Alexandra",
  abstract  = "A recent approach to auditory processing suggests a close
               relationship of regularity processing in auditory sensory memory
               (ASM) and stream segregation, such that within-stream
               regularities can be used to stabilize stream segregation. The
               present study investigates age-related changes in how regular
               patterns are used for auditory scene analysis (ASA), when the
               stream containing the regularity is attended or unattended. In
               order to accomplish an intensity level deviant detection task,
               participants had to segregate the task-relevant pure tone
               sequence from an irrelevant distractor pure tone sequence, which
               randomly varied in level. In three conditions a simple
               spectro-temporal regularity (`` Isochronous'' ), a more complex
               spectro-temporal regularity (`` Rhythmic'' ), or no regularity
               (`` Random'' ) was embedded in either the attended target
               sequence (Experiment 1), or the unattended distractor sequence
               (Experiment 2). When the sequence containing the regularity was
               attended, older participants showed a similar increase of
               performance to younger adults in the conditions with regular
               patterns (`` Isochronous'' and `` Rhythmic'' ) compared to the
               `` Random'' condition. In contrast, when the sequence containing
               the regularity was unattended, older adults showed a specific
               performance decline compared to younger adults in the ``
               Isochronous'' condition. Results suggest a link between impaired
               automatic processing of regularities in ASM, and age-related
               deficits in the use of regular patterns for ASA. \copyright{}
               2012 Elsevier B.V.",
  journal   = "Hearing research",
  publisher = "Elsevier B.V.",
  volume    =  289,
  number    = "1-2",
  pages     = "98--107",
  year      =  2012,
  issn      = "0378-5955",
  pmid      = "22543088",
  doi       = "10.1016/j.heares.2012.04.006"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Rohenkohl2012-oo,
  title    = "Temporal expectation improves the quality of sensory information",
  author   = "Rohenkohl, G and Cravo, a M and Wyart, V and Nobre, a C",
  abstract = "It is increasingly clear that we extract patterns of temporal
              regularity between events to optimize information processing.
              Whereas some of the mechanisms for facilitating action
              preparation and execution have been well documented, much less is
              understood about whether and how temporal expectations influence
              visual perception. We used a psychophysical paradigm and
              computational modeling to investigate the mechanisms by which
              temporal expectation can modulate visual perception. Visual
              targets appeared in a stream of noise-patches separated by a
              fixed (400 ms regular condition) or jittered (200/300/400/500/600
              ms irregular condition) intervals. Targets were visual gratings
              tilted 45° clockwise or counter-clockwise, presented at one of
              seven contrast levels. Human observers were required to perform
              an orientation discrimination (i.e., left or right). Psychometric
              functions for contrast sensitivity fitted for the regular and
              irregular conditions indicated that temporal expectation
              modulates perceptual processing by enhancing the contrast
              sensitivity of visual targets. This increase in the signal
              strength was accompanied by a reduction in reaction times. A
              diffusion model indicated that rhythmic temporal expectation
              enhanced the signal-to-noise gain of the sensory evidence upon
              which decisions were made. These effects support the idea that
              temporal structure of external events can entrain the attentional
              focus and psychophysical data, optimizing the processing of
              relevant sensory information.",
  journal  = "Journal of Neuroscience",
  volume   =  32,
  number   =  24,
  pages    = "8424--8428",
  year     =  2012,
  issn     = "0270-6474",
  pmid     = "22699922",
  doi      = "10.1523/JNEUROSCI.0804-12.2012"
}

@ARTICLE{Gigerenzer2009-zj,
  title    = "Homo Heuristicus: Why biased minds make better inferences",
  author   = "Gigerenzer, Gerd and Brighton, Henry",
  abstract = "Heuristics are efficient cognitive processes that ignore
              information. In contrast to the widely held view that less
              processing reduces accuracy, the study of heuristics shows that
              less information, computation, and time can in fact improve
              accuracy. We review the major progress made so far: (a) the
              discovery of less-is-more effects; (b) the study of the
              ecological rationality of heuristics, which examines in which
              environments a given strategy succeeds or fails, and why; (c) an
              advancement from vague labels to computational models of
              heuristics; (d) the development of a systematic theory of
              heuristics that identifies their building blocks and the evolved
              capacities they exploit, and views the cognitive system as
              relying on an ``adaptive toolbox;'' and (e) the development of an
              empirical methodology that accounts for individual differences,
              conducts competitive tests, and has provided evidence for
              people's adaptive use of heuristics. Homo heuristicus has a
              biased mind and ignores part of the available information, yet a
              biased mind can handle uncertainty more efficiently and robustly
              than an unbiased mind relying on more resource-intensive and
              general-purpose processing strategies.",
  journal  = "Topics in cognitive science",
  volume   =  1,
  number   =  1,
  pages    = "107--143",
  year     =  2009,
  keywords = "Decision-making; Heuristics; Induction; Inferences; Rationality;
              Uncertainity",
  issn     = "1756-8757",
  pmid     = "25164802",
  arxivid  = "1011.1669v3",
  doi      = "10.1111/j.1756-8765.2008.01006.x"
}

@ARTICLE{Bendixen2015-fq,
  title    = "Noise occlusion in discrete tone sequences as a tool towards
              auditory predictive processing?",
  author   = "Bendixen, Alexandra and Duwe, Susann and Reiche, Martin",
  journal  = "Brain research",
  volume   =  1626,
  pages    = "97--107",
  year     =  2015,
  keywords = "erp; human event-related potential",
  issn     = "0006-8993",
  pmid     = "26187755",
  doi      = "10.1016/j.brainres.2015.06.045"
}

@ARTICLE{Lee1967-rz,
  title   = "An Investigation of the Use of the Musical Aptitude Profile with
             College and University Freshman Music Students",
  author  = "Lee, Robert E",
  journal = "Journal of Research in Music Education",
  volume  =  15,
  number  =  4,
  pages   = "278--288",
  year    =  1967
}

@ARTICLE{Cleary1997-ts,
  title    = "Unbounded length contexts for {PPM}",
  author   = "Cleary, John G and Teahan, W J",
  abstract = "The PPM data compression scheme has set the performance standard
              in lossless compression of text throughout the past decade. PPM
              is a ``nite-context statistical modelling technique that can be
              viewed as blending together several ''xed-order context models to
              predict the next character in the input sequence. This paper
              gives a brief introduction to PPM, and describes a variant of the
              algorithm, called PPM*, which exploits contexts of unbounded
              length. Although requiring considerably greater computational
              resources (in both time and space), this reliably achieves
              compression superior to the benchmark PPMC version. Its major
              contribution is that it shows that the full information available
              by considering all substrings of the input string can be used
              effectively to generate high-quality predictions. Hence, it
              provides a useful tool for exploring the bounds of compression.",
  journal  = "Computer Journal",
  volume   =  40,
  number   =  2,
  pages    = "67--75",
  year     =  1997,
  issn     = "0010-4620",
  doi      = "10.1093/comjnl/40.2\_and\_3.67"
}

@ARTICLE{Brown1969-vr,
  title    = "The Optimum Length of the Musical Aptitude Profile Subtests",
  author   = "Brown, Merrill",
  abstract = "Quantitative 3 Innate (aptitude)",
  journal  = "Journal of Research in Music Education",
  volume   =  17,
  number   =  2,
  pages    = "240",
  year     =  1969,
  issn     = "0022-4294",
  doi      = "10.2307/3344329"
}

@ARTICLE{Moffat1990-lu,
  title    = "Implementing the {PPM} data compression scheme",
  author   = "Moffat, Alistair",
  abstract = "The prediction by partial matching (PPM) data compression
              algorithm developed by J. Cleary and I. Witten (1984) is capable
              of very high compression rates, encoding English text in as
              little as 2.2 b/character. It is shown that the estimates made by
              Cleary and Witten of the resources required to implement the
              scheme can be revised to allow for a tractable and useful
              implementation. In particular, a variant is described that
              encodes and decodes at over 4 kB/s on a small workstation and
              operates within a few hundred kilobytes of data space, but still
              obtains compression of about 2.4 b/character for English text",
  journal  = "IEEE Transactions on Communications",
  volume   =  38,
  number   =  11,
  pages    = "1917--1921",
  year     =  1990,
  issn     = "0090-6778",
  doi      = "10.1109/26.61469"
}

@ARTICLE{Cleary1984-cv,
  title    = "Data compression using adaptive coding and partial string
              matching",
  author   = "Cleary, John G and Witten, Ian H",
  abstract = "The recently developed technique of arithmetic coding, in
              conjunction with a Markov model of the source, is a powerful
              method of data compression in situations where a linear treatment
              is inappropriate. Adaptive coding allows the model to be
              constructed dynamically by both encoder and decoder during the
              course of the transmission, and has been shown to incur a smaller
              coding overhead than explicit transmission of the model's
              statistics. But there is a basic conflict between the desire to
              use high-order Markov models and the need to have them formed
              quickly as the initial part of the message is sent. This paper
              describes how the conflict can be resolved with partial string
              matching, and reports experimental results which show that
              mixed-case English text can be coded in as little as 2.2 bits/
              character with no prior knowledge of the source. View full
              abstract",
  journal  = "IEEE Transactions on Communications",
  volume   =  32,
  number   =  4,
  pages    = "396--402",
  year     =  1984,
  issn     = "0090-6778",
  doi      = "10.1109/TCOM.1984.1096090"
}

@ARTICLE{Jones1982-uk,
  title    = "Controlled attending as a function of melodic and temporal
              context",
  author   = "Jones, Mari Riess and Boltz, Marilyn and Kidd, Gary",
  abstract = "Melodic and rhythmic context were systematically varied in a
              pattern recognition task involving pairs (standard-comparison) of
              nine-tone auditory sequences. The experiment was designed to test
              the hypothesis that rhythmic context can direct attention toward
              or away from tones which instantiate higher order melodic rules.
              Three levels of melodic structure (one, two, no higher order
              rules) were crossed with four levels of rhythm [isochronous,
              dactyl (A U U), anapest (U U A), irregular]. Rhythms were
              designed to shift accent locations on three centrally embedded
              tones. Listeners were more accurate in detecting violations of
              higher order melodic rules when the rhythmic context induced
              accents on tones which instantiated these rules. Effects are
              discussed in terms of attentional rhythmicity.",
  journal  = "Perception \& psychophysics",
  volume   =  32,
  number   =  3,
  pages    = "211--218",
  year     =  1982,
  issn     = "0031-5117",
  pmid     = "7177759",
  doi      = "10.3758/BF03206225"
}

@ARTICLE{Warrier2002-rl,
  title    = "Influence of tonal context and timbral variation on perception of
              pitch",
  author   = "Warrier, Catherine M and Zatorre, Robert J",
  abstract = "In this study, spectral timbre's effect on pitch perception is
              examined in varying contexts. In two experiments, subjects
              detected pitch deviations of tones differing in brightness in an
              isolated context in which they compared two tones, in a
              tone-series context in which they judged whether the last tone of
              a simple sequence was in or out of tune, and in a melodic context
              in which they determined whether the last note of familiar
              melodies was in or out of tune. Timbre influenced pitch judgments
              in all the conditions, but increasing tonal context allowed the
              subjects to extract pitch information more accurately. This
              appears to be due to two factors: (1) The presence of extra tones
              creates a stronger reference point from which to judge pitch, and
              (2) the melodies' tonal structure gives more cues that facilitate
              pitch extraction, even in the face of conflicting spectral
              information.",
  journal  = "Perception \& psychophysics",
  volume   =  64,
  number   =  2,
  pages    = "198--207",
  year     =  2002,
  issn     = "0031-5117",
  pmid     = "12013375",
  doi      = "10.3758/BF03195786"
}

@INCOLLECTION{Deutsch2012-tb,
  title     = "Absolute pitch",
  booktitle = "The Psychology of Music",
  author    = "Deutsch, Diana",
  publisher = "Academic Press",
  pages     = "141--182",
  year      =  2012,
  address   = "London, England"
}

@ARTICLE{Levitin1994-wo,
  title    = "Absolute memory for musical pitch: Evidence from the production
              of learned melodies",
  author   = "Levitin, D J",
  abstract = "Evidence for the absolute nature of long-term auditory memory is
              provided by analyzing the production of familiar melodies.
              Additionally, a two-component theory of absolute pitch is
              presented, in which this rare ability is conceived as consisting
              of a more common ability, pitch memory, and a separate, less
              common ability, pitch labeling. Forty-six subjects sang two
              different popular songs, and their productions were compared with
              the actual pitches used in recordings of those songs. Forty
              percent of the subjects sang the correct pitch on at least one
              trial; 12\% of the subjects hit the correct pitch on both trials,
              and 44\% came within two semitones of the correct pitch on both
              trials. The results show a convergence with previous studies on
              the stability of auditory imagery and latent absolute pitch
              ability; the results further suggest that individuals might
              possess representations of pitch that are more stable and
              accurate than previously recognized.",
  journal  = "Perception \& psychophysics",
  volume   =  56,
  number   =  4,
  pages    = "414--423",
  year     =  1994,
  issn     = "0031-5117",
  pmid     = "7984397",
  doi      = "10.3758/BF03206733"
}

@ARTICLE{Baharloo1998-cq,
  title    = "Absolute pitch: an approach for identification of genetic and
              nongenetic components",
  author   = "Baharloo, S and Johnston, P a and Service, S K and Gitschier, J
              and Freimer, N B",
  abstract = "Absolute pitch (AP) is the ability to recognize a pitch, without
              an external reference. By surveying more than 600 musicians in
              music conservatories, training programs, and orchestras, we have
              attempted to dissect the influences of early musical training and
              genetics on the development of this ability. Early musical
              training appears to be necessary but not sufficient for the
              development of AP. Forty percent of musicians who had begun
              training at =9 years of age did so. Self-reported AP possessors
              were four times more likely to report another AP possessor in
              their families than were non-AP possessors. These data suggest
              that both early musical training and genetic predisposition are
              needed for the development of AP. We developed a simple
              computer-based acoustical test that has allowed us to subdivide
              AP possessors into distinct groups, on the basis of their
              performance. Investigation of individuals who performed extremely
              well on this test has already led us to identify several families
              that will be suitable for studies of the genetic basis of AP.",
  journal  = "American journal of human genetics",
  volume   =  62,
  number   =  2,
  pages    = "224--231",
  year     =  1998,
  keywords = "Adolescent; Age Factors; Audiometry, Pure-Tone; Auditory
              Perception; Auditory Perception: genetics; Child; Child,
              Preschool; Female; Humans; Male; Music; Pedigree; Pitch
              Discrimination; Pitch Discrimination: physiology; Students",
  issn     = "0002-9297",
  pmid     = "9463312",
  doi      = "10.1086/301704"
}

@ARTICLE{Takeuchi1991-ui,
  title   = "Absolute-pitch judgments of black- and white-key pitches",
  author  = "Takeuchi, Annie H and Hulse, Stewart H",
  journal = "Music perception",
  volume  =  9,
  number  =  1,
  pages   = "27--46",
  year    =  1991,
  issn    = "0730-7829"
}

@ARTICLE{Bachem1954-cl,
  title   = "Time factors in relative and absolute pitch determination",
  author  = "Bachem, A",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  26,
  number  =  5,
  pages   = "751--753",
  year    =  1954,
  issn    = "0001-4966"
}

@ARTICLE{Takeuchi1993-rl,
  title   = "Absolute pitch",
  author  = "Takeuchi, A H and Hulse, S H",
  journal = "Psychological bulletin",
  volume  =  113,
  number  =  2,
  pages   = "345--361",
  year    =  1993,
  issn    = "0033-2909"
}

@ARTICLE{Miyazaki2004-nc,
  title    = "How well do we understand absolute pitch?",
  author   = "Miyazaki, Ken'ichi",
  abstract = "Absolute pitch (AP) is the ability based on the fixed association
              between musical pitch and its verbal label. Experiments on AP
              identification demonstrated extreme accuracy of AP listeners in
              identifying pitch, influences of timbre and pitch range, and
              difference in accuracy between white-key notes and black-key
              notes. However, contrary to the common belief that AP is a
              component of musical ability, it was found that AP listeners have
              difficulty in perceiving pitch relations in different pitch
              contexts, and in recognizing transposed melodies, as compared to
              listeners having no AP. These results suggest that AP is
              irrelevant and even disadvantageous to music. Systematic music
              training in early childhood seems effective for acquiring AP.
              Possible genetic contributions to AP are undeniable, but evidence
              for them is inconclusive. There are several AP-like phenomena
              that do not reach consciousness: absolute tonality, long-term
              memory of pitch of repeatedly heard tunes, specific patterns of
              pitch comparison in the tritone paradox, and fixed pitch levels
              in speech. Contrary to true AP observed as a pitch naming
              ability, the implicit AP phenomena are widespread among general
              population.",
  journal  = "Acoustical science and technology / edited by the Acoustical
              Society of Japan",
  volume   =  25,
  number   =  6,
  pages    = "426--432",
  year     =  2004,
  keywords = "10; 1250; 25; 426; 43; 75; absolute pitch; ast; cd; doi; early
              learning; pacs number; pitch naming; relative pitch; tonality",
  issn     = "1346-3969",
  doi      = "10.1250/ast.25.426"
}

@ARTICLE{Athos2007-xm,
  title    = "Dichotomy and perceptual distortions in absolute pitch ability",
  author   = "Athos, E Alexandra and Levinson, Barbara and Kistler, Amy and
              Zemansky, Jason and Bostrom, Alan and Freimer, Nelson and
              Gitschier, Jane",
  abstract = "Absolute pitch (AP) is the rare ability to identify the pitch of
              a tone without the aid of a reference tone. Understanding both
              the nature and genesis of AP can provide insights into
              neuroplasticity in the auditory system. We explored factors that
              may influence the accuracy of pitch perception in AP subjects
              both during the development of the trait and in later age. We
              used a Web-based survey and a pitch-labeling test to collect
              perceptual data from 2,213 individuals, 981 (44\%) of whom proved
              to have extraordinary pitch-naming ability. The bimodal
              distribution in pitch-naming ability signifies AP as a distinct
              perceptual trait, with possible implications for its genetic
              basis. The wealth of these data has allowed us to uncover
              unsuspected note-naming irregularities suggestive of a
              ``perceptual magnet'' centered at the note ``A.'' In addition, we
              document a gradual decline in pitch-naming accuracy with age,
              characterized by a perceptual shift in the ``sharp'' direction.
              These findings speak both to the process of acquisition of AP and
              to its stability.",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  104,
  number   =  37,
  pages    = "14795--14800",
  year     =  2007,
  issn     = "0027-8424",
  pmid     = "17724340",
  doi      = "10.1073/pnas.0703868104"
}

@ARTICLE{Bachem1955-fe,
  title   = "Absolute pitch",
  author  = "Bachem, A",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  27,
  number  =  6,
  pages   = "1180--1185",
  year    =  1955,
  issn    = "0001-4966"
}

@ARTICLE{Profita1988-fo,
  title   = "Perfect pitch",
  author  = "Profita, J and Bidder, T G and Opitz, J M and Reynolds, J F",
  journal = "American journal of medical genetics",
  volume  =  29,
  number  =  4,
  pages   = "763--771",
  year    =  1988,
  issn    = "0148-7299"
}

@ARTICLE{Dowling1973-ga,
  title    = "Rhythmic groups and subjective chunks in memory for melodies",
  author   = "Dowling, W Jay",
  abstract = "Memory for brief melodic phrases was tested using a short-term
              recognition-memory paradigm. The five-note phrases were
              rhythmically separated from each other and presented in-lists
              four phrases in length. A single five-note test item followed
              each list and either corresponded rhythmically to one of the
              phrases as presented in the list (within items) or to the last
              three notes of one phrase and the first two notes of the next
              (across items). Within items were easier than across items. Slow
              presentation (3 notes/sec) was slightly easier than fast (6
              notes/sec). The J-shaped serial position curve typical of
              short-term memory for verbal material was obtained. The results
              support the position that rhythmic grouping of input determines
              subjective chunking and memory storage, facilitating the
              recognition of test items chunked in the same way as list items.",
  journal  = "Perception \& psychophysics",
  volume   =  14,
  number   =  1,
  pages    = "37--40",
  year     =  1973,
  issn     = "0031-5117",
  doi      = "10.3758/BF03198614"
}

@ARTICLE{Krumhansl2000-zy,
  title    = "Tonality induction: A statistical approach applied
              cross-culturally",
  author   = "Krumhansl, Carol L",
  abstract = "Explored sensitivity to tone distributions (TDs) in a
              cross-cultural context using 2 styles of music: Finnish spiritual
              folk hymns and North Sami yoiks. Ss were 12 youth choir members,
              25 Finnish undergraduate music majors, and Western musicians. The
              groups varied in familiarity with the styles of music. Krumhansl
              tested models using 3 kinds of statistics of the musical style
              (i.e., TDs, 2- and 3-tone transitions) to categorize short
              initial segments as coming from one style or the other. The model
              using TDs made numerous categorization errors, which can be
              understood because the TDs for these styles are similar.
              Categorization was better for models that used 2- and 3-tone
              transitions. The major differences between the transitional
              probabilities in the styles were used to account for cases that
              the models found difficult. Results point to listeners'
              sensitivity to higher order transition information and its
              utility for style identification. (PsycINFO Database Record (c)
              2004 APA, all rights reserved)",
  journal  = "Music perception",
  volume   =  17,
  number   =  4,
  pages    = "461--479",
  year     =  2000,
  keywords = "Cross Cultural Differences; Finland; Human; Music; Music
              Perception; Musicians; Pitch Perception; Stimulus Novelty;
              familiarity with music style \& sensitivity to tone distributions
              in 2 styles of F",
  issn     = "0730-7829"
}

@ARTICLE{Bartlett1980-xo,
  title    = "Recognition of transposed melodies: A key-distance effect in
              developmental perspective",
  author   = "Bartlett, James C and Dowling, W Jay",
  abstract = "Four experiments examined the possibility of a key-distance
              effect in a transposition detection task. Ss were 20 musically
              experienced and 19 inexperienced undergraduates and 42
              kindergartners through 3rd graders. Ss heard standard melodies
              followed by comparison melodies presented in the same key, a
              musically near key, or a musically far key. The task was to
              recognize comparisons that were exact transpositions of the
              standards, rejecting nontranspositions. Results suggest a largely
              invarient key-distance effect with nontransposition comparisons
              (lures); same- and near-key lures evoked more false alarms than
              far-key lures. The variables of musical experience, age of S, and
              familiarity of melody affected the level of
              transposition-recognition performance but did not consistently
              affect the size of the key-distance effect. Results support the
              physiological reality of key distance and are consistent with
              both musical and nonmusical auditory theories of its effects. The
              key-distance effect was not found with transposition comparisons
              (targets), a result with implications for the separability of key
              and interval information in short-term memory for melodies. (12
              ref) (PsycINFO Database Record (c) 2012 APA, all rights reserved)",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  6,
  number   =  3,
  pages    = "501--515",
  year     =  1980,
  issn     = "0096-1523"
}

@ARTICLE{LaDuca1986-uw,
  title   = "Item modelling procedure for constructing content-equivalent
             multiple choice questions",
  author  = "LaDuca, A and Staples, W and Templeton, B",
  journal = "Medical education",
  volume  =  20,
  number  = "C",
  pages   = "53--56",
  year    =  1986,
  issn    = "0308-0110"
}

@ARTICLE{Green1993-tx,
  title   = "A maximum-likelihood method for estimating thresholds in a yes-no
             task",
  author  = "Green, David M",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  93,
  number  =  4,
  pages   = "2096--2105",
  year    =  1993,
  issn    = "0001-4966"
}

@ARTICLE{Green1990-pe,
  title   = "Stimulus selection in adaptive psychophysical procedures",
  author  = "Green, David M",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  87,
  number  =  6,
  pages   = "2662--2674",
  year    =  1990,
  issn    = "0001-4966"
}

@ARTICLE{Kirchberger2015-jw,
  title    = "Development of the Adaptive Music Perception Test",
  author   = "Kirchberger, Martin J and Russo, Frank A",
  abstract = "OBJECTIVES: Despite vast amounts of research examining the
              influence of hearing loss on speech perception, comparatively
              little is known about its influence on music perception. No
              standardized test exists to quantify music perception of
              hearing-impaired (HI) persons in a clinically practical manner.
              This study presents the Adaptive Music Perception (AMP) test as a
              tool to assess important aspects of music perception with hearing
              loss.\textbackslashn\textbackslashnDESIGN: A computer-driven test
              was developed to determine the discrimination thresholds of 10
              low-level physical dimensions (e.g., duration, level) in the
              context of perceptual judgments about musical dimensions: meter,
              harmony, melody, and timbre. In the meter test, the listener is
              asked to judge whether a tone sequence is duple or triple in
              meter. The harmony test requires that the listener make judgments
              about the stability of the chord sequences. In the melody test,
              the listener must judge whether a comparison melody is the same
              as a standard melody when presented in transposition and in the
              context of a chordal accompaniment that serves as a mask. The
              timbre test requires that the listener determines which of two
              comparison tones is different in timbre from a standard tone (ABX
              design). Twenty-one HI participants and 19 normal-hearing (NH)
              participants were recruited to carry out the music tests.
              Participants were tested twice on separate occasions to evaluate
              test-retest reliability.\textbackslashn\textbackslashnRESULTS:
              The HI group had significantly higher discrimination thresholds
              than the NH group in 7 of the 10 low-level physical dimensions:
              frequency discrimination in the meter test, dissonance and
              intonation perception in the harmony test, melody-to-chord ratio
              for both melody types in the melody test, and the perception of
              brightness and spectral irregularity in the timbre test. Small
              but significant improvement between test and retest was observed
              in three dimensions: frequency discrimination (meter test),
              dissonance (harmony test), and attack length (timbre test). All
              other dimensions did not show a session effect. Test-retest
              reliability was poor (0.6) for pitch and duration (meter test),
              dissonance and intonation (harmony test), and melody-to-chord
              ratio I and II (melody test); and excellent (>0.8) for level
              (meter test) and attack (timbre
              test).\textbackslashn\textbackslashnCONCLUSION: The AMP test
              revealed differences in a wide range of music perceptual
              abilities between NH and HI listeners. The recognition of meter
              was more difficult for HI listeners when the listening task was
              based on frequency discrimination. The HI group was less
              sensitive to changes in harmony and had more difficulties with
              distinguishing melodies in a background of music. In addition,
              the thresholds to discriminate timbre were significantly higher
              for the HI group in brightness and spectral irregularity
              dimensions. The AMP test can be used as a research tool to
              further investigate music perception with hearing aids and
              compare the benefit of different music processing strategies for
              the HI listener. Future testing will involve larger samples with
              the inclusion of hearing aided conditions allowing for the
              establishment of norms so that the test might be appropriate for
              use in clinical practice.",
  journal  = "Ear \& Hearing",
  volume   =  36,
  number   =  2,
  pages    = "217--228",
  year     =  2015,
  keywords = "adaptive test; hearing impairment; hearing loss; music",
  issn     = "1538-4667",
  pmid     = "25350404",
  doi      = "10.1097/AUD.0000000000000112"
}

@ARTICLE{Vispoel1993-id,
  title    = "The development and evaluation of a computerized adaptive test of
              tonal memory",
  author   = "Vispoel, Walter P",
  abstract = "The purpose of this three-phase investigation was to develop and
              evaluate a computerized adaptive test of tonal memory. In the
              first phase, characteristics of commercially available tonal
              memory tests (instrument timbre, rhythmic complexity, tonality)
              were systematically varied and compared to determine the types of
              items most likely to yield reliable and valid scores. Results
              from ANOVA, factor-analytic, correlation, and regression analyses
              indicated that synthesizer-produced, varied-rhythm tonal and
              atonal melodies of four to nine notes would provide reliable and
              concurrently valid scores over a wide range of ability levels. In
              the second phase, the adaptive test was constructed, and its
              measurement precision and efficiency were evaluated in a series
              of computer-simulation analyses. Results showed that the adaptive
              test required 5 to 11 items to yield reliabilities from .80 to
              .90, and 80\% fewer items to surpass the reliability of the
              Seashore Tonal Memory Test. In the final phase, the adaptive test
              was field-tested on the PLATO computer system. In line with the
              computer-simulation findings, the adaptive test required an
              average of 6.05, 8.55, and 11.60 items to reach reliabilities of
              .80, .85, and .90, respectively.",
  journal  = "Journal of Research in Music Education",
  volume   =  41,
  number   =  2,
  pages    = "111--136",
  year     =  1993,
  issn     = "0022-4294",
  doi      = "10.2307/3345403"
}

@TECHREPORT{Wetzel1983-qm,
  title       = "Influence of fallible item parameters on test information
                 during adaptive testing",
  author      = "Wetzel, C D and McBride, J R",
  institution = "Navy Personnel Research and Development Center",
  year        =  1983,
  address     = "San Diego"
}

@TECHREPORT{Martin1983-an,
  title       = "Reliability and validity of adaptive and conventional tests in
                 a military recruit population",
  author      = "Martin, John T and McBride, James R and Weiss, David J",
  institution = "University of Minnesota",
  year        =  1983,
  address     = "Minneapolis, MN"
}

@ARTICLE{Patton2013-nz,
  title    = "The influence of item calibration error on variable-length
              computerized adaptive testing",
  author   = "Patton, J M and Cheng, Ying and Yuan, K-H and Diao, Q",
  journal  = "Applied psychological measurement",
  volume   =  37,
  number   =  1,
  pages    = "24--40",
  year     =  2013,
  keywords = "ability; cat; classification; computerized adaptive testing;
              estimation; is to match items; item calibration; test length;
              test termination; the fundamental goal of; variable-length
              computerized adaptive testing; with examinee",
  issn     = "0146-6216",
  doi      = "10.1177/0146621612461727"
}

@ARTICLE{Weiss1982-lc,
  title    = "Improving measurement quality and efficiency with adaptive
              testing",
  author   = "Weiss, D J",
  abstract = "Approaches to adaptive (tailored) testing based on item response
              theory are described and research results summarized. Through
              appropriate combinations of item pool design and use of different
              test termination criteria, adaptive tests can be designed (1) to
              improve both measurement quality and measurement efficiency,
              resulting in measurements of equal precision at all trait levels;
              (2) to improve measurement efficiency for test batteries using
              item pools designed for conventional test administration; and (3)
              to improve the accuracy and efficiency of testing for
              classification (e.g., mastery testing). Research results show
              that tests based on item response theory (IRT) can achieve
              measurements of equal precision at all trait levels, given an
              adequately designed item pool; these results contrast with those
              of conventional tests which require a tradeoff of bandwidth for
              fidelity/precision of measurements. Data also show reductions in
              bias, inaccuracy, and root mean square error of ability
              estimates. Improvements in test fidelity observed in simulation
              studies are supported by live-testing data, which showed adaptive
              tests requiring half the number of items as that of conventional
              tests to achieve equal levels of reliability, and almost
              one-third the number to achieve equal levels of validity. When
              used with item pools from conventional tests, both simulation and
              live-testing results show reductions in test battery length from
              conventional tests, with no reductions in the quality of
              measurements. Adaptive tests designed for dichotomous
              classification also represent improvements over conventional
              tests designed for the same purpose. Simulation studies show
              reductions in test length and improvements in classification
              accuracy for adaptive vs. conventional tests; live-testing
              studies in which adaptive tests were compared with ``optimal''
              conventional tests support these findings. Thus, the research
              data show that IRT-based adaptive testing takes advantage of the
              capabilities of IRT to improve the quality and/or efficiency of
              measurement for each examinee.",
  journal  = "Applied psychological measurement",
  volume   =  6,
  number   =  4,
  pages    = "473--492",
  year     =  1982,
  issn     = "0146-6216",
  doi      = "10.1177/014662168200600408"
}

@ARTICLE{Ward1984-gc,
  title    = "Using microcomputers to administer tests",
  author   = "Ward, William C",
  abstract = "Discusses benefits available from using computers to administer
              the kinds of tests that are most familiar in educational
              settings. Four applications that represent current or near-term
              enhancements of assessment---computerized adaptive testing,
              diagnostic testing, test preparation, and administration of
              simulations of complex problem situations---are discussed. The
              applications offer improvements, including the individualization
              of assessment, increased accuracy, efficiency in handling test
              information, more detailed information to guide instruction, and
              decreased costs. (4 ref) (PsycINFO Database Record (c) 2010 APA,
              all rights reserved)",
  journal  = "Educational Measurement: Issues and Practice",
  volume   =  3,
  number   =  2,
  pages    = "16--20",
  year     =  1984,
  keywords = "Computer Applications; Educational Measurement; Microcomputers;
              Test Administration; microcomputers \& test administration",
  doi      = "10.1111/j.1745-3992.1984.tb00744.x"
}

@ARTICLE{Wang1998-dh,
  title    = "Properties of ability estimation methods in computerized adaptive
              testing",
  author   = "Wang, Tianyou and Vispoel, Walter P",
  abstract = "Simulations of computerized adaptive tests (CATs) were used to
              evaluate results yielded by four commonly used ability estimation
              methods: maximum likelihood estimation (MLE) and three Bayesian
              approaches---Owen's method, expected a posteriori (EAP), and
              maximum a posteriori. In line with the theoretical nature of the
              ability estimates and previous empirical research, the results
              showed clear distinctions between MLE and the Bayesian methods,
              with MLE yielding lower bias, higher standard errors, higher root
              mean square errors, lower fidelity, and lower administrative
              efficiency. Standard errors for MLE based on test information
              underestimated actual standard errors, whereas standard errors
              for the Bayesian methods based on posterior distribution standard
              deviations accurately estimated actual standard errors. Among the
              Bayesian methods, Owen's provided the worst overall results, and
              EAP provided the best. Using a variable starting rule in which
              examinees were initially classified into three broad/ability
              groups greatly reduced the bias for the Bayesian methods, but had
              little effect on the results for MLE. On the basis of these
              results, guidelines are offered for selecting appropriate CAT
              ability estimation methods in different decision contexts.",
  journal  = "Journal of Educational Measurement",
  volume   =  35,
  number   =  2,
  pages    = "109--135",
  year     =  1998,
  issn     = "1745-3984",
  doi      = "10.1111/j.1745-3984.1998.tb00530.x"
}

@UNPUBLISHED{Harrison2015-qx,
  title  = "Joining the two traditions of melodic memory research with formal
            models of similarity perception",
  author = "Harrison, Peter M C and Musil, Jason and M{\"u}llensiefen, Daniel",
  year   =  2015
}

@BOOK{De_Groot1965-ab,
  title     = "Thought and choice in chess",
  author    = "de Groot, A D",
  publisher = "Mouton",
  year      =  1965,
  address   = "The Hague, Netherlands"
}

@ARTICLE{Chase1973-ge,
  title   = "Perception in chess",
  author  = "Chase, W G and Simon, Herbert A",
  journal = "Cognitive psychology",
  volume  =  4,
  pages   = "55--81",
  year    =  1973,
  issn    = "0010-0285"
}

@ARTICLE{Egan1979-tz,
  title    = "Chunking in recall of symbolic drawings",
  author   = "Egan, D E and Schwartz, B J",
  abstract = "Three experiments explored memory for symbolic circuit drawings
              using skilled electronics technicians and novice subjects. In the
              first experiment a skilled technician reconstructed circuit
              diagrams from memory. Recall showed marked ``chunking'', or
              grouping, by functional units similar to Chess Masters' recall of
              chess positions. In the second experiment skilled technicians
              were able to recall more than were novice subjects following
              abrief exposure of the drawings. This advantage did not hold for
              randomly arranged symbols. In the third experiment the size of
              chunks retrieved systematically increased with additional study
              time. Supplementary analyses suggested that the chunking by
              skilled subjects was not an arti- fact of spatial proximity and
              chunk statistics, and that severe constraints are placed on any
              explanation of the data based on guessing. It is proposed that
              skilled subjects identify the conceptual category for an entire
              drawing, and retrieve elements using a generate-and- test
              process. The",
  journal  = "Memory \& cognition",
  volume   =  7,
  number   =  2,
  pages    = "149--158",
  year     =  1979,
  keywords = "Electronics; Form Perception; Humans; Male; Memory; Mental
              Recall; Middle Aged; Symbolism",
  issn     = "0090-502X",
  pmid     = "88658",
  doi      = "10.3758/BF03197595"
}

@ARTICLE{Cheng2010-wz,
  title    = "The impact of fallible item parameter estimates on latent trait
              recovery",
  author   = "Cheng, Ying and Yuan, Ke-Hai",
  journal  = "Psychometrika",
  volume   =  75,
  number   =  2,
  pages    = "280--291",
  year     =  2010,
  keywords = "irt scoring; latent trait; pml; pseudo maximum likelihood;
              standard error; upward correction",
  issn     = "0033-3123, 0896-6273"
}

@ARTICLE{Bod2001-ju,
  title    = "{Memory-Based} Models of Melodic Analysis: Challenging the
              Gestalt Principles",
  author   = "Bod, Rens",
  abstract = "We argue for a memory-based approach to music analysis which
              works with concrete musical experiences rather than with abstract
              rules or principles. New pieces of music are analyzed by
              combining fragments from structures of previously encountered
              pieces. The occurrence-frequencies of the fragments are used to
              determine the preferred analysis of a piece. We test some
              instances of this approach against a set of 1,000 manually
              annotated folksongs from the Essen Folksong Collection, yielding
              up to 85.9\% phrase accuracy. A qualitative analysis of our
              results indicates that there are grouping phenomena that
              challenge the commonly accepted Gestalt principles of proximity,
              similarity and parallelism. These grouping phenomena can neither
              be explained by other musical factors, such as meter and harmony.
              We argue that music perception may be much more memory-based than
              previously assumed.",
  journal  = "Journal of New Music Research",
  volume   =  30,
  number   =  3,
  pages    = "27--36",
  year     =  2001,
  issn     = "0929-8215",
  doi      = "10.1076/jnmr.31.1.27.8106"
}

@ARTICLE{Berz1995-ov,
  title   = "Working memory in music: A theoretical model",
  author  = "Berz, W L",
  journal = "Music perception",
  volume  =  12,
  number  =  3,
  pages   = "353--364",
  year    =  1995,
  issn    = "0730-7829"
}

@ARTICLE{Hoshino2008-au,
  title   = "Standard errors of estimated latent variable scores with estimated
             structural parameters",
  author  = "Hoshino, T and Shigemasu, K",
  journal = "Applied psychological measurement",
  volume  =  32,
  number  =  2,
  pages   = "181--189",
  year    =  2008,
  issn    = "0146-6216",
  doi     = "10.1177/0146621607301652"
}

@ARTICLE{Krumhansl2000-pm,
  title    = "Rhythm and pitch in music cognition",
  author   = "Krumhansl, C L",
  abstract = "Rhythm and pitch are the 2 primary dimensions of music. They are
              interesting psychologically because simple, well-defined units
              combine to form highly complex and varied patterns. This article
              brings together the major developments in research on how these
              dimensions are perceived and remembered, beginning with
              psychophysical results on time and pitch perception.
              Progressively larger units are considered, moving from basic
              psychological categories of temporal and frequency ratios, to
              pulse and scale, to metrical and tonal hierarchies, to the
              formation of musical rhythms and melodies, and finally to the
              cognitive representation of large-scale musical form.
              Interactions between the dimensions are considered, and major
              theoretical proposals are described. The article identifies
              various links between musical structure and perceptual and
              cognitive processes, suggesting psychological influences on how
              sounds are patterned in music.",
  journal  = "Psychological bulletin",
  volume   =  126,
  number   =  1,
  pages    = "159--179",
  year     =  2000,
  issn     = "0033-2909",
  pmid     = "10668354",
  doi      = "10.1037/0033-2909.126.1.159"
}

@ARTICLE{Olea2012-jx,
  title    = "Computerized Adaptive Testing: The capitalization on chance
              problem",
  author   = "Olea, Julio and Barrada, Juan Ram{\'o}n and Abad, Francisco J and
              Ponsoda, Vicente and Cuevas, Lara",
  abstract = "This paper describes several simulation studies that examine the
              effects of capitalization on chance in the selection of items and
              the ability estimation in CAT, employing the 3-parameter logistic
              model. In order to generate different estimation errors for the
              item parameters, the calibration sample size was manipulated (! =
              500, 1000 and 2000 subjects) as was the ratio of item bank size
              to test length (banks of 197 and 788 items, test lengths of 20
              and 40 items), both in a CAT and in a random test. Results show
              that capitalization on chance is particularly serious in CAT, as
              revealed by the large positive bias found in the small sample
              calibration conditions. For broad ranges of $\vartheta$, the
              overestimation of the precision (asymptotic Se) reaches levels of
              40\%, something that does not occur with the RMSE ($\vartheta$).
              The problem is greater as the item bank size to test length ratio
              increases. Potential solutions were tested in a second study,
              where two exposure control methods were incorporated into the
              item selection algorithm. Some alternative solutions are
              discussed. \copyright{} 2012 by The Spanish Journal of
              Psychology.",
  journal  = "The Spanish journal of psychology",
  volume   =  15,
  number   =  1,
  pages    = "424--441",
  year     =  2012,
  keywords = "azar en la selecci{\'o}n; capitalizaci{\'o}n del; capitalization
              on chance; computerized adaptive testing; de; de 3
              par{\'a}metros; de simulaci{\'o}n para examinar; de {\'\i}tems y
              la; empleando el modelo log{\'\i}stico; estimaci{\'o}n de rasgo
              en; item parameter estimation; los efectos de la; para generar
              diferentes errores; se describen varios estudios; tai; tests
              adaptativos informatizados",
  issn     = "1138-7416",
  doi      = "10.5209/rev\_SJOP.2012.v15.n1.37348"
}

@ARTICLE{Obusek1973-cv,
  title   = "Relation of the verbal transformation and the phonemic restoration
             effects",
  author  = "Obusek, Charles J and Warren, Richard M",
  journal = "Cognitive psychology",
  volume  =  5,
  pages   = "97--107",
  year    =  1973,
  issn    = "0010-0285"
}

@ARTICLE{Layton1975-bo,
  title   = "Differential effects of two nonspeech sounds on phonemic
             restoration",
  author  = "Layton, Barry",
  journal = "Bulletin of the Psychonomic Society",
  volume  =  6,
  number  =  5,
  pages   = "487--490",
  year    =  1975,
  issn    = "0090-5054"
}

@ARTICLE{Ladefoged1960-zy,
  title   = "Perception of sequence in auditory events",
  author  = "Ladefoged, Peter and Broadbent, Donald E",
  journal = "The Quarterly journal of experimental psychology",
  volume  =  12,
  number  =  3,
  pages   = "162--170",
  year    =  1960,
  issn    = "0033-555X",
  doi     = "10.1080/17470216008416720"
}

@ARTICLE{Carlyon2002-mv,
  title    = "The Continuity Illusion and Vowel Identification",
  author   = "Carlyon, Robert P and Deeks, John and Norris, Dennis and
              Butterfield, Sally",
  abstract = "Listeners were required to identify one of four steady-state
              vowels, each consisting of only two formants (F1 and F2). In one
              condition, F1 and F2 were pulsed on and off together with a 50\%
              duty cycle, every 100 or 200 ms. Vowel identification in this
              condition was almost perfect. However, when F1 and F2 were pulsed
              on and off in an alternating fashion, so that the two were never
              present at the same time, performance was very poor. Performance
              was greatly improved by inserting bursts of low-frequency
              (50--624 Hz) noise in the silent gaps between each instance of
              F1, and bursts of high-frequency (624--4000 Hz) noise in the gaps
              between instances of F2. The levels of these noise bursts were
              set in a preliminary experiment to ensure that the low-frequency
              noise would cause the F1s to sound continuous, and that the
              high-frequency noise would cause the F2s to sound continuous. It
              is concluded that this ``continuity illusion'' helped the
              auditory system to combine information from physically
              non-simultaneous formants. In addition, the data indicate that
              the neural mechanisms involved in vowel identification receive an
              input from those responsible for the continuity illusion",
  journal  = "Acta Acustica united with Acustica",
  volume   =  88,
  number   =  3,
  pages    = "408--415",
  year     =  2002,
  issn     = "1436-7947"
}

@ARTICLE{Bashford1987-qb,
  title    = "Multiple phonemic restorations follow the rules for auditory
              induction",
  author   = "Bashford, J A and Warren, Richard M",
  journal  = "Perception \& psychophysics",
  volume   =  42,
  number   =  2,
  pages    = "114--121",
  year     =  1987,
  keywords = "Adolescent; Adult; Attention; Female; Humans; Illusions; Male;
              Phonetics; Speech Perception",
  issn     = "0031-5117",
  pmid     = "3627931"
}

@ARTICLE{Srinivasan2005-kw,
  title    = "A schema-based model for phonemic restoration",
  author   = "Srinivasan, S and Wang, D L",
  abstract = "Phonemic restoration is the perceptual synthesis of phonemes when
              masked by appropriate replacement sounds by utilizing linguistic
              context. Current models attempting to accomplish acoustic
              restoration of phonemes, however, use only temporal continuity
              and produce poor restoration of unvoiced phonemes, and are also
              limited in their ability to restore voiced phonemes. We present a
              schema-based model for phonemic restoration. The model employs a
              missing data speech recognition system to decode speech based on
              intact portions and activates word templates corresponding to the
              words containing the masked phonemes. An activated template is
              dynamically time warped to the noisy word and is then used to
              restore the speech frames corresponding to the masked phoneme,
              thereby synthesizing it. The model is able to restore both voiced
              and unvoiced phonemes with a high degree of naturalness.
              Systematic testing shows that this model outperforms a
              Kalman-filter based model. (C) 2004 Elsevier B.V. All rights
              reserved.",
  journal  = "Speech communication",
  volume   =  45,
  number   =  1,
  pages    = "63--87",
  year     =  2005,
  keywords = "asr; computational auditory scene analysis; dynamic time warping;
              missing data; phonemic restoration; prediction; speech schemas;
              top-down model",
  issn     = "0167-6393",
  doi      = "10.1016/j.specom.2004.09.002"
}

@ARTICLE{Grossberg2011-gz,
  title    = "Laminar cortical dynamics of conscious speech perception: neural
              model of phonemic restoration using subsequent context in noise",
  author   = "Grossberg, Stephen and Kazerounian, Sohrob",
  abstract = "How are laminar circuits of neocortex organized to generate
              conscious speech and language percepts? How does the brain
              restore information that is occluded by noise, or absent from an
              acoustic signal, by integrating contextual information over many
              milliseconds to disambiguate noise-occluded acoustical signals?
              How are speech and language heard in the correct temporal order,
              despite the influence of contexts that may occur many
              milliseconds before or after each perceived word? A neural model
              describes key mechanisms in forming conscious speech percepts,
              and quantitatively simulates a critical example of contextual
              disambiguation of speech and language; namely, phonemic
              restoration. Here, a phoneme deleted from a speech stream is
              perceptually restored when it is replaced by broadband noise,
              even when the disambiguating context occurs after the phoneme was
              presented. The model describes how the laminar circuits within a
              hierarchy of cortical processing stages may interact to generate
              a conscious speech percept that is embodied by a resonant wave of
              activation that occurs between acoustic features, acoustic item
              chunks, and list chunks. Chunk-mediated gating allows speech to
              be heard in the correct temporal order, even when what is heard
              depends upon future context.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  130,
  number   =  1,
  pages    = "440--460",
  year     =  2011,
  issn     = "0001-4966",
  pmid     = "21786911",
  doi      = "10.1121/1.3589258"
}

@ARTICLE{Baskent2010-mf,
  title    = "Phonemic restoration by hearing-impaired listeners with mild to
              moderate sensorineural hearing loss",
  author   = "Ba{\c s}kent, Deniz and Eiler, Cheryl L and Edwards, Brent",
  abstract = "The auditory system is capable of perceptually restoring
              inaudible portions of speech. This restoration may be compromised
              as a result of hearing impairment, particularly if it is combined
              with advanced age, because of degradations in the bottom-up and
              top-down processes. To test this hypothesis, phonemic restoration
              was quantitatively measured with hearing-impaired listeners of
              varying ages and degrees of hearing impairment, as well as with a
              normal hearing control group. The results showed that the
              restoration benefit was negatively correlated with both hearing
              impairment and age, supporting the original hypothesis. Group
              data showed that listeners with mild hearing loss were able to
              perceptually restore the missing speech segments as well as
              listeners with normal hearing. By contrast, the
              moderately-impaired listeners showed no evidence of perceptual
              restoration. Further analysis using the articulation index showed
              that listeners with mild hearing loss were able to increase
              phonemic restoration with audibility. Moderately-impaired
              listeners, on the other hand, were unable to do so, even when the
              articulation index was high. The overall findings suggest that,
              in addition to insufficient audibility, degradations in the
              bottom-up and/or top-down mechanisms as a result of hearing loss
              may limit or entirely prevent phonemic restoration. \copyright{}
              2009 Elsevier B.V. All rights reserved.",
  journal  = "Hearing research",
  volume   =  260,
  number   = "1-2",
  pages    = "54--62",
  year     =  2010,
  keywords = "Aging; Auditory scene analysis; Bottom-up processing; Hearing
              impairment; Phonemic restoration; Top-down processing",
  issn     = "0378-5955",
  pmid     = "19922784",
  doi      = "10.1016/j.heares.2009.11.007"
}

@ARTICLE{Sivonen2006-jw,
  title   = "Phonemic restoration in a sentence context: Evidence from early
             and late {ERP} effects",
  author  = "Sivonen, P{\"a}ivi and Maess, Burkhard and Lattner, Sonja and
             Friederici, Angela D",
  journal = "Brain research",
  volume  =  1121,
  number  =  1,
  pages   = "177--189",
  year    =  2006,
  issn    = "0006-8993",
  doi     = "10.1016/j.brainres.2006.08.123"
}

@ARTICLE{Elman1988-nu,
  title    = "Cognitive penetration of the mechanisms of perception:
              Compensation for coarticulation of lexically restored phonemes",
  author   = "Elman, Jeffrey L and McClelland, James L",
  abstract = "Examined whether putative interlevel phenomena can trigger the
              operation of intralevel language processes at lower levels. The
              intralevel process involved the perceptual compensation for the
              coarticulatory influences of one speech sound on another. The
              TRACE model of speech perception predicts that this compensation
              can be triggered by illusory phonemes that are perceived as a
              result of top-down, lexical influences. In Exp I, the authors
              confirmed this prediction. Exps II-IV replicated this finding and
              failed to support several potential alternative explanations of
              the results of Exp I. The basic finding that intralevel phenomena
              could be triggered by interlevel processes argues against the
              view that aspects of speech perception are encapsulated in a
              module impervious to influences from higher levels. (PsycINFO
              Database Record (c) 2007 APA, all rights reserved)",
  journal  = "Journal of memory and language",
  volume   =  27,
  number   =  2,
  pages    = "143--165",
  year     =  1988,
  keywords = "Articulation (Speech); Contextual Associations; Human Information
              Storage; Models; Speech Perception; TRACE model of speech
              perception, perceptual compe",
  issn     = "0749-596X",
  doi      = "10.1016/0749-596X(88)90071-X"
}

@ARTICLE{Cutler1987-no,
  title    = "Phoneme identification and the lexicon",
  author   = "Cutler, Anne and Mehler, Jacques and Norris, Dennis and Segui,
              Juan",
  abstract = "In seven experiments reaction time to detect the initial phoneme
              of words and nonwords was measured. Reaction time advantages for
              words over nonwords come and go according to the particular
              characteristics of the experimental situation. One relevant
              characteristic is degree of task monotony, an effect which is
              most parsimoniously explained by attention shifting between
              levels of processing. General classes of models of the
              relationship between levels of processing in comprehension are
              discussed in light of the results. Serial models incorporate an
              attention shift explanation of the monotony effect more elegantly
              than do interactive models. Alternative serial models are
              available in the literature in this area. One recent model, which
              allows only a single outlet point for phoneme detection
              responses, and hence requires that apparent reaction time
              advantages for words are artefactual, can be unambiguously
              rejected on the basis of the present data. It is argued that a
              serial model involving competition between target detection based
              on a prelexical representation and detection based on a lexical
              representation most satisfactorily accounts for the overall
              pattern of results.",
  journal  = "Cognitive psychology",
  volume   =  19,
  number   =  2,
  pages    = "141--177",
  year     =  1987,
  issn     = "0010-0285",
  doi      = "10.1016/0010-0285(87)90010-7"
}

@ARTICLE{Ockelford2006-oa,
  title    = "Implication and expectation in music: a zygonic model",
  author   = "Ockelford, Adam",
  abstract = "This article examines implication and expectation in music,
              taking as its starting point music-theoretical and
              music-psychological work ranging from the seminal thinking of
              Meyer (1956, 1967, 1973) to its development in the theories of
              Narmour (1990, 1992) and subsequent empirical and theoretical
              investigation by, for example, Schellenberg (1996, 1997), Von
              Hippel and Huron (2000) and Aarden (2003). Other psychological
              approaches, such as those adopted by Jones (1981, 1982, 1992) and
              Bharucha (1987, 1999), are considered too. The most important
              contemporary reference point, however, is Huron's latest extended
              thinking on expectation (forthcoming), which summarizes,
              consolidates and develops a wide range of theoretical and
              empirical work in the field. These diverse perspectives on
              musical implication and expectation are analysed using the
              `zygonic' theory of musical understanding recently developed by
              Ockelford (for example, 1999, 2002, 2004, 2005a, 2005b). This
              holds that the cognition of structure stems from a sense of
              derivation arising from the presence of repetition in certain
              contexts. Using this framework, a new, composite theory of
              expectation in music is developed, which acknowledges the
              potential implications of three sources of regularity in music:
              patterns within groups of notes, and between them - as encoded in
              short-term memory and long-term, both veridically and
              schematically. Finally, the phenomenological relevance of the new
              model to `typical' listening experiences is discussed, and the
              need for future empirical work is set out.",
  journal  = "Psychology of Music",
  volume   =  34,
  number   =  1,
  pages    = "81--142",
  year     =  2006,
  issn     = "0305-7356",
  doi      = "10.1177/0305735606059106"
}

@ARTICLE{Groppe2010-ns,
  title    = "Supportive Sentence Context in Speech Perception",
  author   = "Groppe, David M and Choi, Marvin and Huang, Tiffany and Schilz,
              Joseph and Topkins, Ben and Thomas, P and Kutas, Marta",
  journal  = "Brain research",
  volume   =  1361,
  pages    = "54--66",
  year     =  2010,
  keywords = "erp; n400; phonemic restoration effect; speech comprehension",
  issn     = "0006-8993",
  doi      = "10.1016/j.brainres.2010.09.003.The"
}

@ARTICLE{Elfner1966-nf,
  title   = "Continuity effects with alternately sounded noise and tone signals",
  author  = "Elfner, Lloyd F and Marsella, A J",
  journal = "Medical research engineering",
  volume  =  5,
  pages   = "22--23",
  year    =  1966,
  issn    = "0025-7508"
}

@ARTICLE{Elfner1965-pl,
  title   = "Continuity effects with alternately sounded noise and tone signals
             as a function of manner of presentation",
  author  = "Elfner, Lloyd F and Caskey, W E",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  38,
  pages   = "543--547",
  year    =  1965,
  issn    = "0001-4966"
}

@ARTICLE{Elfner1971-ww,
  title   = "Continuity in alternately sounded tonal signals in a free field",
  author  = "Elfner, Lloyd F",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  49,
  pages   = "447--449",
  year    =  1971,
  issn    = "0001-4966"
}

@ARTICLE{Elfner1969-hi,
  title   = "Continuity in alternately sounded tone and noise signals in a free
             field",
  author  = "Elfner, Lloyd F",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  46,
  pages   = "914--917",
  year    =  1969,
  issn    = "0001-4966"
}

@ARTICLE{Warren1972-cu,
  title   = "Auditory induction: Illusory continuity of the fainter of two
             alternating sounds",
  author  = "Warren, Richard M and Obusek, Charles J",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  51,
  number  =  114,
  year    =  1972,
  issn    = "0001-4966"
}

@BOOK{Narmour1990-gv,
  title     = "The analysis and cognition of basic melodic structures: The
               implication-realization model",
  author    = "Narmour, E",
  publisher = "University of Chicago Press",
  year      =  1990,
  address   = "Chicago, IL"
}

@BOOK{Huron2006-rh,
  title     = "Sweet anticipation: Music and the psychology of expectation",
  author    = "Huron, David",
  publisher = "MIT Press",
  year      =  2006,
  address   = "Cambridge, MA"
}

@ARTICLE{Jones2006-wy,
  title   = "Effects of auditory pattern structure on anticipatory and reactive
             attending",
  author  = "Jones, Mari Riess and Johnston, Heather Moynihan and Puente,
             Jennifer",
  journal = "Cognitive psychology",
  volume  =  53,
  pages   = "59--96",
  year    =  2006,
  issn    = "0010-0285",
  doi     = "10.1016/j.cogpsych.2006.01.003"
}

@ARTICLE{Creelman1960-qd,
  title   = "Detection of signals of uncertain frequency",
  author  = "Creelman, C Douglas",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  32,
  number  =  7,
  pages   = "805--810",
  year    =  1960,
  issn    = "0001-4966"
}

@ARTICLE{Swets1959-kx,
  title   = "Multiple observations of signals in noise",
  author  = "Swets, John A and Shipley, Elizabeth F and McKey, Molly J and
             Green, David M",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  31,
  number  =  4,
  pages   = "514--521",
  year    =  1959,
  issn    = "0001-4966"
}

@ARTICLE{Veniar1958-vk,
  title    = "Signal detection as a function of frequency ensemble. {I}",
  author   = "Veniar, Florence A",
  abstract = "This paper presents the results of an experimental investigation
              of the detection of a signal in noise as a function of signal
              ensemble size and ensemble frequency range. By signal ensemble
              size we mean the number of signals of different frequency that
              are equally likely to occur and which the observer must try to
              detect. By ensemble frequency range we mean the frequency
              separation between the lowest and the highest frequency signals
              included in that ensemble. Data are presented for the four
              observers who took part in the experiment. The results obtained
              are compared with predictions based upon three mathematical
              models. Using efficiency measures, the results obtained are also
              compared with performance expected of a mathematically optimum
              detector. Finally, the possibility is suggested that the models
              discussed are not necessarily mutually exclusive, but rather
              complementary in the over-all view of detection.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  30,
  number   =  11,
  pages    = "1020--1024",
  year     =  1958,
  issn     = "0001-4966"
}

@ARTICLE{Veniar1958-vz,
  title   = "Signal detection as a function of frequency ensemble. {II}",
  author  = "Veniar, Florence A",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  30,
  number  =  12,
  pages   = "1075--1078",
  year    =  1958,
  issn    = "0001-4966"
}

@ARTICLE{Swets1961-uc,
  title    = "Stimulus vs response uncertainty in recognition",
  author   = "Swets, J A and Sewall, S T",
  abstract = "We raise again, in the framework of a very simple recognition
              task, the question of the relative efficacy of specifying the
              stimuuls alternatives before and after the stimulus is presented.
              Our experiments show information given before the observation to
              facilitate recognition and information given after the
              observation to have little, if any, effect. We conclude that the
              facilitative effect of restricting alternatives, in the task
              studied, depends on a perceptual mechanism rather than on a
              response mechanism. These experiments are discused in connection
              with two current psychological theories: the theory of signal
              detectability, which is essentially a perceptual theory, and the
              theory of individual choice behavior, which is essentially a
              response theory. The results of another experiment, the only
              other experiment dicovered to date for which these two theories
              make different predictions, are also reported. In this
              experiment, too, the results are in agreement with the detection
              theory.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  33,
  number   =  11,
  pages    = "1586--1592",
  year     =  1961,
  issn     = "0001-4966",
  doi      = "10.1121/1.1908507"
}

@ARTICLE{Margulis2006-cu,
  title    = "Timbre priming effects and expectation in melody",
  author   = "Margulis, Elizabeth Hellmuth and Levine, William H",
  abstract = "Abstract In this study, participants identified the timbre of
              pitches when they occurred in isolation, and again when they
              occurred appended to short melodies. For pitches congruent with
              the melody, timbre identification generally improved when the
              pitches were appended to the melody in comparison to when they
              occurred in isolation. In addition, the amount of improvement was
              broadly consistent with theoretical accounts of the degree to
              which the pitches were expected, given the preceding melody. This
              finding relates both to proposed interactions in processing
              between pitch and timbre, and to theoretical work regarding
              melodic expectations. It suggests that melodic expectations can
              be revealed implicitly, and is consistent with the idea that they
              operate at a relatively early stage of perceptual processing. In
              this study, priming effects were shown in listeners without
              musical training, demonstrating that expectations can develop in
              response to passive exposure to music, not only in response to
              formal training. In this study, participants identified the
              timbre of pitches when they occurred in isolation, and again when
              they occurred appended to short melodies. For pitches congruent
              with the melody, timbre identification generally improved when
              the pitches were appended to the melody in comparison to when
              they occurred in isolation. In addition, the amount of
              improvement was broadly consistent with theoretical accounts of
              the degree to which the pitches were expected, given the
              preceding melody. This finding relates both to proposed
              interactions in processing between pitch and timbre, and to
              theoretical work regarding melodic expectations. It suggests that
              melodic expectations can be revealed implicitly, and is
              consistent with the idea that they operate at a relatively early
              stage of perceptual processing. In this study, priming effects
              were shown in listeners without musical training, demonstrating
              that expectations can develop in response to passive exposure to
              music, not only in response to formal training.",
  journal  = "Journal of New Music Research",
  volume   =  35,
  number   =  2,
  pages    = "175--182",
  year     =  2006,
  issn     = "0929-8215",
  doi      = "10.1080/09298210600835042"
}

@ARTICLE{Harris1952-it,
  title    = "The decline of pitch discrimination with time",
  author   = "Harris, J Donald",
  abstract = "A comparison of pitch discrimination using a fixed standard
              stimulus and a roving standard stimulus while varying the
              inter-stimulus interval. Results indicated an appreciably greater
              decline in discrimination with the roving standard as the
              inter-stimulus interval was increased above 3 sec. (PsycINFO
              Database Record (c) 2012 APA, all rights reserved)",
  journal  = "Journal of experimental psychology",
  volume   =  43,
  number   =  2,
  pages    = "96--99",
  year     =  1952,
  issn     = "0022-1015"
}

@ARTICLE{Schmuckler1997-wn,
  title   = "Expectancy effects in memory for melodies",
  author  = "Schmuckler, Mark A",
  journal = "Canadian journal of experimental psychology = Revue canadienne de
             psychologie experimentale",
  volume  =  51,
  number  =  4,
  pages   = "292--306",
  year    =  1997,
  issn    = "1196-1961"
}

@ARTICLE{Repp1992-fh,
  title    = "Perceptual restoration of a ``missing'' speech sound: Auditory
              induction or illusion?",
  author   = "Repp, B H",
  abstract = "This study investigated whether the apparent completeness of the
              acoustic speech signal during phonemic restoration derives from a
              process of auditory induction (Warren, 1984) or segregation, or
              whether it is an auditory illusion that accompanies the
              completion of an abstract phonological representation.
              Specifically, five experiments tested the prediction of the
              auditory induction (segregation) hypothesis that active
              perceptual restoration of an [s] noise that has been replaced
              with an extraneous noise would use up a portion of that noise's
              high-frequency energy and consequently change the perceived pitch
              (timbre, brightness) of the extraneous noise. Listeners were
              required to compare the pitch of a target noise, which replaced a
              fricative noise in a sentence, with that of a probe noise
              preceding or following the speech. In the first two experiments,
              a significant tendency was found in favor of the auditory
              induction hypothesis, although the effect was small and may have
              been caused by variations in acoustic context. In the following
              three experiments, a larger variety of stimuli were used and
              context was controlled more carefully; this yielded negative
              results. Phoneme identification responses collected in the same
              experiments, as well as informal observations about the quality
              of the restored phoneme, suggested that restoration of a
              fricative phone distinct from the extraneous noise did not occur;
              rather, the spectrum of the extraneous noise itself influenced
              phoneme identification. These results suggest that the apparent
              auditory restoration which accompanies phonemic restoration is
              illusory, and that the schema-guided process of phoneme
              restoration does not interact with auditory processing.",
  journal  = "Perception \& psychophysics",
  volume   =  51,
  pages    = "14--32",
  year     =  1992,
  issn     = "0031-5117",
  pmid     = "1549420",
  doi      = "10.3758/BF03205070"
}

@ARTICLE{Plack2000-ja,
  title    = "Perceived continuity and pitch perception",
  author   = "Plack, C J and White, L J",
  abstract = "Three experiments investigated the importance of perceived
              stimulus continuity For the perception of the fundamental
              frequency (F0) of an unresolved complex tone. The F0 of the
              complex was 250 Hz and the harmonics were bandpass filtered
              between 5500 and 7500 Hz. In the first experiment, F0
              discrimination was measured for single-burst tones with durations
              of 20, 40, and 80 ms, and for stimuli containing two 20- or 40-ms
              tone bursts separated by an 8- or 16-ms gap. For the single-burst
              conditions, there was a large decrease in threshold as the
              duration was increased from 20 to 40 ms. However, performance in
              the gapped conditions was much worse than that for the
              single-burst condition with the same cumulative duration (e.g.,
              two 20-ms bursts separated by 8 ms produced higher thresholds
              than one 40-ms burst). Adding a bandpass noise (with the same
              spectral envelope as the tone) in the gap between the two tone
              bursts improved performance to the level of the single-burst
              condition. When the noise was added, the two discrete tone bursts
              were perceived as one single tone burst interrupted by the noise,
              and this seemed to facilitate discrimination. Tn a second
              experiment, the effects on pitch of an envelope delay (phase
              shift) of 0.75 periods between two tone bursts separated by an
              8-ms gap were investigated. If the gap was silent, the pitch of
              the pair was unaffected by the phase shift. However, if the gap
              contained the bandpass noise, the phase shift between the bursts
              did produce a significant downward shift in the pitch of the
              pair. Finally, the third experiment showed that presenting a
              noise before a single 20-ms burst may improve discrimination
              performance in some listeners, but not sufficiently to account
              for the results of the first experiment purely in terms of an
              improvement in the discriminability of the second tone burst in
              the pair. The experiments suggest that a level decrease between
              two tone bursts may disrupt or reset a long integration
              mechanism, decreasing performance. When there is no level
              decrease between the bursts, the auditory system may assume that
              the two bursts belong to the same single tone and analyze them
              together in order to derive F0. (C) 2000 Acoustical Society of
              America. [S0001-4966(00)00209-5].",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  108,
  number   =  3,
  pages    = "1162--1169",
  year     =  2000,
  issn     = "0001-4966",
  pmid     = "11008817",
  doi      = "10.1121/1.1287022"
}

@ARTICLE{Lyzenga2005-ze,
  title    = "Dynamic aspects of the continuity illusion: perception of level
              and of the depth, rate, and phase of modulation",
  author   = "Lyzenga, J and Carlyon, R P and Moore, B C J",
  abstract = "The perception of modulation of a tone interrupted by a noise
              burst was investigated. The tone and its modulation were
              perceived as continuing through the noise. In experiment 1,
              subjects rated the similarity of an uninterrupted tone and a tone
              interrupted by noise, in terms of the perceived level and
              modulation depth of the sinusoidal carrier. The values of these
              parameters in the central portion of the uninterrupted tone were
              systematically varied. Both amplitude and frequency modulation
              (AM and FM) were used. The results indicated that the perceived
              level and modulation depth of the carrier did not change greatly
              during the noise burst. When the modulation rate differed before
              and after the noise burst, the modulation-rate transition was
              perceived to occur near the end of the noise burst for the FM
              stimuli. Hence, for these stimuli, the continuity illusion
              appears to be dominated by the portion of the tone before, rather
              than after, the interruption. Results for the AM stimuli showed a
              non-significant trend in the same direction. Experiment 2 used
              forced-choice tasks to evaluate the ability to detect a change in
              the ongoing phase of AM and FM following interruption by a noise
              burst. The results confirmed earlier findings for FM tones, and
              extended them to AM tones, showing that listeners lost track of
              the phase of the modulation, even though the modulation was
              perceived as continuous.",
  journal  = "Hearing research",
  volume   =  210,
  number   = "1-2",
  pages    = "30--41",
  year     =  2005,
  keywords = "Acoustic Stimulation; Auditory Perception; Auditory Perception:
              physiology; Humans; Loudness Perception; Loudness Perception:
              physiology; Perceptual Masking; Perceptual Masking: physiology",
  issn     = "0378-5955",
  pmid     = "16125887",
  doi      = "10.1016/j.heares.2005.07.002"
}

@ARTICLE{Bregman1999-df,
  title    = "Is a common grouping mechanism involved in the phenomena of
              illusory continuity and stream segregation?",
  author   = "Bregman, A S and Colantonio, C and Ahad, P A",
  abstract = "Two auditory phenomena--stream segregation and illusory
              continuity through a wide-band noise interruption--were studied
              to determine whether the same principles of perceptual
              organization applied to both. A cycle was formed of a repeating
              alternation of two short bursts of narrow-band noise (NBN), one
              centered at a high frequency (H) and the other at a low frequency
              (L), with shorter bursts of wide-band noise (WBN) inserted
              between successive NBNs (H WBN L WBN H WBN...). In some
              conditions, listeners could hear a single NBN moving up and down
              behind the WBN bursts, although there was no NBN present with the
              WBN. Listeners rated the strength of this illusory continuity.
              Center frequency separation, rate of onsets, and bandwidth of the
              NBNs were varied. Increases in values of all three variables
              decreased illusory continuity. Other listeners rated the stream
              segregation of the H and L bands when successive NBNs were
              separated either by WBN bursts (as above) or by silences. The
              same three acoustic variables were manipulated. Increases in all
              three variables decreased the perception of a single stream. The
              similar disruptive effects on illusory continuity and on the
              one-stream percept in the stream segregation task support the
              idea that both phenomena depend on a common preliminary process
              of linking together the parts of a sequence that have similar
              frequencies.",
  journal  = "Perception \& psychophysics",
  volume   =  61,
  number   =  2,
  pages    = "195--205",
  year     =  1999,
  issn     = "0031-5117",
  pmid     = "10089755",
  doi      = "10.3758/BF03206882"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Aronoff2006-tg,
  title    = "Investigating auditory induction without complete continuity",
  author   = "Aronoff, Justin",
  abstract = "Auditory induction, the process of restoring missing auditory
              information, plays a crucial role in perception. A number of
              researchers have examined the characteristics of this phenomenon
              when there is a signal anchoring both sides of the induced sound
              (i.e., complete anchoring). However, the characteristics of
              partially anchored induced sounds (i.e., anchoring on only one
              side of the induced sound) are largely unknown, although prior
              research suggests that such partially anchored induction can
              occur [Wrightson and Warren, J. Acoust. Soc. Am. 69, S105--S106
              (1981)]. To examine the characteristics of this latter type of
              induced sound, synthetic stop‐initial syllables were used in a
              forced‐choice task, allowing easy assessment of the type and
              amount of induced information. The first 25 ms of each transition
              was removed, and noise (used to elicit the induced sound) was
              added to the truncated transition in small segments, replacing
              the removed transition. Accuracy increased with increasing
              amounts of noise, indicating that induction was occurring with
              partial anchoring. However, this induction was strongly limited,
              extending only 15 ms into the noise. This suggests that complete
              anchoring plays an important role in extending the induced sound,
              although it is not necessary for its creation.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  119,
  number   =  3333,
  year     =  2006,
  issn     = "0001-4966"
}

@ARTICLE{Bashford1992-gf,
  title    = "Increasing the intelligibility of speech through multiple
              phonemic restorations",
  author   = "Bashford, J A and Riener, K R and Warren, Richard M",
  abstract = "Outside of the laboratory, listening conditions are often less
              than ideal, and when attending to sounds from a particular
              source, portions are often obliterated by extraneous noises.
              However, listeners possess rather elegant reconstructive
              mechanisms. Restoration can be complete, so that missing segments
              are indistinguishable from those actually present and the
              listener is unaware that the signal is fragmented. This
              phenomenon, called temporal induction (TI), has been studied
              extensively with nonverbal signals and to a lesser extent with
              speech. Earlier studies have demonstrated that TI can produce
              illusory continuity spanning gaps of a few hundred milliseconds
              when portions of a signal are replaced by a louder sound capable
              of masking the signal were it actually present. The present study
              employed various types of speech signals with periodic gaps and
              measured the effects upon intelligibility produced by filling
              these gaps with noises. Enhancement of intelligibility through
              multiple phonemic restoration occurred when the acoustic
              requirements for TI were met and when sufficient contextual
              information was available in the remaining speech fragments. It
              appears that phonemic restoration is a specialized form of TI
              that uses linguistic skills for the reconstruction of obliterated
              speech.",
  journal  = "Perception \& psychophysics",
  volume   =  51,
  number   =  3,
  pages    = "211--217",
  year     =  1992,
  keywords = "INHIBITION; NOISE; PERCEPTUAL RESTORATION; SOUNDS",
  issn     = "0031-5117",
  pmid     = "1561046",
  doi      = "10.3758/BF03212247"
}

@ARTICLE{Ciocca1987-ks,
  title    = "Perceived continuity of gliding and steady-state tones through
              interrupting noise",
  author   = "Ciocca, V and Bregman, A S",
  abstract = "Studied perceived continuity in 4 experiments using 55
              undergraduates by varying the direction (steady-state, upward
              glide, or downward glide); the frequency separation; and the
              slope of 2 sinusoidal tones separated by a louder burst of white
              noise. When the 2 tones had different directions, continuity was
              perceived according to a frequency-proximity principle
              (frequency-interpolation effect). When the tones had the same
              direction, continuity was perceived on the basis of a
              good-continuation principle (frequency-extrapolation, or
              frequency-trajectory, effect). There was some tuning for the
              starting frequency of the postnoise glide. Results suggest that
              auditory processes need to analyze the postnoise sound before
              deciding whether the prenoise tone continued underneath the noise
              burst. (PsycINFO Database Record (c) 2004 APA, all rights
              reserved)",
  journal  = "Perception \& psychophysics",
  volume   =  42,
  number   =  5,
  pages    = "476--484",
  year     =  1987,
  issn     = "0031-5117",
  pmid     = "3696942",
  doi      = "10.3758/BF03209755"
}

@ARTICLE{Shahin2009-hy,
  title    = "Neural mechanisms for filling in of degraded speech",
  author   = "Shahin, A J and Bishop, C W and Miller, L M",
  journal  = "NeuroImage",
  volume   =  44,
  number   =  3,
  pages    = "1133--1143",
  year     =  2009,
  keywords = "auditory induction; continuity illusion; fmri; perceptual
              filling-in; phonemic restoration; speech",
  issn     = "1053-8119",
  doi      = "10.1016/j.neuroimage.2008.09.045.Neural"
}

@ARTICLE{Watson1975-pi,
  title   = "Factors in the discrimination of tonal patterns. I. Component
             frequency, temporal position, and silent intervals",
  author  = "Watson, Charles S and Wroton, Henry W and Kelly, W J and
             Benbassat, C A",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  57,
  number  =  5,
  pages   = "1175--1185",
  year    =  1975,
  issn    = "0001-4966",
  pmid    = "1127172",
  doi     = "10.1121/1.380576"
}

@ARTICLE{Watson1976-yp,
  title   = "Factors in the discrimination of tonal patterns. {II}. Selective
             attention and learning under various levels of stimulus
             uncertainty",
  author  = "Watson, Charles S and Kelly, William J and Wroton, Henry W",
  journal = "The Journal of Technology, Learning and Assessment",
  volume  =  60,
  number  =  5,
  pages   = "1176--1186",
  year    =  1976
}

@ARTICLE{Houtgast1972-qw,
  title    = "Psychophysical evidence for lateral inhibition in hearing",
  author   = "Houtgast, T",
  abstract = "Although there are some clear demonstration or it has escaped
              indications in this paper that the threshold repeated masker of
              the possible of it in psychophysical psychophysical verification.
              role of lateral inhibition experiments. Accepting
              lateral-inhibition effects since the inhibition affects both the
              test tone and the masker. Two different methods, in which the
              test tone and the masker lateral inhibition in hearing. Firstly,
              the threshold between shows marked edge effects. bursts (noise
              Secondly, indicate that the nervous of two tones ponent. The
              effect at the edges the interaction the results is suggestive of
              a test tone presented were presented with a steep curve of short
              test4one bursts presented negative succsesively, or positive
              activity due to one frequency of the frequency of the two-tone of
              psychophysical component spectrum inhibition measurements are
              comparable may be suppressed found in auditory-nerve give clear
              psychophysical gradient at a particular on two-tone of in
              hearing, Either the phenomenon for a moment the second
              simultaneously with a masker plays only a minor role,
              possibility, does there has been no it is argued not reflect
              clear evidence in the gaps frequency) suppression by another com-
              with visual Mach bands, and fibers",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  51,
  number   =  6,
  pages    = "1885--1894",
  year     =  1972,
  issn     = "0001-4966",
  pmid     = "4339849",
  doi      = "10.1121/1.1913048"
}

@ARTICLE{Warren1988-wf,
  title    = "Illusory continuity of tonal and infratonal periodic sounds",
  author   = "Warren, Richard M and Wrightson, J M and Puretz, J",
  abstract = "Temporal induction can restore masked or obliterated portions of
              signals so that tones may seem continuous when alternated with
              sounds having appropriate spectral composition and intensity. The
              upper intensity limits for the induction of tones (pulsation
              thresholds) are related to masking functions and have been used
              to define the characteristics of frequency domain (place)
              analysis of tones. The present study has found that induction
              also occurs for infratonal periodic sounds that require a time
              domain analysis for perception of acoustic repetition. Limits for
              temporal induction were determined for iterated frozen noise
              segments from 10-2000 Hz alternated with a louder on-line noise.
              Masked thresholds were also obtained for the pulsed signals
              presented along with continuous noise, and it was found that the
              relation between induction limits and masking changed with
              frequency. The results obtained for induction and masking are
              discussed in terms of general principles governing restoration of
              obliterated sounds.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  84,
  number   =  4,
  pages    = "1338--1342",
  year     =  1988,
  keywords = "Attention; Humans; Illusions; Loudness Perception; Perceptual
              Masking; Pitch Discrimination; Psychoacoustics; Time Perception",
  issn     = "0001-4966",
  pmid     = "3198869",
  doi      = "10.1121/1.396632"
}

@INCOLLECTION{Nusbaum1982-yy,
  title     = "Controlled perceptual strategies in phonemic restoration",
  booktitle = "Research on Speech Perception Progress Report 8",
  author    = "Nusbaum, H C and Walley, A C and Carrel, T D and Ressler,
               William H",
  publisher = "Department of Psychology, Indiana University",
  pages     = "83--103",
  year      =  1982,
  address   = "Bloomington, IN"
}

@ARTICLE{Samuel1986-az,
  title    = "Attention within auditory word perception: Insights from the
              phonemic restoration illusion",
  author   = "Samuel, Arthur G and Ressler, William H",
  abstract = "Conducted 2 experiments to determine the extent to which
              attention plays a role in the phonemic restoration illusion and
              to infer from this the nature of attention in auditory word
              perception. Exp I examined the effect of training on the
              magnitude of the phonemic restoration illusion. 24 Ss received
              training with the potentially restorable stimuli (972 trials with
              feedback); in addition, the presence or absence of an attentional
              cue, contained in a visual prime preceeding each trial, was
              varied between groups of Ss. Findings reveal that cuing the
              identity and location of the critical phoneme of each test word
              allowed Ss to attend to the critical phoneme, thereby inhibiting
              the illusion, but only when the prime also identified the test
              word itself. Exp II was a 2-part replication of Exp I, using 92
              Ss and some modifications of the conditions. Results show that
              when the prime provided only the identity or location of the
              critical phoneme, or only the identity of the word, Ss performed
              identically to those Ss for whom the prime contained no
              information at all about the test word. Training did not produce
              any generalized learning about the types of stimuli used. Results
              indicate that attention is necessary to perceive phonemic units
              selectively and is focused through the level that has primacy in
              the perception of spoken words, the mental lexicon.",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  12,
  number   =  1,
  pages    = "70--79",
  year     =  1986,
  issn     = "0096-1523"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Sasaki2006-kn,
  title    = "Music sound restoration and the effect of presentation conditions",
  author   = "Sasaki, Takayuki",
  abstract = "When a music sound in a melody was deleted and replaced by a
              noise, a missing sound can be restored perceptually. This
              illusory phenomenon in audition, named music sound restoration,
              can be proved indirectly by inaccurate judgment of temporal
              position of the inserted noise. In the present study, music sound
              restoration was investigated in terms of the temporal position of
              replaced noise, headphone listening or free field listening, and
              the listeners' knowledge of the phenomenon. The results showed
              that the accuracy of the noise location differed between the
              positions of replaced noise in the melody or within a beat. The
              perceptual restoration occurred not only in a headphone listening
              but also in a free‐field listening. It was revealed that the
              accuracy of noise localization elevated when the listeners knew
              the stimulus construction, but it was still lower than that of a
              blank. It was also confirmed that a missing sound could be
              restored perceptually, not only in a melodic sequence but also in
              a simple sequence such as scale.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  120,
  number   =  5,
  pages    = "3204--3204",
  year     =  2006,
  issn     = "0001-4966"
}

@ARTICLE{Liederman2011-sd,
  title    = "Are women more influenced than men by top-down semantic
              information when listening to disrupted speech?",
  author   = "Liederman, J and Gilbert, K and Fisher, J M and Mathews, G and
              Frye, R E and Joshi, P",
  abstract = "Perception is a product of the interaction between bottom-up
              sensory processing and top-down higher order cognitive activity.
              For example, when the initial phoneme of a word is obliterated
              and replaced with noise, listeners hear it as intact provided
              there is semantic context. We modified this phonemic restoration
              paradigm by masking (not obliterating) the initial phoneme of a
              target word and presenting it within a carrier phrase which was
              informative (I), uninformative (U), or misinformative (M). Bias
              in favor of top-down context was measured as the extent to which
              M trials mislead listeners into reporting a target word other
              than that which was presented (relative to U trials that have
              irrelevant top-down semantic context). Forty-one participants (20
              men) completed 600 test trials (300 delayed report of the phrase,
              300 forced choice). Relative to the U condition, women were more
              affected by both the I and M cues than men, at certain levels of
              audibility during the forced choice condition. Moreover, the
              semantic strength of the I carrier phrases was correlated with
              the rate of correct reports of the target words in women but not
              in men. This suggests that women can be more affected by top-down
              semantic context than men. \copyright{} 2010 The Author(s).",
  journal  = "Language and speech",
  volume   =  54,
  number   =  1,
  pages    = "33--48",
  year     =  2011,
  keywords = "lexical ambiguity phonemic restoration retroactive",
  issn     = "0023-8309",
  doi      = "10.1177/0023830910388000"
}

@ARTICLE{Sasaki2004-lc,
  title    = "Music sound restoration: Effect of temporal position of noise in
              a melody and a beat",
  author   = "Sasaki, Takayuki",
  journal  = "Transactions of the Technical Committee of Psychological and
              Physiological Acoustics (The Acoustical Society of Japan)",
  volume   =  34,
  number   =  10,
  pages    = "663--668",
  year     =  2004,
  keywords = "auditory induction; melody perception; music sound restoration;
              perceptual restoration"
}

@ARTICLE{Verschuure1983-cb,
  title    = "Intelligibility of interrupted meaningful and nonsense speech
              with and without intervening noise",
  author   = "Verschuure, J and Brocaar, M P",
  abstract = "The insertion of noise in the silent intervals of interrupted
              speech has a very striking per- ceptual effect if a certain
              signal-to-noise ratio is used. Conflicting reports have been
              published as to whether the inserted noise improves speech
              intelligibility or not. The major difference be- tween studies
              was the level of redundancy in the speech material. Weshow in the
              present paper that the noise leads to a better intelligibility of
              interrupted speech. The redundancy level deter- mines the
              possible amount of improvement. The consequences of our findings
              are discussed in relation to such phenomena as continuity
              perception and pulsation threshold measurement. A hypothesis is
              formulated for the processing of interrupted stimuli with and
              without intervening noise; for stimuli presented with intervening
              noise, the presence in the auditory system of an automatic
              interpolation mechanism is assumed. The mechanism operates only
              if the noise makes it impossible to perceive the interruption.
              The",
  journal  = "Perception \& psychophysics",
  volume   =  33,
  number   =  3,
  pages    = "232--240",
  year     =  1983,
  issn     = "0031-5117",
  pmid     = "6866682",
  doi      = "10.3758/BF03202859"
}

@ARTICLE{Warren1971-gy,
  title    = "Speech perception and phonemic restorations",
  author   = "Warren, Richard M and Obusek, Charles J",
  abstract = "When a speech sound in a sentence is replaced completely by an
              extraneous sound (such as a cough or tone), the listene restores
              the missing sound on the bases of both prior and subsequent
              context. This illusory effect, called phonemic restoration (PhR),
              causes the physically absent phoneme to seem as real as the
              speech sounds which are present. The extraneous sound seems to
              occur along with other phonemes without interfering with their
              clarity. But if a silent gap (rather than an extraneous sound)
              replaces the same phoneme, the interruption in the sentence is
              more readily localized in its true position and PhRs occours less
              frequently. Quantitative measures were taken both of the
              incidence of PhRs and of the direction and extent of temporal
              mislocalizations of interruptions for several related stimuli
              under a variety of experimental conditions. The results were
              connected with other auditory illusions and temporal confusions
              reported in the literature, and suggestions were made concerning
              mechanisms employed normally for verbal organization.",
  journal  = "Perception \& psychophysics",
  volume   =  9,
  number   =  3,
  pages    = "358--362",
  year     =  1971,
  issn     = "0031-5117",
  doi      = "10.3758/BF03212667"
}

@ARTICLE{Elfner1966-dp,
  title   = "Some factors affecting the perception of continuity in alternately
             sounded tone and noise signals",
  author  = "Elfner, Lloyd F and Homick, J L",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  40,
  pages   = "27--31",
  year    =  1966,
  issn    = "0001-4966"
}

@ARTICLE{Thurlow1959-et,
  title   = "Continuity effects with alternately sounding tones",
  author  = "Thurlow, Willard R and Elfner, Lloyd F",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  31,
  number  =  10,
  pages   = "1337--1339",
  year    =  1959,
  issn    = "0001-4966"
}

@ARTICLE{Warren1974-kn,
  title    = "Phonemic restorations based on subsequent context",
  author   = "Warren, Richard M and Sherman, Gary L",
  abstract = "Earlier experiments have shown that when one or more speech
              sounds in a sentence are replaced by a noise meeting certain
              criteria, the listener mislocalizes the extraneous sound and
              believes he hears the missing phoneme(s) clearly. The present
              study confirms and extends these earlier reports of phonemic
              restorat.ions under a variety of novel conditions. All stimuli
              had some of the context necessary for the appropriate phonemic
              restoration following the missing sound, and all sentences had
              the missing phoneme deliberately mispronounced before electronic
              deletion (so that the neighboring phonemes could not provide
              acoustic cues to aid phonemic restorations). The results are
              interpreted in terms of mechanisms normally aiding veridical
              perception of speech and nonspeech sounds.",
  journal  = "Perception \& psychophysics",
  volume   =  16,
  number   =  1,
  pages    = "150--156",
  year     =  1974,
  issn     = "0031-5117",
  doi      = "10.3758/BF03203268"
}

@ARTICLE{Holloway1970-cr,
  title    = "Passing the strongly voiced components of noisy speech",
  author   = "Holloway, C M",
  abstract = "THE Laemmli-loading buffer paper",
  journal  = "Nature",
  volume   =  226,
  pages    = "178--179",
  year     =  1970,
  issn     = "0028-0836",
  pmid     = "5432063",
  doi      = "10.1038/227680a0"
}

@ARTICLE{Warren1970-dm,
  title   = "Perceptual restoration of missing speech sounds",
  author  = "Warren, Richard M",
  journal = "Science",
  volume  =  167,
  number  =  3917,
  pages   = "392--393",
  year    =  1970,
  issn    = "0036-8075"
}

@ARTICLE{Miller1950-gn,
  title   = "The intelligibility of interrupted speech",
  author  = "Miller, A and Licklider, J C R",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  22,
  number  =  2,
  pages   = "167--173",
  year    =  1950,
  issn    = "0001-4966"
}

@ARTICLE{Hall1996-fp,
  title    = "A computer model of blues music and its evaluation",
  author   = "Hall, M A and Smith, L",
  abstract = "This paper describes a new algorithm that composes blues melodies
              to fit a given chord sequence It comprises an analysis stage
              followed by a synthesis stage The analysis stage produces a
              Markov model composed of zero, first, and secondorder transition
              tables covering both pitches and rhythms In order to capture the
              relationship between harmony and melody, a set of transition
              tables is produced for each chord in the analyzed songs The
              synthesis stage uses the output tables from analysis to generate
              new melodies secondorder tables are used as much as possible,
              with fall back procedures to lowerorder tables Some constraints
              are encoded in the form of rules to control the placement of
              rhythmic patterns within measures, pitch values for long duration
              notes and pitch values for the start of new phrases The model was
              evaluated by a listening experiment results showed that listeners
              were unable to reliably distinguish human from computer composed
              melodies C 1996 Acoustical Society of America",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  100,
  number   = "October 1995",
  pages    = "1163--1167",
  year     =  1996,
  issn     = "0001-4966",
  doi      = "Article"
}

@INPROCEEDINGS{Paiement2005-uv,
  title     = "A probabilistic model for chord progressions",
  booktitle = "Proceedings of the 6th International Conference on Music
               Information Retrieval",
  author    = "Paiement, Jean-Francois and Eck, Douglas and Bengio, Samy",
  abstract  = "Chord progressions are the building blocks from which tonal
               music is constructed. Inferring chord progressions is thus an
               essential step towards modeling long term dependencies in music.
               In this paper, a distributed representation for chords is
               designed such that Euclidean distances roughly correspond to
               psychoacoustic dissimilarities. Estimated probabilities of chord
               substitutions are derived from this representation and are used
               to introduce smoothing in graphical models observing chord
               progressions. Parameters in the graphical models are learnt with
               the EM algorithm and the classical Junction Tree algorithm is
               used for inference. Various model architectures are compared in
               terms of conditional out-of-sample likelihood. Both perceptual
               and statistical evidence show that binary trees related to meter
               are well suited to capture chord dependencies.",
  year      =  2005,
  address   = "London, UK",
  keywords  = "information retrieval \& textual information access"
}

@ARTICLE{Dubnov2003-ow,
  title    = "Using machine-learning methods for musical style modeling",
  author   = "Dubnov, Shlomo and Assayag, Gerard and Lartillot, Olivier and
              Bejerano, Gill",
  abstract = "The ability to construct a musical theory from examples presents
              a great intellectual challenge that, if successfully met, could
              foster a range of new creative applications. Inspired by this
              challenge, we sought to apply machine-learning methods to the
              problem of musical style modeling. Our work so far has produced
              examples of musical generation and applications to a
              computer-aided composition system. Machine learning consists of
              deriving a mathematical model, such as a set of stochastic rules,
              from a set of musical examples. The act of musical composition
              involves a highly structured mental process. Although it is
              complex and difficult to formalize, it is clearly far from being
              a random activity. Our research seeks to capture some of the
              regularity apparent in the composition process by using
              statistical and information theoretic tools to analyze musical
              pieces. The resulting models can be used for inference and
              prediction and, to a certain extent, to generate new works that
              imitate the style of the great masters.",
  journal  = "IEEE Computer",
  volume   =  36,
  number   =  10,
  pages    = "73--80",
  year     =  2003,
  issn     = "0018-9162",
  doi      = "10.1109/MC.2003.1236474"
}

@ARTICLE{Necker1832-sf,
  title   = "Observations on some remarkable optical phaenomena seen in
             Switzerland; and on an optical phaenomenon which occurs on viewing
             a figure of a crystal or geometrical solid",
  author  = "Necker, L A",
  journal = "London and Edinburgh Philosophical Magazine and Journal of Science",
  volume  =  1,
  number  =  5,
  pages   = "329--337",
  year    =  1832
}

@INBOOK{Pascall2015-sb,
  title     = "Style",
  booktitle = "Grove Music Online",
  author    = "Pascall, Robert",
  publisher = "Oxford University Press",
  year      =  2015
}

@BOOK{Cope1996-vw,
  title   = "Experiments in musical intelligence",
  author  = "Cope, David",
  edition = "A-R Editio",
  year    =  1996,
  address = "Madison, WI"
}

@ARTICLE{Desain1998-wj,
  title    = "Computational modeling of music cognition: Problem or solution?",
  author   = "Desain, P and Honing, H and VanThienen, H and Windsor, L",
  abstract = "The central purpose of this paper is to elaborate on the methods
              for\textbackslashncomputational modeling and to show how,
              although computational modeling\textbackslashnshould in principle
              be instrumental in the understanding of the
              structure\textbackslashnof musical knowledge and the processes
              involved in music cognition,\textbackslashnin practice it too
              often degenerates into a loose ``if you want
              to\textbackslashnunderstand the theory, here, look in my
              program'' approach. We will\textbackslashnshow how many issues
              cannot be decided by inspecting computer
              programs\textbackslashnas they are written nowadays, and we will
              indicate a possible solution,\textbackslashngiving examples from
              the field of music cognition research.",
  journal  = "Music perception",
  volume   =  16,
  number   =  1,
  pages    = "151--166",
  year     =  1998,
  issn     = "0730-7829"
}

@ARTICLE{Babyak2004-jr,
  title   = "What you see may not be what you get: A brief, nontechnical
             introduction to overfitting in regression-type models",
  author  = "Babyak, M A",
  journal = "Psychosomatic medicine",
  volume  =  66,
  number  =  3,
  pages   = "411--421",
  year    =  2004,
  issn    = "0033-3174",
  pmid    = "15184705",
  doi     = "10.1097/01.psy.0000127692.23278.a9"
}

@ARTICLE{Dowling1973-zb,
  title   = "The perception of interleaved melodies",
  author  = "Dowling, W Jay",
  journal = "Cognitive psychology",
  volume  =  5,
  pages   = "322--337",
  year    =  1973,
  issn    = "0010-0285"
}

@ARTICLE{Van_Noorden1977-br,
  title   = "Minimum differences of level and frequency for perceptual fission
             of tone sequences {ABAB*}",
  author  = "Van Noorden, Leon P A S",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  61,
  number  =  4,
  pages   = "1041--1045",
  year    =  1977,
  issn    = "0001-4966"
}

@ARTICLE{Rendall1998-sa,
  title    = "The role of vocal tract filtering in identity cueing in rhesus
              monkey (Macaca mulatta) vocalizations",
  author   = "Rendall, D and Owren, M J and Rodman, P S",
  abstract = "The importance of individual identity and kinship has been
              demonstrated in the social behavior of many nonhuman primates,
              with some evidence suggesting that individually distinctive
              acoustic features are present in their vocalizations as well. In
              order to systematically test whether acoustic cues to identity
              are reliably present across the vocal repertoire of rhesus
              monkeys (Macaca mulatta), we examined coos, grunts, and noisy
              screams produced by adult females of two free-ranging groups.
              First, acoustic analyses were used to characterize spectral
              patterning, the fundamental frequency, and temporal
              characteristics of these three distinct call types. Vocalizations
              were then classified by caller identity, based on discriminant
              function analyses. Results showed that coos (rich, harmonically
              structured sounds) were markedly more distinctive by caller than
              were either grunts or noisy screams, and that spectral-patterning
              measures related to vocal tract filtering effects were the most
              reliable markers of individual identity. Grunts (pulsed, noisy
              calls) were classified at lower, but above-chance rates and
              spectral patterning cues were again critical in this sorting.
              Noisy screams (continuous, broadband noise bursts that could
              include a high-frequency, periodic component) could not be
              reliably sorted by caller. Playback experiments conducted with
              the screams showed no response differences when listening animals
              heard vocalizations produced by kin or nonkin individuals. This
              result was strikingly different from the corresponding outcome of
              a previous test with coo calls, but consistent with the acoustic
              analysis. Implications of these findings for vocal production
              mechanisms in nonhuman primates and previous studies of rhesus
              monkey vocalizations are discussed.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  103,
  number   =  1,
  pages    = "602--614",
  year     =  1998,
  issn     = "0001-4966",
  pmid     = "9440345",
  doi      = "10.1121/1.421104"
}

@ARTICLE{Belin2006-qx,
  title    = "Voice processing in human and non-human primates",
  author   = "Belin, P",
  journal  = "Philosophical transactions of the Royal Society of London. Series
              B, Biological sciences",
  volume   =  361,
  number   =  1476,
  pages    = "2091--2107",
  year     =  2006,
  keywords = "auditory cortex; conspecific vocalizations; speaker recognition;
              speech; voice",
  issn     = "0962-8436",
  doi      = "10.1098/rstb.2006.1933"
}

@ARTICLE{Izumi2002-su,
  title    = "Auditory stream segregation in Japanese monkeys",
  author   = "Izumi, A",
  abstract = "Japanese monkeys were examined to determine whether they
              perceptually segregate tone sequences. Monkeys were required to
              discriminate two sequences of tones (target sequences) differing
              in frequency contours. Distractor sequences were presented
              simultaneously with the target sequences. Monkeys could
              discriminate the sequences when the frequency ranges of the
              target and distractor sequences did not overlap, but they could
              not when the ranges overlapped. Subsequent probe tests confirmed
              that the discrimination depended on cues other than the local
              pitch of the component tones regardless of the presence of the
              distractor sequence. The results suggest that monkeys segregate
              tone sequences based on frequency proximity, and they perceive
              global characters of the segregated streams. (C) 2002 Elsevier
              Science B.V. All rights reserved.",
  journal  = "Cognition",
  volume   =  82,
  number   =  3,
  pages    = "B113--B122",
  year     =  2002,
  keywords = "auditory stream; discrimination; japanese monkey",
  issn     = "0010-0277",
  pmid     = "11747868",
  doi      = "10.1016/S0010-0277(01)00161-5"
}

@ARTICLE{McAdams1997-nu,
  title    = "Organization and discrimination of repeating sound sequences by
              newborn infants",
  author   = "McAdams, S and Bertoncini, J",
  abstract = "A study was conducted to determine whether newborn infants
              organize auditory streams in a manner similar to that of adults.
              A series of three experiments investigated the ability of 3- to
              4-day-old infants to discriminate repeated rising and falling
              four-tone sequences in two configurations of source timbre and
              spatial position. It was hypothesized that if the sequences were
              organized into two auditory streams on the basis of timbre and
              spatial position, one of the configurations should be
              discriminable from its reversal while the other should not. The
              sequences were tested with different pitch and temporal intervals
              separating the tones. Sequences were discriminated for the first
              configuration by adults at both fast tempo/small interval and
              slow tempo/large interval combinations, while only the latter was
              discriminated by newborns as measured with a non-nutritive
              high-amplitude sucking paradigm. Neither adults nor infants could
              discriminate the sequence reversals for the second configuration.
              The results suggest that newborn infants organize auditory
              streams on the basis of source timbre and/or spatial position.
              They also suggest that newborns have limits in temporal and/or
              pitch resolution when discriminating tone sequences.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  102,
  number   =  5,
  pages    = "2945--2953",
  year     =  1997,
  keywords = "Auditory Perception; Auditory Perception: physiology; Humans;
              Infant; Newborn; Newborn: physiology; Sucking Behavior",
  issn     = "0001-4966",
  pmid     = "9373981",
  doi      = "10.1121/1.420349"
}

@ARTICLE{Fay1998-gb,
  title    = "Auditory stream segregation in goldfish (Carassius auratus)",
  author   = "Fay, Richard R",
  abstract = "Goldfish were classically conditioned to a mixture of two pulse
              trains differing in both repetition rate and the spectral profile
              of the pulses. Animals were then tested for generalization to
              single pulse trains having one or the other spectral profile
              presented at a variety of repetition rates. Generalization
              functions of repetition rate were qualitatively similar to those
              obtained following conditioning to either of the pulse trains
              alone. Thus, the spectral profile of each pulse type was
              appropriately associated with the repetition rate at which that
              pulse type was presented during conditioning. These results
              indicate that the two concurrent pulse trains making up the
              conditioning stimuli were analyzed independently, forming two
              auditory streams. When either of the two pulse trains were
              presented with a 500 ms onset asynchrony, stream segregation was
              enhanced. These and other results suggest that many fundamental
              features of the human sense of hearing are widely shared among
              vertebrate animals, and may have developed first among fishes.",
  journal  = "Hearing research",
  volume   =  120,
  number   = "1-2",
  pages    = "69--76",
  year     =  1998,
  keywords = "Auditory scene analysis; Auditory stream segregation; Fish;
              Hearing",
  issn     = "0378-5955",
  doi      = "10.1016/S0378-5955(98)00058-6"
}

@ARTICLE{MacDougall-Shackleton1998-ei,
  title    = "Auditory scene analysis by European starlings (Sturnus vulgaris):
              Perceptual segregation of tone sequences",
  author   = "MacDougall-Shackleton, S A and Hulse, S H and Gentner, T Q and
              White, W",
  abstract = "Like humans, animals that use acoustic stimuli to perceive their
              world ought to be able to parse the auditory scene into
              functionally significant sounds. The ability to do so ought to
              have significant adaptive value when, for example, an animal can
              identify the sounds of a predator among other natural noises. In
              earlier work it was shown that a species of songbird, the
              European starling, can identify excerpts of both its own song and
              songs from other avian species when the songs are mixed
              concurrently with other natural signals. In this experiment it is
              demonstrated that starlings can segregate two synthetic pure-tone
              sequences when the sequences differ in frequency. Taken together,
              the experiments show that at least one nonhuman species is
              capable of auditory scene analysis both for natural and for
              non-natural acoustic stimuli. This suggests in turn that auditory
              scene analysis may be a general perceptual process that occurs in
              many species that make use of acoustic information. (C) 1998
              Acoustical Society of America.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  103,
  number   =  6,
  pages    = "3581--3587",
  year     =  1998,
  keywords = "acoustic-signals; attention; chorus; masking; noise; pitch;
              release; stream segregation",
  issn     = "0001-4966"
}

@ARTICLE{Demany1982-hf,
  title    = "Auditory stream segregation in infancy",
  author   = "Demany, Laurent",
  abstract = "Infants were able to detect a change in the order of the
              component tones of certain repetitive melodic sequences. - S.
              Thomas.",
  journal  = "Infant behavior \& development",
  volume   =  5,
  number   = "2-4",
  pages    = "261--276",
  year     =  1982,
  issn     = "0163-6383",
  doi      = "10.1016/S0163-6383(82)80036-2"
}

@ARTICLE{Wertheimer1923-ij,
  title   = "Untersuchung zur Lehre von der Gestalt {II}",
  author  = "Wertheimer, M",
  journal = "Psychologische Forschung",
  volume  =  4,
  pages   = "301--350",
  year    =  1923,
  issn    = "0033-3026"
}

@ARTICLE{Miller1950-ht,
  title   = "The trill threshold",
  author  = "Miller, George A and Heise, George A",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  22,
  number  =  5,
  pages   = "637--638",
  year    =  1950,
  issn    = "0001-4966"
}

@ARTICLE{Aubin2002-dj,
  title    = "Localisation of an acoustic signal in a noisy environment: the
              display call of the king penguin Aptenodytes patagonicus",
  author   = "Aubin, Thierry and Jouventin, Pierre",
  abstract = "King penguin chicks identify their parents by an acoustic signal,
              the display call. This call consists of a succession of similar
              syllables. Each syllable has two harmonic series, strongly
              modulated in frequency and amplitude, with added beats of varying
              amplitude generated by a two-voice system. Previous work showed
              that only one syllable of the call is needed for the chick to
              identify the calling adult. Both the frequency modulation pattern
              of the syllable and the two-voice system play a role in the call
              identification. The syllabic organisation of the call, the
              harmonic structure and the amplitude modulations of the syllables
              apparently do not contribute to individual recognition. Are these
              acoustic features useless? To answer to this question, playback
              experiments were conducted using three categories of experimental
              signals: (i) signal with only the fundamental frequencies of the
              natural call, (ii) signal with the amplitude of each syllable
              kept at a constant level and (iii) signals with only one
              syllable, repeated or not. The responses of chicks to these
              experimental signals were compared to those obtained with the
              calls of their natural parents. We found that these acoustic
              features, while not directly implicated in the individual
              recognition process, help the chicks to better localise the
              signal of their parents. In addition, the redundant syllabic
              organisation of the call is a means of counteracting the masking
              effect of the background noise of the colony.",
  journal  = "The Journal of experimental biology",
  volume   =  205,
  pages    = "3793--3798",
  year     =  2002,
  keywords = "aptenodytes patagonicus; categories of experimental;
              communication in noise; indivi; individual; king penguin;
              recognition; sound localisation; were conducted using three",
  issn     = "0022-0949",
  pmid     = "12432003"
}

@BOOK{Bregman1990-tx,
  title     = "Auditory scene analysis: The perceptual organization of sound",
  author    = "Bregman, A S",
  publisher = "MIT Press",
  year      =  1990,
  address   = "Cambridge, MA"
}

@ARTICLE{Gaffney2003-am,
  title    = "The visual acuity and refractive state of the American kestrel
              (Falco sparverius)",
  author   = "Gaffney, Matthew F and Hodos, William",
  journal  = "Vision research",
  volume   =  43,
  number   =  19,
  pages    = "2053--2059",
  year     =  2003,
  keywords = "american kestrel; birds; falco sparverius; pattern
              electroretinogram; refractive state; visual acuity",
  issn     = "0042-6989"
}

@ARTICLE{Jones2007-wr,
  title    = "Bat echolocation calls: adaptation and convergent evolution",
  author   = "Jones, G and Holderied, M W",
  journal  = "Proceedings of the Royal Society B: Biological Sciences",
  volume   =  274,
  number   =  1612,
  pages    = "905--912",
  year     =  2007,
  keywords = "adaptation; bats; convergent evolution; echolocation",
  issn     = "0962-8452",
  doi      = "10.1098/rspb.2006.0200"
}

@ARTICLE{Koay1998-qx,
  title    = "Hearing in a megachiropteran fruit bat (Rousettus aegyptiacus)",
  author   = "Koay, G and Heffner, R S and Heffner, H E",
  abstract = "The Egyptian fruit bat (Rousettus aegyptiacus) is one of the few
              megachiropteran bats capable of echolocation. However, it uses
              rudimentary tongue clicks rather than laryngeally produced echo
              calls. We determined the audiogram of 2 bats using a conditioned
              avoidance procedure with fruit puree reward. At an intensity of
              60 dB sound pressure level, the bats' hearing extended from 2.25
              kHz to 64 kHz, with a region of good sensitivity between 8 kHz
              and 45 kHz. A dip in sensitivity at 32 kHz appears to be due to
              pinna directionality. The hearing of Egyptian fruit bats is
              typical for a mammal of that size and is not as limited as
              previously reported. Methodological issues, specifically training
              an animal to listen for low-intensity signals and imposing a
              significant cost for failing to report signals (i.e., misses),
              are discussed as the basis for the discrepancy between our
              results and earlier reports.",
  journal  = "Journal of comparative psychology",
  volume   =  112,
  number   =  4,
  pages    = "371--382",
  year     =  1998,
  issn     = "0093-4127, 0735-7036",
  pmid     = "9861710",
  doi      = "10.1037/0735-7036.112.4.371"
}

@ARTICLE{Ernst2004-zk,
  title   = "Merging the senses into a robust percept",
  author  = "Ernst, Marc O and B{\"u}lthoff, Heinrich H",
  journal = "Trends in cognitive sciences",
  volume  =  8,
  number  =  4,
  pages   = "162--169",
  year    =  2004,
  issn    = "1364-6613",
  doi     = "10.1016/j.tics.2004.02.002"
}

@ARTICLE{Bode1984-yd,
  title    = "History of electronic sound modification",
  author   = "Bode, Harald",
  abstract = "The history of electronic sound modification is as old as the
              history of electronic musical instruments and electronic sound
              transmission, recording, and reproduction. Means for modifying
              electrically generated sound have been known since the late 19th
              century, when Thaddeus Cahill created his Telharmonium. With the
              advent of the electronic age, spurred first by the invention of
              the electron tube, and the more recent development of solid-state
              devices, an astounding variety of sound modifiers have been
              created for filtering, distorting, equalizing, amplitude and
              frequency modulating, Doppler effect and ringmodulating,
              compressing, reverberating, repeating, flanging, phasing, pitch
              changing, chorusing, frequency shifting, analyzing, and
              resynthesizing natural and artificial sound. In this paper some
              highlights of historical development are reviewed, covering the
              time from1896 to the present.",
  journal  = "Journal of the Audio Engineering Society. Audio Engineering
              Society",
  volume   =  32,
  number   =  10,
  pages    = "730--739",
  year     =  1984,
  issn     = "0004-7554"
}

@ARTICLE{Henricksen1981-nw,
  title   = "Unearthing the Mysteries of the Leslie Cabinet",
  author  = "Henricksen, Clifford A",
  journal = "Recording Engineer/Producer magazine",
  year    =  1981
}

@ARTICLE{Ramirez2010-xp,
  title     = "Automatic performer identification in commercial monophonic Jazz
               performances",
  author    = "Ramirez, Rafael and Maestre, Esteban and Serra, Xavier",
  abstract  = "We present a pattern recognition approach to the task of
               identifying performers from their interpretative styles. We
               investigate how professional musicians express their view of the
               musical content of musical pieces and how to use this
               information in order to automatically identify performers. We
               apply sound analysis techniques based on spectral models for
               extracting deviation patterns of parameters such as pitch,
               timing, amplitude and timbre characterising both the internal
               structure of notes and the musical context in which they appear.
               We describe successful performer identification case studies
               involving monophonic audio recordings of both score-guided and
               commercial improvised performances.",
  journal   = "Pattern recognition letters",
  publisher = "Elsevier B.V.",
  volume    =  31,
  number    =  12,
  pages     = "1514--1523",
  year      =  2010,
  keywords  = "expressive performance; information retrieval",
  issn      = "0167-8655",
  doi       = "10.1016/j.patrec.2009.12.032"
}

@INPROCEEDINGS{Chudy2010-zk,
  title     = "Towards Music Performer Recognition Using Timbre Features",
  booktitle = "Proceedings of the 3rd International Conference of Students of
               Systematic Musicology",
  author    = "Chudy, Magdalena and Dixon, Simon",
  pages     = "45--50",
  year      =  2010,
  address   = "Cambridge, UK",
  keywords  = "performer discrimination; timbre descriptors; timbre
               dissimilarities"
}

@ARTICLE{Barthet2010-fv,
  title    = "From clarinet control to timbre perception",
  author   = "Barthet, Mathieu and Guillemain, Philippe and Kronland-Martinet,
              Richard and Ystad, S{\o}lvi",
  abstract = "This study investigates the relationships between the control
              gestures of the clarinet, the generated timbres and their
              perceptual representation. The understanding of such
              relationships can provide great interest in several re- search
              contexts: synthesis and control (e.g., to improve the quality of
              current synthesis models), music analysis and perception (e.g.,
              to study music performance), and music information retrieval
              (e.g., to find relevant acous- tical descriptors for automatic
              instrument and/or performer identification). A physics-based
              model was used to generate synthetic clarinet tones by varying
              the main control parameters of the model (related to the blowing
              pressure and lip pressure on the reed). 16 participants had to
              rate the dissimilarities between pairs of different tones and
              describe the factors on which they based their judgments in a
              questionnaire. The collected data were subjected to various
              statistical analyses (multidimensional scaling and hierarchical
              clustering) in order to obtain a low-dimensional spatial
              configuration (timbre space) which best represents the
              dissimilarity ratings. The structure of the clarinet timbre space
              was interpreted both in terms of control parameters and
              acoustical descriptors. The analyses revealed a 3-dimensional
              timbre space, whose dimensions were well correlated to the Attack
              Time, the Spectral Centroid, and the Odd/Even Ratio. Comparisons
              of natural and synthetic clarinet tones showed that the Odd/Even
              Ratio appears to be a good predictor of the beating reed
              situation, specific to single-reed instruments.",
  journal  = "Acta Acustica united with Acustica",
  volume   =  96,
  pages    = "678--689",
  year     =  2010,
  issn     = "1610-1928"
}

@INPROCEEDINGS{Barthet2007-zp,
  title     = "The effect of timbre in clarinet interpretation",
  booktitle = "Proceedings of the 2007 International Computer Music Conference",
  author    = "Barthet, Mathieu and Kronland-Martinet, Richard and Ystad, Solvi
               and Depalle, Philippe",
  year      =  2007
}

@ARTICLE{Juslin1997-do,
  title   = "Perceived emotional expression in synthesized performances of a
             short melody: Capturing the listener's judgment policy",
  author  = "Juslin, Patrik N",
  journal = "Musicae scientiae: the journal of the European Society for the
             Cognitive Sciences of Music",
  volume  =  1,
  number  =  2,
  pages   = "225--256",
  year    =  1997,
  issn    = "1029-8649"
}

@ARTICLE{Seashore1923-cn,
  title   = "Measurements on the expression of emotion in music",
  author  = "Seashore, C E",
  journal = "Proceedings of the National Academy of Sciences of the United
             States of America",
  volume  =  9,
  number  =  9,
  pages   = "323--325",
  year    =  1923,
  issn    = "0027-8424",
  pmid    = "16576728",
  doi     = "10.1073/pnas.9.9.323"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Barthet2006-jo,
  title   = "Consistency of timbre patterns in expressive music performance",
  author  = "Barthet, Mathieu",
  journal = "Proceedings of the 9th …",
  pages   = "1--6",
  year    =  2006
}

@ARTICLE{Barthet2010-vv,
  title    = "Acoustical correlates of timbre and expressiveness in clarinet
              performance",
  author   = "Barthet, Mathieu and Depalle, Philippe and Kronland-Martinet,
              Richard and Ystad, S{\o}lvi",
  abstract = "This study deals with the acoustical factors liable to account
              for expressiveness in clarinet performances. Mechanical and
              expressive performances of excerpts from Bach's Suite No. II and
              Mozart's Quintet for Clarinet and Strings were recorded. Timbre,
              timing, dynamics, and pitch descriptors were extracted from the
              recorded performances. The data were processed using a two-way
              analysis of variance, where the musician's expressive intentions
              and the note factors were defined as the independent variables.
              In both musical excerpts, a strong effect of the expressive
              intention was observed on the timbre (attack time, spectral
              centroid, odd/even ratio), timing (intertone onset intervals) and
              dynamics (root mean square envelope) descriptors. The changes in
              the timbre descriptors were found to depend on the position of
              the notes in the musical phrases. These results suggest that
              timbre, as well as timing and dynamics variations, may mediate
              expressiveness in the musical messages transmitted from
              performers to lis...",
  journal  = "Music perception",
  volume   =  28,
  number   =  2,
  pages    = "135--154",
  year     =  2010,
  keywords = "1990; 1992; and dynamics; asynchronization; carterette; dynamics;
              expressive clarinet performance; g; interpretation; intonation;
              kendall; musical; musical interpretation; repp; see e; timbre;
              timing; todd",
  issn     = "0730-7829",
  doi      = "10.1525/mp.2010.28.2.135"
}

@ARTICLE{Thom2003-el,
  title   = "Interactive improvisational music companionship: A user-modeling
             approach",
  author  = "Thom, Belinda",
  journal = "User modeling and user-adapted interaction",
  volume  =  13,
  pages   = "133--177",
  year    =  2003,
  issn    = "0924-1868",
  doi     = "10.1023/A:1024014923940"
}

@ARTICLE{Thom2000-gm,
  title   = "{BoB}: an interactive improvisational music companion",
  author  = "Thom, B",
  journal = "Proceedings of the fourth international conference on autonomous
             agents",
  year    =  2000
}

@ARTICLE{Dubnov2005-dp,
  title   = "Improvisation planning and jam session design using concepts of
             sequence variation and flow experience",
  author  = "Dubnov, Shlomo and Assayag, G",
  journal = "Proc. International Conference on Sound and Music Computing",
  pages   = "24--26",
  year    =  2005
}

@INPROCEEDINGS{Assayag2006-zz,
  title     = "Omax brothers: A dynamic topology of agents for improvisation
               learning",
  booktitle = "{ACM} Multimedia Workshop on Audio and Music Computing for
               Multimedia",
  author    = "Assayag, G and Bloch, G and Chemillier, M and Cont, A and
               Dubnov, Shlomo",
  abstract  = "We describe a multi-agent architecture for an improvization
               oriented musician-machine interaction system that learns in real
               time from human performers. The improvization kernel is based on
               sequence modeling and statistical learning. The working system
               involves a hybrid architecture using two popular
               composition/perfomance environments, Max and OpenMusic, that are
               put to work and communicate together, each one handling the
               process at a different time/memory scale. The system is capable
               of processing real-time audio/video as well as MIDI. After
               discussing the general cognitive background of improvization
               practices, the statistical modeling tools and the concurrent
               agent architecture are presented. Finally, a prospective
               Reinforcement Learning scheme for enhancing the system's realism
               is described.",
  year      =  2006,
  isbn      = "9781595935007",
  doi       = "10.1145/1178723.1178742"
}

@ARTICLE{Assayag2004-gh,
  title    = "Using factor oracles for machine improvisation",
  author   = "Assayag, G and Dubnov, Shlomo",
  journal  = "Soft Computing",
  volume   =  8,
  number   =  9,
  pages    = "1--7",
  year     =  2004,
  keywords = "computer music; factor oracle; improvisation; in earlier works;
              incremental parsing; machine learning; model order problem;
              prediction; suffix trees; to cope with the; variable markov
              models",
  issn     = "1432-7643",
  doi      = "10.1007/s00500-004-0385-4"
}

@INPROCEEDINGS{Francois2007-bi,
  title     = "Visual feedback in performer-machine interaction for musical
               improvisation",
  booktitle = "Proceedings of the 7th international conference on new
               interfaces for musical expression ({NIME07})",
  author    = "Fran{\c c}ois, Alexandre R J and Chew, Elaine and Thurmond,
               Dennis",
  abstract  = "This paper describes the design of Mimi, a multi-modal
               interactive musical improvisation system that explores the
               potential and powerful impact of visual feedback in
               performer-machine interaction. Mimi is a performer-centric tool
               designed for use in performance and teaching. Its key and novel
               component is its visual interface, designed to provide the
               performer with instantaneous and continuous information on the
               state of the system. For human improvisation, in which context
               and planning are paramount, the relevant state of the system
               extends to the near future and recent past. Mimis visual
               interface allows for a peculiar blend of raw reflex typically
               associated with improvisation, and preparation and timing more
               closely affiliated with score-based reading. Mimi is not only an
               effective improvisation partner, it has also proven itself to be
               an invaluable platform through which to interrogate the mental
               models necessary for successful improvisation.",
  pages     = "277--280",
  year      =  2007,
  keywords  = "machine; performer machine interaction; visualization design",
  doi       = "10.1145/1279740.1279798"
}

@ARTICLE{Pachet2011-id,
  title    = "Finite-length Markov processes with constraints",
  author   = "Pachet, Fran{\c c}ois and Roy, Pierre and Barbieri, Gabriele",
  abstract = "Many systems use Markov models to generate finite-length
              sequences that imitate a given style. These systems often need to
              enforce specific con- trol constraints on the sequences to
              generate. Un- fortunately, control constraints are not compatible
              with Markov models, as they induce long-range de- pendencies that
              violate the Markov hypothesis of limited memory. Attempts to
              solve this issue us- ing heuristic search do not give any
              guarantee on the nature and probability of the sequences gener-
              ated. We propose a novel and efficient approach to controlled
              Markov generation for a specific class of control constraints
              that 1) guarantees that generated sequences satisfy control
              constraints and 2) fol- low the statistical distribution of the
              initial Markov model. Revisiting Markov generation in the frame-
              work of constraint satisfaction, we show how con- straints can be
              compiled into a non-homogeneous Markov model, using
              arc-consistency techniques and renormalization. We illustrate the
              approach on a melody generation problem and sketch some real-
              time applications in which control constraints are given by
              gesture controllers.",
  journal  = "IJCAI: proceedings of the conference / sponsored by the
              International Joint Conferences on Artificial Intelligence",
  pages    = "635--642",
  year     =  2011,
  issn     = "1045-0823",
  doi      = "10.5591/978-1-57735-516-8/IJCAI11-113"
}

@ARTICLE{Pachet2011-mj,
  title    = "Markov constraints: Steerable generation of Markov sequences",
  author   = "Pachet, Fran{\c c}ois and Roy, Pierre",
  abstract = "Markov chains are a well known tool to model temporal properties
              of many phenomena, from text structure to fluctuations in
              economics. Because they are easy to generate, Markovian
              sequences, i.e. temporal sequences having the Markov property,
              are also used for content generation applications such as text or
              music generation that imitate a given style. However, Markov
              sequences are traditionally generated using greedy, left-to-right
              algorithms. While this approach is computationally cheap, it is
              fundamentally unsuited for interactive control. This paper
              addresses the issue of generating steerable Markovian sequences.
              We target interactive applications such as games, inwhich
              userswant to control, through simple input devices, the way the
              system generates aMarkovian sequence, such as a text, a musical
              sequence or a drawing. To this aim, we propose to revisitMarkov
              sequence generation as a branch and bound constraint satisfaction
              problem (CSP). We pro- pose a CSP formulation of the basic
              Markovian hypothesis as elementary Markov Constraints (EMC).We
              propose algorithms that achieve domain-consistency for the
              propagators of EMCs, in an event-based implementation of CSP. We
              show how EMCs can be combined to estimate the global Markovian
              probability of a whole sequence, and accommodate for different
              species of Markov generation such as fixed order, variable-order,
              or smoothing. Such a formulation, although more costly than
              traditional greedy generation algorithms, yields the immense
              advantage of being naturally steerable, since control
              specifications can be represented by arbitrary additional
              constraints, without any modification of the generation
              algorithm. We illustrate our approach on simple yet combinatorial
              chord sequence and melody generation problems and give some
              performance results.",
  journal  = "Constraints: an international journal",
  volume   =  16,
  number   =  2,
  pages    = "148--172",
  year     =  2011,
  keywords = "CSP; Global constraints Interactive applications; Markov chains;
              Sequence constraints",
  issn     = "1383-7133",
  doi      = "10.1007/s10601-010-9101-4"
}

@ARTICLE{Ferrari2006-kt,
  title    = "New technologies for new music education: The Continuator in a
              classroom setting",
  author   = "Ferrari, Laura and Addessi, Anna Rita and Pachet, Fran{\c c}ois",
  abstract = "In this paper we describe a new didactical experience carried out
              about the interaction between young children and the Continuator,
              an interactive reflexive musical system elaborated at SONY-
              Computer Science Laboratory in Paris (Pachet 2003). From a
              pedagogical view the general aim was to analyse if and how the
              Continuator can be used in the daily school activities. We are
              also interesting to understand the role of the teacher in two
              different situations: in the free games and in the guided
              activities with the system. The experience was carried out with
              18 children of 3/5 years old, in an Italian kindergarten
              (Bologna). Children, divided into small groups (3/4 children),
              played with the Continuator for three times. The children reached
              high levels of well-being and pleasure, very similar to those
              described in the Theory of Flow (Csikszentmihalyi, 1996). They
              learned to dialogue musically with the system, developing
              autonomy and learning to manage some kinds of collaborative
              playing. These factors gave rise to some particularly careful and
              prolonged bouts of listening, stimulating the children to think
              in sound, spending time with the system and developing a genuine
              desire of ``play'' with music. This practice experience shows the
              Continuator could represent a versatile device to enhance the
              musical invention and exploration in classroom setting. The
              system's double role of partner and teacher seems to enhance
              socialization and an important self-regulation (Canevaro, 2002)
              of the group.",
  journal  = "Proceedings of the International Conference on Music Perception
              and Cognition",
  pages    = "1392--1398",
  year     =  2006
}

@ARTICLE{Pachet2009-wh,
  title    = "{Description-Based} Design of Melodies",
  author   = "Pachet, Fran{\c c}ois",
  abstract = "Most current approaches in computer-aided compo- sition (CAC) are
              based on an explicit construction paradigm: users build musical
              objects by assembling components using various construction
              tools. Virtu- ally all technologies developed by computer science
              and artificial intelligence have been applied to CAC, thereby
              progressively increasing the sophistication of music-composition
              tools. Composers can choose between many programming paradigms to
              express the compositions they ``have in mind,'' from the
              now-standard time-lined sequencers (e.g., Stein- berg's Cubase)
              to advanced programming languages or libraries (e.g., OpenMusic;
              Assayag et al. 1999). Although these explicit constructions do
              benefit from abstractions of increasing sophistication (ob-
              jects, constraints, rules, flow diagrams, etc.), CAC always
              remains based on an explicit construction paradigm: Users must
              give the computer a clear and complete definition of their
              material. This ap- proach has the enormous advantage of letting
              users control all dimensions of their work. However, it also
              requires from users a fine understanding of the technicalities at
              work. For instance, composing music with object-orientation
              requires the under- standing of objects, classes, and message
              passing. Using constraints requires the understanding of
              constraint satisfaction, filtering, and of the basic constraint
              libraries, etc.",
  journal  = "Computer Music Journal",
  volume   =  33,
  number   =  4,
  pages    = "56--68",
  year     =  2009,
  issn     = "0148-9267",
  doi      = "10.1162/comj.2009.33.4.56"
}

@ARTICLE{Pachet2002-cq,
  title    = "Interacting with a Musical Learning System : The Continuator",
  author   = "Pachet, Fran{\c c}ois",
  abstract = "Music and Artificial Intelligence Lecture Notes in Computer
              Science, 2002, Volume 2445/2002, 103-108, DOI:
              10.1007/3-540-45722-4\_12",
  journal  = "Lecture notes in computer science",
  volume   =  2445,
  pages    = "103--108",
  year     =  2002,
  keywords = "and consequently the music; but not; generated is strongly
              correlated; improvisation; is no memory of; music; musical
              interaction; share a common drawback; the past; there; they do
              not manage; time; with musical input",
  issn     = "0302-9743, 1611-3349",
  doi      = "10.1007/3-540-45722-4\_12"
}

@ARTICLE{Walker1997-bs,
  title    = "A computer participant in musical improvisation",
  author   = "Walker, William F",
  abstract = "Musical improvisation is a collaborative activity analogous to
              conversation. Both are sequences of spontaneous utterances
              constructed within a collaborative structure that is
              interactively managed by the participants. Based on results from
              conversation analysis, I have constructed a computer improviser
              that participates in small group improvisation. Using
              conversation analysis rules for turn-taking, the computer tracks
              the roles of the other musicians and follows a structural model
              of the improvisation to determine its own role as the
              improvisation unfolds. User-centered design was crucial to the
              successful development and deployment of the system.",
  journal  = "CHI ... conference proceedings / Conference on Human Factors in
              Computing Systems. CHI Conference",
  number   =  1,
  pages    = "14--17",
  year     =  1997,
  keywords = "conversation analysis; copyright acm 1997; cscw; musical
              improvisation; object-oriented frameworks for collaboration;
              user-centered design",
  doi      = "10.1145/258549.258629"
}

@ARTICLE{Pachet2002-hn,
  title    = "The Continuator: Musical interaction with style",
  author   = "Pachet, Fran{\c c}ois",
  abstract = "We propose a system, the Continuator, that bridges the gap
              between two classes of traditionally incompatible musical
              systems: 1) interactive musical systems, limited in their ability
              to generate stylistically consistent material, and 2) music
              imitation systems, which are fundamentally not inter- active. Our
              purpose is to allow musicians to extend their technical ability
              with stylistically consistent, automatically learnt material.
              This goal requires the ability for the system to build
              operational representations of musical styles in a real time
              context. Our approach is based on a Markov model of musical
              styles augmented to account for musical issues such as management
              of rhythm, beat, harmony, and imprecision. The resulting system
              is able to learn and generate music in any style, either in
              standalone mode, as continuations of musician's input, or as
              interactive improvisation back up. Lastly, the very design of the
              system makes possible new modes of musical collaborative playing.
              We describe the architecture, implementation issues and
              experimentations conducted with the system in several real world
              contexts.",
  journal  = "Journal of New Music Research",
  volume   =  31,
  number   =  1,
  pages    = "333--341",
  year     =  2002,
  issn     = "0929-8215",
  doi      = "10.1076/jnmr.32.3.333.16861"
}

@MISC{Deutsch1982-li,
  title   = "Organizational Processes in Music",
  author  = "Deutsch, Diana",
  journal = "Music, Mind, and Brain: The Neuropsychology of Music",
  pages   = "119--136",
  year    =  1982
}

@ARTICLE{Deutsch1979-ub,
  title    = "Binaural integration of melodic patterns",
  author   = "Deutsch, Diana",
  abstract = "It has been argued that there is a limit to the rate at which we
              can switch attention between ears in monitoring auditory
              information. Listeners identified melodic configurations formed
              by rapid sequences of tones. When these sequences were presented
              binaurally, excellent performance was obtained. Yet when the
              component tones of the melody were distributed between the ears,
              per- formance was largely nullified when a drone (i.e., a lower
              constant-frequency tone) was presented to the ear opposite that
              receiving the melody component. This improvement in performance
              can- not be attributed to processing the harmonic relationships
              between melody and drone, since when, instead, the drone was
              presented to the same ear as the melody component, performance
              was at chance. Onset-offset asynchronies between the drone and
              melody components resulted in perform- ance levels between those
              where the drone and melody components were synchronous and those
              where the melody switched between ears without an accompanying
              drone. It is argued that diffi- culties in binaural integration
              are due not to processing limitations, but to a mechanism that is
              invoked under certain conditions to prevent confusion in
              monitoring individual sound sources.",
  journal  = "Perception \& psychophysics",
  volume   =  25,
  number   =  5,
  pages    = "399--405",
  year     =  1979,
  keywords = "Auditory Perception; Cerebral; Dominance; Humans; Music",
  issn     = "0031-5117",
  pmid     = "461100",
  doi      = "10.3758/BF03199848"
}

@ARTICLE{Deutsch1983-yn,
  title   = "Auditory illusions, handedness, and the spatial environment",
  author  = "Deutsch, Diana",
  journal = "Journal of the Audio Engineering Society. Audio Engineering
             Society",
  volume  =  31,
  number  =  9,
  pages   = "606--620",
  year    =  1983,
  issn    = "0004-7554"
}

@ARTICLE{Deutsch2004-ko,
  title   = "The octave illusion revisited again",
  author  = "Deutsch, Diana",
  journal = "Journal of experimental psychology. Human perception and
             performance",
  volume  =  30,
  number  =  2,
  pages   = "355--364",
  year    =  2004,
  issn    = "0096-1523",
  doi     = "10.1037/0096-1523.30.2.355"
}

@INCOLLECTION{Deutsch1981-bf,
  title     = "The octave illusion and auditory perceptual integration",
  booktitle = "Hearing Research and Theory",
  author    = "Deutsch, Diana",
  editor    = "Tobias, J V and Schubert, E D",
  publisher = "Academic Press",
  volume    =  1,
  pages     = "99--142",
  year      =  1981,
  address   = "New York, NY"
}

@ARTICLE{Judd1979-xn,
  title   = "Comments on Deutsch's musical scale illusion",
  author  = "Judd, Tedd",
  journal = "Perception \& psychophysics",
  volume  =  26,
  number  =  1,
  pages   = "85--92",
  year    =  1979,
  issn    = "0031-5117, 0037-7961",
  pmid    = "693255",
  doi     = "10.1086/630223"
}

@ARTICLE{Deutsch1987-or,
  title   = "Illusions For Stereo Headphones",
  author  = "Deutsch, Diana",
  journal = "Audiology: official organ of the International Society of
             Audiology",
  number  = "March",
  pages   = "36--48",
  year    =  1987,
  issn    = "0020-6091"
}

@ARTICLE{Brancucci2009-ts,
  title   = "``Octave illusion'' or ``Deutsch's illusion''?",
  author  = "Brancucci, Alfredo and Padulo, Caterina and Tommasi, Luca",
  journal = "Psychological research",
  volume  =  73,
  number  =  3,
  pages   = "303--307",
  year    =  2009,
  issn    = "0340-0727",
  doi     = "10.1007/s00426-008-0153-7"
}

@ARTICLE{Deouell2007-ki,
  title    = "No disillusions in auditory extinction: Perceiving a melody
              comprised of unperceived notes",
  author   = "Deouell, Leon Y and Deutsch, Diana and Scabini, Donatella and
              Soroker, Nachum and Knight, Robert T",
  abstract = "The formation of coherent percepts requires grouping together
              spatio-temporally disparate sensory inputs. Two major questions
              arise: (1) is awareness necessary for this process; and (2) can
              non-conscious elements of the sensory input be grouped into a
              conscious percept? To address this question, we tested two
              patients suffering from severe left auditory extinction following
              right hemisphere damage. In extinction, patients are unaware of
              the presence of left side stimuli when they are presented
              simultaneously with right side stimuli. We used the 'scale
              illusion' to test whether extinguished tones on the left can be
              incorporated into the content of conscious awareness. In the
              scale illusion, healthy listeners obtain the illusion of distinct
              melodies, which are the result of grouping of information from
              both ears into illusory auditory streams. We show that the two
              patients were susceptible to the scale illusion while being
              consciously unaware of the stimuli presented on their left. This
              suggests that awareness is not necessary for auditory grouping
              and non-conscious elements can be incorporated into a conscious
              percept.",
  journal  = "Frontiers in human neuroscience",
  volume   =  1,
  number   = "March",
  pages    = "15",
  year     =  2007,
  keywords = "auditory extinction; auditory scene analysis; implicit
              processing; scale illusion; streaming; unilateral neglect",
  issn     = "1662-5161",
  pmid     = "18958228",
  doi      = "10.3389/neuro.09.015.2007"
}

@ARTICLE{Deutsch1974-iq,
  title   = "An illusion with musical scales",
  author  = "Deutsch, Diana",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  56,
  number  = "S25",
  year    =  1974,
  issn    = "0001-4966"
}

@ARTICLE{Radvansky1992-vt,
  title    = "Structural alterations of an ambiguous musical figure: The scale
              illusion revisited",
  author   = "Radvansky, G A and Hartmann, W M and Rakerd, B",
  abstract = "The scale illusion (Deutsch, 1975) shows the importance of
              frequency range in the perceptual organization of a sequence of
              notes. This paper includes three experiments on the scale
              illusion. Experiments 1 and 2 demonstrated that if the structure
              of the pattern of notes used in the original scale illusion study
              is altered slightly, by adding or subtracting a pair of notes
              from the ends of the sequence, there is a significant decrease in
              the rate of frequency-based responses, suggesting a weaker
              illusion. Experiment 3 investigated two features of the note
              patterns that may have led to this change. Specifically, it asked
              whether the decrease in the strength of the illusion is due to
              (1) the nature of the notes at the extremes of the frequency
              range and/or (2) the nature of the notes at the crossing point of
              the two scales. While both sources were found to affect the
              strength of the scale illusion, the former had a greater
              influence.",
  journal  = "Perception \& psychophysics",
  volume   =  52,
  number   =  3,
  pages    = "256--262",
  year     =  1992,
  keywords = "Adult; Attention; Humans; Illusions; Music; Pitch Discrimination;
              Psychoacoustics",
  issn     = "0031-5117",
  pmid     = "1408637",
  doi      = "10.3758/BF03209143"
}

@ARTICLE{Butler1979-ry,
  title   = "A further study of melodic channeling",
  author  = "Butler, David",
  journal = "Perception \& psychophysics",
  volume  =  25,
  number  =  4,
  pages   = "264--268",
  year    =  1979,
  issn    = "0031-5117",
  pmid    = "461086"
}

@ARTICLE{Smith1982-at,
  title    = "Ambiguous musical figures and auditory streaming",
  author   = "Smith, J and Hausfeld, S and Power, R P and Gorta, A",
  journal  = "Perception \& psychophysics",
  volume   =  32,
  number   =  5,
  pages    = "454--464",
  year     =  1982,
  keywords = "Adolescent; Auditory Perception; Ear; Functional Laterality;
              Humans; Illusions; Music; Pitch Perception",
  issn     = "0031-5117",
  pmid     = "7162947"
}

@ARTICLE{Gregory1994-kg,
  title    = "Timbre and Auditory Streaming",
  author   = "Gregory, Andrew H",
  abstract = "Listeners rated the subjective difference between pairs of
              different synthesized orchestral instrumental timbres. They then
              reported their perception of variations on crossing ascending and
              descending musical scales played in different timbres. With
              little or no timbre difference between the scales, auditory
              streaming by pitch led to the perception of separate high and low
              halfscales. Increasing timbre difference led to the perception of
              the complete scales played by each instrument, particularly if
              the two scales were in distant keys or temporally interleaved
              rather than simultaneous. If the notes of each scale alternated
              between two instruments, then perceptual separation by timbre
              would result in the perception of the ``jumping'' sequence of
              notes played by each instrument. This sequence was perceived only
              if the scales were discordant or temporally interleaved.
              Multidimensional scaling of the difference ratings led to three
              dimensions, which were correlated with acoustic parameters
              resulting from spectral analysis of the sounds. The most
              important aspects of timbre for perceptual separation were the
              proportion of energy in the lower partials and, for discordant
              scales, the duration of the decay. Auditory streaming by timbre
              thus depends on particular dimensions of timbre and on musical
              factors such as harmonic relation, simultaneity, and continuity.",
  journal  = "Music Perception: An Interdisciplinary Journal",
  volume   =  12,
  number   =  2,
  pages    = "161--174",
  year     =  1994,
  issn     = "0730-7829"
}

@INCOLLECTION{Deutsch2013-kn,
  title     = "Grouping mechanisms in music",
  booktitle = "The Psychology of Music",
  author    = "Deutsch, Diana",
  editor    = "Deutsch, Diana",
  abstract  = "Music provides us with a complex, rapidly changing acoustic
               spectrum, often derived from the superposition of sounds from
               many different sources. Our audi- tory system has the task of
               analyzing this spectrum so as to reconstruct the origi- nating
               sound events. This is analogous to the task performed by our
               visual system when it interprets the mosaic of light impinging
               on the retina in terms of visually perceived objects. Such a
               view of perception as a process of ``unconscious infer- ence''
               was proposed in the last century by Helmholtz (1909-1911/1925),
               and we shall see that many phenomena of music perception can be
               viewed in this way.",
  publisher = "Academic Press",
  pages     = "299--348",
  edition   = "3rd ed.",
  year      =  2013,
  address   = "London, England",
  isbn      = "9780123814609"
}

@ARTICLE{Deutsch1975-ca,
  title    = "Two-channel listening to musical scales",
  author   = "Deutsch, Diana",
  abstract = "Ss listened to a dichotic tonal sequence consisting of the
              repetitive\textbackslashnpresentation of the C major scale with
              successive tones alternating\textbackslashnfrom ear to ear. The
              scale was presented simultaneously in both
              ascending\textbackslashnand descending form, such that when a
              component of the ascending\textbackslashnscale was in one ear, a
              component of the descending scale was in\textbackslashnthe other,
              and vice versa. All Ss channeled this sequence by
              frequency\textbackslashnrange: no S channeled by ear of input,
              and none reported a full ascending\textbackslashnor descending
              scale. Various illusory percepts were obtained,
              which\textbackslashnvaried in correlation with the handedness of
              the listener. Right-handers\textbackslashntended to perceive the
              upper tones of the dichotic sequence as
              emanating\textbackslashnfrom the right earphone and the lower
              tones from the left, and to\textbackslashnmaintain this percept
              when the earphones were places in reverse
              position.\textbackslashnLeft-handers as a group did not display
              the same localization tendency.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  57,
  pages    = "1156--1160",
  year     =  1975,
  issn     = "0001-4966",
  pmid     = "1127169",
  doi      = "10.1121/1.380573"
}

@ARTICLE{Jones1993-ho,
  title   = "An assessment of audiation skills of accurate and inaccurate
             singers in grades 1, 2, and 3",
  author  = "Jones, Merilyn",
  journal = "Update: Applications of Research in Music Education",
  volume  =  11,
  number  =  2,
  pages   = "14--17",
  year    =  1993
}

@ARTICLE{Husain2005-vs,
  title   = "Investigating the neural basis of the auditory continuity illusion",
  author  = "Husain, Fatima T and Lozito, Thomas P and Ulloa, Antonio and
             Horwitz, Barry",
  journal = "Journal of cognitive neuroscience",
  volume  =  17,
  number  =  8,
  pages   = "1275--1292",
  year    =  2005,
  issn    = "0898-929X"
}

@ARTICLE{Sasaki1980-dq,
  title    = "Sound restoration and temporal localization of noise in speech
              and music sounds",
  author   = "Sasaki, Takayuki",
  abstract = "Using three very familiar piano pieces (Beethoven's ``Fur
              Elise,'' Mozart's ``Turkish March,'' and Chopin's ``Min- ute''
              Waltz in D-flat, Op. 64, No. 1), Sasaki had subjects try to
              localize on a musical score which tone had been replaced with
              noise. The subjects were generally unsuccessful at this task
              (accurate on less than 10\% of judgments). Their percep- tion was
              that of an intact melody with noise added to it, but the location
              of the noise in relation to the tones was not easily identified.
              Sasaki suggested that the placement of the melody and the noise
              into different streams leads to ``errors of tem- poral
              localization'' that facilitate the sense of auditory conti-
              nuity.",
  journal  = "Tohoku Psychologica Folia",
  volume   =  39,
  pages    = "79--88",
  year     =  1980
}

@ARTICLE{Riecke2009-yu,
  title     = "The continuity illusion adapts to the auditory scene",
  author    = "Riecke, Lars and Mendelsohn, Daniel and Schreiner, Claudia and
               Formisano, Elia",
  abstract  = "The human auditory system is efficient at restoring sounds of
               interest. In noisy environments, for example, an interrupted
               target sound may be illusorily heard as continuing smoothly when
               a loud noise masks the interruptions. In quiet environments,
               however, sudden interruptions might signal important events. In
               that case, restoration of the target sound would be
               disadvantageous. Achieving useful perceptual stability may
               require the restoration mechanism to adapt its output to current
               perceptual demands, a hypothesis which has not yet been fully
               evaluated. In this study, we investigated whether auditory
               restoration depends on preceding auditory scenes, and we report
               evidence that restoration adapts to the perceived continuity of
               target sounds and to the loudness of interrupting sounds. In the
               first experiment, listeners adapted to illusory and non-illusory
               tone sweeps (targets) and interrupting noise, and we observed
               that the perceived continuity of the target and the loudness of
               the interrupting noise influenced the extent of subsequent
               restorations. A second experiment revealed that these adaptation
               effects were unrelated to the adapted spectra, indicating that
               non-sensory representations of the perceived auditory scene were
               involved. We argue that auditory restoration is a dynamic
               illusory phenomenon which recalibrates continuity hearing to
               different acoustic environments. ?? 2008 Elsevier B.V. All
               rights reserved.",
  journal   = "Hearing research",
  publisher = "Elsevier B.V.",
  volume    =  247,
  number    =  1,
  pages     = "71--77",
  year      =  2009,
  keywords  = "Adaptation; Auditory restoration; Auditory scene analysis;
               Continuity illusion; Hearing",
  issn      = "0378-5955",
  pmid      = "19015017",
  doi       = "10.1016/j.heares.2008.10.006"
}

@ARTICLE{Bashford1996-ca,
  title    = "Use of speech-modulated noise adds strong ``bottom-up'' cues for
              phonemic restoration",
  author   = "Bashford, J A and Warren, Richard M and Brown, C A",
  abstract = "When deleted segments of speech are replaced by extraneous sounds
              rather than silence, the missing speech fragments may be
              perceptually restored and intelligibility improved. This phonemic
              restoration (PhR) effect has been used to measure various aspects
              of speech processing, with deleted portions of speech typically
              being replaced by stochastic noise. However, several recent
              studies of PhR have used speech-modulated noise, which may
              provide amplitude-envelope cues concerning the replaced speech.
              The present study compared the effects upon intelligibility of
              replacing regularly spaced portions of speech with stochastic
              (white) noise versus speech-modulated noise. In Experiment 1,
              filling periodic gaps in sentences with noise modulated by the
              amplitude envelope of the deleted speech fragments produced twice
              the intelligibility increase obtained with interpolated
              stochastic noise. Moreover, when lists of isolated monosyllables
              were interrupted in Experiment 2, interpolation of
              speech-modulated noise increased intelligibility whereas
              stochastic noise reduced intelligibility. The augmentation of PhR
              produced by modulated noise appeared without practice, suggesting
              that speech processing normally involves not only a narrowband
              analysis of spectral information but also a wideband integration
              of amplitude levels across critical bands. This is of
              considerable theoretical interest, but it also suggests that
              since PhRs produced by speech-modulated noise utilize potent
              bottom-up cues provided by the noise, they differ from the PhRs
              produced by extraneous sounds, such as coughs and stochastic
              noise.",
  journal  = "Perception \& psychophysics",
  volume   =  58,
  number   =  5,
  pages    = "342--350",
  year     =  1996,
  issn     = "0031-5117",
  pmid     = "8935895",
  doi      = "10.3758/BF03206810"
}

@ARTICLE{Bregman1977-si,
  title    = "Auditory continuity and amplitude edges",
  author   = "Bregman, A S and Dannenbring, G L",
  abstract = "Two experiments with a total of 50 college students investigated
              the illusion of a soft tone sounding continuously when it was
              actually alternating with a burst of louder noise. It was found
              that brief changes in the amplitude of the tones, introduced
              before and after the noise burst, reduced the illusion of
              continuity; this reduction was greater when the amplitude
              decreased rather than increased before the noise. Results suggest
              that lack of ``edge information'' is implicated in the illusion
              of continuity. (French summary) (PsycINFO Database Record (c)
              2004 APA, all rights reserved)",
  journal  = "Canadian journal of psychology",
  volume   =  31,
  number   =  3,
  pages    = "151--159",
  year     =  1977,
  issn     = "0008-4255",
  pmid     = "922594",
  doi      = "10.1037/h0081658"
}

@ARTICLE{Hannon2005-in,
  title    = "Tuning in to musical rhythms: infants learn more readily than
              adults",
  author   = "Hannon, Erin E and Trehub, Sandra E",
  abstract = "Domain-general tuning processes may guide the acquisition of
              perceptual knowledge in infancy. Here, we demonstrate that
              12-month-old infants show an adult-like, culture-specific pattern
              of responding to musical rhythms, in contrast to the
              culture-general responding that is evident at 6 months of age.
              Nevertheless, brief exposure to foreign music enables
              12-month-olds, but not adults, to perceive rhythmic distinctions
              in foreign musical contexts. These findings may indicate a
              sensitive period early in life for acquiring rhythm in particular
              or socially and biologically important structures more generally.",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  102,
  number   =  35,
  pages    = "12639--12643",
  year     =  2005,
  issn     = "0027-8424",
  pmid     = "16105946",
  doi      = "10.1073/pnas.0504254102"
}

@ARTICLE{Hannon2005-rm,
  title    = "Metrical categories in infancy and adulthood",
  author   = "Hannon, Erin E and Trehub, Sandra E",
  abstract = "Intrinsic perceptual biases for simple duration ratios are
              thought to constrain the organization of rhythmic patterns in
              music. We tested that hypothesis by exposing listeners to folk
              melodies differing in metrical structure (simple or complex
              duration ratios), then testing them on alterations that preserved
              or violated the original metrical structure. Simple meters
              predominate in North American music, but complex meters are
              common in many other musical cultures. In Experiment 1, North
              American adults rated structure-violating alterations as less
              similar to the original version than structure-preserving
              alterations for simple-meter patterns but not for complex-meter
              patterns. In Experiment 2, adults of Bulgarian or Macedonian
              origin provided differential ratings to structure-violating and
              structure-preserving alterations in complex- as well as
              simple-meter contexts. In Experiment 3, 6-month-old infants
              responded differentially to structure-violating and
              structure-preserving alterations in both metrical contexts. These
              findings imply that the metrical biases of North American adults
              reflect enculturation processes rather than processing
              predispositions for simple meters.",
  journal  = "Psychological science",
  volume   =  16,
  number   =  1,
  pages    = "48--55",
  year     =  2005,
  keywords = "ience; yc hologica l sc",
  issn     = "0956-7976",
  pmid     = "15660851",
  doi      = "10.1111/j.0956-7976.2005.00779.x"
}

@ARTICLE{Smith2000-ln,
  title    = "On the sins of short-form development",
  author   = "Smith, G T and McCarthy, D M and Anderson, K G",
  abstract = "The empirical short-form literature has been characterized by
              overly optimistic views of the transfer of validity from parent
              form to short form and by the weak application of psychometric
              principles in validating short forms. Reviewers have thus opposed
              constructing short forms altogether, implying researchers are
              succumbing to an inappropriate temptation by trying to abbreviate
              measures. The authors disagree. The authors do not oppose the
              development of short forms, but they do assert that the validity
              standards for short forms should be quite high. The authors
              identify 2 general and 9 specific methodological sins
              characterizing short-form construction and offer methodological
              suggestions for the sound development of short forms. They
              recommend a set of 6 a priori steps researchers should consider
              and 9 methodological procedures researchers can use to develop
              valid abbreviated forms of clinical-assessment procedures.",
  journal  = "Psychological assessment",
  volume   =  12,
  number   =  1,
  pages    = "102--111",
  year     =  2000,
  issn     = "1040-3590",
  pmid     = "10752369",
  doi      = "10.1037/1040-3590.12.1.102"
}

@ARTICLE{Baddeley1996-xl,
  title   = "Exploring the central executive",
  author  = "Baddeley, Alan D",
  journal = "The Quarterly journal of experimental psychology",
  volume  = "49A",
  number  =  1,
  pages   = "5--28",
  year    =  1996,
  issn    = "0033-555X"
}

@ARTICLE{Jacobs1887-fy,
  title    = "Experiments on ``prehension''",
  author   = "Jacobs, Joseph",
  journal  = "Mind; a quarterly review of psychology and philosophy",
  volume   =  12,
  pages    = "75--79",
  year     =  1887,
  keywords = "digit span",
  issn     = "0026-4423"
}

@INCOLLECTION{Miyake1999-ax,
  title     = "Toward unified theories of working memory: Emerging consensus,
               unresolved theoretical issues, and future research directions",
  booktitle = "Models of Working Memory: Mechanisms of active maintenance and
               executive control",
  author    = "Miyake, Akira and Shah, Priti",
  editor    = "Miyake, Akira and Shah, Priti",
  publisher = "Cambridge University Press",
  pages     = "442--481",
  year      =  1999,
  address   = "Cambridge, England"
}

@INCOLLECTION{Richardson1996-pu,
  title     = "Evolving concepts of working memory",
  booktitle = "Working memory and human cognition",
  author    = "Richardson, J T E",
  editor    = "Richardson, J T E and Engle, Randall W and Hasher, L and Logie,
               R H and Stoltzfus, E R and Zacks, R T",
  publisher = "Oxford University Press",
  pages     = "3--30",
  year      =  1996,
  address   = "New York, NY"
}

@INCOLLECTION{Andrade2001-ga,
  title     = "An introduction to working memory",
  booktitle = "Working memory in perspective",
  author    = "Andrade, Jackie",
  editor    = "Andrade, Jackie",
  publisher = "Psychology Press",
  pages     = "3--30",
  year      =  2001,
  address   = "Hove, England",
  keywords  = "Andrade;England: Psychology Press.;J. (2001). An introduction to
               working memory. In J;Working memory in perspective (pp. 3--30).
               Hove"
}

@ARTICLE{Baddeley2012-cc,
  title   = "Working memory",
  author  = "Baddeley, Alan D",
  journal = "Current biology: CB",
  volume  =  20,
  number  =  4,
  pages   = "136--140",
  year    =  2012,
  issn    = "0960-9822"
}

@ARTICLE{Croonen1994-ag,
  title    = "Effects of length, tonal structure, and contour in the
              recognition of tone series",
  author   = "Croonen, W L",
  abstract = "Four experiments on recognition of tone series are reported. The
              first experiment tested the accuracy of recognition in relation
              to length, contour complexity, and tonal structure of the series.
              Series comprised (1) 7 or 10 tones, (2) either a strong or a weak
              tonal structure, depending on the temporal ordering of the tones,
              and (3) few or many contour reversals. The second experiment used
              7-tone series having either a strong or a weak tonal structure,
              depending on the mode (Ionian or Phrygian) in which the series
              was presented. Both experiments employed a same-different task in
              which a standard series was compared with either an exact or an
              inexact transposition, the latter type having one incorrectly
              transposed tone (mostly nondiatonic in Experiment 1 and always
              diatonic in Experiment 2). These experiments showed that (1)
              7-tone series were better recognized than were 10-tone series,
              (2) series with a strong tonal structure were better recognized
              than were series with a weak tonal structure, and (3) contour
              complexity did not influence the responses. Two control
              experiments, using mistuned tone series, showed that the outcomes
              of Experiments 1 and 2 could not be attributed to nonmusical
              artifacts of the stimulus set.",
  journal  = "Perception \& psychophysics",
  volume   =  55,
  number   =  6,
  pages    = "623--632",
  year     =  1994,
  keywords = "Adolescent; Adult; Attention; Female; Humans; Male; Mental
              Recall; Pitch Discrimination; Psychoacoustics; Serial Learning;
              Time Perception;contour;length;melodic memory;melodic
              recognition;tonality",
  issn     = "0031-5117",
  pmid     = "8058450"
}

@ARTICLE{Mullensiefen2015-jm,
  title    = "Investigating the importance of self-theories of intelligence and
              musicality for students' academic and musical achievement",
  author   = "M{\"u}llensiefen, Daniel and Harrison, Peter M C and Caprini,
              Francesco and Fancourt, Amy",
  abstract = "Musical abilities and active engagement with music have been
              shown to be positively associated with many cognitive abilities
              as well as social skills and academic performance in secondary
              school students. While there is evidence from intervention
              studies that musical training can be a cause of these positive
              relationships, recent findings in the literature have suggested
              that other factors, such as genetics, family background or
              personality traits, might also be contributing factors. In
              addition, there is mounting evidence that self-concepts and
              beliefs can affect academic performance independently of
              intellectual ability. Students who believe that intelligence is
              malleable are more likely to attribute poor academic performances
              to effort rather than ability, and are more likely to take
              remedial action to improve their performance. However, it is
              currently not known whether student's beliefs about the nature of
              musical talent also influence the development of musical
              abilities in a similar fashion. Therefore, this study introduces
              a short self-report measure termed `` Musical Self-Theories and
              Goals, '' closely modeled on validated measures for self-theories
              in academic scenarios. Using this measure the study investigates
              whether musical self-theories are related to students' musical
              development as indexed by their concurrent musical activities and
              their performance on a battery of listening tests. We use data
              from a cross-sectional sample of 313 secondary school students to
              construct a network model describing the relationships between
              self-theories and academic as well as musical outcome measures,
              while also assessing potential effects of intelligence and the
              Big Five personality dimensions. Results from the network model
              indicate that self-theories of intelligence and musicality are
              closely related. In addition, both kinds of self-theories are
              connected to the students' academic achievement through the
              personality dimension conscientiousness and academic effort.
              Finally, applying the do-calculus method to the network model we
              estimate that the size of the assumed causal effects between
              musical self-theories and academic achievement lie between 0.07
              and 0.15 standard deviations.",
  journal  = "Frontiers in psychology",
  volume   =  6,
  pages    = "1--14",
  year     =  2015,
  keywords = "academic performance; musical ability; personality;
              self-concepts; theory of intelligence; theory of musicality",
  issn     = "1664-1078",
  doi      = "10.3389/fpsyg.2015.01702"
}

@ARTICLE{Remillard2010-qm,
  title    = "Implicit learning of fifth- and sixth-order sequential
              probabilities",
  author   = "Remillard, Gilbert",
  abstract = "Serial reaction time (SRT) task studies have established that
              people can implicitly learn sequential contingencies as complex
              as fourth-order probabilities. The present study examined
              people's ability to learn fifth-order (Experiment 1) and
              sixth-order (Experiment 2) probabilities. Remarkably, people
              learned fifth- and sixth-order probabilities. This suggests that
              the implicit sequence learning mechanism can operate over a range
              of at least seven sequence elements.",
  journal  = "Memory \& cognition",
  volume   =  38,
  number   =  7,
  pages    = "905--915",
  year     =  2010,
  keywords = "Adolescent; Adult; Cognition; Humans; Learning; Pattern
              Recognition; Probability; Reaction Time; Visual; Young Adult",
  issn     = "0090-502X, 1532-5946",
  pmid     = "20921103",
  doi      = "10.3758/MC.38.7.905"
}

@ARTICLE{Remillard1999-hd,
  title    = "Generating fixed-length sequences satisfying any given nth-order
              transition probability matrix",
  author   = "Remillard, G and Clark, J M",
  abstract = "An experimental design involving sequences of m distinct events
              can be conceptualized as an nth-order transition probability
              matrix specifying the probabilities with which each of the m
              distinct events is to follow certain n-grams. This paper
              describes a general method for constructing sequences of shortest
              possible length that satisfy any such matrix and presents a
              computer program that randomly generates such sequences.",
  journal  = "Behavior research methods, instruments, \& computers: a journal
              of the Psychonomic Society, Inc",
  volume   =  31,
  number   =  2,
  pages    = "235--243",
  year     =  1999,
  keywords = "Algorithms; Probability; Software",
  issn     = "0743-3808",
  pmid     = "10495805"
}

@ARTICLE{Gebauer2007-fx,
  title   = "Psychometric intelligence dissociates implicit and explicit
             learning",
  author  = "Gebauer, Guido F and Mackintosh, Nicholas J",
  journal = "Journal of experimental psychology. Learning, memory, and
             cognition",
  volume  =  33,
  number  =  1,
  pages   = "34--54",
  year    =  2007,
  issn    = "0278-7393"
}

@ARTICLE{Remillard2008-jq,
  title    = "Implicit learning of second-, third-, and fourth-order adjacent
              and nonadjacent sequential dependencies",
  author   = "Remillard, Gilbert",
  abstract = "Serial reaction time (SRT) task studies have established that
              people can implicitly learn first- and second-order adjacent
              dependencies. Sequential confounds have made it impossible to
              draw conclusions regarding learning of nonadjacent dependencies
              and learning of third- and fourth-order adjacent dependencies.
              Addressing the confounds, the present study shows that people can
              implicitly learn second-, third-, and fourth-order adjacent and
              nonadjacent dependencies embedded in probabilistic sequences of
              target locations.",
  journal  = "Quarterly journal of experimental psychology",
  volume   =  61,
  number   =  3,
  pages    = "400--424",
  year     =  2008,
  issn     = "1747-0218",
  pmid     = "17853201",
  doi      = "10.1080/17470210701210999"
}

@ARTICLE{Furl2011-fm,
  title    = "Neural prediction of higher-order auditory sequence statistics",
  author   = "Furl, Nicholas and Kumar, Sukhbinder and Alter, Kai and Durrant,
              Simon and Shawe-Taylor, John and Griffiths, Timothy D",
  abstract = "During auditory perception, we are required to abstract
              information from complex temporal sequences such as those in
              music and speech. Here, we investigated how higher-order
              statistics modulate the neural responses to sound sequences,
              hypothesizing that these modulations are associated with higher
              levels of the peri-Sylvian auditory hierarchy. We devised
              second-order Markov sequences of pure tones with uniform
              first-order transition probabilities. Participants learned to
              discriminate these sequences from random ones.
              Magnetoencephalography was used to identify evoked fields in
              which second-order transition probabilities were encoded. We show
              that improbable tones evoked heightened neural responses after
              200 ms post-tone onset during exposure at the learning stage or
              around 150 ms during the subsequent test stage, originating near
              the right temporoparietal junction. These signal changes
              reflected higher-order statistical learning, which can contribute
              to the perception of natural sounds with hierarchical structures.
              We propose that our results reflect hierarchical predictive
              representations, which can contribute to the experiences of
              speech and music.",
  journal  = "NeuroImage",
  volume   =  54,
  number   =  3,
  pages    = "2267--2277",
  year     =  2011,
  keywords = "Acoustic Stimulation; Auditory; Auditory Cortex; Auditory Cortex:
              physiology; Auditory Perception; Auditory Perception: physiology;
              Auditory: physiology; Discrimination Learning; Discrimination
              Learning: physiology; Evoked Potentials; Forecasting; Humans;
              Learning; Learning: physiology; Magnetoencephalography; Markov
              Chains; Parietal Lobe; Parietal Lobe: physiology; Temporal Lobe;
              Temporal Lobe: physiology",
  issn     = "1053-8119, 1095-9572",
  pmid     = "20970510",
  doi      = "10.1016/j.neuroimage.2010.10.038"
}

@ARTICLE{Sueur2008-ve,
  title   = "Sound analysis and synthesis with the package Seewave",
  author  = "Sueur, J and Aubin, T and Simonis, C",
  journal = "Bioacoustics",
  volume  =  18,
  number  =  2,
  pages   = "213--226",
  year    =  2008,
  issn    = "0952-4622"
}

@ARTICLE{Perruchet1998-wt,
  title    = "{PARSER}: A model for word segmentation",
  author   = "Perruchet, Pierre and Vinter, Annie",
  abstract = "Saffran, Newport, and Aslin (1996b) showed that adults were able
              to segment into words an artificial language that included no
              pauses or other prosodic cues for word boundaries. We propose an
              account of their results that requires only limited computational
              abilities and memory capacity. In this account, parsing emerges
              as a natural consequence of the on-line attentional processing of
              the input, thanks to basic laws of memory and associative
              learning. Our account was implemented in a computer program,
              PARSER. Simulations revealed that PARSER extracted the words of
              the language well before exhausting the material presented to
              participants in the Saffran et al. experiments. In addition,
              PARSER was able to simulate the results obtained under
              attention-disturbing conditions (Saffran, Newport, Aslin, Tunick,
              \& Barrueco, 1997) and those collected from 8-month-old infants
              (Saffran, Aslin, and Newport, 1996a). Finally, the good
              performance of PARSER was not limited to the trisyllabic words
              used by Saffran et al., but also extended to a language composed
              of one- to five-syllable words.",
  journal  = "Journal of memory and language",
  volume   =  39,
  number   =  2,
  pages    = "246--263",
  year     =  1998,
  issn     = "0749-596X",
  doi      = "10.1006/jmla.1998.2576"
}

@ARTICLE{Hunt2001-uj,
  title   = "Statistical learning in a serial reaction time task: Access to
             separable statistical cues by individual learners",
  author  = "Hunt, Ruskin H and Aslin, Richard N",
  journal = "Journal of Educational Psychology: General",
  volume  =  130,
  number  =  4,
  pages   = "658--680",
  year    =  2001
}

@ARTICLE{Saffran2003-be,
  title    = "From Syllables to Syntax : Multilevel Statistical Learning by
              {12-Month-Old} Infants",
  author   = "Saffran, Jenny R and Wilson, Diana P",
  abstract = "To successfully acquire language, infants must be able to track
              multiple levels of regularities in the input. In many cases,
              regularities only emerge after some learning has already
              occurred. For example, the grammatical relationships between
              words are only evident once the words have been segmented from
              continuous speech. To ask whether infants can engage in this type
              of learning process, 12-month-old infants in 2 experiments were
              familiarized with multiword utterances synthesized as continu-
              ous speech. The words in the utterances were ordered based on a
              simple finite-state grammar. Following exposure, infants were
              tested on novel grammatical and un- grammatical sentences. The
              results indicate that the infants were able to perform 2
              statistical learning tasks in sequence: first segmenting the
              words from continuous speech, and subsequently discovering the
              permissible orderings of the words. Given a single set of input,
              infants were able to acquire multiple levels of structure, sug-
              gesting that multiple levels of representation (initially
              syllable-level combinations, subsequently word-level
              combinations) can emerge during the course of learning. Mo",
  journal  = "Infancy: the official journal of the International Society on
              Infant Studies",
  volume   =  4,
  number   =  2,
  pages    = "273--284",
  year     =  2003,
  issn     = "1525-0008",
  doi      = "10.1207/S15327078IN0402\_07"
}

@ARTICLE{Ericsson2000-dc,
  title    = "Shortcomings of generic retrieval structures with slots of the
              type that Gobet (1993) proposed and modelled",
  author   = "Ericsson, K a and Kintsch, W",
  abstract = "Argues that F. Gobet's (see record 2000-16648-006) criticisms of
              long-term working memory (LTWM) failed to recognize the basic
              differences between the retrieval structures discussed in K. A.
              Ericsson and W. Kintsch's (see record 1995-24067-001) LTWM and
              the retrieval structures explicated by H. B. Richman, J. J.
              Staszewski, and H. A. Simon (see record 1995-27476-001). The
              authors describe the independent development of computational
              models of superior memory performance of chess experts within the
              Elementary Perceiver and Memorizer (EPAM) framework and their
              proposal for how experts can acquire expanded working memory
              memory via LTWM to support memory demands while performing tasks
              representative of their domain. They show how these 2 research
              approaches differ in regard to theoretical issues analysed and
              empirical phenomena reviewed, as well as their use of simulations
              within cognitive architecture. The authors describe Gobet's
              efforts to further specify the mechanisms of LTWM so they could
              be interpreted as computational mechanisms within the tightly
              constrained EPAM architecture and point out weaknesses in his
              inferences about Ericsson and Kintsch's work. (PsycINFO Database
              Record (c) 2004 APA, all rights reserved)",
  journal  = "British journal of psychology",
  volume   =  91,
  pages    = "571--590",
  year     =  2000,
  issn     = "0007-1269",
  pmid     = "11104179",
  doi      = "<a data-auto=``ep\_link\_''
              href=``http://dx.doi.org.libezproxy.open.ac.uk/10.1348/000712600161998''
              target=``\_blank''
              id=``linkhttp:dx.doi.org10.1348000712600161998''
              title=``http://dx.doi.org.libezproxy.open.ac.uk/10.1348/000712600161998''
              data-title=``http://dx.doi"
}

@ARTICLE{Lleras2006-vl,
  title   = "What You See Is What You Get and a Physically Presented Stimulus",
  author  = "Lleras, Alejandro and Moore, Cathleen M",
  journal = "Psychological science",
  volume  =  17,
  number  =  10,
  pages   = "876--881",
  year    =  2006,
  issn    = "0956-7976",
  doi     = "10.1111/j.1467-9280.2006.01797.x"
}

@ARTICLE{King1991-hs,
  title  = "Individual Differences in Syntactic Processing: The Role of Working
            Memory",
  author = "King, Jonathan and Just, Marcel Adam",
  pages  = "580--602",
  year   =  1991
}

@ARTICLE{Conway2003-zg,
  title   = "Working memory capacity and its relation to general intelligence",
  author  = "Conway, Andrew R A and Kane, Michael J and Engle, Randall W",
  journal = "Trends in cognitive sciences",
  volume  =  7,
  number  =  12,
  pages   = "547--552",
  year    =  2003,
  issn    = "1364-6613",
  doi     = "10.1016/j.tics.2003.10.005"
}

@ARTICLE{Baddeley2003-wc,
  title   = "Working memory: looking back and looking forward",
  author  = "Baddeley, Alan D",
  journal = "Nature reviews. Neuroscience",
  volume  =  4,
  number  =  10,
  pages   = "829--839",
  year    =  2003,
  issn    = "1471-003X",
  doi     = "10.1038/nrn1201"
}

@ARTICLE{Just1992-fw,
  title    = "A capacity theory of comprehension: Individual differences in
              working memory",
  author   = "Just, M A and Carpenter, P A",
  abstract = "A theory of the way working memory capacity constrains
              comprehension is proposed. The theory proposes that both
              processing and storage are mediated by activation and that the
              total amount of activation available in working memory varies
              among individuals. Individual differences in working memory
              capacity for language can account for qualitative and
              quantitative differences among college-age adults in several
              aspects of language comprehension. One aspect is syntactic
              modularity: The larger capacity of some individuals permits
              interaction among syntactic and pragmatic information, so that
              their syntactic processes are not informationally encapsulated.
              Another aspect is syntactic ambiguity: The larger capacity of
              some individuals permits them to maintain multiple
              interpretations. The theory is instantiated as a production
              system model in which the amount of activation available to the
              model affects how it adapts to the transient computational and
              storage demands that occur in comprehension.",
  journal  = "Psychological review",
  volume   =  99,
  number   =  1,
  pages    = "122--149",
  year     =  1992,
  issn     = "0033-295X",
  pmid     = "1546114",
  doi      = "10.1037/0033-295X.99.1.122"
}

@INCOLLECTION{Baddeley1974-yu,
  title     = "Working memory",
  booktitle = "The psychology of learning and motivation: Advances in research
               and theory",
  author    = "Baddeley, Alan D and Hitch, Graham",
  pages     = "47--89",
  year      =  1974,
  doi       = "10.1126/science.1736359"
}

@ARTICLE{Daneman1980-cn,
  title    = "Individual differences in working memory and reading",
  author   = "Daneman, Meredyth and Carpenter, Patricia A",
  abstract = "Individualdifferences in reading comprehension may reflect
              differences in workingmemory capacity, specifically in the
              trade-off between its processing and storage functions. A poor
              reader's processes may be inefficient, so that they lessen the
              amount of additional information that can be maintained in
              workingmemory. A test with heavy processing and storage demands
              was devised to measure this trade-off. Subjects read aloud a
              series of sentences and then recalled the final word of each
              sentence. The reading span, the number of final words recalled,
              varied from two to five for 20 college students. This span
              correlated with three reading comprehension measures, including
              verbal SAT and tests involving fact retrieval and pronominal
              reference. Similar correlations were obtained with a listening
              span task, showing that the correlation is not specific to
              reading. These results were contrasted with traditional digit
              span and word span measures which do not correlate with
              comprehension.",
  journal  = "Journal of Verbal Learning and Verbal Behavior",
  volume   =  19,
  number   =  4,
  pages    = "450--466",
  year     =  1980,
  issn     = "0022-5371",
  pmid     = "21417512",
  doi      = "10.1016/S0022-5371(80)90312-6"
}

@ARTICLE{Turner1989-yv,
  title    = "Is working memory capacity task dependent?",
  author   = "Turner, Marilyn L and Engle, Randall W",
  abstract = "The complex span measure of working memory is a word/digit span
              measured while performing a secondary task. Two experiments
              investigated whether correlations between the complex span and
              reading comprehension depend on the nature of the secondary task
              and individual skill in that task. The secondary task did not
              have to be reading related for the span to predict reading
              comprehension. An arithmetic-related secondary task led to corre-
              lations with reading comprehension similar to those found when
              the secondary task was reading. The relationship remained
              significant when quantitative skills were factored out of the
              complex span/comprehension correlations. Simple digit and word
              spans (measured with- out a background task) did not correlate
              with reading comprehension and SAT scores. The second experiment
              showed that the complex span/comprehension correlations were a
              func- tion of the difficulty of the background task. When the
              difficulty level of the reading-related or arithmetic-related
              background tasks was moderate, the span/comprehension
              correlations were higher in magnitude than when the background
              tasks were very simple, or, were very difficult. 8",
  journal  = "Journal of memory and language",
  volume   =  28,
  number   =  2,
  pages    = "127--154",
  year     =  1989,
  issn     = "0749-596X",
  pmid     = "2816",
  doi      = "10.1016/0749-596X(89)90040-5"
}

@ARTICLE{Dempster1981-rc,
  title    = "Memory span: Sources of individual and developmental differences",
  author   = "Dempster, Frank N",
  abstract = "Ten possible sources of individual and developmental differences
              in memory span (rehearsal, grouping, chunking, retrieval
              strategies, item identification, item ordering, capacity,
              susceptibility to interference, search rate, and the output
              buffer) are examined, drawing on existing research. Considerable
              evidence suggests that the speed with which presented items can
              be identified is a major source of both individual and
              developmental differences in span. By contrast, there is no
              conclusive evidence that the other possibilities examined,
              including those traditionally associated with span differences
              (rehearsal, grouping, chunking, and overall
              information-processing capacity) contributes to variations in
              span. Speed of item identification differences is discussed in
              terms of processing efficiency or the capacity needed to activate
              appropriate perceptual/cognitive units and linguistic programs.",
  journal  = "Psychological bulletin",
  volume   =  89,
  number   =  1,
  pages    = "63--100",
  year     =  1981,
  issn     = "0033-2909",
  doi      = "10.1037/0033-2909.89.1.63"
}

@ARTICLE{Abla2008-zp,
  title    = "On-line assessment of statistical learning by event-related
              potentials",
  author   = "Abla, Dilshat and Katahira, Kentaro and Okanoya, Kazuo",
  abstract = "Abstract We investigated the neural processes involved in on-line
              statistical learning and word segmentation. Auditory
              event-related potentials (ERPs) were recorded while participants
              were exposed to continuous, nonlinguistic auditory sequences, the
              elements of which were organized into ``tritone words'' that were
              sequenced in random order, with no silent spaces between them.
              After listening to three 6.6-min sessions of sequences, the
              participants performed a behavioral choice test, in which they
              were instructed to indicate the most familiar tone sequence in
              each test trial by pressing buttons. The participants were
              divided into three groups (high, middle, and low learners) based
              on their behavioral performance. The overall mean performance was
              74.4\%, indicating that the tone sequence was segmented and that
              the participants learned the tone words statistically.
              Grand-averaged ERPs showed that word onset (initial tone)
              elicited the largest N100 and N400 in the early learning session
              of high learners, but in middle learners, the word-onset effect
              was elicited in a later session, and there was no effect in low
              learners. The N400 amplitudes significantly differed between the
              three learning sessions in the high- and middle-learner groups.
              The results suggest that the N400 effect indicates not only
              on-line word segmentation but also the degree of statistical
              learning. This study provides insight into the neural mechanisms
              underlying on-line statistical learning processes.",
  journal  = "Journal of cognitive neuroscience",
  volume   =  20,
  number   =  6,
  pages    = "952--964",
  year     =  2008,
  keywords = "Acoustic Stimulation; Adult; Data Interpretation;
              Electroencephalography; Evoked Potentials; Evoked Potentials:
              physiology; Female; Fixation; Humans; Learning; Learning:
              physiology; Male; Middle Aged; Ocular; Online Systems;
              Psychomotor Performance; Psychomotor Performance: physiology;
              Statistical",
  issn     = "0898-929X",
  pmid     = "18211232",
  doi      = "10.1162/jocn.2008.20058"
}

@ARTICLE{Perruchet2006-rq,
  title   = "Implicit learning and statistical learning: one phenomenon, two
             approaches",
  author  = "Perruchet, Pierre and Pacton, Sebastien",
  journal = "Trends in cognitive sciences",
  volume  =  10,
  number  =  5,
  pages   = "233--238",
  year    =  2006,
  issn    = "1364-6613",
  doi     = "10.1016/j.tics.2006.03.006"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Miyake1998-sm,
  title     = "Individual differences in second language proﬁciency: Working
               memory as language aptitude",
  booktitle = "Foreign Language Learning: Psycholinguistic Studies on Training
               and Retention",
  author    = "Miyake, Akira and Friedman, Naomi P",
  pages     = "339--364",
  year      =  1998
}

@ARTICLE{Melby-Lervag2013-qa,
  title    = "Is working memory training effective? A meta-analytic review",
  author   = "Melby-Lerv{\aa}g, Monica and Hulme, Charles",
  journal  = "Developmental psychology",
  volume   =  49,
  number   =  2,
  pages    = "270--291",
  year     =  2013,
  keywords = "adhd; at least; attention; constructs in cognitive psychology;
              from links between measures; in part; learning disabilities; of
              the most influential; of working memory capacity; theoretical;
              this influence derives; working memory is one; working memory
              training",
  issn     = "0012-1649, 1939-0599",
  doi      = "10.1037/a0028228"
}

@ARTICLE{Olesen2004-ra,
  title    = "Increased prefrontal and parietal activity after training of
              working memory",
  author   = "Olesen, Pernille J and Westerberg, Helena and Klingberg, Torkel",
  abstract = "Working memory capacity has traditionally been thought to be
              constant. Recent studies, however, suggest that working memory
              can be improved by training. In this study, we have investigated
              the changes in brain activity that are induced by working memory
              training. Two experiments were carried out in which healthy,
              adult human subjects practiced working memory tasks for 5 weeks.
              Brain activity was measured with functional magnetic resonance
              imaging (fMRI) before, during and after training. After training,
              brain activity that was related to working memory increased in
              the middle frontal gyrus and superior and inferior parietal
              cortices. The changes in cortical activity could be evidence of
              training-induced plasticity in the neural systems that underlie
              working memory.",
  journal  = "Nature neuroscience",
  volume   =  7,
  number   =  1,
  pages    = "75--79",
  year     =  2004,
  keywords = "Adult; Brain Mapping; Brain Mapping: methods; Female; Humans;
              Magnetic Resonance Imaging; Magnetic Resonance Imaging: methods;
              Male; Memory; Memory: physiology; Parietal Lobe; Parietal Lobe:
              physiology; Prefrontal Cortex; Prefrontal Cortex: physiology;
              Reaction Time; Reaction Time: physiology",
  issn     = "1097-6256",
  pmid     = "14699419",
  doi      = "10.1038/nn1165"
}

@ARTICLE{Guida2012-dj,
  title    = "How chunks, long-term working memory and templates offer a
              cognitive explanation for neuroimaging data on expertise
              acquisition: A two-stage framework",
  author   = "Guida, Alessandro and Gobet, Fernand and Tardieu, Hubert and
              Nicolas, Serge",
  abstract = "Our review of research on PET and fMRI neuroimaging of experts
              and expertise acquisition reveals two apparently discordant
              patterns in working-memory-related tasks. When experts are
              involved, studies show activations in brain regions typically
              activated during long-term memory tasks that are not observed
              with novices, a result that is compatible with functional brain
              reorganization. By contrast, when involving novices and training
              programs, studies show a decrease in brain regions typically
              activated during working memory tasks, with no functional
              reorganization. We suggest that the latter result is a
              consequence of practice periods that do not allow important
              structures to be completely acquired: knowledge structures (i.e.,
              Ericsson and Kintsch's retrieval structures; Gobet and Simon's
              templates) and in a lesser way, chunks. These structures allow
              individuals to improve performance on working-memory tasks, by
              enabling them to use part of long-term memory as working memory,
              causing a cerebral functional reorganization. Our hypothesis is
              that the two brain activation patterns observed in the literature
              are not discordant, but involve the same process of expertise
              acquisition in two stages: from decreased activation to brain
              functional reorganization. The dynamic of these two physiological
              stages depend on the two above-mentioned psychological
              constructs: chunks and knowledge structures. ?? 2012 Elsevier
              Inc.",
  journal  = "Brain and cognition",
  volume   =  79,
  number   =  3,
  pages    = "221--244",
  year     =  2012,
  keywords = "Brain functional reorganization; Chunks; Expertise; Long-term
              working memory; Template theory; Working memory",
  issn     = "0278-2626",
  pmid     = "22546731",
  doi      = "10.1016/j.bandc.2012.01.010"
}

@ARTICLE{Qi2013-xo,
  title    = "Neural changes after training to perform cognitive tasks",
  author   = "Qi, Xue Lian and Constantinidis, Christos",
  abstract = "Cognitive operations requiring working memory rely on the
              activity of neurons in areas of the association cortex, most
              prominently the lateral prefrontal cortex. Human imaging and
              animal neurophysiological studies indicate that this activity is
              shaped by learning, though much is unknown about how much
              training alters neural activity and cortical organization.
              Results from non-human primates demonstrate that prior to any
              training in cognitive tasks, prefrontal neurons respond to
              stimuli, exhibit persistent activity after their offset, and
              differentiate between matching and non-matching stimuli presented
              in sequence. A number of important changes also occur after
              training in a working memory task. More neurons are recruited by
              the stimuli and exhibit higher firing rates, particularly during
              the delay period. Operant stimuli that need to be recognized in
              order to perform the task elicit higher overall rates of
              responses, while the variability of individual discharges and
              correlation of discharges between neurons decrease after
              training. New information is incorporated in the activity of a
              small population of neurons highly specialized for the task and
              in a larger population of neurons that exhibit modest task
              related information, while information about other aspects of
              stimuli remains present in neuronal activity. Despite such
              changes, the relative selectivity of the dorsal and ventral
              aspect of the lateral prefrontal cortex is not radically altered
              with regard to spatial and non-spatial stimuli after training.
              Collectively, these results provide insights on the nature and
              limits of cortical plasticity mediating cognitive tasks. ?? 2012
              Elsevier B.V.",
  journal  = "Behavioural brain research",
  volume   =  241,
  number   =  1,
  pages    = "235--243",
  year     =  2013,
  keywords = "Cognitive training; Monkey; Neuron; Neurophysiology; Prefrontal
              cortex",
  issn     = "0166-4328",
  pmid     = "23261872",
  doi      = "10.1016/j.bbr.2012.12.017"
}

@ARTICLE{McKendrick2014-tr,
  title    = "Enhancing dual-task performance with verbal and spatial working
              memory training: Continuous monitoring of cerebral hemodynamics
              with {NIRS}",
  author   = "McKendrick, Ryan and Ayaz, Hasan and Olmstead, Ryan and
              Parasuraman, Raja",
  abstract = "To better understand the mechanisms by which working memory
              training can augment human performance we continuously monitored
              trainees with near infrared spectroscopy (NIRS) while they
              performed a dual verbal-spatial working memory task. Linear mixed
              effects models were used to model the changes in cerebral
              hemodynamic response as a result of time spent training working
              memory. Nonlinear increases in left dorsolateral prefrontal
              cortex (DLPFC) and right ventrolateral prefrontal cortex (VLPFC)
              were observed with increased exposure to working memory training.
              Adaptive and yoked training groups also showed differential
              effects in rostral prefrontal cortex with increased exposure to
              working memory training. There was also a significant negative
              relationship between verbal working memory performance and
              bilateral VLPFC activation. These results are interpreted in
              terms of decreased proactive interference, increased neural
              efficiency, reduced mental workload for stimulus processing, and
              increased working memory capacity with training. \copyright{}
              2013 Elsevier Inc.",
  journal  = "NeuroImage",
  volume   =  85,
  pages    = "1014--1026",
  year     =  2014,
  keywords = "Dorsolateral prefrontal cortex; Hemodynamics; Near infrared
              spectroscopy; Ventrolateral prefrontal cortex; Working memory
              training",
  issn     = "1053-8119",
  pmid     = "23727530",
  doi      = "10.1016/j.neuroimage.2013.05.103"
}

@ARTICLE{Lorenc2014-qd,
  title    = "Expertise for upright faces improves the precision but not the
              capacity of visual working memory",
  author   = "Lorenc, Elizabeth S and Pratte, Michael S and Angeloni,
              Christopher F and Tong, Frank",
  journal  = "Attention, perception \& psychophysics",
  volume   =  76,
  number   =  7,
  pages    = "1975--1984",
  year     =  2014,
  keywords = "face inversion effect; face perception; face recognition; visual
              expertise; visual short-term memory",
  issn     = "1943-3921",
  doi      = "10.3758/s13414-014-0653-z"
}

@ARTICLE{Shin2015-po,
  title    = "Training Improves the Capacity of Visual Working Memory When It
              Is Adaptive, Individualized, and Targeted",
  author   = "Shin, E and Lee, H and Yoo, S-A and Chong, S C",
  abstract = "The current study investigated whether training improves the
              capacity of visual working memory using individualized adaptive
              training methods. Two groups of participants were trained for two
              targeted processes, filtering and consolidation. Before and after
              the training, the participants, including those with no training,
              performed a lateralized change detection task in which one side
              of the visual display had to be selected and the other side
              ignored. Across ten-day training sessions, the participants
              performed two modified versions of the lateralized change
              detection task. The number of distractors and duration of the
              consolida- tion period were adjusted individually to increase the
              task difficulty of the filtering and con- solidation training,
              respectively. Results showed that the degree of improvement shown
              during the training was positively correlated with the increase
              in memory capacity, and training-induced benefits weremost
              evident for larger set sizes in the filtering training group.
              These results suggest that visual working memory training is
              effective, especially when it is adaptive, individualized, and
              targeted.",
  journal  = "PloS one",
  volume   =  10,
  number   =  4,
  pages    = "e0121702",
  year     =  2015,
  issn     = "1932-6203",
  pmid     = "25836651",
  doi      = "10.1371/journal.pone.0121702"
}

@ARTICLE{Li2015-gm,
  title    = "The neuroplastic effect of working memory training in healthy
              volunteers and patients with schizophrenia: Implications for
              cognitive rehabilitation",
  author   = "Li, Xu and Xiao, Ya-Hui and Zhao, Qing and Leung, Ada W W and
              Cheung, Eric F C and Chan, Raymond C K",
  abstract = "We conducted an activation likelihood estimation (ALE)
              meta-analysis to quantitatively review the existing working
              memory (WM) training studies that investigated neural activation
              changes both in healthy individuals and patients with
              schizophrenia. ALE analysis of studies in healthy individuals
              indicates a widespread distribution of activation changes with WM
              training in the frontal and parietal regions, especially the
              dorsolateral prefrontal cortex, the medial frontal cortex and the
              precuneus, as well as subcortical regions such as the insula and
              the striatum. WM training is also accompanied by activation
              changes in patients with schizophrenia, mainly in the
              dorsolateral prefrontal cortex, the precuneus and the fusiform
              gyrus. Our results demonstrate that WM training is accompanied by
              changes in neural activation patterns in healthy individuals,
              which may provide the basis for understanding neuroplastic
              changes in patients with schizophrenia.",
  journal  = "Neuropsychologia",
  volume   =  75,
  pages    = "149--162",
  year     =  2015,
  issn     = "0028-3932, 1873-3514",
  pmid     = "26032579",
  doi      = "10.1016/j.neuropsychologia.2015.05.029"
}

@ARTICLE{Curby2009-kb,
  title    = "A visual short-term memory advantage for objects of expertise",
  author   = "Curby, Kim M and Glazek, Kuba and Gauthier, Isabel",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  35,
  number   =  1,
  pages    = "94--107",
  year     =  2009,
  keywords = "constrained by bot-; each of our interactions; expertise; faces;
              holistic processing; including how many pieces; is there anything
              a; objects; of; retain in memory; tlenecks of information
              processing; visual information we can; visual short-term memory;
              with the world is",
  issn     = "0096-1523, 1939-1277",
  doi      = "10.1037/0096-1523.35.1.94"
}

@ARTICLE{Bor2007-ni,
  title   = "Cognitive training: Neural correlates of expert skills",
  author  = "Bor, Daniel and Owen, Adrian M",
  journal = "Current biology: CB",
  volume  =  17,
  number  =  3,
  pages   = "R95--R97",
  year    =  2007,
  issn    = "0960-9822",
  doi     = "10.1016/j.cub.2006.11.054"
}

@ARTICLE{Jausovec2012-ao,
  title   = "Working memory training: Improving intelligence -- Changing brain
             activity",
  author  = "Jau{\v s}ovec, Norbert and Jau{\v s}ovec, Ksenija",
  journal = "Brain and cognition",
  volume  =  79,
  number  =  2,
  pages   = "96--106",
  year    =  2012,
  issn    = "0278-2626",
  doi     = "10.1016/j.bandc.2012.02.007"
}

@ARTICLE{Jolles2010-yj,
  title   = "Practice effects in the brain: Changes in cerebral activation
             after working memory practice depend on task demands",
  author  = "Jolles, Dietsje D and Grol, Meike J and Van Buchem, Mark A and
             Rombouts, Serge A R B and Crone, Eveline A",
  journal = "NeuroImage",
  volume  =  52,
  number  =  2,
  pages   = "658--668",
  year    =  2010,
  issn    = "1053-8119",
  doi     = "10.1016/j.neuroimage.2010.04.028"
}

@ARTICLE{Klingberg2010-cg,
  title    = "Training and plasticity of working memory",
  author   = "Klingberg, Torkel",
  abstract = "Working memory (WM) capacity predicts performance in a wide range
              of cognitive tasks. Although WM capacity has been viewed as a
              constant trait, recent studies suggest that it can be improved by
              adaptive and extended training. This training is associated with
              changes in brain activity in frontal and parietal cortex and
              basal ganglia, as well as changes in dopamine receptor density.
              Transfer of the training effects to non-trained WM tasks is
              consistent with the notion of training-induced plasticity in a
              common neural network for WM. The observed training effects
              suggest that WM training could be used as a remediating
              intervention for individuals for whom low WM capacity is a
              limiting factor for academic performance or in everyday life. ??
              2010 Elsevier Ltd.",
  journal  = "Trends in cognitive sciences",
  volume   =  14,
  number   =  7,
  pages    = "317--324",
  year     =  2010,
  issn     = "1364-6613",
  pmid     = "20630350",
  doi      = "10.1016/j.tics.2010.05.002"
}

@ARTICLE{Zimmer2012-aj,
  title    = "Gains of item-specific training in visual working memory and
              their neural correlates",
  author   = "Zimmer, Hubert D and Popp, Christian and Reith, Wolfgang and
              Krick, Christoph",
  abstract = "Experts sometimes show higher working memory performance than
              novices but contrary to this finding, evidence for a positive
              effect of item-specific training is rare. This study provides
              evidence for item-specific training gains. We presented Chinese
              characters and artificial patterns (spotted figures) in a change
              detection task before and after training (varying set size from 1
              to 3). A part of the Chinese characters were trained; others and
              the spotted figures were not trained. Memory capacity was between
              one and two items. For set size two, memory performance for
              trained characters was higher than for untrained characters and
              they were processed faster. Within superior intraparietal sulcus
              and middle occipital cortex (part of the putative posterior
              working memory network), the neural activity asymptotically
              increased with set size. Untrained items reached the activation
              maximum already at set size two. For this set size, the activity
              was significantly reduced for trained items so that a further
              increase from two to three items was observed. We interpret this
              difference as a correlate of a gain in neural efficiency. The
              size of this difference correlated with the training gain in
              memory. We assume that training causes a more efficient neural
              representation of trained items supported by long-term memory and
              this allows holding more items in working memory.",
  journal  = "Brain research",
  volume   =  1466,
  pages    = "44--55",
  year     =  2012,
  keywords = "Adolescent; Adult; Attention; Attention: physiology; Brain
              Mapping; Discrimination (Psychology); Discrimination
              (Psychology): physiology; Female; Humans; Magnetic Resonance
              Imaging; Male; Memory, Short-Term; Memory, Short-Term:
              physiology; Middle Aged; Occipital Lobe; Occipital Lobe:
              physiology; Parietal Lobe; Parietal Lobe: physiology; Pattern
              Recognition, Visual; Pattern Recognition, Visual: physiology",
  issn     = "0006-8993, 1872-6240",
  pmid     = "22659025",
  doi      = "10.1016/j.brainres.2012.05.019"
}

@ARTICLE{Grill-Spector2004-yf,
  title   = "The fusiform face area subserves face perception, not generic
             within-category identification",
  author  = "Grill-Spector, Kalanit and Knouf, Nicholas and Kanwisher, Nancy",
  journal = "Nature neuroscience",
  volume  =  7,
  number  =  5,
  pages   = "555--562",
  year    =  2004,
  issn    = "1097-6256",
  doi     = "10.1038/nn1224"
}

@ARTICLE{Gauthier1999-wx,
  title    = "Activation of the middle fusiform 'face area' increases with
              expertise in recognizing novel objects",
  author   = "Gauthier, I and Tarr, M J and Anderson, A W and Skudlarski, P and
              Gore, J C",
  abstract = "Part of the ventral temporal lobe is thought to be critical for
              face perception, but what determines this specialization remains
              unknown. We present evidence that expertise recruits the fusiform
              gyrus 'face area'. Functional magnetic resonance imaging (fMRI)
              was used to measure changes associated with increasing expertise
              in brain areas selected for their face preference. Acquisition of
              expertise with novel objects (greebles) led to increased
              activation in the right hemisphere face areas for matching of
              upright greebles as compared to matching inverted greebles. The
              same areas were also more activated in experts than in novices
              during passive viewing of greebles. Expertise seems to be one
              factor that leads to specialization in the face area.",
  journal  = "Nature neuroscience",
  volume   =  2,
  number   =  6,
  pages    = "568--573",
  year     =  1999,
  keywords = "Adult; Face; Female; Humans; Magnetic Resonance Imaging; Male;
              Neurophysiological; Neurophysiological: physiology; Pattern
              Recognition; Recruitment; Temporal Lobe; Temporal Lobe:
              physiology; Visual; Visual: physiology",
  issn     = "1097-6256",
  pmid     = "10448223",
  doi      = "10.1038/9224"
}

@ARTICLE{Hambrick2002-uc,
  title    = "Effects of domain knowledge, working memory capacity, and age on
              cognitive performance: an investigation of the knowledge-is-power
              hypothesis",
  author   = "Hambrick, David Z and Engle, Randall W",
  abstract = "Domain knowledge facilitates performance in many cognitive tasks.
              However, very little is known about the interplay between domain
              knowledge and factors that are believed to reflect general, and
              relatively stable, characteristics of the individual. The primary
              goal of this study was to investigate the interplay between
              domain knowledge and one such factor: working memory capacity.
              Adults from wide ranges of working memory capacity, age, and
              knowledge about the game of baseball listened to, and then
              answered questions about, simulated radio broadcasts of baseball
              games. There was a strong facilitative effect of preexisting
              knowledge of baseball on memory performance, particularly for
              information judged to be directly relevant to the baseball games.
              However, there was a positive effect of working memory capacity
              on memory performance as well, and there was no indication that
              domain knowledge attenuated this effect. That is, working memory
              capacity contributed to memory performance even at high levels of
              domain knowledge. Similarly, there was no evidence that domain
              knowledge attenuated age-related differences (favoring young
              adults) in memory performance. We discuss implications of the
              results for understanding proficiency in cognitive domains from
              an individual-differences perspective.",
  journal  = "Cognitive psychology",
  volume   =  44,
  number   =  4,
  pages    = "339--387",
  year     =  2002,
  keywords = "adulthood; age; and danielle; anders ericsson; chris hertzog;
              differences; domain knowledge; individual; john murray; karen
              zabrucky; memory; neal schmitt; oliver wilhelm; reviewers and tim
              salthouse; we thank three anonymous; wendy rogers; working memory
              capacity",
  issn     = "0010-0285",
  pmid     = "12018938",
  doi      = "10.1006/cogp.2001.0769"
}

@ARTICLE{Moore2006-ii,
  title    = "Neural Mechanisms of Expert Skills in Visual Working Memory",
  author   = "Moore, C D and Cohen, M X and Ranganath, C",
  journal  = "Journal of Neuroscience",
  volume   =  26,
  number   =  43,
  pages    = "11187--11196",
  year     =  2006,
  keywords = "cortex; expertise; fmri; inferior; learning; prefrontal;
              temporal; vision",
  issn     = "0270-6474",
  doi      = "10.1523/JNEUROSCI.1873-06.2006"
}

@ARTICLE{Meinz1998-pm,
  title    = "The effects of age and experience on memory for visually
              presented music",
  author   = "Meinz, E J and Salthouse, T a",
  abstract = "Increased age is often associated with lower levels of
              performance in tests of memory for spatial information. The
              primary question in the current study was whether this
              relationship could be moderated as a function of one's relevant
              experience and/or knowledge. Stimulus materials consisted of
              short (7-11 note), visually presented musical melodies and
              structurally equivalent nonmusical stimuli. Participants (N =
              128) were recruited from a wide range of age and experience
              levels. Although there were strong main effects of age and
              experience on memory for music, there was no evidence that the
              age-related differences in memory for these stimuli were smaller
              for individuals with moderate to large amounts of experience with
              music.",
  journal  = "The journals of gerontology. Series B, Psychological sciences and
              social sciences",
  volume   =  53,
  number   =  1,
  pages    = "P60--P69",
  year     =  1998,
  issn     = "1079-5014",
  pmid     = "9469173",
  doi      = "10.1093/geronb/53B.1.P60"
}

@ARTICLE{Gilhooly1988-oc,
  title    = "Skill in map reading and memory for maps",
  author   = "Gilhooly, K J and Wood, M and Kinnear, P R and Green, C",
  abstract = "Used contour maps and planimetric maps to investigate the effect
              of expertise on map recall in 51 low-skill and 49 high-skill
              undergraduates. In Exp I, the expected superiority in memory
              performance was found for skilled map readers with contour maps
              but not with planimetric maps. In Exp II, the main results of Exp
              I were replicated, and process tracing data were obtained during
              both study and test phases of contour map learning. Objective
              measures of attentional and retrieval focusing revealed almost no
              differences between the skilled and unskilled Ss. Analyses of
              verbal protocols showed that the skilled Ss made more use of
              specialist schemata, whereas the unskilled Ss spent more time in
              reading place names in both study and recall phases. (PsycINFO
              Database Record (c) 2012 APA, all rights reserved)",
  journal  = "The Quarterly journal of experimental psychology. A, Human
              experimental psychology",
  volume   =  40,
  number   = "October",
  pages    = "87--107",
  year     =  1988,
  keywords = "Ability; Experience Level; Geography; Knowledge Level; Recall
              (Learning); expertise, contour map reading \& recall, skilled v",
  issn     = "0272-4987",
  doi      = "10.1080/14640748808402284"
}

@ARTICLE{Starkes1987-hq,
  title    = "Skill in Field Hockey : The Nature of the Cognitive Advantage",
  author   = "Starkes, Janet L",
  abstract = "The present study assessed the relative importance of attributes
              determined largely by the efficiency of the central nervous
              system versu.s cognitive at- tributes in the determitiation of
              expertise in field hockey. Three groups were assessed on a
              battery of field hockey related perceptual and cognitive tasks:
              the Canadian Women's Field Hockey team, a university team, and a
              novice group. The attributes assessed were simple reaction time,
              dynamic visual acui- ty, coincident anticipation, ball detection
              speed and accuracy, complex deci- sion speed and accuracy, shot
              prediction accuracy both when ball impact was viewed and when it
              was occluded, and recall accuracy of game-structured and
              nonstructured information. The multitask approach revealed the
              impor- tance of cognitive abilities in the determination of skill
              in field hockey",
  journal  = "Journal of Sport Psychology",
  volume   =  9,
  pages    = "146--160",
  year     =  1987
}

@ARTICLE{Starkes1990-jb,
  title   = "Motor recall of experts for structured and unstructured sequences
             in creative modern dance",
  author  = "Starkes, Janet L and Caicco, M and Boutilier, C and Sevsek, B",
  journal = "Journal of sport \& exercise psychology",
  volume  =  12,
  number  =  3,
  pages   = "317--321",
  year    =  1990,
  issn    = "0895-2779"
}

@ARTICLE{Starkes1987-cm,
  title    = "Motor versus verbal recall of ballet sequences by young expert
              dancers",
  author   = "Starkes, Janet L and Deakin, Janice M and Lindley, Susan",
  abstract = "Two experiments investigated the role of motor performance, and
              the role of music in the retention and recall of ballet sequences
              by young expert dancers. Experiment 1 examined 11-year-old expert
              (N=8) and novice (N=8) dancers, to determine the influence of
              motor performance in the recall of ballet steps. Subjects were
              presented with two conditions, either structured choreographed or
              unstructured sequences. All sequences consisted of eight steps or
              elements. Subjects recalled both types of sequences motorically
              by simply performing the steps. Verbal recall was also assessed
              for structured sequences. Results from analyses of variance
              indicated main effects of skill, recall condition, and serial
              position across elements. Experts recalled more than novices,
              structured sequences were recalled better than nonstructured, and
              the last sequence element was recalled less. An interaction of
              Skill x Recall Condition x Serial Position revealed that although
              experts and novices performed the same on unstructured trials,
              their performances differed for motor versus verbal structured
              trials, particularly on the last elements. Experiment 2 examined
              only expert dancers (N=8) on structured sequences and determined
              whether the presence of music at time of recall aided retention.
              Correlated t tests revealed that with music, recall was
              maintained across all eight elements; without music, recall of
              the last element suffered.",
  journal  = "Journal of Sport Psychology",
  volume   =  9,
  number   =  1973,
  pages    = "222--230",
  year     =  1987,
  issn     = "0163-433X"
}

@ARTICLE{Chiesi1979-ly,
  title    = "Acquisition of domain-related information in relation to high and
              low domain knowledge",
  author   = "Chiesi, Harry L and Spilich, George J and Voss, James F",
  abstract = "This research was concerned with how knowledge of a given topic
              influences the acquisition of topic-related information. The
              knowledge domain studied was baseball, and a knowledge structure
              was postulated which included the goal structure as well as the
              states and actions of the game. In each of five experiments,
              passages of domain-related information were presented and
              performance was compared for individuals with high (HK) or low
              (LK) baseball knowledge. Experiment 1 indicated that HK
              recognition performance was superior to LK, and that this
              difference was greater for changes in ``New'' material that were
              more important in terms of the game. Experiment 2 showed that HK
              individuals need less information to make recognition judgments
              than LK individuals. Experiment 4 showed that HK individuals
              anticipated a greater percentage of high-level goal state
              outcomes than LK individuals. Experiments 3 and 5 indicated that
              HK individuals are superior at recalling event sequences, a
              finding attributed to the greater ability of HK individuals to
              relate successive segments of input information. The results are
              considered in relation to a conceptual framework and to related
              literature.",
  journal  = "Journal of Verbal Learning and Verbal Behavior",
  volume   =  18,
  pages    = "257--273",
  year     =  1979,
  issn     = "0022-5371",
  doi      = "10.1016/S0022-5371(79)90146-4"
}

@ARTICLE{Simon1974-fo,
  title    = "How Big Is a Chunk?: By combining data from several experiments,
              a basic human memory unit can be identified and measured",
  author   = "Simon, H A A",
  abstract = "By combining data from several experiments, a basic human memory
              unit can be identified and measured.",
  journal  = "Science",
  volume   =  183,
  number   =  4124,
  pages    = "482--488",
  year     =  1974,
  issn     = "0036-8075",
  pmid     = "17773029",
  doi      = "10.1126/science.183.4124.482"
}

@ARTICLE{Miller1956-hy,
  title    = "The magical number seven, plus or minus two: some limits on our
              capacity for processing information",
  author   = "Miller, G A",
  abstract = "First, the span of absolute judgment and the span of immediate
              memory impose severe limitations on the amount of information
              that we are able to receive, process, and remember. By organizing
              the stimulus input simultaneously into several dimensions and
              successively into a sequence or chunks, we manage to break (or at
              least stretch) this informational bottleneck. Second, the process
              of recoding is a very important one in human psychology and
              deserves much more explicit attention than it has received. In
              particular, the kind of linguistic recoding that people do seems
              to me to be the very lifeblood of the thought processes. Recoding
              procedures are a constant concern to clinicians, social
              psychologists, linguists, and anthropologists and yet, probably
              because recoding is less accessible to experimental manipulation
              than nonsense syllables or T mazes, the traditional experimental
              psychologist has contributed little or nothing to their analysis.
              Nevertheless, experimental techniques can be used, methods of
              recoding can be specified, behavioral indicants can be found. And
              I anticipate that we will find a very orderly set of relations
              describing what now seems an uncharted wilderness of individual
              differences. Third, the concepts and measures provided by the
              theory of information provide a quantitative way of getting at
              some of these questions. The theory provides us with a yardstick
              for calibrating our stimulus materials and for measuring the
              performance of our subjects. In the interests of communication I
              have suppressed the technical details of information measurement
              and have tried to express the ideas in more familiar terms; I
              hope this paraphrase will not lead you to think they are not
              useful in research. Informational concepts have already proved
              valuable in the study of discrimination and of language; they
              promise a great deal in the study of learning and memory; and it
              has even been proposed that they can be useful in the study of
              concept formation. A lot of questions that seemed fruitless
              twenty or thirty years ago may now be worth another look. In
              fact, I feel that my story here must stop just as it begins to
              get really interesting. And finally, what about the magical
              number seven? What about the seven wonders of the world, the
              seven seas, the seven deadly sins, the seven daughters of Atlas
              in the Pleiades, the seven ages of man, the seven levels of hell,
              the seven primary colors, the seven notes of the musical scale,
              and the seven days of the week? What about the seven-point rating
              scale, the seven categories for absolute judgment, the seven
              objects in the span of attention, and the seven digits in the
              span of immediate memory? For the present I propose to withhold
              judgment. Perhaps there is something deep and profound behind all
              these sevens, something just calling out for us to discover it.
              But I suspect that it is only a pernicious, Pythagorean
              coincidence.",
  journal  = "Psychological review",
  volume   =  63,
  number   = "81-97",
  pages    = "343--352",
  year     =  1956,
  issn     = "0033-295X",
  pmid     = "8022966",
  doi      = "10.1037/h0043158"
}

@ARTICLE{Gathercole1995-us,
  title    = "Is nonword repetition a test of phonological memory or long-term
              knowledge? It all depends on the nonwords",
  author   = "Gathercole, S E",
  abstract = "The extent to which children's performance on tests of nonword
              repetition is constrained by phonological working memory and
              long-term lexical knowledge was investigated in a longitudinal
              study of 70 children tested at 4 and 5 years of age. At each time
              of testing, measures of nonword repetition, memory span, and
              vocabulary knowledge were obtained. Reading ability was also
              assessed at 5 years. At both ages, repetition accuracy was
              greater for nonwords of high- rather than low-rated wordlikeness,
              and memory-span measures were more closely related to repetition
              accuracy for the low-wordlike than for the high-wordlike stimuli.
              It is argued that these findings indicate that nonword repetition
              for unwordlike stimuli is largely dependent on phonological
              memory, whereas repetition for wordlike items is also mediated by
              long-term lexical knowledge and is therefore less sensitive to
              phonological memory constraints. Reading achievement was
              selectively linked with earlier repetition scores for
              low-wordlike nonwords, suggesting a phonological memory
              contribution in the early stages of reading development.
              Vocabulary knowledge was associated with repetition accuracy for
              both low- and high-wordlike nonwords, consistent with the notion
              that lexical knowledge and nonword repetition share a reciprocal
              developmental relationship.",
  journal  = "Memory \& cognition",
  volume   =  23,
  number   =  1,
  pages    = "83--94",
  year     =  1995,
  issn     = "0090-502X",
  pmid     = "7885268",
  doi      = "10.3758/BF03210559"
}

@ARTICLE{Hecht2001-ti,
  title    = "The relations between phonological processing abilities and
              emerging individual differences in mathematical computation
              skills: a longitudinal study from second to fifth grades",
  author   = "Hecht, S a and Torgesen, J K and Wagner, R K and Rashotte, C a",
  abstract = "The primary purpose of this longitudinal correlational study was
              to examine relations between phonological processing abilities
              and emerging individual differences in math computation skills
              and also to investigate the source of covariation between reading
              and math computation skills in a random sample (n = 201).
              Phonological memory, rate of access to phonological codes in
              long-term memory, and phonological awareness were uniquely
              associated with growth in estimated total number of computation
              procedures mastered (general computation skills) from 92.5 to
              134.8 months in age, although the contributions of the first two
              abilities were developmentally limited. Phonological processing
              almost completely accounted for the associations between reading
              and general computation skills. Evidence of bidirectional
              relations between general computation skills and simple
              arithmetic problem solving speed was found.",
  journal  = "Journal of experimental child psychology",
  volume   =  79,
  number   =  2,
  pages    = "192--227",
  year     =  2001,
  keywords = "arithmetic; emerging individual differences in; further our
              understanding of; mathematical achievement; mathematical cog-;
              mathematical cognition; mathematical computation; mathematical
              computation skills as; nition; phonological processing; reading
              and mathematics; reading and mathematics.; the primary purpose
              of; this investigation was to; well as the",
  issn     = "0022-0965",
  pmid     = "11343408",
  doi      = "10.1006/jecp.2000.2586"
}

@ARTICLE{Cantor1991-uq,
  title    = "Short-term memory, working memory, and verbal abilities: How do
              they relate?",
  author   = "Cantor, Judy and Engle, Randall W and Hamilton, George",
  abstract = "Subjects performance on short-term memory (STM) spans, STM
              probe-recall tasks, and complex working memory (WM) spans was
              used to assess the relationship between STM and WM, and to test
              whether these measures independently relate to verbal abilities.
              Factor analysis indicated that scores on the STM spans and
              probe-recall tasks loaded on a factor that was distinct from the
              WM spans, and regression and part correlations showed that these
              different factors accounted for separate variance in the Verbal
              Scholastic Aptitude Test (VSAT). These results provided evidence
              that STM and WM are different cognitive constructs, both of which
              are important to verbal abilities. It was also shown that within
              STM measures, rehearsal can obscure the relationship between STM
              capacity and abilities. For example, in the probe-recall tasks,
              only performance on final list items correlated with VSAT, and it
              was argued that these items were the most recently represented in
              STM, but had the least opportunity to be rehearsed. It was also
              suggested that digits are easier to rehearse than words, and we
              found that a STM word span correlated with VSAT, but a STM digit
              span did not. Furthermore, in considering each serial position in
              the probe-recall tasks, fewer items correlated with verbal
              abilities when digits were used as stimuli than when words were
              used. These results converge on the notion that rehearsal drives
              down the correlation between STM capacity and abilities. Overall,
              it was concluded that STM and WM tasks do reflect diffferent
              cognitive constructs,both of which seem to be important in
              abilities. In addition, when predicting verbal abilities from a
              STM tasks, the best measure is one in which rehearsal is not
              strongly influencing performance.",
  journal  = "Intelligence",
  volume   =  15,
  number   =  2,
  pages    = "229--246",
  year     =  1991,
  issn     = "0160-2896",
  doi      = "10.1016/0160-2896(91)90032-9"
}

@ARTICLE{De_Smedt2009-qv,
  title     = "Working memory and individual differences in mathematics
               achievement: A longitudinal study from first grade to second
               grade",
  author    = "De Smedt, Bert and Janssen, Rianne and Bouwens, Kelly and
               Verschaffel, Lieven and Boets, Bart and Ghesqui{\`e}re, Pol",
  abstract  = "This longitudinal study examined the relationship between
               working memory and individual differences in mathematics.
               Working memory measures, comprising the phonological loop, the
               visuospatial sketchpad, and the central executive, were
               administered at the start of first grade. Mathematics
               achievement was assessed 4 months later (at the middle of first
               grade) and 1 year later (at the start of second grade). Working
               memory was significantly related to mathematics achievement in
               both grades, showing that working memory clearly predicts later
               mathematics achievement. The central executive was a unique
               predictor of both first- and second-grade mathematics
               achievement. There were age-related differences with regard to
               the contribution of the slave systems to mathematics
               performance; the visuospatial sketchpad was a unique predictor
               of first-grade, but not second-grade, mathematics achievement,
               whereas the phonological loop emerged as a unique predictor of
               second-grade, but not first-grade, mathematics achievement.
               \copyright{} 2009 Elsevier Inc. All rights reserved.",
  journal   = "Journal of experimental child psychology",
  publisher = "Elsevier Inc.",
  volume    =  103,
  number    =  2,
  pages     = "186--201",
  year      =  2009,
  keywords  = "Longitudinal study; Mathematics achievement; Working memory",
  issn      = "0022-0965",
  pmid      = "19281998",
  doi       = "10.1016/j.jecp.2009.01.004"
}

@ARTICLE{Martin1978-kl,
  title    = "Memory span as a measure of individual differences in memory
              capacity",
  author   = "Martin, Maryanne",
  abstract = "Two experiments with a total of 54 college students investigated
              whether the immediate digit span measure traditionally used in
              the assessment of individual differences in cognition is a good
              predictor of performance on other memory tasks. In Exp I, Ss'
              digit spans were not significantly related to their performances
              on either short-term or long-term memory tasks or to theoretical
              measures of their memory store capacities. Memory for the
              temporal occurrence of events, however, proved to be positively
              correlated with digit span. A 2nd experiment confirmed that digit
              span was correlated with memory for the temporal occurrence of
              events, but not with item memory. Thus, it is concluded that an
              individual's digit span reflects the ability to retain
              information about the order of a sequence of events rather than
              the capacity of short- or long-term memory. (23 ref)",
  journal  = "Memory \& cognition",
  volume   =  6,
  number   =  2,
  pages    = "194--198",
  year     =  1978,
  issn     = "0090-502X",
  doi      = "10.3758/BF03197446"
}

@ARTICLE{Bayliss2003-kb,
  title   = "The complexities of complex span: Explaining individual
             differences in working memory in children and adults",
  author  = "Bayliss, Donna M and Jarrold, Christopher and Gunn, Deborah M and
             Baddeley, Alan D",
  journal = "Journal of experimental psychology. General",
  volume  =  132,
  number  =  1,
  pages   = "71--92",
  year    =  2003,
  issn    = "0096-3445",
  doi     = "10.1037/0096-3445.132.1.71"
}

@ARTICLE{Shah1996-ho,
  title    = "The separability of working memory resources for spatial thinking
              and language processing: an individual differences approach",
  author   = "Shah, Priti and Miyake, Akira",
  abstract = "The current study demonstrates the separability of spatial and
              verbal working memory resources among college students. In
              Experiment 1, we developed a spatial span task that taxes both
              the processing and storage components of spatial working memory.
              This measure correlates with spatial ability (spatial
              visualization) measures, but not with verbal ability measures. In
              contrast, the reading span test, a common test of verbal working
              memory, correlates with verbal ability measures, but not with
              spatial ability measures. Experiment 2, which uses an
              interference paradigm to cross the processing and storage demands
              of span tasks, replicates this dissociation and further
              demonstrates that both the processing and storage components of
              working memory tasks are important for predicting performance on
              spatial thinking and language processing tasks.",
  journal  = "Journal of experimental psychology. General",
  volume   =  125,
  number   =  1,
  pages    = "4--27",
  year     =  1996,
  issn     = "0096-3445",
  pmid     = "8851737",
  doi      = "10.1037/0096-3445.125.1.4"
}

@ARTICLE{Howard1980-oy,
  title    = "Syntactic and semantic factors in the classification of nonspeech
              transient patterns",
  author   = "Howard, J H and Ballas, J a",
  abstract = "Investigated in 3 experiments with 36 undergraduates the role of
              both syntactic (i.e., temporal structure) and semantic (i.e.,
              knowledge of the source events) factors in a 2-alternative
              (target/nontarget) categorization task involving patterns of
              nonspeech acoustic transients. Results demonstrate that both
              factors can play an important role in the classification of such
              patterns. Although pattern syntax influenced performance in all 3
              experiments, the effects of syntactic structure were clearest
              when Ss categorized meaningless tonal patterns. Ss who
              categorized a syntactically structured target set performed
              better than did those with an unstructured set. When Ss were
              given explicit descriptive information about the pattern
              components in their instructions, performance actually improved
              for interpretable but not for uninterpretable patterns. It is
              argued that many complex nonspeech patterns have both syntactic
              and semantic structure, which is determined by the sequence of
              source events that produce them. In classifying such patterns, as
              in the case of speech, listeners rely on their knowledge of these
              factors as well as on the perceptual information in the sound
              itself. (14 ref) ((c) 1997 APA/PsycINFO, all rights reserved).",
  journal  = "Perception \& psychophysics",
  volume   =  28,
  number   =  5,
  pages    = "431--439",
  year     =  1980,
  issn     = "0031-5117",
  pmid     = "7208253",
  doi      = "10.3758/BF03204887"
}

@ARTICLE{Reber1967-nq,
  title    = "Implicit learning of artificial grammars",
  author   = "Reber, Arthur S",
  abstract = "Two experiments were carried out to investigate the process by
              which Ss respond to the statistical nature of the stimulus array,
              a process defined as ``implicit learn- ing.'' An artificial
              grammar was used to generate the stimuli. Experiment I showed
              that Ss learned to become increasingly sensitive to the
              grammatical structure of the stimuli, but little was revealed
              about the nature of such learning. Experiment II showed that
              information gathered about the grammar in a memorization task
              could be extended to a recognition task with new stimuli. Various
              analyses of the data strongly implied that Ss were learning to
              respond to the general grammatical nature of the stimuli, rather
              than learning to respond according to specific coding systems
              imposed upon the stimuli. It was argued that this ``implicit''
              learning is similar in nature to the ``differentiation'' process
              of perceptual learning espoused by Gibson and Gibson (1955). In",
  journal  = "Journal of Verbal Learning and Verbal Behavior",
  volume   =  6,
  number   =  6,
  pages    = "855--863",
  year     =  1967,
  issn     = "0022-5371",
  pmid     = "693",
  doi      = "10.1016/S0022-5371(67)80149-X"
}

@ARTICLE{Reber1989-jl,
  title   = "Implicit learning and tacit knowledge",
  author  = "Reber, A S",
  journal = "Journal of experimental psychology. General",
  volume  =  118,
  number  =  3,
  pages   = "219--235",
  year    =  1989,
  issn    = "0096-3445",
  doi     = "10.1037//0096-3445.118.3.219"
}

@ARTICLE{Jacoby1983-zg,
  title    = "Perceptual enhancement: Persistent effects of an experience",
  author   = "Jacoby, L L",
  abstract = "Presenting a word enhances its later perceptual identification.
              This article focuses on the relation between this effect on
              perception and recognition memory. Prior experiments have
              revealed that perceptual enhancement is independent of
              recognition memory and have led to the two types of task being
              identified with separate memory systems. In contrast, the present
              experiments reveal parallel effects on the two types of task.
              Perceptual enhancement persists over days but, like recognition
              memory, is influenced by manipulations of retrieval conditions. I
              conclude that both perceptual and memory tasks rely on the
              retrieval of memory for whole prior processing episodes but can
              differ in terms of the number and nature of retrieval cues that
              they provide. I describe perception and memory within a common
              framework.",
  journal  = "Journal of experimental psychology. Learning, memory, and
              cognition",
  volume   =  9,
  number   =  1,
  pages    = "21--38",
  year     =  1983,
  issn     = "0278-7393",
  pmid     = "6220114",
  doi      = "10.1037/0278-7393.9.1.21"
}

@ARTICLE{Dulany1984-ph,
  title    = "A case of syntactical learning and judgment: How conscious and
              how abstract?",
  author   = "Dulany, Don E and Carlson, Richard a and Dewey, Gerald I",
  abstract = "Examined 2 possible bases for grammatical judgments following
              syntactical learning: unconscious representations of a formal
              grammar, as in A. S. Reber's (see record 1976-21811-001)
              hypothesis of implicit learning, and conscious rules within
              information grammars. 50 undergraduates inspected strings
              generated by a finite-state grammar, viewed either one at a time
              or all at a time, with implicit or explicit learning
              instructions. 15 undergraduates served as controls. In a transfer
              test, Ss and controls judged the grammaticality of grammatical
              and nongrammatical strings and reported the bases for their
              judgments. Concurrent with previous results, Ss correctly
              classified a significant number of novel strings, indicating the
              operation of grammatical abstraction. However, reported rules
              predicted those grammatical judgments without significant
              residual. Ss acquired correlated grammars---personal sets of
              conscious rules, each of limited scope and many of imperfect
              validity. The rules embodied abstractions, consciously
              represented novelty that could account for abstraction embodied
              in judgments. It is argued that a better explanation of these
              results credits grammatical judgments to conscious rules within
              informal grammars rather than to unconscious representations of a
              formal grammar.",
  journal  = "Journal of experimental psychology. General",
  volume   =  113,
  number   =  4,
  pages    = "541--555",
  year     =  1984,
  issn     = "0096-3445",
  doi      = "10.1037/0096-3445.113.4.541"
}

@ARTICLE{Medin1981-vb,
  title    = "Strategies and classification learning",
  author   = "Medin, Douglas L and Smith, Edward E",
  abstract = "unassigned: How do strategies affect the learning of categories
              that lack necessary and sufficient attributes? The usual answer
              is that different strategies correspond to different models.
              Results from the present study provide evidence for an
              alternative view: Strategy variations induced by instructions
              affect only the amount of information represented about
              attributes, not the process operating on these representations.
              96 17-30 yr old Ss were required to classify schematic faces into
              2 categories. Three groups of Ss worked with different sets of
              instructions: form a prototype of each category, learn each
              category as a rule-plus-exception, or standard neutral
              instructions. In addition to learning the faces (Phase 1), Ss
              were given transfer tests on learned and novel faces (Phase 2)
              and speeded categorization tests on learned faces (Phase 3).
              There were performance differences in all 3 phases due to
              instructions, but these results are readily accounted for by
              specific changes in the representations posited by the context
              model of D. L. Medin and M. M. Schaffer (see record
              1979-12633-001); that is, strategies seemed to affect only the
              amount of information stored about each exemplar's attributes.
              (11 ref) (PsycINFO Database Record (c) 2000 APA, all rights
              reserved):",
  journal  = "Journal of experimental psychology. Human learning and memory",
  volume   =  7,
  number   =  4,
  pages    = "241--253",
  year     =  1981,
  issn     = "0096-1515",
  doi      = "10.1037//0278-7393.7.4.241"
}

@ARTICLE{Loui2010-be,
  title    = "Humans rapidly learn grammatical structure in a new musical scale",
  author   = "Loui, Psyche and Wessel, David and Hudson Kam, Carla L",
  journal  = "Music perception",
  volume   =  27,
  number   =  5,
  pages    = "377--388",
  year     =  2010,
  keywords = "auditory perception; between pitches and chords; day is composed
              according; devoto; grammar; jannery; music cognition; music we
              encounter every; over time; piston; preference; principles; rules
              dictate the relationship; statistical learning; these; to
              structural rules and",
  issn     = "0730-7829",
  doi      = "10.1525/mp.2010.27.5.377"
}

@ARTICLE{McKinney1999-ea,
  title    = "A possible neurophysiological basis of the octave enlargement
              effect",
  author   = "McKinney, M F and Delgutte, B",
  abstract = "Although the physical octave is defined as a simple ratio of 2:1,
              listeners prefer slightly greater octave ratios. Ohgushi [J.
              Acoust. Soc. Am. 73, 1694-1700 (1983)] suggested that a temporal
              model for octave matching would predict this octave enlargement
              effect because, in response to pure tones, auditory-nerve
              interspike intervals are slightly larger than the stimulus
              period. In an effort to test Ohgushi's hypothesis, auditory-nerve
              single-unit responses to pure-tone stimuli were collected from
              Dial-anesthetized cats. It was found that although interspike
              interval distributions show clear phase-locking to the stimulus,
              intervals systematically deviate from integer multiples of the
              stimulus period. Due to refractory effects, intervals smaller
              than 5 msec are slightly larger than the stimulus period and
              deviate most for small intervals. On the other hand, first-order
              intervals are smaller than the stimulus period for stimulus
              frequencies less than 500 Hz. It is shown that this deviation is
              the combined effect of phase-locking and multiple spikes within
              one stimulus period. A model for octave matching was implemented
              which compares frequency estimates of two tones based on their
              interspike interval distributions. The model quantitatively
              predicts the octave enlargement effect. These results are
              consistent with the idea that musical pitch is derived from
              auditory-nerve interspike interval distributions.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  106,
  number   =  5,
  pages    = "2679--2692",
  year     =  1999,
  issn     = "0001-4966",
  pmid     = "12",
  arxivid  = "NIHMS150003",
  doi      = "10.1121/1.428098"
}

@ARTICLE{Jiang2012-gv,
  title     = "Unconscious structural knowledge of tonal symmetry: Tang poetry
               redefines limits of implicit learning",
  author    = "Jiang, Shan and Zhu, Lei and Guo, Xiuyan and Ma, Wendy and Yang,
               Zhiliang and Dienes, Zoltan",
  abstract  = "The study aims to help characterize the sort of structures about
               which people can acquire unconscious knowledge. It is already
               well established that people can implicitly learn n-grams
               (chunks) and also repetition patterns. We explore the
               acquisition of unconscious structural knowledge of symmetry.
               Chinese Tang poetry uses a specific sort of mirror symmetry, an
               inversion rule with respect to the tones of characters in
               successive lines of verse. We show, using artificial poetry to
               control both n-gram structure and repetition patterns, that
               people can implicitly learn to discriminate inversions from
               non-inversions, presenting a challenge to existing models of
               implicit learning.",
  journal   = "Consciousness and cognition",
  publisher = "Elsevier Inc.",
  volume    =  21,
  number    =  1,
  pages     = "476--486",
  year      =  2012,
  keywords  = "Adult; China; Consciousness; Female; Humans; Learning; Male;
               Pattern Recognition; Physiological; Poetry as Topic;
               Psycholinguistics; Speech Acoustics",
  issn      = "1053-8100, 1090-2376",
  pmid      = "22273573",
  doi       = "10.1016/j.concog.2011.12.009"
}

@ARTICLE{Bigand1998-fu,
  title   = "Implicit learning of an artificial grammar of musical timbres",
  author  = "Bigand, E and Perruchet, Pierre and Boyer, Maud",
  journal = "Cahiers de Psychologie Cognitive/Current Psychology of Cognition",
  volume  =  17,
  number  =  3,
  pages   = "577--600",
  year    =  1998
}

@ARTICLE{Knowlton1994-hw,
  title    = "The information acquired during artificial grammar learning",
  author   = "Knowlton, Barbara J and Squire, Larry R",
  abstract = "In an artificial grammar learning task, amnesic patients
              classified test items as well as normal subjects did. Item
              similarity did not affect grammaticality judgments when similar
              and nonsimilar test items were balanced for the frequency with
              which bigrams and trigrams (chunks) that appeared in the training
              set also appeared in the test items. Amnesic patients performed
              like normal subjects. The results suggest that concrete
              information about letter chunks can influence gramaticality
              judgments and that this information is acquired implicitly. The
              similarity of whole test items to training items does not appear
              to affect grammaticality judgments.",
  journal  = "Journal of experimental psychology. Learning, memory, and
              cognition",
  volume   =  20,
  number   =  1,
  pages    = "79--91",
  year     =  1994,
  keywords = "Aged; Amnesia; Amnesia: diagnosis; Amnesia: physiopathology;
              Amnesia: psychology; Brain; Brain: physiopathology; Female;
              Humans; Language; Learning; Male; Middle Aged; Wechsler Scales",
  issn     = "0278-7393",
  pmid     = "8138790",
  doi      = "10.1037/0278-7393.20.1.79"
}

@ARTICLE{Fiser2002-ah,
  title   = "Statistical learning of higher-order temporal structure from
             visual shape sequences",
  author  = "Fiser, J{\'o}zsef and Aslin, Richard N",
  journal = "Journal of experimental psychology. Learning, memory, and
             cognition",
  volume  =  28,
  number  =  3,
  pages   = "458--467",
  year    =  2002,
  issn    = "0278-7393",
  doi     = "10.1037//0278-7393.28.3.458"
}

@ARTICLE{Saffran1997-nu,
  title    = "Incidental language learning: Listening (and learning) out of the
              corner of your ear",
  author   = "Saffran, Jenny R and Newport, Elissa L and Aslin, Richard N and
              Tunick, Rachel a and Barrueco, Sandra",
  abstract = "Abstract---Two experiments investigated the performance of first-
              grade children and adults on an incidental language-learning
              task. Learning entailed word segmentation from continuous speech,
              an initial and crucial component of language acquisition.
              Subjects were briefly exposed to an unsegmented artificial
              language, pre- sented auditorily, in which the only cues to word
              boundaries were the transitional probabilities between syllables.
              Subjects were not told that they were listening to a language, or
              even to listen at all; rather, they were engaged in a cover task
              of creating computer illustrations. Both adults and children
              learned the words of the language. Moreover, the children
              performed as well as the adults. These data suggest that a
              statistical learning mechanism (transi- tional probability
              computation) is able to operate incidentally and, surprisingly,
              as well in children as in adults.",
  journal  = "Psychological science",
  volume   =  8,
  number   =  2,
  pages    = "101--105",
  year     =  1997,
  issn     = "0956-7976",
  pmid     = "1560574",
  doi      = "10.1111/j.1467-9280.1997.tb00690.x"
}

@ARTICLE{Saffran1996-lz,
  title    = "Word segmentation: The role of distributional cues",
  author   = "Saffran, Jenny R and Newport, Elissa L and Aslin, Richard N",
  abstract = "One of the infant's first tasks in language acquisition is to
              discover the words embedded in a mostly continuous speech stream.
              This learning problem might be solved by using distributional
              cues to word boundaries---for example, by computing the
              transitional probabilities between sounds in the language input
              and using the relative strengths of these probabilities to
              hypothesize word boundaries. The learner might be further aided
              by language-specific prosodic cues correlated with word
              boundaries. As a first step in testing these hypotheses, we
              briefly exposed adults to an artificial language in which the
              only cues available for word segmentation were the transitional
              probabilities between syllables. Subjects were able to learn the
              words of this language. Furthermore, the addition of certain
              prosodic cues served to enhance performance. These results
              suggest that distributional cues may play an important role in
              the initial word segmentation of language learners.",
  journal  = "Journal of memory and language",
  volume   =  35,
  number   =  4,
  pages    = "606--621",
  year     =  1996,
  issn     = "0749-596X",
  doi      = "10.1006/jmla.1996.0032"
}

@ARTICLE{Saffran1996-px,
  title   = "Statistical learning by 8-month old infants",
  author  = "Saffran, J R and Aslin, R N and Newport, Elissa L",
  journal = "Science",
  volume  =  274,
  number  =  5294,
  pages   = "1926--1928",
  year    =  1996,
  issn    = "0036-8075",
  pmid    = "8943209",
  doi     = "10.1126/science.274.5294.1926"
}

@ARTICLE{Aslin1998-th,
  title    = "Computation of conditional probability statistics by 8-month-old
              infants",
  author   = "Aslin, R N and Saffran, J R and Newport, E L",
  abstract = "A recent report demonstrated that 8-month-olds can segment a
              continuous stream of speech syllables, containing no acoustic or
              prosodic cues to word boundaries, into wordlike units after only
              2 min of listening experience (Saffran, Aslin, \& Newport, 1996).
              Thus, a powerful learning mechanism capable of extracting
              statistical information from fluent speech is available early in
              development. The present study extends these results by
              documenting the particular type of statistical
              computationtransitional (conditional) probabilityused by infants
              to solve this word-segmentation task. An artificial language
              corpus, consisting of a continuous stream of trisyllabic nonsense
              words, was presented to 8-month-olds for 3 min. A
              postfamiliarization test compared the infants' responses to words
              versus part-words (trisyllabic sequences spanning word
              boundaries). The corpus was constructed so that test words and
              part-words were matched in frequency, but differed in their
              transitional probabilities. Infants showed reliable
              discrimination of words from part-words, thereby demonstrating
              rapid segmentation of continuous speech into words on the basis
              of transitional probabilities of syllable pairs.",
  journal  = "Psychological science",
  volume   =  9,
  number   =  4,
  pages    = "321--324",
  year     =  1998,
  issn     = "0956-7976",
  doi      = "10.1111/1467-9280.00063"
}

@ARTICLE{Reber1971-op,
  title   = "Event tracking in probability learning",
  author  = "Reber, Arthur S and Millward, Richard B",
  journal = "The American journal of psychology",
  volume  =  84,
  number  =  1,
  pages   = "85--99",
  year    =  1971,
  issn    = "0002-9556"
}

@ARTICLE{Millward1972-xd,
  title   = "Probability learning: Contingent-event schedules with lags",
  author  = "Millward, Richard B and Reber, Arthur S",
  journal = "The American journal of psychology",
  volume  =  85,
  number  =  1,
  pages   = "81--98",
  year    =  1972,
  issn    = "0002-9556"
}

@ARTICLE{Lewicki1988-xf,
  title    = "Acquisition of procedural knowledge about a pattern of stimuli
              that cannot be articulated",
  author   = "Lewicki, Pawel and Hill, Thomas and Bizot, E",
  abstract = "This research demonstrates a process of nonconscious acquisition
              of informa- tion about a pattern of stimuli and the facilitating
              influence of this knowledge on subjects' subsequent performance.
              Subjects were exposed to a sequence of frames containing a
              target, and their task was to search for the target in each
              frame. The sequence of target locations followed a complex
              pattern. The specific sample of subjects was selected to ensure
              that they would be sufficiently moti- vated and that they would
              have appropriate analytical and verbal skills to report whatever
              they experienced while participating in the task: All subjects
              were fac- ulty members of a psychology department. Extensive
              postexperimental inter- views with subjects indicated that none
              of them noticed anything even remotely similar to the actual
              nature of the manipulation (i.e., the pattern). However, the
              accuracy and latency of their responses indicated that, in fact,
              they had acquired a specific working knowledge about the pattern,
              and that this knowledge facili- tated their performance. The
              results demonstrate that nonconsciously acquired knowledge can
              automatically be utilized to facilitate performance, without re-
              quiring conscious awareness or control over this knowledge. This
              phenomenon is discussed as a ubiquitous process involved in the
              development of both elementary and high-level cognitive skills.",
  journal  = "Cognitive psychology",
  volume   =  20,
  number   =  1,
  pages    = "24--37",
  year     =  1988,
  issn     = "0010-0285",
  pmid     = "3338266",
  doi      = "10.1016/0010-0285(88)90023-0"
}

@ARTICLE{Lewicki1987-qy,
  title    = "Unconscious acquisition of complex procedural knowledge",
  author   = "Lewicki, Pawel and Czyzewska, Maria and Hoffman, Hunter",
  abstract = "This research demonstrates a process of acquisition of
              information about a complex pattern of stimuli and the
              facilitating influence of this knowledge on subjects' subsequent
              performance. In two experiments, subjects were exposed for 12 hr
              to a sequence of frames containing a target, and their task was
              to search for the target in each frame. The sequence was divided
              into logical blocks of seven trials each. Locations of the target
              in the seventh trial of each block were predictable on the basis
              of the specific sequences of target locations in four out of the
              previous six trials. Pilot studies and extensive postexperimental
              interviews indicated that none of the subjects noticed anything
              even close to the real nature of the manipulation (i.e., the
              pattern). However, the predicted patterns of latency of their
              responses to the critical trials indicate that they had, in fact,
              acquired some intuitive (unconscious) knowledge about how the
              pattern of prior trials was related to the critical trial. The
              phenomenon is discussed as a ubiquitous unconscious process
              involved in the development of both elementary and high-level
              cognitive skills.",
  journal  = "Journal of experimental psychology. Learning, memory, and
              cognition",
  volume   =  13,
  number   =  4,
  pages    = "523--530",
  year     =  1987,
  issn     = "0278-7393",
  pmid     = "910",
  doi      = "10.1037/0278-7393.13.4.523"
}

@ARTICLE{Lewicki1986-uq,
  title    = "Processing information about covariations that cannot be
              articulated",
  author   = "Lewicki, Pawel",
  abstract = "Processing of covariation (among features) present in stimulus
              material was investigated. Subjects were unable to articulate the
              manipulated covariation between verbally described psychological
              char- acteristics and appearance of a set of stimulus persons.
              Based on the two-stage question answering model (Glucksberg \&
              McCloskey, 1981), it was hypothesized that if the information
              related to the manipulated covariation was processed and
              registered, it would result in an increase of processing time for
              the questions that might be considered relevant to the
              covariation. The pattern of response latencies obtained in each
              of 3 experiments conformed exactly to the predictions. In 2 of
              these ex- periments, effects of the stimulus material on
              subjects' subsequent judgments were found, consistent with the
              model. Subjects behaved as if they had ``learned'' the rule
              (implied by the covariation) and followed it in their subsequent
              judgments. The demonstrated phenomenon pertains to an important
              and presumably ubiquitous aspect of processing categorical
              information.",
  journal  = "Journal of experimental psychology. Learning, memory, and
              cognition",
  volume   =  12,
  number   =  1,
  pages    = "135--146",
  year     =  1986,
  issn     = "0278-7393",
  doi      = "10.1037/0278-7393.12.1.135"
}

@ARTICLE{Perruchet1990-yk,
  title    = "Synthetic grammar learning: Implicit rule abstraction or explicit
              fragmentary knowledge?",
  author   = "Perruchet, Pierre and Pacteau, Chantal",
  abstract = "3 experiments were designed to demonstrate that classifying new
              letter strings as grammatical (i.e., conforming to a set of rules
              called a synthetic grammar) or ungrammatical may proceed from
              fragmentary conscious knowledge of the bigrams constituting the
              grammatical strings displayed in the study phase, rather than
              from an unconscious structured representation of the grammar, as
              A. S. Reber (see record 1989-38920-001) contended. In Experiment
              1, grammaticality judgments of subjects initially studying
              grammatical letter strings did not differ from judgments by
              subjects learning from a list of the bigrams making up these
              strings. In Experiment 2, judgments about nongrammatical strings
              composed of valid bigrams placed in invalid locations were
              extremely poor, although better than chance. In Experiment 3 the
              explicit knowledge of bigrams as assessed by a recognition
              procedure appeared sufficient to account for observed performance
              on a standard test of grammaticality. (PsycINFO Database Record
              (c) 2002 APA, all rights reserved) LHM: UQ Library Call No. BF1
              .J655 SS\&H Journal holding: 1(1975)-129(2000);130(2001)-",
  journal  = "Journal of experimental psychology. General",
  volume   =  119,
  number   =  3,
  pages    = "264--275",
  year     =  1990,
  issn     = "0096-3445",
  pmid     = "685",
  doi      = "10.1037/0096-3445.119.3.264"
}

@ARTICLE{Creel2012-pr,
  title    = "Similarity-based restoration of metrical information: different
              listening experiences result in different perceptual inferences",
  author   = "Creel, Sarah C",
  abstract = "How do perceivers apply knowledge to instances they have never
              experienced before? On one hand, listeners might use idealized
              representations that do not contain specific details. On the
              other, they might recognize and process information based on more
              detailed memory representations. The current study examined the
              latter possibility with respect to musical meter perception,
              previously thought to be computed based on highly-idealized
              (isochronous) internal representations. In six experiments,
              listeners heard sets of metrically-ambiguous melodies. Each
              melody was played in a simultaneous musical context with
              unambiguous metrical cues (3/4 or 6/8). Cross-melody similarity
              was manipulated by pairing certain cues-timbre (musical
              instrument) and motif content (2-6-note patterns)-with each
              meter, or distributing cues across meters. After multiple
              exposures, listeners heard each melody without context, and
              judged metrical continuations (all Experiments) or familiarity
              (Experiments 5-6). Responses were assessed for ``metrical
              restoration''-the tendency to make metrical judgments that fit
              the melody's previously-heard metrical context. Cross-melody
              similarity affected the presence and degree of metrical
              restoration, and timbre affected familiarity. Results suggest
              that metrical processing may be calculated based on fairly
              detailed representations rather than idealized isochronous
              pulses, and is dissociated somewhat from familiarity judgments.
              Implications for theories of meter perception are discussed.",
  journal  = "Cognitive psychology",
  volume   =  65,
  number   =  2,
  pages    = "321--351",
  year     =  2012,
  keywords = "Auditory Perception; Cues; Humans; Learning; Music; Recognition
              (Psychology); Time Perception; Young Adult",
  issn     = "0010-0285, 1095-5623",
  pmid     = "22659582",
  doi      = "10.1016/j.cogpsych.2012.04.004"
}

@ARTICLE{McMurray2008-xq,
  title    = "Context effects on musical chord categorization: Different forms
              of top-down feedback in speech and music?",
  author   = "McMurray, Bob and Dennhardt, Joel L and Struck-Marcell, Andrew",
  abstract = "A critical issue in perception is the manner in which top-down
              expectancies guide lower-level perceptual processes. In speech, a
              common paradigm is to construct continua ranging between two
              phonetic endpoints and to determine how higher level lexical
              context influences the perceived boundary. We applied this
              approach to music, presenting subjects with major/minor triad
              continua after brief musical contexts. Two experiments yielded
              results that differed from classic results in speech perception.
              In speech, context generally expands the category of the expected
              stimuli. We found the opposite in music: the major/minor boundary
              shifted toward the expected category, contracting it. Together,
              these experiments support the hypothesis that musical expectancy
              can feed back to affect lower-level perceptual processes.
              However, it may do so in a way that differs fundamentally from
              what has been seen in other domains.",
  journal  = "Cognitive science",
  volume   =  32,
  number   =  785026720,
  pages    = "893--920",
  year     =  2008,
  keywords = "activation; context effects; feedback; interactive; music
              perception; perceptual categorization; speech perception; triad
              identification",
  issn     = "0364-0213, 1551-6709",
  pmid     = "21490878",
  doi      = "10.1080/03640210802222021"
}

@BOOK{Graham1995-lw,
  title    = "{ANSI} Common Lisp",
  author   = "Graham, Paul",
  abstract = "This book provides an excellent introduction to Common Lisp. In
              addition to chapters covering the basic language concepts, there
              are sections discussing the Common Lisp object system (CLOS) and
              speed considerations in Lisp. Three fair-sized examples of
              nontrivial Lisp projects are also included. The book's clear and
              engaging format explains complicated constructs simply. This
              format makes ANSI Common Lisp accessible to a general
              audience-even those who have never programmed before. The book
              also provides an excellent perspective on the value of using
              Lisp.",
  pages    = "432",
  year     =  1995,
  isbn     = "9780133708752"
}

@PHDTHESIS{Aronoff2007-gg,
  title  = "The role of similarity in restoring missing notes in music",
  author = "Aronoff, Justin",
  year   =  2007
}

@INPROCEEDINGS{Sasaki2008-zy,
  title     = "Effects of leading and following contexts on the music sound
               restoration",
  booktitle = "Proceedings of the 10th International Conference on Music
               Perception and Cognition",
  author    = "Sasaki, Takayuki",
  year      =  2008,
  address   = "Sapporo, Japan"
}

@ARTICLE{Simonis2015-lu,
  title  = "Package ` seewave '",
  author = "Simonis, Caroline and Lellouch, Laurent and Brown, Ethan C and
            Depraetere, Marion and Desjonqueres, Camille and Fabianek, Francois
            and Gasc, Amandine and Lazerte, Stefanie and Lees, Jonathan and
            Marchal, Jean and Pavoine, Sandrine and Stotz, Alicia and Witthoft,
            Carl G and Zhivomirov, Hristo",
  year   =  2015
}

@BOOK{Macmillan2005-fn,
  title     = "Detection theory: A user's guide",
  author    = "Macmillan, Neil A and Creelman, C Douglas",
  publisher = "Lawrence Erlbaum",
  year      =  2005,
  address   = "New York, NY"
}

@INCOLLECTION{Levitin1999-ga,
  title     = "Memory for musical attributes",
  booktitle = "Music, cognition and computerized sound: An introduction to
               psychoacoustics",
  author    = "Levitin, Daniel J",
  editor    = "Cook, P R",
  publisher = "MIT Press",
  pages     = "209--227",
  year      =  1999,
  address   = "Cambridge, MA"
}

@BOOK{McDonald1999-iw,
  title     = "Test theory: A unified treatment",
  author    = "McDonald, R P",
  publisher = "Erlbaum",
  year      =  1999,
  address   = "Hillsdale, NJ"
}

@ARTICLE{Tervaniemi2001-ar,
  title    = "Superior formation of cortical memory traces for melodic patterns
              in musicians",
  author   = "Tervaniemi, Mari and Rytk{\"o}nen, Mika and Schr{\"o}ger, Erich
              and Ilmoniemi, Risto J and N{\"a}{\"a}t{\"a}nen, Risto",
  abstract = "The human central auditory system has a remarkable ability to
              establish memory traces for invariant features in the acoustic
              environment despite continual acoustic variations in the sounds
              heard. By recording the memory-related mismatch negativity (MMN)
              component of the auditory electric and magnetic brain responses
              as well as behavioral performance, we investigated how subjects
              learn to discriminate changes in a melodic pattern presented at
              several frequency levels. In addition, we explored whether
              musical expertise facilitates this learning. Our data show that
              especially musicians who perform music primarily without a score
              learn easily to detect contour changes in a melodic pattern
              presented at variable frequency levels. After learning, their
              auditory cortex detects these changes even when their attention
              is directed away from the sounds. The present results thus show
              that, after perceptual learning during attentive listening has
              taken place, changes in a highly complex auditory pattern can be
              detected automatically by the human auditory cortex and, further,
              that this process is facilitated by musical expertise.",
  journal  = "Learning \& memory",
  volume   =  8,
  number   =  5,
  pages    = "295--300",
  year     =  2001,
  issn     = "1072-0502",
  pmid     = "11584077",
  doi      = "10.1101/lm.39501"
}

@BOOK{Raykov1999-tf,
  title     = "Introduction to psychometric theory",
  author    = "Raykov, T and Marcoulides, G A",
  publisher = "Routledge",
  year      =  1999,
  address   = "New York, NY"
}

@ARTICLE{Dowling1995-pr,
  title    = "The time course of recognition of novel melodies",
  author   = "Dowling, W Jay and Kwak, S and Andrews, Melinda W",
  abstract = "Seven experiments explored the time course of recognition of
              brief novel melodies. In a continuous-running-memory task,
              subjects recognized melodic transpositions following delays up to
              2.0 min. The delays were either empty or filled with other
              melodies. Test items included exact transpositions (T),
              same-contour lures (SC) with altered pitch intervals, and
              different-contour lures (DC); DCs differed from Ts in the pattern
              of ups and downs of pitch. With this design, we assessed
              subjects' discrimination of detailed changes in pitch intervals
              (T/SC discrimination) as well as their discrimination of contour
              changes (T/DC). We used both artificial and ``real'' melodies.
              Artificial melodies differed in conformity to a musical key,
              being tonal or atonal. After empty delays, T/DC discrimination
              was superior to T/SC discrimination. Surprisingly, after filled
              delays, T/SC discrimination was superior to T/DC. When only
              filled delays were tested, T/SC discrimination did not decline
              over the longest delays. T/DC performance declined more than did
              T/SC performance across both empty and filled delays. Tonality
              was an important factor only for T/SC discrimination after filled
              delays. T/DC performance was better with rhythmically intact folk
              melodies than with artificial isochronous melodies. Although T/SC
              performance improved over filled delays, it did not overtake T/DC
              performance. These results suggest that (1) contour and
              pitch-interval information make different contributions to
              recognition, with contour dominating performance after brief
              empty delays and pitch intervals dominating after longer filled
              delays; (2) a coherent tonality facilitates the encoding of
              pitch-interval patterns of melodies; and (3) the rich
              melodic-rhythmic contours of real melodies facilitate T/DC
              discrimination. These results are discussed in terms of automatic
              and controlled processing of melodic information.",
  journal  = "Perception \& psychophysics",
  volume   =  57,
  number   =  2,
  pages    = "136--149",
  year     =  1995,
  issn     = "0031-5117",
  pmid     = "7885812",
  doi      = "10.3758/BF03206500"
}

@INCOLLECTION{Chase1981-uj,
  title     = "Skilled memory",
  booktitle = "Cognitive skills and their acquisition",
  author    = "Chase, W G and Ericsson, K A",
  editor    = "Anderson, J R",
  publisher = "Erlbaum",
  pages     = "141--189",
  year      =  1981,
  address   = "Hillsdale, NJ"
}

@ARTICLE{Shannon1948-li,
  title    = "A mathematical theory of communication",
  author   = "Shannon, Claude E",
  abstract = "The recent development of various methods of modulation such as
              PCM and PPM which exchange bandwidth for signal-to-noise ratio
              has intensified the interest in a general theory of
              communication. A basis for such a theory is contained in the
              important papers of Nyquist and Hartley on this subject. In the
              present paper we will extend the theory to include a number of
              new factors, in particular the effect of noise in the channel,
              and the savings possible due to the statistical structure of the
              original message and due to the nature of the final destination
              of the information. The fundamental problem of communication is
              that of reproducing at one point either exactly or approximately
              a message selected at another point. Frequently the messages have
              meaning; that is they refer to or are correlated according to
              some system with certain physical or conceptual entities. These
              semantic aspects of communication are irrelevant to the
              engineering problem. The significant aspect is that the actual
              message is one selected from a set of possible messages. The
              system must be designed to operate for each possible selection,
              not just the one which will actually be chosen since this is
              unknown at the time of design. If the number of messages in the
              set is finite then this number or any monotonic function of this
              number can be regarded as a measure of the information produced
              when one message is chosen from the set, all choices being
              equally likely. As was pointed out by Hartley the most natural
              choice is the logarithmic function. Although this definition must
              be generalized considerably when we consider the influence of the
              statistics of the message and when we have a continuous range of
              messages, we will in all cases use an essentially logarithmic
              measure.",
  journal  = "The Bell System Technical Journal",
  volume   =  27,
  number   =  3,
  pages    = "379--423 and 623--656",
  year     =  1948,
  issn     = "0724-6811",
  pmid     = "9230594",
  arxivid  = "chao-dyn/9411012",
  doi      = "10.1145/584091.584093"
}

@INCOLLECTION{Halpern2010-oj,
  title     = "Memory for melodies",
  booktitle = "Music Perception",
  author    = "Halpern, Andrea R and Bartlett, James C",
  editor    = "Jones, Mari Riess and Popper, Arthur N and Fay, Richard R",
  publisher = "Springer-Verlag",
  pages     = "233--258",
  year      =  2010,
  address   = "New York, NY"
}

@BOOK{Rasch1960-zd,
  title     = "Probabilistic models for some intelligence and attainment tests",
  author    = "Rasch, G",
  publisher = "University of Chicago Press",
  year      =  1960,
  address   = "Chicago, IL"
}

@ARTICLE{Tillmann2000-ag,
  title    = "Implicit learning of tonality: A self-organizing approach",
  author   = "Tillmann, Barbara and Bharucha, Jamshed J and Bigand, E",
  journal  = "Psychological review",
  volume   =  107,
  number   =  4,
  pages    = "885--913",
  year     =  2000,
  keywords = "Music cognition",
  issn     = "0033-295X",
  doi      = "10.1037/0033-295X.107.4.885"
}

@ARTICLE{Johnson2012-nx,
  title    = "Semantic priming of familiar songs",
  author   = "Johnson, Sarah K and Halpern, Andrea R",
  journal  = "Memory \& cognition",
  volume   =  40,
  number   =  4,
  pages    = "579--593",
  year     =  2012,
  keywords = "music; priming; semantic memory",
  issn     = "0090-502X",
  doi      = "10.3758/s13421-011-0175-z"
}

@ARTICLE{Creel2004-fx,
  title    = "Distant melodies: Statistical learning of nonadjacent
              dependencies in tone sequences",
  author   = "Creel, Sarah C and Newport, Elissa L and Aslin, Richard N",
  abstract = "Human listeners can keep track of statistical regularities among
              temporally adjacent elements in both speech and musical streams.
              However, for speech streams, when statistical regularities occur
              among nonadjacent elements, only certain types of patterns are
              acquired. Here, using musical tone sequences, the authors
              investigate nonadjacent learning. When the elements were all
              similar in pitch range and timbre, learners acquired moderate
              regularities among adjacent tones but did not acquire highly
              consistent regularities among nonadjacent tones. However, when
              elements differed in pitch range or timbre, learners acquired
              statistical regularities among the similar, but temporally
              nonadjacent, elements. Finally, with a moderate grouping cue,
              both adjacent and nonadjacent statistics were learned, indicating
              that statistical learning is governed not only by temporal
              adjacency but also by Gestalt principles of similarity.",
  journal  = "Journal of experimental psychology. Learning, memory, and
              cognition",
  volume   =  30,
  number   =  5,
  pages    = "1119--1130",
  year     =  2004,
  issn     = "0278-7393",
  pmid     = "15355140",
  doi      = "10.1037/0278-7393.30.5.1119"
}

@ARTICLE{Endress2010-fh,
  title    = "Learning melodies from non-adjacent tones",
  author   = "Endress, Ansgar D",
  abstract = "Language acquisition might heavily rely on statistical learning
              mechanisms. This has led many researchers to investigate the
              computational constraints that limit such learning. In
              particular, it has been argued that statistical relations among
              non-adjacent items cannot be tracked, as this might lead to a
              ``computational explosion'' making statistical learning
              intractable. In line with this view, previous research suggests
              that listeners cannot track relations among non-adjacent musical
              tones (Creel, Newport, \& Aslin, 2004). Here I show that
              participants readily track non-adjacent tone relations when these
              are implemented in a musically meaningful way. Specifically,
              participants readily track non-adjacent tone relations in tonal
              melodies, but find it more difficult to track non-adjacent tone
              relations in random melodies, suggesting that non-adjacent
              relations are easier to track when listeners face ``ecological'',
              musically meaningful stimuli.",
  journal  = "Acta psychologica",
  volume   =  135,
  number   =  2,
  pages    = "182--190",
  year     =  2010,
  keywords = "Adolescent; Adult; Female; Humans; Italy; Learning; Male; Music;
              Pattern Recognition; Physiological; Probability; United States",
  issn     = "0001-6918, 1873-6297",
  pmid     = "20605014",
  doi      = "10.1016/j.actpsy.2010.06.005"
}

@ARTICLE{Loui2009-ym,
  title    = "A generalized mechanism for perception of pitch patterns",
  author   = "Loui, Psyche and Wu, E H and Wessel, D L and Knight, R T",
  journal  = "Journal of Neuroscience",
  volume   =  29,
  number   =  2,
  pages    = "454--459",
  year     =  2009,
  keywords = "auditory perception; event-related potentials; mismatch
              negativity; mmn; music; pattern processing; probability learning",
  issn     = "0270-6474",
  doi      = "10.1523/JNEUROSCI.4503-08.2009"
}

@ARTICLE{Altmann1995-xl,
  title  = "Modality independence of implicitly learned grammatical knowledge",
  author = "Altmann, Gerry T M and Dienes, Zolt{\'a}n and Goode, Alastair",
  year   =  1995
}

@ARTICLE{Dienes2004-dz,
  title    = "Can musical transformations be implicitly learned?",
  author   = "Dienes, Zolt{\'a}n and Longuet-Higgins, Christopher",
  journal  = "Cognitive science",
  volume   =  28,
  pages    = "531--558",
  year     =  2004,
  keywords = "chunks; implicit learning; music; serialism; unconscious
              knowledge",
  issn     = "0364-0213",
  doi      = "10.1016/j.cogsci.2004.03.003"
}

@ARTICLE{Loui2008-zm,
  title    = "Learning and liking an artificial musical system: Effects of set
              size and repeated exposure",
  author   = "Loui, Psyche and Wessel, David",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  volume   =  12,
  number   =  2,
  pages    = "207--230",
  year     =  2008,
  keywords = "computer-aided drug design; cyclophilin; free energy
              perturbation; hiv; reverse transcriptase",
  issn     = "1029-8649"
}

@ARTICLE{Kuhn2006-vs,
  title   = "Differences in the types of musical regularity learnt in
             incidental- and intentional-learning conditions",
  author  = "Kuhn, Gustav and Dienes, Zolt{\'a}n",
  journal = "The Quarterly journal of experimental psychology",
  volume  =  59,
  number  =  10,
  pages   = "1725--1744",
  year    =  2006,
  issn    = "0033-555X, 1747-0218",
  doi     = "10.1080/17470210500438361"
}

@ARTICLE{Bly2009-zu,
  title   = "Domain-specific learning of grammatical structure in musical and
             phonological sequences",
  author  = "Bly, Benjamin Martin and Carri{\'o}n, Ricardo E and Rasch,
             Bj{\"o}rn",
  journal = "Memory \& cognition",
  volume  =  37,
  number  =  1,
  pages   = "10--20",
  year    =  2009,
  issn    = "0090-502X",
  doi     = "10.3758/MC.37.1.10"
}

@ARTICLE{Tillmann2004-ad,
  title    = "Implicit Learning of Musical Timbre Sequences: Statistical
              Regularities Confronted With Acoustical ({Dis)Similarities}",
  author   = "Tillmann, Barbara and McAdams, Stephen",
  abstract = "The present study investigated the influence of acoustical
              characteristics on the implicit learning of statistical
              regularities (transition probabilities) in sequences of musical
              timbres. The sequences were constructed in such a way that the
              acoustical dissimilarities between timbres potentially created
              segmentations that either supported (S1) or contradicted (S2) the
              statistical regularities or were neutral (S3). In the learning
              group, participants first listened to the continuous timbre
              sequence and then had to distinguish statistical units from new
              units. In comparison to a control group without the exposition
              phase, no interaction between sequence type and amount of
              learning was observed: Performance increased by the same amount
              for the three sequences. In addition, performance reflected an
              overall preference for acoustically similar timbre units. The
              present outcome extends previous data from the domain of implicit
              learning to complex nonverbal auditory material. It further
              suggests that listeners become sensitive to statistical
              regularities despite acoustical characteristics in the material
              that potentially affect grouping. (PsycINFO Database Record (c)
              2012 APA, all rights reserved)",
  journal  = "Journal of experimental psychology. Learning, memory, and
              cognition",
  volume   =  30,
  number   =  5,
  pages    = "1131--1142",
  year     =  2004,
  keywords = "*Acoustics; *Auditory Stimulation; *Incidental Learning;
              *Learning; *Music; *Music Perception; *Pitch Perception;
              *Stimulus Similarity; Acoustics; Humans; Implicit Learning; Pitch
              Discrimination",
  issn     = "0278-7393",
  pmid     = "15355141",
  doi      = "10.1037/0278-7393.30.5.1131"
}

@ARTICLE{Kuhn2005-vx,
  title    = "Implicit learning of nonlocal musical rules: Implicitly learning
              more than chunks",
  author   = "Kuhn, Gustav and Dienes, Zolt{\'a}n",
  journal  = "Journal of experimental psychology. Learning, memory, and
              cognition",
  volume   =  31,
  number   =  6,
  pages    = "1417--1432",
  year     =  2005,
  keywords = "artificial grammar; implicit learning; inversion rule; mere
              exposure effect; nonlocal rules",
  issn     = "0278-7393",
  doi      = "10.1037/0278-7393.31.6.1417"
}

@INPROCEEDINGS{Loui2006-wc,
  title     = "Acquiring new musical grammars: A statistical learning approach",
  booktitle = "Proceedings of the 9th International Conference on Music
               Perception and Cognition",
  author    = "Loui, Psyche and Wessel, David",
  abstract  = "In the present study we examine the ability of humans to acquire
               knowledge via passive exposure to a new musical system. We
               designed two new musical grammars based on a non-Western tuning
               system, and created melodies as legal exemplars of each grammar.
               In two experiments each participant was exposed to a set of
               melodies from one grammar. Several tests were conducted to
               assess learning, including forced-choice recognition and
               generalization, pre- and post-exposure probe tone ratings, and
               subjective preference ratings. In Experiment 1, five melodies
               were presented repeatedly. Participants correctly recognized and
               preferred melodies they had heard, but failed to generalize
               their recognition to new exemplars of the same grammar. In
               Experiment 2, 15 melodies were presented repeatedly.
               Participants showed some tendency to make generalizations about
               new melodies in their given grammar, and also showed an
               increased sensitivity to the statistics of the musical grammar
               following exposure. Results suggest that larger sets of
               exemplars promote the extraction of regularities underlying the
               examples, whereas smaller sets lead to better recognition and
               are more likely to influence subjective preference.",
  pages     = "1009--1017",
  year      =  2006,
  isbn      = "9788873951551"
}

@ARTICLE{Mullensiefen2009-ls,
  title    = "Court decisions on music plagiarism and the predictive value of
              similarity algorithms",
  author   = "M{\"u}llensiefen, Daniel and Pendzich, M",
  abstract = "Tune plagiarism in pop music is a common and often feverishly
              debated phenomenon which surely has to do with the vast amounts
              of money that individual melodies are able to generate in today's
              pop music business. The similarity between melodies is assumed to
              be a very important factor in a court's decision about whether a
              new tune is an illegitimate version of a pre-existing melody.
              Despite the widespread belief that there is a fixed and simple
              limit to the number of corresponding notes between two melodies,
              actual court decisions are based on far more complex
              considerations regarding the musical material. The legal
              framework and principal features of the legal processing of cases
              of alleged melodic plagiarism are sketched with a focus on U.S.
              copyright law, and selected cases are discussed to highlight the
              corresponding legal practices. Court decisions for cases of
              alleged melodic plagiarism are modeled using a number of
              similarity algorithms. As a ground truth dataset, a collection of
              20 publicly available cases from the last 20 years of U.S.
              jurisdiction is used. The performance of standard similarity
              algorithms (edit distance and n-gram similarity measures) are
              compared to several new similarity algorithms that make use of
              statistical information about the prevalence of chains of pitch
              intervals in a large pop music database. Results indicate that
              these statistically informed algorithms generally outperform the
              comparison algorithms. In particular, algorithms based on
              Tversky's (1977) concept of similarity show a high performance of
              up to 90\% of court decisions correctly predicted. The
              performance and structure of the algorithms is discussed in
              relation to a few example cases, and an outlook on the potential
              and intricacies of the approach is given.",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  volume   =  13,
  number   = "1 Suppl",
  pages    = "257--295",
  year     =  2009,
  issn     = "1029-8649",
  doi      = "10.1177/102986490901300111"
}

@INPROCEEDINGS{Meek2001-vo,
  title     = "Thematic extractor",
  booktitle = "Proceedings of the 2nd Annual International Symposium on Music
               Information Retrieval ({ISMIR} 2001)",
  author    = "Meek, C and Birmingham, William P",
  pages     = "119--128",
  year      =  2001
}

@INPROCEEDINGS{Birmingham2001-lb,
  title     = "{MUSART}: Music retrieval via aural queries",
  booktitle = "Proceedings of the International Symposium on Music Information
               Retrieval",
  author    = "Birmingham, William P and Dannenberg, Roger B and Wakefield,
               Gregory H and Bartsch, Mark and Bykowski, David and Mazzoni,
               Dominic and Meek, Colin and Mellody, Maureen and Rand, William",
  pages     = "73--81",
  year      =  2001
}

@INCOLLECTION{Downie2003-bm,
  title     = "Music Information Retrieval",
  booktitle = "Annual Review of Information Science and Technology 37",
  author    = "Downie, J Stephen",
  editor    = "Cronin, Blaise",
  abstract  = "Myriad difficulties remain to be overcome before the creation,
               deployment, and evaluation of robust, large-scale, and
               content-based Music Information Retrieval (MIR) systems become
               reality. The dizzyingly complex interaction of music's pitch,
               temporal, harmonic, timbral, editorial, textual, and
               bibliographic ``facets,'' for example, demonstrates just one of
               MIR's perplexing problems. The choice of music representation---
               whether symbol-based, audio-based, or both---further compounds
               matters, as each choice determines bandwidth, computation,
               storage, retrieval, and interface requirements and capabilities.
               Overlay the multicultural, multiexperiential, and
               multidisciplinary aspects of music and it becomes apparent that
               the challenges facing MIR research and development are far from
               trivial.",
  publisher = "Information Today",
  pages     = "295--340",
  year      =  2003,
  address   = "Medford, NJ",
  issn      = "0093-402X",
  isbn      = "9783642116735",
  pmid      = "18737979",
  doi       = "10.1002/aris.1440370108"
}

@INCOLLECTION{Crawford1998-ao,
  title     = "String-matching techniques for musical similarity and melodic
               recognition",
  booktitle = "Computing in musicology: Vol. 11. Melodic similarity: Concepts,
               procedures, and applications",
  author    = "Crawford, Tim and Ilipoulos, Costas S and Raman, Rajeev",
  editor    = "Hewlett, W B and Selfridge-Field, E",
  publisher = "MIT Press",
  pages     = "73--199",
  year      =  1998,
  address   = "Cambridge, MA"
}

@ARTICLE{Mongeau1990-vs,
  title   = "Comparison of musical sequences",
  author  = "Mongeau, M and Sankoff, D",
  journal = "Computers and the humanities",
  volume  =  24,
  number  =  3,
  pages   = "161--175",
  year    =  1990,
  issn    = "0010-4817"
}

@INCOLLECTION{OMaidin1998-id,
  title     = "A geometrical algorithm for melodic difference in melodic
               similarity",
  booktitle = "Melodic similarity: Concepts, procedures, and applications
               (Computing in Musicology 11)",
  author    = "O'Maidin, Donncha",
  editor    = "Hewlett, Walter B and Selfridge-Field, Eleanor",
  publisher = "The MIT Press",
  year      =  1998,
  address   = "Cambridge, MA"
}

@ARTICLE{Grachten2005-cu,
  title    = "Melody retrieval using the {Implication/Realization} model",
  author   = "Grachten, Maarten and Arcos, Josep Lluis and de Mantaras, Ramon
              Lopez",
  journal  = "MIREX-ISMIR 2005: 6th International Conference on Music
              Information retrieval, London 2005",
  year     =  2005,
  keywords = "edit distance; ilarity; implication; melody retrieval;
              realization model; symbolic melodic sim-"
}

@BOOK{Gigerenzer1987-xy,
  title     = "Cognition as intuitive statistics",
  author    = "Gigerenzer, Gerd and Murray, David J",
  publisher = "Lawrence Erlbaum",
  year      =  1987,
  address   = "Hillsdale, NJ"
}

@INCOLLECTION{Roediger1996-cj,
  title     = "Retrieval processes",
  booktitle = "Memory",
  author    = "Roediger, H L and Guynn, M J",
  editor    = "Bjork, Elizabeth Ligon and Bjork, Robert A",
  publisher = "Academic Press",
  pages     = "197--236",
  year      =  1996,
  address   = "New York, NY"
}

@INCOLLECTION{Messick1989-gc,
  title     = "Validity",
  booktitle = "Educational measurement",
  author    = "Messick, Samuel",
  editor    = "Linn, R L",
  publisher = "American Council on Education",
  pages     = "13--103",
  year      =  1989,
  address   = "Washington, DC"
}

@ARTICLE{Cronbach1955-ep,
  title    = "Construct validity in psychological tests",
  author   = "Cronbach, L J and Meehl, P E",
  abstract = "``Construct validation was introduced in order to specify types
              of research required in developing tests for which the
              conventional views on validation are inappropriate. Personality
              tests, and some tests of ability, are interpreted in terms of
              attributes for which there is no adequate criterion. This paper
              indicates what sorts of evidence can substantiate such an
              interpretation, and how such evidence is to be interpreted.'' 60
              references.",
  journal  = "Psychological bulletin",
  volume   =  52,
  number   =  4,
  pages    = "281--302",
  year     =  1955,
  keywords = "SCALE",
  issn     = "0033-2909",
  pmid     = "13245896",
  doi      = "10.1037/h0040957"
}

@INCOLLECTION{Borsboom2009-eu,
  title     = "The two disciplines of scientific psychology, or: The disunity
               of psychology as a working hypothesis",
  booktitle = "Dynamic Process Methodology in the Social and Developmental
               Sciences",
  author    = "Borsboom, Denny and Kievit, Rogier A and Cervone, Daniel and
               Hood, S Brian",
  editor    = "Valsiner, Jaan and Molenaar, Peter C M and Lyra, Maria C D P and
               Chaudhary, Nandita",
  abstract  = "(from the chapter) The structure of this chapter is as follows.
               First, we will sketch, roughly, what we perceive to be the
               ruling research paradigms in psychology: experimental and
               correlational methodology. Second, we will discuss recent
               methodological research into homogeneity conditions and show how
               their violations may affect the conclusions that researchers
               draw from their observations. Some particularly problematic
               fields are discussed in detail by focusing on the fields of
               intelligence and personality research. Third, we discuss
               possible loci of homogeneity in scientific models, and sketch
               the prospects for scientific psychology that may arise from
               these. (PsycINFO Database Record (c) 2010 APA, all rights
               reserved) (chapter)",
  publisher = "Springer",
  pages     = "67--97",
  year      =  2009,
  address   = "New York, NY",
  isbn      = "9780387959214",
  doi       = "10.1007/978-0-387-95922-1"
}

@ARTICLE{Unyk1987-ed,
  title   = "The influence of expectancy on music perception",
  author  = "Unyk, A M and Carlsen, J C",
  journal = "Psychomusicology",
  volume  =  7,
  number  =  1,
  pages   = "3--23",
  year    =  1987
}

@ARTICLE{Cronbach1957-xo,
  title   = "The two disciplines of scientific psychology",
  author  = "Cronbach, L J",
  journal = "The American psychologist",
  volume  =  12,
  number  =  11,
  pages   = "671--684",
  year    =  1957,
  issn    = "0003-066X"
}

@ARTICLE{Schubert2006-yg,
  title   = "The effect of implied harmony, contour and musical expertise on
             judgments of similarity of familiar melodies",
  author  = "Schubert, Emery and Stevens, Catherine",
  journal = "Journal of New Music Research",
  volume  =  35,
  number  =  2,
  pages   = "161--174",
  year    =  2006,
  issn    = "0929-8215",
  doi     = "10.1080/09298210600835000"
}

@ARTICLE{DeCarlo1998-qu,
  title   = "Signal detection theory and generalized linear models",
  author  = "DeCarlo, Lawrence T",
  journal = "Psychological methods",
  volume  =  3,
  number  =  2,
  pages   = "186--205",
  year    =  1998,
  issn    = "1082-989X",
  doi     = "10.1037/1082-989X.3.2.186"
}

@ARTICLE{Typke2007-me,
  title   = "Transportation distances and human perception of melodic
             similarity",
  author  = "Typke, Rainer and Wiering, F and Veltkamp, R C",
  journal = "Musicae scientiae: the journal of the European Society for the
             Cognitive Sciences of Music",
  volume  = "Disc.4A",
  pages   = "153--181",
  year    =  2007,
  issn    = "1029-8649",
  doi     = "10.1177/102986490701100107"
}

@INPROCEEDINGS{Mullensiefen2004-wn,
  title     = "Melodic Similarity: Approaches and applications",
  booktitle = "Proceedings of the 8th International Conference on Music
               Perception \& Cognition",
  author    = "M{\"u}llensiefen, Daniel and Frieler, Klaus",
  abstract  = "This paper describes the systematization, testing and
               optimiziation of different approaches for measuring similarities
               of melodies. First, a quick overview of our mathematical
               systematization for similarity measures, including data
               transformations and calculation methods is given. Behavioral
               data from three listener experiments is used to model experts'
               similarity judgments of short melodies from popular music in
               different contextual situations. A weighted combination of
               several similarity measures, representing two resp. three
               different sources of information, is found to explain user
               ratings best. As an application example one of the optimal
               similarity measures resulting from these three experiments is
               used to analyze a body of about 600 folk melodies from
               Luxembourg. Finally, the expert classification of the individual
               phrases of these melodies that has carried out in an extensive
               ethno-musicological study (Sagrillo, 1999) is reconstructed with
               the help of an optimal combination of similarity measures using
               logistic regression.",
  pages     = "283--289",
  year      =  2004,
  isbn      = "9781876346508"
}

@ARTICLE{Wright2009-mi,
  title   = "Multilevel modelling: Beyond the basic applications",
  author  = "Wright, Daniel B and London, Kamala",
  journal = "The British journal of mathematical and statistical psychology",
  volume  =  62,
  number  =  2,
  pages   = "439--456",
  year    =  2009,
  issn    = "0007-1102",
  doi     = "10.1348/000711008X327632"
}

@ARTICLE{Yonelinas2002-cz,
  title   = "The nature of recollection and familiarity: A review of 30 years
             of research",
  author  = "Yonelinas, Andrew P",
  journal = "Journal of memory and language",
  volume  =  46,
  pages   = "441--517",
  year    =  2002,
  issn    = "0749-596X",
  doi     = "10.1006/jmla.2002.2864"
}

@MISC{Knoblauch2014-el,
  title  = "psyphy: Functions for analyzing psychophysical data in {R}",
  author = "Knoblauch, Kenneth",
  year   =  2014
}

@ARTICLE{Krumhansl1982-pu,
  title    = "Tracing the dynamic changes in perceived tonal organization in a
              spatial representation of musical keys",
  author   = "Krumhansl, Carol L and Kessler, E J",
  abstract = "Investigated the cognitive representation of harmonic and tonal
              structure in Western music using a tone-profile technique in 2
              experiments with 24 undergraduates and community adults.
              Listeners rated how well single tones (any one of the 12 tones of
              the chromatic scale) followed a musical element such as a scale,
              chord, or cadence. Stable rating profiles reflecting the tonal
              hierarchies in major and minor keys were obtained, which, when
              intercorrelated and analyzed using multidimensional scaling,
              produced a 4-dimensional spatial map of the distances between
              keys. Listeners integrated harmonic functions over multiple
              chords, developing a sense of key that needed to be re-evaluated
              as additional chords were sounded. It is suggested that the
              perceived relations between chords and keys and between different
              keys are mediated through an internal representation of the
              hierarchy of tonal functions of single tones in music. (56 ref)
              (PsycINFO Database Record (c) 2012 APA, all rights reserved)",
  journal  = "Psychological review",
  volume   =  89,
  number   =  4,
  pages    = "334--368",
  year     =  1982,
  issn     = "0033-295X",
  pmid     = "7134332",
  doi      = "10.1037/0033-295X.89.4.334"
}

@ARTICLE{Eerola2007-jd,
  title    = "Melodic and contextual similarity of folk song phrases",
  author   = "Eerola, T and Bregman, M",
  abstract = "Various models of melodic similarity have been proposed and
              assessed in perceptual experiments. Contour and pitch content
              variables haven been favoured although music-theoretical and
              statistical variables have also been claimed to explain
              similarity ratings. A Re-analysis of earlier work by Rosner \&
              Meyer (1986) suggests that simple contextual features can also be
              highly explanatory with more complex stimuli. A new experiment
              containing short melodic phrases investigated the effectiveness
              of several global and comparative variables. A multi-dimensional
              scaling solution indicated that both melodic direction and pitch
              range are highly relevant for making such similarity judgments
              and that the most salient aspects of melody when making
              similarity judgments are relatively simple context-dependent
              features.",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  volume   = "Disc.4A",
  pages    = "211--233",
  year     =  2007,
  keywords = "5840 words; contour; experiments involving similarity judgments;
              have been; in psychological research; m elodic and contextual;
              melody; music; phrases; similarity; similarity of folk song; word
              count",
  issn     = "1029-8649",
  doi      = "10.1177/102986490701100109"
}

@ARTICLE{Pothos2007-jq,
  title    = "Theories of artificial grammar learning",
  author   = "Pothos, Emmanuel M",
  journal  = "Psychological bulletin",
  volume   =  133,
  number   =  2,
  pages    = "227--244",
  year     =  2007,
  keywords = "1967; a; accounts; agl; artificial grammar learning; associative
              learning; been extensively used to; evaluates the main
              theoretical; implicit learning; in artificial grammar learning;
              reber; rules; s; similarity; since its conception; the agl
              paradigm has; this paper reviews and",
  issn     = "0033-2909, 1939-1455",
  doi      = "10.1037/0033-2909.133.2.227"
}

@ARTICLE{Dowling1991-ti,
  title    = "Tonal strength and melody recognition after long and short delays",
  author   = "Dowling, W Jay",
  abstract = "In a continuous-running-memory task, subjects heard novel
              seven-note melodies that were tested after delays of 11 sec
              (empty) or 39 sec (filled). Test items were transposed to new
              pitch levels (to moderately distant keys in the musical sense)
              and included exact transpositions (targets), same-contour lures
              with altered pitch intervals, and new-contour lures. Melodies
              differed in tonal strength (degree of conformity to a musical
              key) and were tonally strong, tonally weak, or atonal. False
              alarms to same-contour lures decreased over the longer delay
              period, but only for tonal stimuli. In agreement with previous
              studies, discrimination of detailed changes in pitch intervals
              improved with increased delay, whereas discrimination of more
              global contour information declined, again only for tonal
              stimuli. These results suggest that poor short-delay performance
              in rejecting same-contour lures arises from confusion that is
              based on the similarity of tonality between standard stimuli and
              lures. If a test item has the same contour and a similar tonality
              to a just-presented item, subjects tend to accept it. After a
              delay filled with melodies in other tonalities, the salience of
              key information recedes, and subjects base their judgments on
              more detailed pattern information (namely, exact pitch
              intervals). The fact that tonality affects judgments of melodic
              contour indicates that contour is not an entirely separable
              feature of melodies but rather that a melody with its contour
              constitutes an integrated perceptual whole.",
  journal  = "Perception \& psychophysics",
  volume   =  50,
  number   =  4,
  pages    = "305--313",
  year     =  1991,
  keywords = "Adult; Attention; Humans; Mental Recall; Music; Pitch
              Discrimination; Psychoacoustics; Retention (Psychology)",
  issn     = "0031-5117",
  pmid     = "1758762"
}

@ARTICLE{Dowling1977-cs,
  title    = "The perception of melodies distorted by splitting into several
              octaves: Effects of increasing proximity and melodic contour",
  author   = "Dowling, W Jay and Hollombe, Ava W",
  abstract = "Splitting up the familiar tune Yankee Doodle`` by placing
              successive notes in different octaves makes it very difficult to
              recognize. The present 2 experiments generalized this finding to
              more than one familiar tune and to presentation by actual musical
              instruments. 71 undergraduates were tested. Results show that
              tunes differed in the degree to which their recognizability was
              affected by scrambling into different octaves, but recognition of
              all 10 tunes investigated was substantially diminished by the
              distortion. Increasing pitch proximity of temporally adjacent
              notes by leaving pairs or triples of successive notes intact
              within the same octave increased recognizability of at least some
              scrambled tunes. Leaving the melodic contour (the pattern of ups
              and downs) intact while splitting up the melody increased
              recognizability for Ss informed of the preservation of contour,
              though recognition was still worse than for undistorted versions.
              (19 ref) (PsycINFO Database Record (c) 2004 APA, all rights
              reserved)",
  journal  = "Perception \& psychophysics",
  volume   =  21,
  number   =  1,
  pages    = "60--64",
  year     =  1977,
  issn     = "0031-5117",
  doi      = "10.3758/BF03199469"
}

@INCOLLECTION{Mullensiefen2011-ij,
  title     = "Sloboda's recall paradigm for melodic memory: A new,
               computational perspective",
  booktitle = "Music and the mind: Essays in honour of John Sloboda",
  author    = "M{\"u}llensiefen, Daniel and Wiggins, G A",
  publisher = "Oxford University Press",
  pages     = "160--186",
  year      =  2011,
  address   = "Oxford, England"
}

@INCOLLECTION{Sloboda1985-lo,
  title     = "Immediate recall of melodies",
  booktitle = "Musical structure and cognition",
  author    = "Sloboda, John A and Parker, David H H",
  editor    = "Howell, Peter and Cross, Ian and West, Robert",
  publisher = "Academic Press",
  pages     = "143--167",
  year      =  1985,
  address   = "London, England"
}

@ARTICLE{Long1977-mz,
  title    = "Relationships between pitch memory in short melodies and selected
              factors",
  author   = "Long, Peggy A",
  abstract = "This study investigated relationships between memory for pitch in
              short melodies and melody length, tonal structure, melodic
              contour, and music perception ability. Results indicated that all
              these factors interact to some degree with memory. The factors
              demonstrating the greatest influence were music perception
              ability (a product of previous music learning), and tonal
              structure (the degree of relationships among the pitches of a
              melody, commonly described as tonality or atonality). Memory for
              pitch improved as the number of pitches in a melody decreased.
              Certain melodic contours also caused variations in pitch memory.",
  journal  = "Journal of Research in Music Education",
  volume   =  25,
  number   =  4,
  pages    = "272--282",
  year     =  1977,
  keywords = "acoustics; and music learning have; aural discrimination;
              consistent with more general; context; contour; length; memory;
              memory studies and current; memory studies exploring elements; of
              music such as; produced results; tonality"
}

@INCOLLECTION{Steinbeck1982-yw,
  title     = "Struktur und {\"A}hnlichkeit: Methoden automatisierter
               Melodieanalyse",
  booktitle = "Kieler Schriften zur Musikwissenschaft {XXV}",
  author    = "Steinbeck, W",
  publisher = "B{\"a}renreiter",
  year      =  1982,
  address   = "Kassel, Germany"
}

@PHDTHESIS{Uitdenbogerd2002-qx,
  title  = "Music information retrieval technology",
  author = "Uitdenbogerd, A L",
  year   =  2002,
  school = "Doctoral dissertation, RMIT University, Melbourne, Victoria"
}

@BOOK{Krumhansl1990-fl,
  title     = "Cognitive foundations of musical pitch",
  author    = "Krumhansl, Carol L",
  publisher = "Oxford University Press",
  year      =  1990,
  address   = "New York, NY"
}

@ARTICLE{Huron1993-dy,
  title   = "An improved model of tonality perception incorporating pitch
             salience and echoic memory",
  author  = "Huron, David and Parncutt, Richard",
  journal = "Psychomusicology",
  volume  =  12,
  number  =  2,
  pages   = "154--171",
  year    =  1993
}

@PHDTHESIS{Avron2012-yo,
  title  = "Reliability and validity of the {Gold-MSI}, and links between
            musicality and intelligence",
  author = "Avron, Amit",
  year   =  2012,
  school = "Master's dissertation, Goldsmiths College, University of London"
}

@ARTICLE{Peretz2003-jr,
  title   = "What is specific to music processing? Insights from congenital
             amusia",
  author  = "Peretz, Isabelle and Hyde, Krista L",
  journal = "Trends in cognitive sciences",
  volume  =  7,
  number  =  8,
  pages   = "362--367",
  year    =  2003,
  issn    = "1364-6613",
  doi     = "10.1016/S1364-6613(03)00150-5"
}

@ARTICLE{Terhardt1974-sg,
  title   = "Pitch, consonance, and harmony",
  author  = "Terhardt, Ernst",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  55,
  number  =  5,
  pages   = "1061--1069",
  year    =  1974,
  issn    = "0001-4966",
  doi     = "10.1121/1.1914648"
}

@ARTICLE{Bigand1996-fz,
  title    = "Perception of musical tension in short chord sequences: The
              influence of harmonic function, sensory dissonance, horizontal
              motion, and musical training",
  author   = "Bigand, E and Parncutt, Richard and Lerdahl, F",
  abstract = "This study investigates the effect of four variables (tonal
              hierarchies, sensory chordal consonance, horizontal motion, and
              musical training) on perceived musical tension. Participants were
              asked to evaluate the tension created by a chord X in sequences
              of three chords [C major-->X-->C major] in a C major context key.
              The X chords could be major or minor triads major-minor seventh,
              or minor seventh chords built on the 12 notes of the chromatic
              scale. The data were compared with Krumhansl's (1990) harmonic
              hierarchy and with predictions of Lerdahl's (1988) cognitive
              theory, Hutchinson and Knopoff's (1978) and Parncutt's (1989)
              sensory-psychoacoustical theories, and the model of horizontal
              motion defined in the paper. As a main outcome, it appears that
              judgments of tension arose from a convergence of several
              cognitive and psychoacoustics influences, whose relative
              importance varies, depending on musical training.",
  journal  = "Perception \& psychophysics",
  volume   =  58,
  number   =  1,
  pages    = "124--141",
  year     =  1996,
  issn     = "0031-5117",
  pmid     = "8668513",
  doi      = "10.3758/BF03205482"
}

@ARTICLE{Collins2014-ek,
  title   = "A combined model of sensory and cognitive representations
             underlying tonal expectations in music: From audio signals to
             behavior",
  author  = "Collins, Tom and Tillmann, Barbara and Barrett, Frederick S and
             Delb{\'e}, Charles and Janata, Petr",
  journal = "Psychological review",
  volume  =  121,
  number  =  1,
  pages   = "33--65",
  year    =  2014,
  issn    = "0033-295X, 1939-1471",
  doi     = "10.1037/a0034695"
}

@ARTICLE{Pothos2000-tl,
  title   = "The role of similarity in artificial grammar learning",
  author  = "Pothos, Emmanuel M and Bailey, Todd M",
  journal = "Journal of experimental psychology. Learning, memory, and
             cognition",
  volume  =  26,
  number  =  4,
  pages   = "847--862",
  year    =  2000,
  issn    = "0278-7393, 1939-1285",
  doi     = "10.1037/0278-7393.26.4.847"
}

@ARTICLE{Morgan1981-ms,
  title    = "The role of constituent structure in the induction of an
              artificial language",
  author   = "Morgan, Jl and Newport, El",
  abstract = "Subjects were exposed to a small sample of sentences from an
              artificial linguistic system and tested on their knowledge of the
              linear and hierarchical structures of the language. Four
              reference world conditions were included in order to evaluate the
              effects of providing semantic encoding of the following types of
              information: (1) class membership of words, (2) an arbitrary
              grouping of successive words, (3) phrasal (i.e., constituent)
              grouping of succes- sive words, and (4) linguistic dependencies
              among successive words. Results showed, first, that presence of
              constituent structure information was the effective variable in
              facilitating the learning of complex aspects of syntax,
              particularly linguistic dependencies; providing an explicit
              semantic representation of these dependencies did not
              significantly improve syntax learning. Second, only those
              subjects receiving constituent structure information succeeded in
              inducing phrase structure grammars. These results suggest that it
              is only when the input contains a rich set of correlated cues to
              constituent organization that learners uniformly succeed in
              inducing coherent grammatical systems; in these circumstances,
              both linguistic dependencies and hierarchical structure are
              represented.",
  journal  = "Journal of verbal learning and verbal behavior",
  volume   =  20,
  number   =  1,
  pages    = "67--85",
  year     =  1981,
  issn     = "0022-5371",
  doi      = "10.1016/S0022-5371(81)90312-1"
}

@ARTICLE{Higham2000-id,
  title    = "Beyond dissociation logic: evidence for controlled and automatic
              influences in artificial grammar learning",
  author   = "Higham, P a and Vokey, J R and Pritchard, J L",
  abstract = "Evidence for unconscious learning has typically been based on
              dissociations between direct and indirect tests of learning.
              Because of some inherent problems with dissociation logic, we
              applied the logic of opposition to 2 artificial grammar learning
              experiments. In Experiment 1, participants were exposed to 2
              different sets of letter strings, generated from 2 different
              grammars, and later rated test strings for grammaticality with
              either in-concert (rate grammatical strings consistent with
              either structure) or opposition (rate grammatical only strings
              from 1 of the structures) instructions. Manipulating response
              deadline affected controlled, but not automatic influences. In
              Experiment 2, after similar training, a source-monitoring test
              was administered from which the in-concert and opposition
              conditions were derived. The test indicated that varying the
              retention interval affected controlled, but not automatic,
              influences. The results are discussed in terms of awareness,
              knowledge representation, and metacognitive processing.",
  journal  = "Journal of experimental psychology. General",
  volume   =  129,
  number   =  4,
  pages    = "457--470",
  year     =  2000,
  keywords = "Adolescent; Adult; Cognition; Female; Humans; Linguistics; Logic;
              Male; Mental Processes; Unconscious (Psychology)",
  issn     = "0096-3445",
  pmid     = "11142861",
  doi      = "10.1037/ID096-3445.129.4.457"
}

@ARTICLE{McAdams2001-aq,
  title    = "Similarity, invariance, and musical variation",
  author   = "McAdams, S and Matzkin, D",
  abstract = "Perceptual similarity underlies a number of important
              psychological properties of musical materials, including
              perceptual invariance under transformation, categorization,
              recognition, and the sense of familiarity. Mental processes
              involved in the perception of musical similarity may be an
              integral part of the functional logic of music composition and
              thus underly important aspects of musical experience. How much
              and in what ways can musical materials be varied and still be
              considered as perceptually related or as belonging to the same
              category? The notions of musical material, musical variation,
              perceptual similarity and invariance, and form-bearing dimensions
              are considered in this light. Recent work on similarity
              perception has demonstrated that the transformation space for a
              given musical material is limited by several factors ranging from
              degree of match of the values of auditory attributes of the
              events composing the sequences to their relations of various
              levels of abstraction and to the degree that the transformation
              respects the grammar of the musical system within which the
              material was composed. These notions and results are considered
              in the light of future directions of research, particularly
              concerning the role of similarity and invariance in the
              understanding of musical form during listening.",
  journal  = "Annals of the New York Academy of Sciences",
  volume   =  930,
  pages    = "62--76",
  year     =  2001,
  issn     = "0077-8923",
  pmid     = "11458867",
  doi      = "10.1111/j.1749-6632.2001.tb05725.x"
}

@INPROCEEDINGS{Kaliakatsos-Papakostas2015-qz,
  title     = "Evaluating the general chord type representation in tonal music
               and organising {GCT} chord labels in functional chord categories",
  booktitle = "Proceedings of the 4th International Conference on Music
               Information Retrieval ({ISMIR} 2015)",
  author    = "Kaliakatsos-Papakostas, Maximos and Zacharakis, Asterios and
               Tsougras, Costas and Cambouropoulos, Emilios",
  year      =  2015
}

@ARTICLE{Papakostas2014-hb,
  title   = "Probabilistic harmonization with fixed intermediate chord
             constraints",
  author  = "Papakostas, Maximos Kaliakatsos",
  journal = "Probabilistic harmonisation with fixed intermediate chord
             constraints. ``Proceedings of the Joint 11th Sound and Music
             Computing Conference (SMC) and 40th International Computer Music
             Conference (ICMC)",
  number  = "SEPTEMBER 2014",
  pages   = "14--20",
  year    =  2014,
  doi     = "10.13140/2.1.3079.5526"
}

@INPROCEEDINGS{Cambouropoulos2014-mn,
  title     = "An idiom-independent representation of chords for computational
               music analysis and generation",
  booktitle = "Proceedings of the joint 11th Sound and Music Computing
               Conference ({SMC}) and 40th International Computer Music
               Conference ({ICMC})",
  author    = "Cambouropoulos, Emilios and Kaliakatsos-Papakostas, Maximos and
               Tsougras, Costas",
  abstract  = "In this paper we focus on issues of harmonic representa- tion
               and computational analysis. A new idiom- independent
               representation is proposed of chord types that is appropriate
               for encoding tone simultaneities in any harmonic context (such
               as tonal, modal, jazz, octatonic, atonal). The General Chord
               Type (GCT) representation, allows the re-arrangement of the
               notes of a harmonic simultaneity such that abstract
               idiom-specific types of chords may be derived; this encoding is
               inspired by the standard roman numeral chord type labeling, but
               is more general and flexible. Given a consonance-dissonance
               classification of intervals (that reflects culturally- dependent
               notions of consonance/dissonance), and a scale, the GCT
               algorithm finds the maximal subset of notes of a given note
               simultaneity that contains only con- sonant intervals; this
               maximal subset forms the base upon which the chord type is
               built. The proposed representa- tion is ideal for hierarchic
               harmonic systems such as the tonal system and its many
               variations, but adjusts to any other harmonic system such as
               post-tonal, atonal music, or traditional polyphonic systems. The
               GCT representa- tion is applied to a small set of examples from
               diverse musical idioms, and its output is illustrated and
               analysed showing its potential, especially, for computational
               music analysis \& music information retrieval.",
  year      =  2014,
  address   = "Athens, Greece"
}

@ARTICLE{Saffran1999-ob,
  title    = "Statistical learning of tone sequences by human infants and
              adults",
  author   = "Saffran, J R and Johnson, E K and Aslin, R N and Newport, E L",
  abstract = "Previous research suggests that language learners can detect and
              use the statistical properties of syllable sequences to discover
              words in continuous speech (e.g. Aslin, R.N., Saffran, J.R.,
              Newport, E.L., 1998. Computation of conditional probability
              statistics by 8-month-old infants. Psychological Science 9,
              321-324; Saffran, J.R., Aslin, R.N., Newport, E.L., 1996.
              Statistical learning by 8-month-old infants. Science 274,
              1926-1928; Saffran, J., R., Newport, E.L., Aslin, R.N., (1996).
              Word segmentation: the role of distributional cues. Journal of
              Memory and Language 35, 606-621; Saffran, J.R., Newport, E.L.,
              Aslin, R.N., Tunick, R.A., Barrueco, S., 1997. Incidental
              language learning: Listening (and learning) out of the corner of
              your ear. Psychological Science 8, 101-195). In the present
              research, we asked whether this statistical learning ability is
              uniquely tied to linguistic materials. Subjects were exposed to
              continuous non-linguistic auditory sequences whose elements were
              organized into 'tone words'. As in our previous studies,
              statistical information was the only word boundary cue available
              to learners. Both adults and 8-month-old infants succeeded at
              segmenting the tone stream, with performance indistinguishable
              from that obtained with syllable streams. These results suggest
              that a learning mechanism previously shown to be involved in word
              segmentation can also be used to segment sequences of
              non-linguistic stimuli.",
  journal  = "Cognition",
  volume   =  70,
  number   =  1,
  pages    = "27--52",
  year     =  1999,
  keywords = "- see front matter; 0010-0277; 1999 elsevier science b; 99; all
              rights reserved; continuous speech; corresponding author;
              department of psychology; e-mail; edu; facstaff; jsaffran;
              madison; present address; statistical learning ability;
              university of wisconsin at; usa; v; wi 53706-1696; wisc; word
              segmentation",
  issn     = "0010-0277",
  pmid     = "10193055",
  doi      = "10.1016/S0010-0277(98)00075-4"
}

@INPROCEEDINGS{Martins2015-zn,
  title     = "The cognitive representation of recursive processes in music",
  booktitle = "Proceedings of the Ninth Triennial Conference of the European
               Society for the Cognitive Sciences of Music",
  author    = "Martins, Mauricio and Gingras, Bruno and Waldm{\"u}ller, Estela
               Puig and Fitch, W Tecumseh",
  editor    = "Ginsborg, J and Lamont, A and Phillips, M and Bramley, S",
  year      =  2015,
  address   = "Manchester, UK"
}

@INPROCEEDINGS{Mooney2015-jl,
  title     = "Melody recall and recognition: The effect of musical features on
               memory",
  booktitle = "Proceedings of the Ninth Triennial Conference of the European
               Society for the Cognitive Sciences of Music",
  author    = "Mooney, Joe and Nulli, Margherita and Halpern, Andrea R and
               M{\"u}llensiefen, Daniel",
  editor    = "Ginsborg, J and Lamont, A and Phillips, M and Bramley, S",
  year      =  2015,
  address   = "Manchester, UK"
}

@ARTICLE{Jansen2015-dp,
  title     = "Students' self-concept and self-efficacy in the sciences:
               Differential relations to antecedents and educational outcomes",
  author    = "Jansen, Malte and Scherer, Ronny and Schroeders, Ulrich",
  journal   = "Contemporary educational psychology",
  publisher = "Elsevier Inc.",
  volume    =  41,
  pages     = "13--24",
  year      =  2015,
  keywords  = "Academic self-concept; Big-Fish-Little-Pond-Effect;
               Future-oriented motivation; Inquiry-based teaching; Science
               education; Self-efficacy; academic self-concept",
  issn      = "0361-476X",
  doi       = "10.1016/j.cedpsych.2014.11.002"
}

@INBOOK{Shalizi_undated-zp,
  title  = "Discovering Causal Structure from Observations",
  author = "Shalizi, Cosma",
  pages  = "477--492"
}

@ARTICLE{Spirtes2005-tz,
  title    = "Graphical models, causal inference, and econometric models",
  author   = "Spirtes, Peter",
  abstract = "A graphical model is a graph that represents a set of conditional
              independence relations among the vertices (random variables). The
              graph is often given a causal interpretation as well. I describe
              how graphical causal models can be used in an algorithm for
              constructing partial information about causal graphs from
              observational data that is reliable in the large sample limit,
              even when some of the variables in the causal graph are
              unmeasured. I also describe an algorithm for estimating from
              observational data (in some cases) the total effect of a given
              variable on a second variable, and theoretical insights into
              fundamental limitations on the possibility of certain causal
              inferences by any algorithm whatsoever, and regardless of sample
              size.",
  journal  = "Journal of Economic Methodology",
  volume   =  12,
  number   =  1,
  pages    = "3--34",
  year     =  2005,
  keywords = "causal inference; graphical models; model search; model testing",
  issn     = "1350-178X",
  doi      = "10.1080/1350178042000330887"
}

@ARTICLE{Pearl2009-ij,
  title    = "Causal inference in statistics: An overview",
  author   = "Pearl, Judea",
  abstract = "This reviewpresents empirical researcherswith recent advances in
              causal inference, and stresses the paradigmatic shifts that must
              be un- dertaken in moving fromtraditional statistical analysis to
              causal analysis of multivariate data. Special emphasis is placed
              on the assumptions that un- derly all causal inferences, the
              languages used in formulating those assump- tions, the
              conditional nature of all causal and counterfactual claims, and
              the methods that have been developed for the assessment of such
              claims. These advances are illustrated using a general theory of
              causation based on the Structural Causal Model (SCM) described in
              Pearl (2000a), which subsumes and unifies other approaches to
              causation, and provides a coher- entmathematical foundation for
              the analysis of causes and counterfactuals. In particular, the
              paper surveys the development of mathematical tools for inferring
              (from a combination of data and assumptions) answers to three
              types of causal queries: (1) queries about the effects of
              potential interven- tions, (also called ``causal effects'' or
              ``policy evaluation'') (2) queries about probabilities of
              counterfactuals, (including assessment of ``regret,'' ``attri-
              bution'' or ``causes of effects'') and (3) queries about direct
              and indirect effects (also known as ``mediation''). Finally, the
              paper defines the formal and conceptual relationships between the
              structural and potential-outcome frameworks and presents tools
              for a symbiotic analysis that uses the strong features of both.",
  journal  = "Statistics surveys",
  volume   =  3,
  pages    = "96--146",
  year     =  2009,
  keywords = "and phrases; causal effects; causes of effects; confounding;
              counterfactuals; graph-; ical methods; mediation; policy
              evaluation; potential-outcome; received september 2009;
              structural equation models",
  issn     = "1935-7516",
  doi      = "10.1214/09-SS057"
}

@INPROCEEDINGS{Mullensiefen2015-em,
  title     = "Can correlations imply causation? Causal modeling and music
               psychology research",
  booktitle = "Proceedings of the Ninth Triennial Conference of the European
               Society for the Cognitive Sciences of Music",
  author    = "M{\"u}llensiefen, Daniel and Floridou, Georgina and Jakuboswki,
               Kelly",
  editor    = "Ginsborg, J and Lamont, A and Phillips, M and Bramley, S",
  year      =  2015,
  address   = "Manchester, UK"
}

@INPROCEEDINGS{Burgoyne2015-wc,
  title     = "Adaptive music recognition games for Dementia therapy",
  booktitle = "Proceedings of the Ninth Triennial Conference of the European
               Society for the Cognitive Sciences of Music",
  author    = "Burgoyne, John Ashley and Hofman, Abe and Maas, Han Van Der and
               Honing, Henkjan",
  editor    = "Ginsborg, J and Lamont, A and Phillips, M and Bramley, S",
  year      =  2015,
  address   = "Manchester, UK",
  doi       = "10.1016/j.intell"
}

@ARTICLE{Mullensiefen2014-is,
  title   = "The role of features and context in recognition of novel melodies",
  author  = "M{\"u}llensiefen, Daniel and Halpern, Andrea R",
  journal = "Music perception",
  volume  =  31,
  number  =  5,
  pages   = "418--435",
  year    =  2014,
  issn    = "0730-7829"
}

@MISC{Mullensiefen2009-mi,
  title     = "{FANTASTIC}: Feature {ANalysis} Technology Accessing
               {STatistics} (In a Corpus): Technical Report v. 1.5",
  author    = "M{\"u}llensiefen, Daniel",
  publisher = "Goldsmiths, University of London",
  year      =  2009,
  address   = "London"
}

@ARTICLE{Pembrook1986-tc,
  title   = "Interference of the transcriptionp rocess and other selected
             variables on perception and memory during melodic dictation",
  author  = "Pembrook, Randall G",
  journal = "Journal of Research in Music Education",
  volume  =  34,
  number  =  4,
  pages   = "238--261",
  year    =  1986,
  issn    = "0022-4294",
  doi     = "10.2307/3345259"
}

@ARTICLE{Eerola2006-sb,
  title    = "Perceived complexity of western and African folk melodies by
              western and African listeners",
  author   = "Eerola, T",
  abstract = "Stylistic knowledge and enculturation play a significant role in
              music perception, although the importance of psychophysical cues
              in perception of emotions in music has been acknowledged. The
              psychophysical cues, such as melodic complexity, are assumed to
              be independent of musical experience. A cross-cultural comparison
              was used to investigate the ratings of melodic complexity of
              western and African participants for western (Experiment 1) and
              African folk songs (Experiment 2). A range of melodic complexity
              measures was developed to discover what factors contribute to
              complexity. On the whole, the groups gave similar patterns of
              responses in both experiments. In Experiment 1, western folk
              songs represented a style that was familiar for both groups and
              the results portrayed the differences in stylistic knowledge and
              high predictive rate of melodic variables. In Experiment 2,
              African folk songs were stylistically familiar only for the
              African group and the results illustrated a lower predictive rate
              of variables and differences between the groups in rhythm and
              structural variables. These results suggest that the melodic
              complexity ratings are influenced by musical enculturation.",
  journal  = "Psychology of Music",
  volume   =  34,
  number   =  3,
  pages    = "337--371",
  year     =  2006,
  issn     = "0305-7356",
  doi      = "10.1177/0305735606064842"
}

@ARTICLE{Unyk1992-rz,
  title    = "Lullabies and simplicity: A cross-cultural perspective",
  author   = "Unyk, A M and Trehub, Sandra E and Trainor, Laurel J and
              Schellenberg, E Glenn",
  abstract = "Pairs of folk lullabies and comparison songs from different
              cultures were presented to adult listeners, who were required to
              choose the simpler song in each pair. Adults judged the lullaby
              excerpts as simpler whether presented with original field
              recordings, low-pass filtered versions that made the words
              unintelligible or excerpts synthesised with a uniform (piano)
              timbre. Structural analyses of the songs failed to reveal musical
              features that differentiated lullabies from other songs.
              Nevertheless, such analyses revealed melodic features that
              predicted adults' identification of lullabies.",
  journal  = "Psychology of Music",
  volume   =  20,
  number   =  1,
  pages    = "15--28",
  year     =  1992,
  issn     = "0305-7356",
  doi      = "10.1177/0305735692201002"
}

@INCOLLECTION{Schmuckler2009-sa,
  title     = "Components of melodic processing",
  booktitle = "The Oxford handbook of music psychology",
  author    = "Schmuckler, Mark A",
  editor    = "Hallam, Susan and Cross, Ian and Thaut, Michael",
  publisher = "Oxford University Press",
  year      =  2009,
  address   = "New York, NY"
}

@INPROCEEDINGS{De_Fleurian2014-yt,
  title     = "Comparing perceptual and computational complexity for short
               rhythmic patterns",
  booktitle = "Procedia - Social and Behavioral Sciences",
  author    = "De Fleurian, Remi and Ben-Tal, Oded and M{\"u}llensiefen, Daniel
               and Blackwell, Tim",
  abstract  = "According to Leibniz `Music is the hidden arithmetical exercise
               of a mind unconscious that it is calculating.' The perception or
               experience of time is an essential aspect of listeners'
               engagement with music. As such listeners' experience of rhythmic
               patterns and their aesthetic response can enhance our
               understanding of the perception of time. Studies by Berlyne
               suggest that aesthetic evaluations are low for stimuli that are
               too simple or too complex with a preference for intermediate
               level of complexity. In musical terms we would expect listeners
               to respond negatively to music that is purely repetitive or to
               music that seems incomprehensibly random and to prefer music
               that manages to balance familiarity with variation. We present a
               study that aims to match listeners' evaluation of rhythmic
               complexity with computational measures of complexity. We
               selected five measures derived from information theory -
               Shannon's entropy, entropy rate, excess entropy, transient
               information, and Kolmogorov complexity. Rhythmic sequences,
               covering a wide spectrum of complexity levels according to these
               measures, were generated algorithmically as binary sequences.
               These sequences were synthesized as drum patterns with 1s as
               hits and 0s as rests. 32 participants were asked to guess
               whether the last beat of each sequence was supposed to be a drum
               hit or a rest. We averaged the participants' scores in order to
               assign an implicit rating of rhythm complexity to each sequence.
               We also obtained an explicit rating of complexity by asking the
               participants to rate the perceived difficulty of guessing the
               last beat for each sequence. Finally, the participants completed
               the Gold-MSI questionnaire and a shortened version of the
               Raven's matrices, in order to investigate the effects of
               musicality and visual pattern identification on the perception
               of rhythm complexity. The Kolmogorov complexity of the sequences
               was correlated with the scores on the explicit task (r=.973,
               p<.001), and the entropy rate of the sequences was correlated
               with the scores on both implicit (r=.670, p=.012) and explicit
               tasks (r=.909, p<.001). There was also a Kolmogorov
               complexity-by-musicality interaction (F=5.498, p=.026),
               confirming the influence of musical expertise in the perception
               of rhythm complexity. There was no effect of the scores on the
               Raven's matrices, showing that auditory sequence perception and
               visual pattern identification seem to be different abilities.
               These results show that information-theoretical concepts capture
               some salient features of rhythm perception, and provide the
               framework for further studies on the aesthetic perception of
               rhythm.",
  publisher = "Elsevier",
  volume    =  126,
  pages     = "111--112",
  year      =  2014,
  keywords  = "Complexity; Computation; Music; Perception; Rhythm",
  issn      = "1877-0428",
  doi       = "10.1016/j.sbspro.2014.02.333"
}

@ARTICLE{Mikumo1992-hh,
  title    = "Encoding strategies for tonal and atonal melodies",
  author   = "Mikumo, M",
  abstract = "In this experiment, strategies of pitch encoding in the
              processing of melodies were investigated. Twenty-six students who
              were highly trained in music and twenty-six who were less well
              trained were in- structed to make recognition judgments
              concerning melodies after a 12-sec retention interval. During
              each retention interval, subjects were exposed to one of four
              conditions (pause, listening to an interfering melody, shadowing
              nonsense syllables, and shadowing note names). Both the standard
              and the comparison melodies were six-tone series that had either
              a high-tonality structure (``tonal melody'') or a low-tonality
              structure (``atonal melody''). The results (obtained by
              Newman-Keuls method) showed that recognition performance for the
              musically highly trained group was severely disrupted by the note
              names for the tonal melodies, while it was disrupted by the
              interfering melody for the atonal melodies. On the other hand,
              for the musically less well trained group, whose recognition
              performance was significantly worse than that of the highly
              trained group even in the Pause condition, there were no sig-
              nificant differences in disruptive effects between the different
              types of interfering materials. These findings suggest that the
              highly trained group could use a verbal (note name) encoding
              strategy for the pitches in the tonal melodies, and also
              rehearsal strategies (such as humming and whistling) for the
              atonal melodies, but that subjects in the less well trained group
              were unable to use any effective strategies to encode the
              melodies.",
  journal  = "Music perception",
  volume   =  10,
  number   =  1,
  pages    = "73--82",
  year     =  1992,
  issn     = "0730-7829"
}

@ARTICLE{Cuddy1979-rr,
  title    = "Melody recognition: The experimental application of musical rules",
  author   = "Cuddy, Lola L and Cohen, Annabel J and Miller, J",
  abstract = "Three experiments tested the recognition of transposed 3-tone
              melodies in a standard 2-alternative forced-choice psychophysical
              paradigm. Melodies were tested alone or embedded in 1 of 3 types
              of contexts that varied in degree of conformity to the rules of
              diatonicism and cadential ending. Results, replicated for both
              piano and sine-tone stimuli, indicate significant effects of
              contextual conditions, key of error, and key of transposition.
              Ease of recognition in transposition was related to the
              identification and application of rules defining structures among
              tones and among tone sets, and to the use of rules for detecting
              structural violations. (French summary) (28 ref) (PsycINFO
              Database Record (c) 2004 APA, all rights reserved)",
  journal  = "Canadian journal of psychology",
  volume   =  33,
  number   =  3,
  pages    = "148--157",
  year     =  1979,
  issn     = "0008-4255",
  pmid     = "519545",
  doi      = "10.1037/h0081713"
}

@ARTICLE{Macmillan1990-kt,
  title    = "Response bias: Characteristics of detection theory, threshold
              theory, and ``nonparametric'' indexes",
  author   = "Macmillan, Neil a and Creelman, C Douglas",
  abstract = "Models of discrimination based on statistical decision theory
              distinguish sensitivity (the ability of an observer to reflect a
              stimulus-response correspondence denned by the experimenter) from
              response bias (the tendency to favor 1 response over others).
              Measures of response bias have received less attention than those
              of sensitivity. Bias measures are classified here according to 1
              characteristics. First, the distributions assumed or implied to
              underlie the observer's decision may be normal, logis- tic, or
              rectangular. Second, the bias index may measure criterion
              location, criterion location relative to sensitivity, or
              likelihood ratio. Both parametric and ``nonparametric'' indexes
              are classified in this manner. The various bias statistics are
              compared on pragmatic and theoretical grounds, and it is
              concluded that criterion location measures have many advantages
              in empirical work.",
  journal  = "Psychological bulletin",
  volume   =  107,
  number   =  3,
  pages    = "401--413",
  year     =  1990,
  issn     = "0033-2909",
  pmid     = "2841625194002500958",
  doi      = "10.1037/0033-2909.107.3.401"
}

@ARTICLE{Stanislaw1999-dd,
  title    = "Calculation of signal detection theory measures",
  author   = "Stanislaw, H and Todorov, N",
  abstract = "Signal detection theory (SDT) may be applied to any area of
              psychology in which two different types of stimuli must be
              discriminated. We describe several of these areas and the
              advantages that can be realized through the application of SDT.
              Three of the most popular tasks used to study discriminability
              are then discussed, together with the measures that SDT
              prescribes for quantifying performance in these tasks.
              Mathematical formulae for the measures are presented, as are
              methods for calculating the measures with lookup tables, computer
              software specifically developed for SDT applications, and general
              purpose computer software (including spreadsheets and statistical
              analysis software).",
  journal  = "Behavior research methods, instruments, \& computers: a journal
              of the Psychonomic Society, Inc",
  volume   =  31,
  number   =  1,
  pages    = "137--149",
  year     =  1999,
  issn     = "0743-3808",
  pmid     = "10495845",
  doi      = "10.3758/BF03207704"
}

@ARTICLE{Powers2007-jw,
  title    = "Evaluation: From Precision , Recall and {F-Factor} to {ROC} ,
              Informedness , Markedness \& Correlation",
  author   = "Powers, David M W",
  abstract = "Commonly used evaluation measures including Recall, Precision,
              F-Factor and Rand Accuracy are biased and should not be used
              without clear understanding of the biases, and corresponding
              identification of chance or base case levels of the statistic.
              Using these measures a system that performs worse in the
              objective sense of Informedness, can appear to perform better
              under any of these commonly used measures. We discuss several
              concepts and measures that reflect the probability that
              prediction is informed versus chance. Informedness and introduce
              Markedness as a dual measure for the probability that prediction
              is marked versus chance. Finally we demonstrate elegant
              connections between the concepts of Informedness, Markedness,
              Correlation and Significance as well as their intuitive
              relationships with Recall and Precision, and outline the
              extension from the dichotomous case to the general multi-class
              case.",
  journal  = "Journal of Machine Learning Technologies",
  volume   =  2,
  number   = "December",
  pages    = "37--63",
  year     =  2007,
  keywords = "bookmaker informedness and markedness; chi-squared significance;
              cohen kappa; evenness; f-factor; log-likelihood; matthews
              correlation; pearson correlation; precision; rand accuracy;
              recall; significance"
}

@ARTICLE{Volk2012-ff,
  title    = "Melodic similarity among folk songs: An annotation study on
              similarity-based categorization in music",
  author   = "Volk, Anna and van Kranenburg, Peter",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  volume   =  0,
  number   =  0,
  pages    = "1--23",
  year     =  2012,
  keywords = "categorization; melodic similarity; musical features; tune
              families",
  issn     = "1029-8649",
  doi      = "10.1177/1029864912448329"
}

@INPROCEEDINGS{Typke2003-vv,
  title     = "Using transportation distances for measuring melodic similarity",
  booktitle = "Proceedings of the Fourth International Conference on Music
               Information Retrieval",
  author    = "Typke, Rainer and Giannopoulos, Panos and Veltkamp, Remco C and
               Wiering, Frans and van Oostrum, Ren{\'e}",
  pages     = "107--114",
  year      =  2003
}

@ARTICLE{Mullensiefen2007-hq,
  title    = "Modelling experts' notions of melodic similarity",
  author   = "M{\"u}llensiefen, Daniel and Frieler, Klaus",
  abstract = "In this article we show that a subgroup of music experts has a
              reliable and consistent notion of melodic similarity, and that
              this notion can be measured with satisfactory precision. Our
              measurements enable us to model the similarity ratings of music
              experts by automated and algorithmic means. A large number of
              algorithmic similarity measure found in the literature were
              mathematically systematised and implemented. The best similarity
              algorithms compared to human experts were chosen and optimised by
              statistical means according to different contexts. A
              multidimensional scaling model of the algorithmic similarity
              measures is constructed to give an overiew over the different
              musical dimensions reflected by these measures. We show some
              examples where this optimised methods could be successfully
              applied to real world problems like folk song categorisation and
              analysis, and discuss further applications and implications.",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  volume   = "Disc.4A",
  pages    = "183--210",
  year     =  2007,
  issn     = "1029-8649",
  doi      = "10.1177/102986490701100108"
}

@ARTICLE{Mullensiefen2003-sx,
  title    = "Cognitive adequacy in the measurement of melodic similarity:
              Algorithmic vs. human judgments",
  author   = "M{\"u}llensiefen, Daniel and Frieler, Klaus",
  abstract = "Melodic similarity is a central concept in many sub-disciplines
              of musicology, as well as for many computer-based applications
              that deal with the classifications and retrieval of melodic
              material. This paper describes a research paradigm for finding an
              `optimal' similarity measure out of a multitude of different
              approaches and algorithmic variants. The repertory used in this
              study are short melodies from popular (pop) songs and the
              empirical data for validation stem from two extensive listener
              experiments with expert listeners (musicology students). The
              different approaches to melodic-similarity measurement are first
              discussed and mathematically systematized. Detailed description
              of the listener experiments is given and the results are
              discussed. Strengths and weaknesses of the several tested
              similarity measures are outlined and an `optimal' similarity
              measure for this specific melodic repertory is proposed.",
  journal  = "Computing in musicology",
  volume   =  13,
  pages    = "1--30",
  year     =  2003
}

@INPROCEEDINGS{Grachten2004-rf,
  title     = "Melodic similarity: Looking for a good abstraction level",
  booktitle = "Proceedings of the 5th International Society for Music
               Information Retrieval",
  author    = "Grachten, Maarten and Arcos, Josep Lluis and M{\'a}ntaras, Ramon
               L{\'o}pez De",
  abstract  = "Computing melodic similarity is a very general problem with
               diverse musical applications ranging from music analysis to
               content-based retrieval. Choosing the appropriate level of
               representation is a crucial issue and depends on the type of
               application. Our research interest concerns the development of a
               CBR system for expressive music processing. In that context, a
               well chosen distance measure for melodies is a crucial issue. In
               this paper we propose a new melodic similarity measure based on
               the I/R model for melodic structure and compare it with other
               existing measures. The experimentation shows that the proposed
               measure provides a good compromise between discriminatory power
               and ability to recognize phrases from the same song.",
  year      =  2004
}

@ARTICLE{Aloupis2006-bl,
  title    = "Algorithms for Computing Geometric Measures of Melodic Similarity",
  author   = "Aloupis, Greg and Fevens, Thomas and Langerman, Stefan and
              Matsui, Tomomi and Mesa, Antonio and Nu{\~n}ez, Yurai and
              Rappaport, David and Toussaint, Godfried",
  abstract = "The article discusses the algorithms for the computation of
              geometric measures of melodic similarity for computer music.
              Algorithms are used to measure rhythmic and melodic similarity.
              Specifically, algorithms are used to find the minimum area
              between orthogonal melodies. The algorithms can also be used for
              cyclic melodies and in the context of retrieving short patterns
              from a database. The article also discusses the natural
              extensions, both for the polygonal description of melodies and
              for different types of queries.",
  journal  = "Computer Music Journal",
  volume   =  30,
  number   =  3,
  pages    = "67--76",
  year     =  2006,
  issn     = "0148-9267",
  doi      = "10.1162/comj.2006.30.3.67"
}

@ARTICLE{Hu2002-gx,
  title    = "A probabilistic model of melodic similarity",
  author   = "Hu, Ning and Dannenberg, Roger B and Lewis, Al",
  abstract = "Melodic similarity is an important concept for music databases,
              musicological studies, and interactive music systems. Dynamic
              programming is commonly used to compare melodies, often with a
              distance function based on pitch differences measured in
              semitones. This approach computes an ``edit distance'' as a
              measure of melodic dissimilarity. The problem can also be viewed
              in probabilistic terms: What is the probability that a melody is
              a ``mutation'' of another melody, given a table of mutation
              probabilities? We explain this approach and demonstrate how it
              can be used to search a database of melodies. Our experiments
              show that the probabilistic model performs better than a typical
              ``edit distance'' comparison. 1",
  journal  = "Proceedings of the 2002 International Computer Music Conference",
  pages    = "509--515",
  year     =  2002
}

@INPROCEEDINGS{Mullensiefen2004-lq,
  title     = "Measuring melodic similarity: Human vs. algorithmic judgments",
  booktitle = "Proceedings of the conference on interdisciplinary musicology",
  author    = "M{\"u}llensiefen, Daniel and Frieler, Klaus",
  year      =  2004
}

@INPROCEEDINGS{Mullensiefen2004-sm,
  title     = "Optimizing measures of melodic similarity for the exploration of
               a large folk song database",
  booktitle = "5th International Conference on Music Information Retrieval
               {ISMIR} 2004",
  author    = "M{\"u}llensiefen, Daniel and Frieler, Klaus",
  abstract  = "This investigation aims at finding an optimal similarity measure
               for melodies. The application purpose for this study was the
               automatic analysis and classification of a large folk song
               collection from Luxembourg that had been thoroughly analysed by
               an expert ethnomusicologist. To find an optimal similarity
               measure, first a systemization of the current approaches to
               similarity measurement of melodies was done. About 50 similarity
               measures differing in the way of transforming musical data and
               in the computational algorithms were implemented. Three listener
               experiments were conducted to compare the performance of the
               different measures to human experts' ratings. An optimized model
               was obtained using linear regression, which combines the output
               of several measures representing different musical dimensions.
               The performance of this optimized measure was compared with the
               classification work of a human ethnomusicologist on a collection
               of 577 folksongs from Luxembourg.",
  pages     = "274--280",
  year      =  2004,
  isbn      = "9788488042446"
}

@ARTICLE{Eerola2001-pe,
  title    = "Statistical Features and Perceived Similarity of Folk Melodies",
  author   = "Eerola, Tuomas and J{\"a}rvinen, Topi and Louhivuori, Jukka and
              Toiviainen, Petri",
  abstract = "Notes that listeners are sensitive to pitch distributional
              information in music (N. Oram and L. L. Cuddy, 1995; C. L.
              Krumhansl, et al, 1999). However, it is uncertain whether
              frequency-based musical features are sufficient to explain the
              similarity judgments that underlie listeners' classification
              processes. A similarity rating experiment was designed to
              determine the effectiveness of these features in predicting
              listeners' similarity ratings. 17 undergraduate music students
              (mean age 23.4 yrs) participated. The material consisted of 15
              melodies representing 5 folk music styles. A multiple regression
              analysis showed that the similarity of frequency-based musical
              properties could account for a moderate amount (40\%) of
              listeners' similarity ratings. A slightly better predictive rate
              (55\%) was achieved by using descriptive variables such as number
              of tones, rhythmic variability, and melodic predictability. The
              results suggest that both measures were able to capture some
              aspects of the structures that portray common salient dimensions
              to which listeners pay attention while categorizing melodies.
              (PsycINFO Database Record (c) 2004 APA, all rights reserved)",
  journal  = "Music perception",
  volume   =  18,
  number   =  3,
  pages    = "275--296",
  year     =  2001,
  issn     = "0730-7829",
  doi      = "10.1525/mp.2001.18.3.275"
}

@INPROCEEDINGS{Toiviainen2002-pd,
  title     = "A computational model of melodic similarity based on multiple
               representations and self-organising maps",
  booktitle = "Proceedings of the 7th international conference on music
               perception and cognition international conference on music
               perception and cognition",
  author    = "Toiviainen, Petri and Eerola, Tuomas",
  editor    = "Stevens, C and Burnham, D and McPherson, G and Schubert, E and
               Renwick, J",
  publisher = "Causal Productions",
  pages     = "236--239",
  year      =  2002,
  address   = "Adelaide, Australia"
}

@ARTICLE{Walley1988-pm,
  title    = "Spoken word recognition by young children and adults",
  author   = "Walley, Amanda C",
  abstract = "The nature of the stimulus information that is important for the
              recognition of auditorily presented words by young (5-year-old)
              children and adults was studied. In Experiment 1, subjects
              identified and rated the extent of noise disruption for words in
              which white noise either was added to or replaced phoneme
              (fricative and nonfricative) segments in word-initial, -medial or
              -final position. In Experiment 2, subjects identified words as
              acoustic-phonetic information accumulated either from their
              beginnings or ends with silence or envelope-shaped noise
              replacing the nonpresented parts. The results point to
              developmental similarities in the derivation of phoneme
              identities from impoverished sensory input to support the
              component processes of recognition. However, position-specific
              information may play a less prominent role in recognition for
              children than for adults.",
  journal  = "Cognitive development",
  volume   =  3,
  number   =  2,
  pages    = "137--165",
  year     =  1988,
  issn     = "0885-2014",
  doi      = "10.1016/0885-2014(88)90016-0"
}

@ARTICLE{Sugita1997-nf,
  title    = "Neuronal correlates of auditory induction in the cat cortex",
  author   = "Sugita, Y",
  abstract = "Cells in the cat primary auditory cortex (A1) were investigated
              to see whether they could integrate sound signals over time. A1
              cells responded well to frequency-modulated sweeps. When a
              portion of the sweep was replaced by silence the response was
              weakened considerably. However, the response strength was
              restored when the silent portion was replaced by a burst of band
              noise, even though the cells did not respond to the burst of
              noise alone. These results indicate that A1 cells do not respond
              simply to instantaneous characteristics of acoustic stimuli but
              respond to those integrated over time.",
  journal  = "Neuroreport",
  volume   =  8,
  number   =  5,
  pages    = "1155--1159",
  year     =  1997,
  keywords = "auditory cortex; auditory induction; cat",
  issn     = "0959-4965",
  pmid     = "9175104",
  doi      = "10.1097/00001756-199703240-00019"
}

@ARTICLE{Petkov2003-lp,
  title    = "Illusory sound perception in macaque monkeys",
  author   = "Petkov, Christopher I and O'Connor, Kevin N and Sutter, Mitchell
              L",
  abstract = "In most natural listening environments, noise occludes objects of
              interest, and it would be beneficial for an organism to correctly
              identify those objects. When a sound of interest (``foreground''
              sound) is interrupted by a loud noise, subjects perceive the
              entire sound, even if the noise was intense enough to completely
              mask a part of it. This phenomenon can be exploited to create an
              illusion: when a silent gap is introduced into the foreground and
              high-intensity noise is superimposed into the gap, subjects
              report the foreground as continuing through the noise although
              that portion of the foreground was deleted. This phenomenon,
              referred to as auditory induction or amodal completion, is
              conceptually similar to visual induction, fill-in, illusory
              motion, and illusory contours. Two rhesus macaque monkeys
              performed a task designed to assess auditory induction. They were
              trained to discriminate complete stimuli from those containing a
              silent gap in the presence of two types of noise. Interrupting
              noise temporally coincided only with the gap, and in humans this
              causes induction. Surrounding noise temporally encompassed the
              entire foreground, and in humans this causes masking without
              auditory induction. Consistent with previous human psychophysical
              results, macaques showed better performance with surrounding
              masking noise than interrupting noise designed to elicit
              induction. These and other control experiments provide evidence
              that primates may share a general mechanism to perceptually
              complete missing sounds.",
  journal  = "The Journal of neuroscience: the official journal of the Society
              for Neuroscience",
  volume   =  23,
  number   =  27,
  pages    = "9155--9161",
  year     =  2003,
  keywords = "auditory; illusion; induction; psychophysics; scene analysis;
              segmentation; speech",
  issn     = "0270-6474, 1529-2401",
  pmid     = "14534249",
  doi      = "23/27/9155 [pii]"
}

@ARTICLE{Nobre2007-zd,
  title    = "The hazards of time",
  author   = "Nobre, Anna C and Correa, A and Coull, J T",
  abstract = "Temporal expectations are continuously formed and updated, and
              interact with expectations about other relevant attributes of
              events, in order to optimise our interaction with unfolding
              sensory stimulation. In this paper, we will highlight some
              evidence revealing the pervasive effects of temporal expectations
              in modulating perception and action, and reflect on the current
              state of understanding about their underlying neural systems and
              mechanisms. ?? 2007 Elsevier Ltd. All rights reserved.",
  journal  = "Current opinion in neurobiology",
  volume   =  17,
  pages    = "1--6",
  year     =  2007,
  issn     = "0959-4388",
  pmid     = "17709239",
  doi      = "10.1016/j.conb.2007.07.006"
}

@ARTICLE{Palmer1987-lw,
  title   = "Pitch and temporal contributions to musical phrase perception:
             Effects of harmony, performance timing, and familiarity",
  author  = "Palmer, Caroline and Krumhansl, Carol L",
  journal = "Perception \& psychophysics",
  volume  =  41,
  number  =  6,
  pages   = "505--518",
  year    =  1987,
  issn    = "0031-5117"
}

@ARTICLE{Newman2004-hy,
  title   = "Perceptual restoration in children versus adults",
  author  = "Newman, Rochelle S",
  journal = "Applied psycholinguistics",
  volume  =  25,
  pages   = "481--493",
  year    =  2004,
  issn    = "0142-7164",
  doi     = "10.1017/S0142716404001237"
}

@ARTICLE{Murray2013-cv,
  title    = "Attention Restores Discrete Items to Visual {Short-Term} Memory",
  author   = "Murray, A M and Nobre, Anna C and Clark, I a and Cravo, a M and
              Stokes, M G",
  journal  = "Psychological science",
  volume   =  24,
  number   =  4,
  pages    = "550--556",
  year     =  2013,
  keywords = "11; 12; 8; 9; attention; frees behavior from direct; received 10;
              revision accepted 6; short-term memory; visual short-term memory;
              vstm",
  issn     = "0956-7976",
  doi      = "10.1177/0956797612457782"
}

@ARTICLE{Jones1989-tn,
  title    = "Dynamic attending and responses to time",
  author   = "Jones, Mari Riess and Boltz, M",
  abstract = "A temporally based theory of attending is proposed that assumes
              that the structure of world events affords different attending
              modes. Future-oriented attending supports anticipatory behaviors
              and occurs with highly coherent temporal events. Time judgments,
              given this attending mode, are influenced by the way an event's
              ending confirms or violates temporal expectancies. Analytic
              attending supports other activities (e.g., grouping, counting),
              and if it occurs with events of low temporal coherence, then time
              judgments depend on the attending levels involved. A weighted
              contrast model describes over- and underestimations of event
              durations. The model applies to comparative duration judgments of
              equal and unequal time intervals; its rationale extends to
              temporal productions/extrapolations. Two experiments compare
              predictions of the contrast model with those derived from other
              traditional approaches.",
  journal  = "Psychological review",
  volume   =  96,
  number   =  3,
  pages    = "459--491",
  year     =  1989,
  issn     = "0033-295X",
  pmid     = "2756068",
  doi      = "10.1037/0033-295X.96.3.459"
}

@ARTICLE{Petkov2007-hg,
  title    = "Encoding of illusory continuity in primary auditory cortex",
  author   = "Petkov, Christopher I and O'Connor, Kevin N and Sutter, Mitchell
              L",
  abstract = "When interfering objects occlude a scene, the visual system
              restores the occluded information. Similarly, when a sound of
              interest (a ``foreground'' sound) is interrupted (occluded) by
              loud noise, the auditory system restores the occluded
              information. This process, called auditory induction, can be
              exploited to create a continuity illusion. When a segment of a
              foreground sound is deleted and loud noise fills the missing
              portion, listeners incorrectly report hearing the foreground
              continuing through the noise. Here we reveal the
              neurophysiological underpinnings of illusory continuity in
              single-neuron responses from awake macaque monkeys' primary
              auditory cortex (A1). A1 neurons represented the missing segment
              of occluded tonal foregrounds by responding to discontinuous
              foregrounds interrupted by intense noise as if they were
              responding to the complete foregrounds. By comparison, simulated
              peripheral responses represented only the noise and not the
              occluded foreground. The results reveal that many A1
              single-neuron responses closely follow the illusory percept.
              \copyright{} 2007 Elsevier Inc. All rights reserved.",
  journal  = "Neuron",
  volume   =  54,
  number   =  1,
  pages    = "153--165",
  year     =  2007,
  keywords = "SYSBIO; SYSNEURO",
  issn     = "0896-6273",
  pmid     = "17408584",
  doi      = "10.1016/j.neuron.2007.02.031"
}

@ARTICLE{Winstone2012-cs,
  title   = "Developmental improvements in perceptual restoration: Can young
             children reconstruct missing sounds in noisy environments?",
  author  = "Winstone, Naomi and Davis, Alyson and de Bruyn, Bart",
  journal = "Infant and child development",
  volume  =  21,
  pages   = "287--297",
  year    =  2012,
  issn    = "1522-7227"
}

@ARTICLE{Kaminska1993-ic,
  title    = "Transformation, migration and restoration",
  author   = "Kaminska, Zofia and Mayer, Peter",
  abstract = "The traditional dichotomy between speech and non-speech sounds
              was questioned. The fate of musical stimuli was explored in three
              illusion-producing paradigms: ?transformation? of veridical
              perception under conditions of invariant stimulus input,
              ?migration? of extraneous sounds revealing cognitive
              re-structuring of the linear input, and ?restoration? of absent
              sounds. These effects, arising from the low correspondence
              between physical input and conscious representation
              characteristic of speech perception, are considered to be
              speech-specific. Experiment 1 revealed musical sounds to be as
              susceptible to perceptual transformations as speech. Experiment 2
              demonstrated cognitively imposed structuring in music evidenced
              by migration of extraneous sounds. Experiments 3 and 4 provided
              evidence of perceptual restoration of missing fragments of music.
              These parallels between music and speech in terms of deviation of
              the psychological representation from the underlying signal
              suggest that listening to music is far from the linear,
              data-driven process assumed by psychological theory and implicate
              strong top-down influences in the perception of
              music.\textbackslashnThe traditional dichotomy between speech and
              non-speech sounds was questioned. The fate of musical stimuli was
              explored in three illusion-producing paradigms: ?transformation?
              of veridical perception under conditions of invariant stimulus
              input, ?migration? of extraneous sounds revealing cognitive
              re-structuring of the linear input, and ?restoration? of absent
              sounds. These effects, arising from the low correspondence
              between physical input and conscious representation
              characteristic of speech perception, are considered to be
              speech-specific. Experiment 1 revealed musical sounds to be as
              susceptible to perceptual transformations as speech. Experiment 2
              demonstrated cognitively imposed structuring in music evidenced
              by migration of extraneous sounds. Experiments 3 and 4 provided
              evidence of perceptual restoration of missing fragments of music.
              These parallels between music and speech in terms of deviation of
              the psychological representation from the underlying signal
              suggest that listening to music is far from the linear,
              data-driven process assumed by psychological theory and implicate
              strong top-down influences in the perception of music.",
  journal  = "Contemporary Music Review",
  volume   =  9,
  number   = "1-2",
  pages    = "151--161",
  year     =  1993,
  issn     = "0749-4467",
  doi      = "10.1080/07494469300640411"
}

@ARTICLE{Samuel1981-gf,
  title    = "The role of bottom-up confirmation in the phonemic restoration
              illusion",
  author   = "Samuel, Arthur G",
  abstract = "Phonemic restoration is an illusion in which listeners hear
              spoken words as intact, even though parts of them have been
              replaced by an extraneous sound. An improved methodology was used
              to investigate how much the illusion depends upon the bottom-up
              confirmation of expectations generated at higher levels. A
              powerful bottom-up factor was phone class of the sound to be
              restored, and its acoustic similarity to the sound that replaced
              it. When white noise was the replacement sound, fricatives were
              better restored than vowels, whereas the pattern reversed with a
              pure tone replacement. Including a short silence period increased
              restoration of stop consonants. The data indicate that phonemic
              restoration depends upon the interplay between the listener's
              expectations and the acoustic signal.",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  7,
  number   =  5,
  pages    = "1124--1131",
  year     =  1981,
  issn     = "0096-1523",
  pmid     = "6457110",
  doi      = "10.1037/0096-1523.7.5.1124"
}

@ARTICLE{White1960-nu,
  title   = "Recognition of distorted melodies",
  author  = "White, Benjamin W",
  journal = "The American journal of psychology",
  volume  =  73,
  number  =  1,
  pages   = "100--107",
  year    =  1960,
  issn    = "0002-9556"
}

@ARTICLE{Warren1972-ef,
  title    = "Auditory induction: Perceptual synthesis of absent sounds",
  author   = "Warren, Richard M and Obusek, Charles J and Ackroff, J M",
  abstract = "Within certain auditory patterns, fainter sounds may be ``heard''
              clearly when replaced by louder sounds having appropriate
              spectral compositions. This auditory induction of fainter by
              louder sounds can cancel the perceptual effects of masking.
              Phonemic restorations, which have been reported previously,
              appear to be a specialized application to speech of the much
              broader phenomenon of auditory induction. The rules governing
              auditory induction indicate that it helps maintain stable
              auditory perception in our frequently noisy environment.",
  journal  = "Science",
  volume   =  176,
  number   =  4039,
  pages    = "1149--1151",
  year     =  1972,
  issn     = "0036-8075",
  pmid     = "5035477",
  doi      = "10.1126/science.176.4039.1149"
}

@ARTICLE{Warren1984-of,
  title    = "Perceptual restoration of obliterated sounds",
  author   = "Warren, Richard M",
  abstract = "When portions of a signal are masked in noisy environments,
              perceptual restoration can be accomplished through auditory
              induction (AI). There are two classes of AI: (a) temporal
              induction (TI), which restores contextually appropriate segments
              of a signal masked at both ears by transient noises (TI can
              prevent fragmentation of steady sounds and can permit
              comprehension of speech that otherwise would be unintelligible),
              and (b) contralateral induction (CI), which restores a signal
              masked at one ear when it is heard at the other (CI can prevent
              mislocalization of a sound source to the side of the unmasked
              ear). Both classes of AI are subtractive processes requiring that
              the neural units corresponding to the perceptually restored sound
              be among those stimulated by the louder interrupting sound. The
              rules governing AI provide information concerning general
              principles underlying perceptual organization in hearing.",
  journal  = "Psychological bulletin",
  volume   =  96,
  number   =  2,
  pages    = "371--383",
  year     =  1984,
  issn     = "0033-2909",
  pmid     = "6385048",
  doi      = "10.1037/0033-2909.96.2.371"
}

@ARTICLE{Warren1970-xp,
  title    = "Auditory illusions and confusions",
  author   = "Warren, Richard M and Warren, R P",
  abstract = "2 auditory illusions, ``phonemic restoration'' and the ``verbal
              transformation effect,'' provide techniques for studying the
              perceptual organization of heard speech. Studies of these
              illusions provide information concerning perceptual processes
              involved in the grouping of speech sounds, the resolution of
              acoustic ambiguities, and age-related changes in the processing
              of verbal input.",
  journal  = "Scientific American",
  volume   =  223,
  number   =  6,
  pages    = "30--36",
  year     =  1970,
  issn     = "0036-8733",
  pmid     = "5480550",
  doi      = "10.1038/scientificamerican1270-30"
}

@ARTICLE{Jones1982-rt,
  title   = "Music as a stimulus for psychological motion: Part {II}. An
             expectancy model",
  author  = "Jones, Mari Riess",
  journal = "Psychomusicology",
  volume  =  2,
  number  =  1,
  pages   = "1--13",
  year    =  1982
}

@ARTICLE{Thurlow1957-fz,
  title   = "An auditory figure-ground effect",
  author  = "Thurlow, Willard R",
  journal = "The American journal of psychology",
  volume  =  70,
  number  =  4,
  pages   = "653--654",
  year    =  1957,
  issn    = "0002-9556"
}

@ARTICLE{Jones1976-ux,
  title    = "Time, our lost dimension: toward a new theory of perception,
              attention, and memory",
  author   = "Jones, Mari Riess",
  abstract = "A theory of perception and attention that emphasizes the
              relational nature of perceptual invariants is developed within
              the context of auditory pattern research. The theory is divided
              into two parts. The first part, addresses world pattern
              structure; the second describes interaction of organisms with
              pattern structure. In the former, world patterns are subjectively
              represented as nested relations within a multi- dimensional space
              defined by pitch, loudness, and time. But dependency of these
              defining dimensions means that a pattern's time scale determines
              the serial integrity of its pitch/loudness structure. Second, the
              theory proposes a time scale for living things that is manifest
              in graded perceptual rhythms. These rhythms can be synchronized
              to corresponding nested time zones within world pattern
              structure. Related assumptions about the deployment of physical
              energy across time zones and cognitive locations of perceptual
              rhythms lead to a simple, but general, attentional theory.
              Theoretical support, found in research with tone patterns,
              speech, and sequences of noise is cited in a final section.
              Beyond this focal research, the theory offers a general framework
              for understanding diverse phenomena that range from speech
              perception and aphasia to sleep, growth, and time estimation.",
  journal  = "Psychological review",
  volume   =  83,
  number   =  5,
  pages    = "323--355",
  year     =  1976,
  issn     = "0033-295X",
  pmid     = "794904",
  doi      = "10.1037/0033-295X.83.5.323"
}

@ARTICLE{Jones1981-kc,
  title    = "Music as a stimulus for psychological motion: Part I. Some
              determinants of expectancies",
  author   = "Jones, Mari Riess",
  abstract = "This is the first of a two-part essay on the role of dynamic
              expectancies and their determinants in melody recognition. In
              this article, general ideas of expectancy as a time-based mental
              set and perceptual reference frames as cognitive anchor points
              are introduced. The bulk of the article addresses the
              identification of objective determinants within musical patterns
              that influence expectancies. It is proposed that these are
              simple, symmetry-based, regularities which follow ideal rules to
              reflect generic musical prototypes.",
  journal  = "Psychomusicology: A Journal of Research in Music Cognition",
  volume   =  1,
  number   =  2,
  pages    = "34--51",
  year     =  1981,
  issn     = "0275-3987",
  doi      = "10.1037/h0094282"
}

@ARTICLE{Dannenbring1976-dx,
  title    = "Perceived auditory continuity with alternately rising and falling
              frequency transitions",
  author   = "Dannenbring, G L",
  abstract = "Six experiments were conducted investigationg percieved auditory
              continuity with alternatly rising and falling frequency glides,
              in which the glides were percieved as continuous when detected
              portions were replaced by white noise bursts. The first three
              experiments showed that perceptual continuity could be obtained
              when the detected portion came eather in the middle of the glide,
              or at the top and bottom of the glides; continuity was actually
              better for the latter condition. Also, it was found that as glide
              duration increased, the threshold between percieved continuity
              and discontinuity increased. It was also found, in Experiments IV
              - VI, that when the peak was deletedand replaced with noise,
              there was no perceptual extrapolation of the incomplete glides;
              rather, there seemed to be considerable rounding off of the
              trajectory of the glide.",
  journal  = "Canadian journal of psychology",
  volume   =  30,
  number   =  2,
  pages    = "99--114",
  year     =  1976,
  issn     = "0008-4255",
  pmid     = "974899",
  doi      = "10.1037/h0082053"
}

@ARTICLE{Schmuckler1989-qx,
  title    = "Expectation in music: Investigation of melodic and harmonic
              processes",
  author   = "Schmuckler, Mark A",
  abstract = "Investigated the formation of expectancies in 32 musically
              trained listeners and 6 performers in 4 experiments. Exps 1 and 2
              examined the factors underlying the formation of melodic and
              harmonic expectancies. Both experiments found evidence for the
              psychological reality of constructs derived from the
              music-theoretic literature in expectancy formation. Exp 3 found
              that melody and harmony were perceptually independent, so that
              they combined additively in expectancy formation for a full
              musical context. In Exp 4, skilled pianists performed their
              expectations for the same passages. These productions strongly
              correlated with the perceptual expectancies of Exps 1-3.
              (PsycINFO Database Record (c) 2007 APA, all rights reserved)",
  journal  = "Music perception",
  volume   =  7,
  number   =  2,
  pages    = "109--149",
  year     =  1989,
  keywords = "Auditory Perception; Cognition; Expectations; Improvisation;
              Music; formation of melodic \& harmonic expectancies; musi",
  issn     = "0730-7829",
  doi      = "10.2307/40285454"
}

@ARTICLE{Schellenberg1997-cu,
  title   = "Simplifying the {Implication-Realization} model of melodic
             expectancy",
  author  = "Schellenberg, E Glenn",
  journal = "Music perception",
  volume  =  14,
  number  =  3,
  pages   = "295--318",
  year    =  1997,
  issn    = "0730-7829"
}

@ARTICLE{Margulis2005-xx,
  title   = "A model of melodic expectation",
  author  = "Margulis, Elizabeth Hellmuth",
  journal = "Music perception",
  volume  =  22,
  number  =  4,
  pages   = "663--714",
  year    =  2005,
  issn    = "0730-7829"
}

@ARTICLE{Large1999-gj,
  title   = "The dynamics of attending: How people track time-varying events",
  author  = "Large, Edward W and Jones, Mari Riess",
  journal = "Psychological review",
  volume  =  106,
  number  =  1,
  pages   = "119--159",
  year    =  1999,
  issn    = "0033-295X"
}

@ARTICLE{Carlsen1981-vc,
  title   = "Some factors which influence melodic expectancy",
  author  = "Carlsen, James C",
  journal = "Psychomusicology: A Journal of Research in Music Cognition",
  volume  =  1,
  number  =  1,
  pages   = "12--29",
  year    =  1981,
  issn    = "0275-3987",
  doi     = "10.1037/h0094276"
}

@ARTICLE{Cravo2013-os,
  title    = "Temporal expectation enhances contrast sensitivity by phase
              entrainment of low-frequency oscillations in visual cortex",
  author   = "Cravo, Andr{\'e} M and Rohenkohl, Gustavo and Wyart, Valentin and
              Nobre, Anna C",
  abstract = "Although it is increasingly accepted that temporal expectation
              can modulate early perceptual processing, the underlying neural
              computations remain unknown. In the present study, we combined a
              psychophysical paradigm with electrophysiological recordings to
              investigate the putative contribution of low-frequency
              oscillatory activity in mediating the modulation of visual
              perception by temporal expectation. Human participants judged the
              orientation of brief targets (visual Gabor patterns tilted
              clockwise or counterclockwise) embedded within temporally regular
              or irregular streams of noise-patches used as temporal cues.
              Psychophysical results indicated that temporal expectation
              enhanced the contrast sensitivity of visual targets. A diffusion
              model indicated that rhythmic temporal expectation modulated the
              signal-to-noise gain of visual processing. The concurrent
              electrophysiological data revealed that the phase of delta
              oscillations overlying human visual cortex (1-4 Hz) was
              predictive of the quality of target processing only in regular
              streams of events. Moreover, in the regular condition, the
              optimum phase of these perception-predictive oscillations
              occurred in anticipation of the expected events. Together, these
              results show a strong correspondence between psychophysical and
              neurophysiological data, suggesting that the phase entrainment of
              low-frequency oscillations to external sensory cues can serve as
              an important and flexible mechanism for enhancing sensory
              processing.",
  journal  = "The Journal of neuroscience: the official journal of the Society
              for Neuroscience",
  volume   =  33,
  number   =  9,
  pages    = "4002--4010",
  year     =  2013,
  keywords = "Adult; Attention; Brain Mapping; Contrast Sensitivity; Contrast
              Sensitivity: physiology; Cues; Electroencephalography; Evoked
              Potentials, Visual; Evoked Potentials, Visual: physiology;
              Female; Humans; Male; Periodicity; Photic Stimulation;
              Psychometrics; Psychophysics; Reaction Time; Reaction Time:
              physiology; Visual Cortex; Visual Cortex: physiology; Young Adult",
  issn     = "0270-6474, 1529-2401",
  pmid     = "23447609",
  doi      = "10.1523/JNEUROSCI.4675-12.2013"
}

@BOOK{Jones1987-hy,
  title    = "Recognizing melodies: A dynamic interpretation",
  author   = "Jones, Mari Riess and Summerell, Lee and Marshburn, Elizabeth",
  abstract = "Two experiments explore hypotheses about rhythm and Contour in
              recognition of simple pitch strings (melodies). Target melodies
              that differed with respect to pitch relationships (interval and
              contour pitch differences) and rhythm, were presented to ordinary
              listeners who were told to leam the melodies (Phase I). In a
              subsequent recognition test (Phase II), listeners had to
              recognize these same target melodies although they were
              transposed to a different musical key. In recognition, target
              melodies appeared in the original rhythm or in new rhythms that
              simulated some pause properties of the original rhythm. Target
              melodies were inter- spersed with decoy melodies that either
              preserved the pitch contour of targets or did not; all appeared
              in the original rhythm and in new rhythms. Results indicated that
              a new rhythmic context lowered recognizability of target
              melodies, and that decoys were most confusing when they possessed
              the same ``dynamic shape'' (contour-plus-rhythm) as targets
              (Experiment 1). Also, target recognition improved with Phase I
              familiarity (Experiment 2), although rhythmic shifts remained
              detrimental across levels of target familiarity. Confusions based
              on ``dynamic shape'' accounted for a rela- tively high proportion
              of errors where familiarity with targets is low. Findings were
              interpreted in terms of a theory of context-sensitive dynamic
              attending in which remembering is assumed to involve recap-
              itulation of the original rhythmical activities involved in
              attending to melodies.",
  volume   =  39,
  pages    = "89--121",
  year     =  1987,
  issn     = "0272-4987",
  isbn     = "9780272498873",
  doi      = "10.1080/02724988743000051"
}

@ARTICLE{Bigand1997-xn,
  title    = "Perceiving musical stability: The effect of tonal structure,
              rhythm, and musical expertise",
  author   = "Bigand, E",
  abstract = "The goal of this study was to investigate several factors that
              determine musical stability in unaccompanied tonal melodies.
              Following M. R. Jones's (1987) theory of dynamic attending, the
              author assumed that strongly accented tones act as stable melodic
              reference points. Three main results were observed: (a) tonal
              structure, rhythm, and melodic factors (i.e., pitch skips or
              change in melodic contour) all contributed to defining the
              stability experienced on the melodic tones; (b) a linear
              combination of 5 melodic and rhythmic features provided a good
              fit to the stability ratings; and (c) some of these features
              contributed differently, depending on the extent of musical
              expertise of the participants. The results are interpreted within
              C. L. Krumhansl's (1990) model of tonal perception and Jones's
              theory of dynamic attending.",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  23,
  number   =  3,
  pages    = "808--822",
  year     =  1997,
  issn     = "0096-1523",
  pmid     = "9180045",
  doi      = "10.1037/0096-1523.23.3.808"
}

@MISC{Laidlow_undated-oz,
  title  = "Effects of pitch changes on perceptual pitch salience and melodic
            similarity",
  author = "Laidlow, Rob"
}

@ARTICLE{Prince2009-mc,
  title    = "Pitch and time, tonality and meter: how do musical dimensions
              combine?",
  author   = "Prince, Jon B and Thompson, William F and Schmuckler, Mark A",
  abstract = "The authors examined how the structural attributes of tonality
              and meter influence musical pitch-time relations. Listeners heard
              a musical context followed by probe events that varied in pitch
              class and temporal position. Tonal and metric hierarchies
              contributed additively to the goodness-of-fit of probes, with
              pitch class exerting a stronger influence than temporal position
              (Experiment 1), even when listeners attempted to ignore pitch
              (Experiment 2). Speeded classification tasks confirmed this
              asymmetry. Temporal classification was biased by tonal stability
              (Experiment 3), but pitch classification was unaffected by
              temporal position (Experiment 4). Experiments 5 and 6 ruled out
              explanations based on the presence of pitch classes and temporal
              positions in the context, unequal stimulus quantity, and
              discriminability. The authors discuss how typical Western music
              biases attention toward pitch and distinguish between dimensional
              discriminability and salience.",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  35,
  number   =  5,
  pages    = "1598--1617",
  year     =  2009,
  keywords = "a central goal of; and; and how they; apprehend the complex
              visual; auditory stimuli with which; cognitive psychology is to;
              dimensional interactions; music; pitch; process by which
              listeners; they come into contact; time; understand the",
  issn     = "0096-1523",
  pmid     = "19803659",
  doi      = "10.1037/a0016456"
}

@ARTICLE{Prince2012-fn,
  title     = "The role of pitch and temporal diversity in the perception and
               production of musical sequences",
  author    = "Prince, Jon B and Pfordresher, Peter Q",
  abstract  = "In two experiments we explored how the dimensions of pitch and
               time contribute to the perception and production of musical
               sequences. We tested how dimensional diversity (the number of
               unique categories in each dimension) affects how pitch and time
               combine. In Experiment 1, 18 musically trained participants
               rated the complexity of sequences varying only in their
               diversity in pitch or time; a separate group of 18 pianists
               reproduced these sequences after listening to them without
               practice. Overall, sequences with more diversity were perceived
               as more complex, but pitch diversity influenced ratings more
               strongly than temporal diversity. Further, although participants
               perceived sequences with high levels of pitch diversity as more
               complex, errors were more common in the sequences with higher
               diversity in time. Sequences in Experiment 2 exhibited diversity
               in both pitch and time; diversity levels were a subset of those
               tested in Experiment 1. Again diversity affected complexity
               ratings and errors, but there were no statistical interactions
               between dimensions. Nonetheless, pitch diversity was the primary
               factor in determining perceived complexity, and again temporal
               errors occurred more often than pitch errors. Additionally,
               diversity in one dimension influenced error rates in the other
               dimension in that both error types were more frequent relative
               to Experiment 1. These results suggest that although pitch and
               time do not interact directly, they are nevertheless not
               processed in an informationally encapsulated manner. The
               findings also align with a dimensional salience hypothesis, in
               which pitch is prioritised in the processing of typical Western
               musical sequences. ?? 2012 Elsevier B.V.",
  journal   = "Acta psychologica",
  publisher = "Elsevier B.V.",
  volume    =  141,
  number    =  2,
  pages     = "184--198",
  year      =  2012,
  keywords  = "Music cognition; Music performance; Pitch; Time",
  issn      = "0001-6918",
  pmid      = "22968192",
  doi       = "10.1016/j.actpsy.2012.07.013"
}

@ARTICLE{Prince2014-wu,
  title    = "Pitch structure, but not selective attention, affects accent
              weightings in metrical grouping",
  author   = "Prince, Jon B",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  40,
  number   =  5,
  pages    = "2073--2090",
  year     =  2014,
  keywords = "10; 1037; a0037730; dimensional processing; doi; dx; http; music;
              org; pitch; supp; supplemental materials; time",
  issn     = "0096-1523"
}

@ARTICLE{Prince2014-lm,
  title    = "Contributions of pitch contour, tonality, rhythm, and meter to
              melodic similarity",
  author   = "Prince, Jon B",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  40,
  number   =  6,
  pages    = "2319--2337",
  year     =  2014,
  keywords = "music; pitch; similarity; time",
  issn     = "0096-1523"
}

@ARTICLE{Graves2014-sq,
  title    = "Expectations for melodic contours transcend pitch",
  author   = "Graves, Jackson E and Micheyl, Christophe and Oxenham, Andrew J",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  40,
  number   =  6,
  pages    = "2338--2347",
  year     =  2014,
  keywords = "expectation; loudness; melody; pitch; timbre",
  issn     = "0096-1523"
}

@ARTICLE{Samuel1997-sk,
  title    = "Lexical activation produces potent phonemic percepts",
  author   = "Samuel, Arthur G",
  abstract = "Theorists disagree about whether auditory word recognition is a
              fully bottom-up, autonomous process, or whether there is top-down
              processing within a more interactive architecture. The current
              study provides evidence for top-down lexical to phonemic
              activation. In several experiments, listeners labeled members of
              a /bI/-/dI/ test series, before and after listening to repeated
              presentations of various adapting sounds. Real English words
              (containing either a /b/ or a /d/) produced reliable adaptation
              shifts in labeling of the /bI/-/dI/ syllables. Critically, so did
              words in which the /b/ or /d/ was perceptually restored (when
              noise replaced the /b/ or /d/). Several control conditions
              demonstrated that no adaptation occurred when no phonemic
              restoration occurred. Similarly, no independent role in
              adaptation was found for lexical representations themselves.
              Thus, the results indicate that lexical activation can cause the
              perceptual process to synthesize a highly functional phonemic
              code. This result provides strong evidence for interactive models
              of word recognition.",
  journal  = "Cognitive psychology",
  volume   =  32,
  number   =  2,
  pages    = "97--127",
  year     =  1997,
  issn     = "0010-0285",
  pmid     = "9095679",
  doi      = "10.1006/cogp.1997.0646"
}

@ARTICLE{Samuel1996-nl,
  title    = "Phoneme restoration",
  author   = "Samuel, Arthur G",
  abstract = "Phonemic restoration is a powerful auditory illusion. When part
              of an utterance is replaced by another sound (e.g. white noise),
              listeners report that the utterance sounds intact---they
              perceptually restore the missing speech. Several paradigms have
              been used to measure this illusion, and to explore its bottom-up
              and top-down bases. These studies have shown that acoustic
              properties of the replacement sound (especially its
              psychoacoustic match to the speech it replaced) strongly affect
              the illusion. The effect also depends on listener-based factors,
              such as the amount of lexical activation of the tested word. The
              current report summarises the results of the restoration
              literature.",
  journal  = "Language and cognitive processes",
  volume   =  11,
  number   =  6,
  pages    = "647--654",
  year     =  1996,
  issn     = "0169-0965",
  doi      = "10.1080/016909696387051"
}

@ARTICLE{Mattys1997-aq,
  title    = "How Lexical Stress Affects Speech Segmentation and Interactivity:
              Evidence from the Migration Paradigm",
  author   = "Mattys, Sven and Samuel, Arthur G",
  abstract = "Current models of word recognition differ on the potential
              influence of lexical knowledge on sublexical processes. The
              present study addresses this issue through a paradigm based on
              the perceptual ``migration'' of linguistic units between two
              stimuli presented simultaneously, re- sulting in an illusory
              percept. For example, ``kinrtrorverrsy'' and ``bosrglorrarfe''
              were played at the same time, with subjects judging, in one
              condition, if ``controversy'' was presented and, in another
              condition, if ``bisrglorrarfe'' was presented. The results showed
              that, in dichotic listening, the migration of the vowel, leading
              to erroneous detection of the prespecified target, occurred less
              often with real word targets than with nonsense word targets.
              However, when the two items of the pairs were played in both ears
              at different amplitudes so that they were perceived to be closer
              to each other than in the dichotic situation, the lexical effect
              only remained when the mispronounced phoneme was in an unstressed
              syllable. This observation suggests that the mispronunciation of
              stressed syllables of words impairs lexical access in such a way
              that no lexical influence on early processing stages is possible.
              In contrast, the mispronunciation of unstressed syllables does
              not affect lexical access, thus allowing the lexical influence to
              take place. These results are problematic for temporally
              sequential (left-to-right) models of lexical access. Rather, they
              support models that include the stress patterns of words as an
              important aspect of both lexical access and the interaction
              between sublexical and lexical knowledge",
  journal  = "Journal of memory and language",
  volume   =  36,
  number   =  1,
  pages    = "87--116",
  year     =  1997,
  issn     = "0749-596X",
  doi      = "10.1006/jmla.1996.2472"
}

@ARTICLE{Wurm1997-vo,
  title   = "Lexical inhibition and attentional allocation during speech
             perception: Evidence from phoneme monitoring",
  author  = "Wurm, Lee H and Samuel, Arthur G",
  journal = "Journal of memory and language",
  volume  =  36,
  pages   = "165--187",
  year    =  1997,
  issn    = "0749-596X"
}

@ARTICLE{Schellenberg2014-yq,
  title    = "Memory for surface features of unfamiliar melodies: Independent
              effects of changes in pitch and tempo",
  author   = "Schellenberg, E Glenn and Stalinski, Stephanie M and Marks,
              Bradley M",
  abstract = "A melody's identity is determined by relations between
              consecutive tones in terms of pitch and duration, whereas surface
              features (i.e., pitch level or key, tempo, and timbre) are
              irrelevant. Although surface features of highly familiar
              recordings are encoded into memory, little is known about
              listeners' mental representations of melodies heard once or
              twice. It is also unknown whether musical pitch is represented
              additively or interactively with temporal information. In two
              experiments, listeners heard unfamiliar melodies twice in an
              initial exposure phase. In a subsequent test phase, they heard
              the same (old) melodies interspersed with new melodies. Some of
              the old melodies were shifted in key, tempo, or key and tempo.
              Listeners' task was to rate how well they recognized each melody
              from the exposure phase while ignoring changes in key and tempo.
              Recognition ratings were higher for old melodies that stayed the
              same compared to those that were shifted in key or tempo, and
              detrimental effects of key and tempo changes were additive in
              between-subjects (Experiment 1) and within-subjects (Experiment
              2) designs. The results confirm that surface features are
              remembered for melodies heard only twice. They also imply that
              key and tempo are processed and stored independently.",
  journal  = "Psychological research",
  volume   =  78,
  number   =  1,
  pages    = "84--95",
  year     =  2014,
  issn     = "0340-0727",
  pmid     = "23385775",
  doi      = "10.1007/s00426-013-0483-y"
}

@ARTICLE{Pitt1995-df,
  title    = "Lexical and sublexical feedback in auditory word recognition",
  author   = "Pitt, Mark A and Samuel, Arthur G",
  abstract = "Currently, there are two qualitatively different model classes in
              the field of spoken language understanding. Autonomous models
              allow only bottom-up information flow, whereas interactive models
              allow higher level representations (e.g., lexical) to affect
              processing at lower levels (e.g., phonemic). Part 1 of the
              present study included a test of a prediction that differentiates
              the two model classes: Is phoneme monitoring faster for targets
              in real words than in pseudowords, even before the word could in
              principle be recognized? The results indicate that this lexical
              advantage does occur, in accord with the predictions of
              interactive models. In Part 2, speech compression and expansion
              were used to assess the sufficiency or necessity of bottom-up
              evidence and of processing time in accomplishing lexical access.
              The results of Parts 1 and 2 suggested that in addition to the
              lexical effects posited by current models, sublexical activation
              may also play an important role. Data are presented in Part 3
              that support this interpretation. Collectively, the results in
              the current study support interactive models of lexical
              processing, but require additional sublexical processes as well.",
  journal  = "Cognitive psychology",
  volume   =  29,
  pages    = "149--188",
  year     =  1995,
  issn     = "0010-0285",
  pmid     = "7587137",
  doi      = "10.1006/cogp.1995.1014"
}

@ARTICLE{Pitt1990-re,
  title   = "Attentional allocation during speech perception: How fine is the
             focus?",
  author  = "Pitt, Mark A and Samuel, Arthur G",
  journal = "Journal of memory and language",
  volume  =  29,
  pages   = "611--632",
  year    =  1990,
  issn    = "0749-596X"
}

@ARTICLE{Samuel1991-wv,
  title    = "A further examination of attentional effects in the phonemic
              restoration illusion",
  author   = "Samuel, Arthur G",
  abstract = "Models of how listeners understand speech must specify the types
              of representations that are computed, the nature of the flow of
              information, and the control structures that modify performance.
              Three experiments are reported that focus on the control
              processes in speech perception. Subjects in the experiments tried
              to discriminate stimuli in which a phoneme had been replaced with
              white noise from stimuli in which white noise was merely
              superimposed on a phoneme. In the first two experiments, subjects
              practiced the discrimination for thousands of trials but did not
              improve, suggesting that they have poor access to low-level
              representations of the speech signal. In the third experiment,
              each (auditory) stimulus was preceded by a visual cue that could
              potentially be used to focus attention in order to enhance
              performance. Only subjects who received information about both
              the identity of the impending word and the identity of the
              critical phoneme showed enhanced discrimination. Other cues,
              including syllabic plus phonemic information, were ineffective.
              The results indicate that attentional control of processing is
              difficult but possible, and that lexical representations play a
              central role in the allocation of attention.",
  journal  = "The Quarterly journal of experimental psychology. A, Human
              experimental psychology",
  volume   =  43,
  number   =  3,
  pages    = "679--699",
  year     =  1991,
  issn     = "0272-4987",
  pmid     = "1775662",
  doi      = "10.1080/14640749108400992"
}

@ARTICLE{Samuel1996-iu,
  title    = "Does lexical information influence the perceptual restoration of
              phonemes?",
  author   = "Samuel, Arthur G",
  abstract = "A critical issue in modeling speech perception is whether lexical
              representations can affect lower level (e.g., phonemic)
              processing. Phonemic restoration studies have provided support
              for such top-down effects, but there have also been a number of
              failures to find them. A methodology is introduced that provides
              good approximations to the underlying distributions of perceived
              intactness that are assumed in signal detection analyses of
              restoration. This methodology provides a sensitive means to
              determine the necessary conditions for lexical feedback to occur.
              When these conditions are created, a reliable lexical influence
              on phonemic perception results. The experiments thus show that
              lexical activation does influence lower level processing, and
              that these influences are fragile. The theoretical implications
              of real but fragile lexical effects are discussed.",
  journal  = "Journal of experimental psychology. General",
  volume   =  125,
  number   =  1,
  pages    = "28--51",
  year     =  1996,
  keywords = "restoration",
  issn     = "0096-3445"
}

@ARTICLE{Samuel1980-qo,
  title    = "The effect of lexical uniqueness on phonemic restoration",
  author   = "Samuel, Arthur G",
  abstract = "Phonemic restoration is a powerful auditory illusion in which
              listeners hear a part of a word that has in fact been replaced by
              another sound. Two experiments explore whether the strength of
              the illusion is affected by whether a single lexical item could
              be restored. In Experiment 1, more perceptual restoration was
              found for stimuli that were multiply restorable (e.g.,
              ``\_egion'' $\rightarrow$ ``legion'' or ``region'') than for
              lexically unique ones (e.g., ``\_esion'' $\rightarrow$
              ``lesion''). In Experiment 2, lexical uniqueness was examined as
              a function of time: Words become lexically unique when enough has
              been heard to eliminate all alternatives. This manipulation also
              affected the strength of the illusion. The results complement
              those of other techniques in supporting an active role for
              lexical representations in the perception of speech.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  68,
  number   = "S1",
  pages    = "S48",
  year     =  1980,
  issn     = "0001-4966",
  doi      = "10.1121/1.2004762"
}

@MISC{R_Core_Team2014-jd,
  title   = "R: A language and environment for statistical computing",
  author  = "{R Core Team}",
  year    =  2014,
  address = "R Foundation for Statistical Computing, Vienna, Austria"
}

@ARTICLE{Chalmers2012-gt,
  title   = "mirt: A multidimensional item response theory package for the {R}
             Environment",
  author  = "Chalmers, R Philip",
  journal = "Journal of statistical software",
  volume  =  48,
  number  =  6,
  pages   = "1--29",
  year    =  2012
}

@ARTICLE{Scalise2015-xm,
  title   = "Use of open-source software for adaptive measurement: Concerto as
             an R-based computer adaptive development and delivery platform",
  author  = "Scalise, Kathleen and Allen, Diane D",
  journal = "The British journal of mathematical and statistical psychology",
  volume  =  68,
  number  =  3,
  pages   = "478--496",
  year    =  2015,
  issn    = "0007-1102",
  doi     = "10.1111/bmsp.12057"
}

@INCOLLECTION{Birnbaum1968-ds,
  title     = "Some latent trait models and their use in inferring an
               examinee's ability",
  booktitle = "Statistical theories of mental test scores",
  author    = "Birnbaum, A",
  publisher = "Addison-Wesley",
  pages     = "397--479",
  year      =  1968,
  address   = "Reading, MA"
}

@ARTICLE{Drasgow1983-lj,
  title   = "Modified parallel analysis: A procedure for examining the latent
             dimensionality of dichotomously scored item responses",
  author  = "Drasgow, Fritz and Lissak, Robin I",
  journal = "The Journal of applied psychology",
  volume  =  68,
  number  =  3,
  pages   = "363--373",
  year    =  1983,
  issn    = "0021-9010"
}

@ARTICLE{Chen1997-rl,
  title    = "Local dependence indexes for item pairs using item response
              theory",
  author   = "Chen, W-H and Thissen, D",
  abstract = "Four statistics are proposed for the detection of local
              dependence (LD) among items analyzed using item response theory.
              Among them, the X2 and G2 LD indexes are of special interest.
              Simulated data are used to study the distribution and sensitivity
              of these statistics under the null condition, as well as under
              conditions in which LD is introduced. The results show that under
              the nul condition, as well as under conditions in which LD is
              introduced. The results show that under the null condition of
              local independence, both the chisquare and the Gsquared LD
              indexes have distributions very similar to the ChiSquare
              distribution with 1 degree of freedom. Under the locally
              dependent conditions, both indexes appear to be sensitive in
              detecting LD or multidimensionality tic often used to detect LD,
              these new statistics are somewhat less powerful for among items.
              When compared to Q\%, underlying LD, equally powerful for surface
              LD, and better behaved in the null case.",
  journal  = "Journal of educational and behavioral statistics: a quarterly
              publication sponsored by the American Educational Research
              Association and the American Statistical Association",
  volume   =  22,
  number   =  3,
  pages    = "265--289",
  year     =  1997,
  keywords = "among; among them; for the detection of; four statistics are
              proposed; g 2 ld; indexes are of special; interest; irt; items
              analyzed using item; ld; local dependence; qj; response theory;
              simulated data are used; the x 2 and; to study the distribution",
  issn     = "1076-9986",
  doi      = "10.3102/10769986022003265"
}

@ARTICLE{Holm1979-ss,
  title    = "A simple sequentially rejective multiple test procedure",
  author   = "Holm, Sture",
  abstract = "This paper presents a simple and widely applicable multiple test
              procedure of the sequentially rejective type, i.e. hypotheses are
              rejected one at a time until no further rejections can be done.
              It is shown that the test has a prescribed level of significance
              protection against error of the first kind for any combination of
              true hypotheses. The power properties of the test and a number of
              possible applications are also discussed.",
  journal  = "Scandinavian journal of statistics, theory and applications",
  volume   =  6,
  pages    = "65--70",
  year     =  1979,
  keywords = "exact definition; methodological motivation; multiple test;
              simultaneous test",
  issn     = "0303-6898"
}

@ARTICLE{Green1960-fj,
  title   = "Psychoacoustics and detection theory",
  author  = "Green, David M",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  32,
  number  =  10,
  pages   = "1189--1203",
  year    =  1960,
  issn    = "0001-4966"
}

@MISC{Mullensiefen2015-bx,
  title   = "Investigating the importance of self-theories for students'
             academic and musical development",
  author  = "M{\"u}llensiefen, Daniel and Harrison, Peter M C and Caprini,
             Francesco and Fancourt, Amy",
  year    =  2015,
  address = "Manuscript under review"
}

@BOOK{Schaffrath1995-xx,
  title     = "The Essen Folksong Collection in Kern Format",
  author    = "Schaffrath, H",
  publisher = "Center for Computer Assisted Research in the Humanities",
  year      =  1995,
  address   = "Menlo Park, CA"
}

@ARTICLE{Repp2013-fg,
  title    = "Sensorimotor synchronization: a review of recent research
              (2006-2012)",
  author   = "Repp, Bruno H and Su, Yi-Huang",
  abstract = "Sensorimotor synchronization (SMS) is the coordination of
              rhythmic movement with an external rhythm, ranging from finger
              tapping in time with a metronome to musical ensemble performance.
              An earlier review (Repp, 2005) covered tapping studies; two
              additional reviews (Repp, 2006a, b) focused on music performance
              and on rate limits of SMS, respectively. The present article
              supplements and extends these earlier reviews by surveying more
              recent research in what appears to be a burgeoning field. The
              article comprises four parts, dealing with (1) conventional
              tapping studies, (2) other forms of moving in synchrony with
              external rhythms (including dance and nonhuman animals'
              synchronization abilities), (3) interpersonal synchronization
              (including musical ensemble performance), and (4) the
              neuroscience of SMS. It is evident that much new knowledge about
              SMS has been acquired in the last 7 years.",
  journal  = "Psychonomic bulletin \& review",
  volume   =  20,
  number   =  3,
  pages    = "403--452",
  year     =  2013,
  keywords = "Dancing; Humans; Music; Periodicity; Psychomotor Performance;
              Psychomotor Performance: physiology",
  issn     = "1069-9384, 1531-5320",
  pmid     = "23397235",
  doi      = "10.3758/s13423-012-0371-2"
}

@ARTICLE{Morrison2008-iq,
  title    = "Enculturation Effects in Music Cognition: The Role of Age and
              Music Complexity",
  author   = "Morrison, S J and Demorest, S M and Stambaugh, L a",
  abstract = "The authors replicate and extend findings from previous studies
              of music enculturation by comparing music memory performance of
              children to that of adults when listening to culturally familiar
              and unfamiliar music. Forty-three children and 50 adults, all
              born and raised in the United States, completed a music memory
              test comprising unfamiliar excerpts of Western and Turkish
              classical music. Examples were selected at two levels of
              difficulty--simple and complex--based on texture, instrument
              variety, presence of simultaneous musical lines, and clarity of
              internal repetition. All participants were significantly better
              at remembering novel music from their own culture than from an
              unfamiliar culture. Simple examples from both cultures were
              remembered significantly better than complex examples. Children
              performed as well as adults when remembering simple music from
              both cultures, whereas adults were better at remembering complex
              Western music. The results provide evidence that enculturation
              affects one's understanding of music structure before adulthood.",
  journal  = "Journal of Research in Music Education",
  volume   =  56,
  number   =  2,
  pages    = "118--129",
  year     =  2008,
  issn     = "0022-4294",
  doi      = "10.1177/0022429408322854"
}

@ARTICLE{Sinharay2003-om,
  title    = "Calibrating item families and summarizing the results using
              family expected response functions",
  author   = "Sinharay, Sandip and Johnson, Matthew S and Williamson, David M",
  journal  = "Journal of educational and behavioral statistics: a quarterly
              publication sponsored by the American Educational Research
              Association and the American Statistical Association",
  volume   =  28,
  number   =  4,
  pages    = "295--313",
  year     =  2003,
  keywords = "automatic item generation; bayesian methods; family expected
              response func-; item model; markov chain monte carlo;
              tion;ISM;RSM",
  issn     = "1076-9986"
}

@ARTICLE{Mair2007-ou,
  title    = "Extended Rasch modeling: The eRm package for the application of
              {IRT} models in {R}",
  author   = "Mair, Patrick and Hatzinger, Reinhold",
  abstract = "Item response theory models (IRT) are increasingly becoming
              established in social science research, particularly in the
              analysis of performance or attitudinal data in psy- chology,
              education, medicine, marketing and other fields where testing is
              relevant. We propose the R package eRm (extended Rasch modeling)
              for computing Rasch models and several extensions. A main
              characteristic of some IRT models, the Rasch model being the most
              prominent, concerns the separation of two kinds of parameters,
              one that describes qualities of the subject under investigation,
              and the other relates to qualities of the situation under which
              the response of a subject is observed. Using conditional maximum
              likelihood (CML) estimation both types of parameters may be
              estimated independently from each other. IRT models are well
              suited to cope with dichotomous and polytomous responses, where
              the response categories may be unordered as well as ordered. The
              incorporation of linear structures allows for modeling the
              effects of covariates and enables the analysis of repeated
              categorical measurements. The eRm package fits the following
              models: the Rasch model, the rating scale model (RSM), and the
              partial credit model (PCM) as well as linear reparameterizations
              through covariate structures like the linear logistic test model
              (LLTM), the linear rating scale model (LRSM), and the linear
              partial credit model (LPCM). We use an unitary, efficient CML
              approach to estimate the item parameters and their standard
              errors. Graphical and numeric tools for assessing goodness-of-fit
              are provided.",
  journal  = "Journal of statistical software",
  volume   =  20,
  number   =  9,
  pages    = "1--20",
  year     =  2007,
  keywords = "cml estimation; lltm; lpcm; lrsm; pcm; rasch model; rsm",
  issn     = "1548-7660"
}

@ARTICLE{Barr2013-tj,
  title     = "Random effects structure for confirmatory hypothesis testing:
               Keep it maximal",
  author    = "Barr, Dale J and Levy, Roger and Scheepers, Christoph and Tily,
               Harry J",
  abstract  = "Linear mixed-effects models (LMEMs) have become increasingly
               prominent in psycholinguistics and related areas. However, many
               researchers do not seem to appreciate how random effects
               structures affect the generalizability of an analysis. Here, we
               argue that researchers using LMEMs for confirmatory hypothesis
               testing should minimally adhere to the standards that have been
               in place for many decades. Through theoretical arguments and
               Monte Carlo simulation, we show that LMEMs generalize best when
               they include the maximal random effects structure justified by
               the design. The generalization performance of LMEMs including
               data-driven random effects structures strongly depends upon
               modeling criteria and sample size, yielding reasonable results
               on moderately-sized samples when conservative criteria are used,
               but with little or no power advantage over maximal models.
               Finally, random-intercepts-only LMEMs used on within-subjects
               and/or within-items data from populations where subjects and/or
               items vary in their sensitivity to experimental manipulations
               always generalize worse than separate F1 and F2 tests, and in
               many cases, even worse than F1 alone. Maximal LMEMs should be
               the 'gold standard' for confirmatory hypothesis testing in
               psycholinguistics and beyond. ?? 2012 Elsevier Inc.",
  journal   = "Journal of memory and language",
  publisher = "Elsevier Inc.",
  volume    =  68,
  number    =  3,
  pages     = "255--278",
  year      =  2013,
  keywords  = "Generalization; Linear mixed-effects models; Monte Carlo
               simulation; Statistics",
  issn      = "0749-596X",
  pmid      = "24403724",
  doi       = "10.1016/j.jml.2012.11.001"
}

@INCOLLECTION{Sinharay2013-al,
  title     = "Statistical modeling of automatically generated items",
  booktitle = "Automatic item generation: Theory and practice",
  author    = "Sinharay, Sandip and Johnson, Matthew S",
  editor    = "Gierl, M J and Haladyna, Thomas M",
  publisher = "Routledge",
  year      =  2013,
  address   = "New York, NY"
}

@MISC{Bates2015-uw,
  title  = "Linear mixed-effects models using Eigen and {S4}",
  author = "Bates, Douglas and Maechler, Martin and Bolker, Ben and Walker,
            Steven",
  year   =  2015
}

@ARTICLE{Sinharay2003-wp,
  title  = "An Application of a Bayesian Hierarchical Model for Item Family
            Calibration",
  author = "Sinharay, Sandip and Johnson, Matthew S and Williamson, David M",
  number = "February",
  year   =  2003
}

@ARTICLE{De_Boeck2011-ht,
  title   = "The estimation of item response models with the lmer function from
             the lme4 package in {R}",
  author  = "de Boeck, Paul and Bakker, Marjan and Zwitser, Robert and Nivard,
             Michel and Hofman, Abe and Tuerlinckx, Francis and Partchev,
             Ivailo",
  journal = "Journal of statistical software",
  volume  =  39,
  number  =  12,
  pages   = "1--28",
  year    =  2011
}

@ARTICLE{Drake1993-er,
  title    = "Reproduction of musical rhythms by children, adult musicians, and
              adult nonmusicians",
  author   = "Drake, C",
  abstract = "Many sequential events, musical rhythms in particular, can be
              described by a hierarchical structure, with lower order events
              recursively combining to form higher levels. This study
              investigated factors influencing the ease of reproduction of
              short musical rhythms that reflect various organizational
              principles. For adults and children, reproduction was better for
              rhythms with the following characteristics: (1) binary rather
              than ternary subdivision, (2) two rather than three different
              durations, (3) the ability to be segmented into two shorter
              rhythms of identical duration, and (4) intensity accents on
              important hierarchical positions. These findings suggest that a
              prototypical temporal structure--that is, a regular beat with
              binary subdivisions--is functional in childhood. The ability to
              process complex hierarchical structure appeared to be influenced
              more by musical training than by passive acculturation.",
  journal  = "Perception \& psychophysics",
  volume   =  53,
  number   =  1,
  pages    = "25--33",
  year     =  1993,
  issn     = "0031-5117",
  pmid     = "8433903",
  doi      = "10.3758/BF03211712"
}

@ARTICLE{Dean2007-ue,
  title    = "Generalized linear mixed models: A review and some extensions",
  author   = "Dean, C B and Nielsen, Jason D",
  abstract = "Breslow and Clayton (J Am Stat Assoc 88:9-25,1993) was, and still
              is, a highly influential paper mobilizing the use of generalized
              linear mixed models in epidemiology and a wide variety of fields.
              An important aspect is the feasibility in implementation through
              the ready availability of related software in SAS (SAS Institute,
              PROC GLIMMIX, SAS Institute Inc., URL http://www.sas.com , 2007),
              S-plus (Insightful Corporation, S-PLUS 8, Insightful Corporation,
              Seattle, WA, URL http://www.insightful.com , 2007), and R (R
              Development Core Team, R: A Language and Environment for
              Statistical Computing, R Foundation for Statistical Computing,
              Vienna, Austria, URL http://www.R-project.org , 2006) for
              example, facilitating its broad usage. This paper reviews
              background to generalized linear mixed models and the inferential
              techniques which have been developed for them. To provide the
              reader with a flavor of the utility and wide applicability of
              this fundamental methodology we consider a few extensions
              including additive models, models for zero-heavy data, and models
              accommodating latent clusters.",
  journal  = "Lifetime data analysis",
  volume   =  13,
  number   =  4,
  pages    = "497--512",
  year     =  2007,
  keywords = "Generalized linear mixed model; Longitudinal data analysis;
              Penalized quasi-likelihood; Random effects",
  issn     = "1380-7870",
  pmid     = "18000755",
  doi      = "10.1007/s10985-007-9065-x"
}

@ARTICLE{Smith1989-ip,
  title    = "Effects of metric and harmonic rhythm on the detection of pitch
              alterations in melodic sequences",
  author   = "Smith, K C and Cuddy, Lola L",
  abstract = "Tested response time to alterations. Metric rhythm and harmonic
              rhythm of 13-note tonal sequences were either matched or
              mismatched. Metric rhythm (3/4 or 4/4 meter) was induced by
              dynamic accents. Harmonic rhythm was induced by implied chord
              progressions initiated on the first note and on either every
              third or every fourth note. Responses were not always faster for
              matched rhythms or for alterations occurring on the dynamic
              accent. Responses were consistently faster for sequences
              presented in 4/4 meter. Musically untrained Ss performed
              similarly to trained Ss, but were slower and more variable.
              Accuracy of recall on a music dictation task also favored 4/4
              meter rather than matched rhythms. Coding of pitch content may
              have been facilitated by the structural framework of 4/4 meter
              rather than by expectancies arising from the match of temporal
              and pitch organization.",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  15,
  number   =  3,
  pages    = "457--471",
  month    =  aug,
  year     =  1989,
  keywords = "Adolescent; Adult; Attention; Discrimination Learning; Female;
              Humans; Male; Mental Recall; Music; Pitch Discrimination; Time
              Perception",
  issn     = "0096-1523",
  pmid     = "2527955"
}

@ARTICLE{DeWitt1990-le,
  title    = "The role of knowledge-based expectations in music perception:
              Evidence from musical restoration",
  author   = "DeWitt, L A and Samuel, Arthur G",
  abstract = "The perceptual restoration of musical sounds was investigated in
              5 experiments with Samuel's (1981a) discrimination methodology.
              Restoration in familiar melodies was compared to phonemic
              restoration in Experiment 1. In the remaining experiments, we
              examined the effect of expectations (generated by familiarity,
              predictability, and musical schemata) on musical restoration. We
              investigated restoration in melodies by comparing familiar and
              unfamiliar melodies (Experiment 2), as well as unfamiliar
              melodies varying in tonal and rhythmic predictability (Experiment
              3). Expectations based on both familiarity and predictability
              were found to reduce restoration at the melodic level.
              Restoration at the submelodic level was investigated with scales
              and chords in Experiments 4 and 5. At this level, key-based
              expectations were found to increase restoration. Implications for
              music perception, as well as similarities between restoration in
              music and speech, are discussed.",
  journal  = "Journal of experimental psychology. General",
  volume   =  119,
  number   =  2,
  pages    = "123--144",
  year     =  1990,
  issn     = "0096-3445",
  pmid     = "2141351",
  doi      = "10.1037/0096-3445.119.2.123"
}

@ARTICLE{Fischer1973-lf,
  title    = "The linear logistic test model as an instrument in educational
              research",
  author   = "Fischer, G H",
  abstract = "The present paper consists of a theoretical and an empirical
              part: First Rasch's test model for items with two answer
              categories is considered under the assumption of linear
              constraints on the item parameters (`linearlogistic model'). It
              is shown that this model is appropriate for the analysis of
              subject areas in instructional research if the subject area
              comprises tasks or items which are solved by the pupil by
              combination of a certain number of cognitive operations or rules.
              An empirical investigation was made which showed that the
              psychological complexity of problems in elementary differential
              calculus, as taught in secondary school mathematics, can be
              approximately explained through the assumption of seven
              psychologically meaningful operations. The psychological
              contribution of this analysis does not lie in a mere statistical
              description of item difficulties, but rather in the testing of
              hypotheses as to which steps (operations) in solving a problem
              are to be viewed as psychological units. It was seen, for
              instance, that differentiation of a polynomial is to be
              considered a single operation psychologically, which is mastered
              and correctly combined with the other operations or not, and that
              the complexity of a task is primarily determined by the
              combination of different operations and is not increased
              significantly when the same operation occurs repeatedly within
              the problem.",
  journal  = "Acta psychologica",
  volume   =  37,
  number   =  6,
  pages    = "359--374",
  year     =  1973,
  issn     = "0001-6918",
  doi      = "10.1016/0001-6918(73)90003-6"
}

@ARTICLE{Sinharay2008-ae,
  title   = "Use of item models in a large-scale admissions test: A case study",
  author  = "Sinharay, Sandip and Johnson, Matthew S",
  journal = "International Journal of Testing",
  volume  =  8,
  number  =  3,
  pages   = "209--236",
  year    =  2008,
  issn    = "1530-5058",
  doi     = "10.1080/15305050802262019"
}

@INCOLLECTION{Gierl2013-dp,
  title     = "Using weak and strong theory to create item models for automatic
               item generation: Some practical guidelines with examples",
  booktitle = "Automatic item generation: Theory and practice",
  author    = "Gierl, M J and Lai, Hollis",
  editor    = "Gierl, M J and Haladyna, Thomas M",
  publisher = "Routledge",
  year      =  2013,
  address   = "New York, NY"
}

@ARTICLE{Wood1973-ax,
  title   = "Response-contingent testing",
  author  = "Wood, Robert",
  journal = "Review of educational research",
  volume  =  43,
  number  =  4,
  pages   = "529--544",
  year    =  1973,
  issn    = "0034-6543"
}

@ARTICLE{Magis2012-jd,
  title    = "Random generation of response patterns under computerized
              adaptive testing with the {R} package catR",
  author   = "Magis, D and Gilles, R",
  abstract = "This paper outlines a computerized adaptive testing (CAT)
              framework and presents an R package for the simulation of
              response patterns under CAT procedures. This package, called
              catR, requires a bank of items, previously calibrated according
              to the four-parameter logistic (4PL) model or any simpler
              logistic model. The package proposes several methods to select
              the early test items, several methods for next item selection,
              different estimators of ability (maximum likelihood, Bayes modal,
              expected a posteriori, weighted likelihood), and three stopping
              rules (based on the test length, the precision of ability
              estimates or the classification of the examinee). After a short
              description of the different steps of a CAT process, the commands
              and options of the catR package are presented and practically
              illustrated.",
  journal  = "Journal of statistical software",
  volume   =  48,
  number   =  8,
  pages    = "1--31",
  year     =  2012,
  keywords = "ability estimation; computerized adaptive testing; item
              selection; r package",
  issn     = "1548-7660"
}

@ARTICLE{Rizopoulos2006-kv,
  title    = "ltm: An {R} package for latent variable modeling and item
              response theory analyses",
  author   = "Rizopoulos, D",
  abstract = "The R package ltm has been developed for the analysis of
              multivariate dichotomous and polytomous data using latent
              variable models, under the Item Response Theory approach. For
              dichotomous data the Rasch, the Two-Parameter Logistic, and
              Birnbaum's Three-Parameter models have been implemented, whereas
              for polytomous data Semejima's Graded Response model is
              available. Parameter estimates are obtained under marginal
              maximum likelihood using the Gauss-Hermite quadrature rule. The
              capabilities and features of the package are illustrated using
              two real data examples",
  journal  = "Journal of statistical software",
  volume   =  17,
  number   =  5,
  pages    = "1--25",
  year     =  2006,
  keywords = "Rasch model; graded response model; item response theory; latent
              variable models; three-parameter model; two-parameter logistic
              model",
  issn     = "1548-7660"
}

@ARTICLE{Chandrasekaran2009-dp,
  title    = "Relative influence of musical and linguistic experience on early
              cortical processing of pitch contours",
  author   = "Chandrasekaran, Bharath and Krishnan, Ananthanarayan and Gandour,
              Jackson T",
  abstract = "To assess domain specificity of experience-dependent pitch
              representation we evaluated the mismatch negativity (MMN) and
              discrimination judgments of English musicians, English
              nonmusicians, and native Chinese for pitch contours presented in
              a nonspeech context using a passive oddball paradigm. Stimuli
              consisted of homologues of Mandarin high rising (T2) and high
              level (T1) tones, and a linear rising ramp (T2L). One condition
              involved a between-category contrast (T1/T2), the other, a
              within-category contrast (T2L/T2). Irrespective of condition,
              musicians and Chinese showed larger MMN responses than
              nonmusicians; Chinese larger than musicians. Chinese, however,
              were less accurate than nonnatives in overt discrimination of T2L
              and T2. Taken together, these findings suggest that
              experience-dependent effects to pitch contours are domain-general
              and not driven by linguistic categories. Yet specific differences
              in long-term experience in pitch processing between domains
              (music vs. language) may lead to gradations in cortical
              plasticity to pitch contours. ?? 2008 Elsevier Inc. All rights
              reserved.",
  journal  = "Brain and language",
  volume   =  108,
  number   =  1,
  pages    = "1--9",
  year     =  2009,
  keywords = "Experience-dependent plasticity; Iterated rippled noise (IRN);
              Language; Lexical tone; Mandarin; Mismatch negativity (MMN);
              Music; Nonspeech stimuli; Pitch; Speech perception",
  issn     = "0093-934X",
  pmid     = "18343493",
  doi      = "10.1016/j.bandl.2008.02.001"
}

@ARTICLE{Besson1995-pv,
  title    = "An event-related potential ({ERP}) study of musical expectancy:
              Comparison of musicians with nonmusicians",
  author   = "Besson, Mireille and Fa{\"\i}ta, Fr{\'e}d{\'e}rique",
  abstract = "Musicians and nonmusicians listened to musical phrases that were
              either selected from the classical repertoire or composed for the
              experiments. The phrases ended either congruously or with a
              nondiatonic, diatonic, or rhythmic violation. Percentage of
              correct responses was analyzed in Exp 1, and event-related
              potentials (ERPs) were recorded in Exps 2 and 3. Musicians
              performed better than nonmusicians in recognizing familiar
              musical phrases and classifying terminal notes. The differences
              found as a function of expertise were larger for unfamiliar than
              for familiar melodies. The ERPs to the end notes differed both in
              terms of amplitude and latency between musicians and
              nonmusicians, and as a function of participants' familiarity with
              the melodies and type of violation. Results show that expertise
              influences the decisional rather than the purely perceptual
              aspects of music processing and that ERPs can provide important
              insight into the study of music perception. (PsycINFO Database
              Record (c) 2012 APA, all rights reserved)",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  21,
  number   =  6,
  pages    = "1278--1296",
  year     =  1995,
  issn     = "0096-1523",
  doi      = "10.1037/0096-1523.21.6.1278"
}

@BOOK{Lord1980-qc,
  title     = "Applications of item response theory to practical testing
               problems",
  author    = "Lord, F M",
  publisher = "Lawrence Erlbaum",
  year      =  1980,
  address   = "Hillsdale, NJ",
  keywords  = "maximum likelihood estimation"
}

@INCOLLECTION{Vispoel1999-mj,
  title     = "Creating computerized adaptive tests of music aptitude:
               Problems, solutions, and future directions",
  booktitle = "Innovations in computerised assessment",
  author    = "Vispoel, Walter P",
  publisher = "Lawrence Erlbaum Associates, Inc.",
  year      =  1999,
  address   = "Mahwah, NJ"
}

@ARTICLE{Maydeu2005-yt,
  title    = "Limited information goodness-of-fit testing in multidimensional
              contingency tables",
  author   = "Maydeu, Alberto and Joe, Harry",
  journal  = "Psychometrika",
  volume   =  71,
  number   =  4,
  pages    = "713--732",
  year     =  2005,
  keywords = "M2 statistic",
  issn     = "0033-3123"
}

@BOOK{DeMars2010-ki,
  title     = "Item response theory",
  author    = "DeMars, Christine",
  publisher = "Oxford University Press",
  year      =  2010,
  address   = "New York, NY"
}

@ARTICLE{Cuddy1981-nx,
  title    = "Musical pattern recognition: A comparison of listening to and
              studying tonal structures and tonal ambiguities",
  author   = "Cuddy, Lola L and Lyons, H I",
  abstract = "In Exp I, 54 listeners with high, moderate, or little previous
              musical training detected alterations of the sequences in a
              short-term musical-pattern recognition task. In Exp II, 12 highly
              trained musicians (19-47 yrs old) rated the structure of the
              sequences under home study conditions with no time constraints
              imposed. Both recognition and rating responses indicated a
              discrimination between tonal sequences and sequences during which
              tonal rules were relaxed or violated. However, Ss in Exp II were
              more sensitive to structural variations within modulating and
              nondiatonic sequences and were less guided by overall pitch
              contour than were Ss in Exp I. Results are discussed in terms of
              the strategies available to detect melodic structure under
              different time constraints. Within the real-time constraints of a
              recognition test, listeners apprehend simple transformational
              rules. With study time during which the sequence may be analyzed
              through a series of hypotheses about structural properties, added
              symmetries become apparent. (20 ref) (PsycINFO Database Record
              (c) 2004 APA, all rights reserved)",
  journal  = "Psychomusicology: A Journal of Research in Music Cognition",
  volume   =  1,
  number   =  2,
  pages    = "15--33",
  year     =  1981,
  keywords = "melodic memory",
  issn     = "0275-3987",
  doi      = "10.1037/h0094283"
}

@UNPUBLISHED{Musil2015-ke,
  title  = "Measuring the ability to tap to music: A new testing paradigm",
  author = "Musil, Jason and Frieler, Klaus and M{\"u}llensiefen, Daniel",
  year   =  2015
}

@UNPUBLISHED{Musil2014-mg,
  title  = "Off and on: Measuring individual differences in the perception of
            the musical beat",
  author = "Musil, Jason and Iversen, John R and M{\"u}llensiefen, Daniel",
  year   =  2014
}

@PHDTHESIS{Vispoel1987-yr,
  title  = "An adaptive test of tonal memory: An application of item response
            theory to the assessment of musical ability",
  author = "Vispoel, Walter P",
  year   =  1987,
  school = "Doctoral dissertation, The University of Illinois, Urbana-Champaign"
}

@INCOLLECTION{Haladyna2013-wk,
  title     = "Automatic item generation: A historical perspective",
  booktitle = "Automatic item generation: Theory and practice",
  author    = "Haladyna, Thomas M",
  editor    = "Gierl, M J and Haladyna, T",
  publisher = "Routledge",
  year      =  2013,
  address   = "New York, NY"
}

@INCOLLECTION{Linacre2000-ud,
  title     = "Computer-adaptive testing: a methodology whose time has come.
               {MESA} Memorandum No. 69",
  booktitle = "Development of computerized middle school achievement test",
  author    = "Linacre, J M",
  editor    = "Chae, Sunhee and Kang, Unson and Jeon, Eunhwa and Linacre, J M",
  publisher = "Komesa Press",
  year      =  2000,
  address   = "Seoul, South Korea"
}

@ARTICLE{Bock1997-vx,
  title    = "A Brief History of Item Response Theory",
  author   = "Bock, R Darrell",
  abstract = "How did early work of Binet and Thurstone foreshadow item
              response theory? What connections to work in other areas are not
              widely recognized? What are current application trends?",
  journal  = "Educational Measurement: Issues and Practice",
  volume   =  16,
  number   =  4,
  pages    = "21--33",
  year     =  1997
}

@ARTICLE{Borsboom2006-hs,
  title    = "The attack of the psychometricians",
  author   = "Borsboom, Denny",
  abstract = "This paper analyzes the theoretical, pragmatic, and substantive
              factors that have hampered the integration between psychology and
              psychometrics. Theoretical factors include the operationalist
              mode of thinking which is common throughout psychology, the
              dominance of classical test theory, and the use of ``construct
              validity'' as a catch-all category for a range of challenging
              psychometric problems. Pragmatic factors include the lack of
              interest in mathematically precise thinking in psychology,
              inadequate representation of psychometric modeling in major
              statistics programs, and insufficient mathematical training in
              the psychological curriculum. Substantive factors relate to the
              absence of psychological theories that are sufficiently strong to
              motivate the structure of psychometric models. Following the
              identification of these problems, a number of promising recent
              developments are discussed, and suggestions are made to further
              the integration of psychology and psychometrics.",
  journal  = "Psychometrika",
  volume   =  71,
  number   =  3,
  pages    = "425--440",
  year     =  2006,
  keywords = "Classical test theory; Construct validity; Modern test theory;
              Psychological measurement; Psychometrics",
  issn     = "0033-3123",
  pmid     = "19946599",
  doi      = "10.1007/s11336-006-1447-6"
}

@BOOK{Sands1997-bp,
  title     = "Computerized adaptive testing: From inquiry to operation",
  editor    = "Sands, William A and Waters, Brian K and McBride, James R",
  abstract  = "This book traces the development of computerized adaptive
               testing (CAT) from its origins in the 1960s to its integration
               with the Armed Services Vocational Aptitude Battery (ASVAB) in
               the 1990s. A paper-and-pencil version of the battery
               (P\&P-ASVAB) has been used by the Defense Department since the
               1970s to measure the abilities of applicants for military
               service. The test scores are used both for initial qualification
               and for classification into entry-level training opportunities.
               This volume provides the developmental history of the CAT-ASVAB
               through its various stages in the Joint-Service arena. Although
               the majority of the book concerns the myriad technical issues
               that were identified and resolved, information is provided on
               various political and funding support challenges that were
               successfully overcome in developing, testing, and implementing
               the battery into one of the nation's largest testing programs.
               The book provides useful information to professionals in the
               testing community and everyone interested in personnel
               assessment and evaluation.",
  publisher = "American Psychological Association",
  year      =  1997,
  address   = "Washington, DC"
}

@ARTICLE{Geerlings2011-mx,
  title    = "Modeling rule-based item generation",
  author   = "Geerlings, Hanneke and Glas, Cees A W",
  journal  = "Psychometrika",
  volume   =  76,
  number   =  2,
  pages    = "337--359",
  year     =  2011,
  keywords = "hierarchical modeling; item generation; item response theory;
              markov chain monte carlo",
  issn     = "0033-3123"
}

@INCOLLECTION{Irvine2010-so,
  title     = "Item generation for test development: An introduction",
  booktitle = "Item generation for test development",
  author    = "Irvine, Sidney H",
  editor    = "Irvine, Sidney H and Kyllonen, Patrick C",
  publisher = "Routledge",
  pages     = "xv--xxvi",
  year      =  2010,
  address   = "Abingdon, England",
  keywords  = "incidental;radical"
}

@INCOLLECTION{Linden2007-ak,
  title     = "Statistical aspects of adaptive testing",
  booktitle = "Handbook of Statistics",
  author    = "Linden, Wim J van der and Glas, Cees A W",
  editor    = "Rao, C R and Sinharay, S",
  publisher = "Elsevier B.V.",
  volume    =  26,
  pages     = "801--838",
  year      =  2007,
  address   = "Amsterdam, The Netherlands",
  doi       = "10.1016/S0169-7161(06)26025-5"
}

@INCOLLECTION{Gorin2013-lv,
  title     = "Using cognitive psychology to generate items and predict item
               characteristics",
  booktitle = "Automatic item generation: Theory and practice",
  author    = "Gorin, J S and Embretson, Susan E",
  editor    = "Gierl, M J and Haladyna, Thomas M",
  publisher = "Routledge",
  year      =  2013,
  address   = "New York, NY"
}

@ARTICLE{Geerlings2013-ij,
  title    = "Optimal Test Design With {Rule-Based} Item Generation",
  author   = "Geerlings, H and van der Linden, Wim J and Glas, Cees A W",
  abstract = "Optimal test-design methods are applied to rule-based item
              generation. Three different cases of automated test design are
              presented: (a) test assembly from a pool of pregenerated,
              calibrated items; (b) test generation on the fly from a pool of
              calibrated item families; and (c) test genera- tion on the fly
              directly from calibrated features defining the item families. The
              last two cases do not assume any item calibration under a regular
              response theory model; instead, entire item families or critical
              features of them are assumed to be calibrated using a
              hierarchical response model developed for rule-based item
              generation. The test-design models maximize an expected version
              of the Fisher information in the test and control critical
              attributes of the test forms through explicit constraints.
              Results from a study with simulated response data highlight both
              the effects of within-family item-parameter variability and the
              severity of the constraint sets in the test-design models on
              their optimal solutions.",
  journal  = "Applied psychological measurement",
  volume   =  37,
  number   =  2,
  pages    = "140--161",
  year     =  2013,
  keywords = "Fisher information; hierarchical modeling; item generation; item
              response theory; optimal test design; rule-based",
  issn     = "0146-6216",
  doi      = "10.1177/0146621612468313"
}

@ARTICLE{Glas2003-zr,
  title    = "Computerized adaptive testing with item cloning",
  author   = "Glas, Cees a W and van der Linden, Wim J",
  abstract = "To increase the number of items available for adaptive testing
              and reduce the cost of item writing, the use of techniques of
              item cloning has been proposed. An important consequence of item
              cloning is possible variability between the item parameters. To
              deal with this variability, a multilevel item response (IRT)
              model is presented which allows for differences between the
              distributions of item parameters of families of item clones. A
              marginal maximum likelihood and a Bayesian procedure for
              estimating the hyperparameters are presented. In addition, an
              item-selection procedure for computerized adaptive testing with
              item cloning is presented which has the following two stages:
              First, a family of item clones is selected to be optimal at the
              estimate of the person parameter. Second, an item is randomly
              selected from the family for administration. Results from
              simulation studies based on an item pool from the Law School
              Admission Test (LSAT) illustrate the accuracy of these item pool
              calibration and adaptive testing procedures. Index terms:
              computerized adaptive testing, item cloning, multilevel item
              response theory, marginal maximum likelihood, Bayesian item
              selection.",
  journal  = "Applied psychological measurement",
  volume   =  27,
  number   =  4,
  pages    = "247--261",
  year     =  2003,
  issn     = "0146-6216",
  doi      = "10.1177/0146621603027004001"
}

@ARTICLE{Freund2008-nw,
  title    = "Explaining and Controlling for the Psychometric Properties of
              {Computer-Generated} Figural Matrix Items",
  author   = "Freund, P a and Hofer, S and Holling, H",
  abstract = "Figural matrix items are a popular task type for assessing
              general intelligence (Spearman's g). Items of this kind can be
              constructed rationally, allowing the implementation of
              computerized generation algorithms. In this study, the influence
              of different task parameters on the degree of difficulty in
              matrix items was investigated. A sample of N = 169 participants
              (all age groups) completed a set of 25 automatically generated 4
              $\times$ 4 matrix items. Data collection was conducted through
              the World Wide Web. All items showed a good fit with the Rasch
              model, and item difficulty could be explained reasonably well
              through the implemented task parameters. The research indicated
              that matrix items can easily be generated using well-defined
              computerized algorithms. Their composite character explains item
              difficulty to a satisfactory degree and enables researchers to
              construct items with anticipated psychometric properties and
              Rasch model conformity. Practical advantages of these findings
              are pointed out.",
  journal  = "Applied psychological measurement",
  volume   =  32,
  number   =  3,
  pages    = "195--210",
  year     =  2008,
  issn     = "0146-6216",
  doi      = "10.1177/0146621607306972"
}

@ARTICLE{Gorin2006-ea,
  title    = "Item Diffficulty Modeling of Paragraph Comprehension Items",
  author   = "Gorin, J S and Embretson, Susan E",
  abstract = "Recent assessment research joining cognitive psychology and
              psychometric theory has introduced a new technology, item
              generation. In algorithmic item generation, items are
              systematically created based on specific combinations of features
              that underlie the processing required to correctly solve a
              problem. Reading comprehension items have been more difficult to
              model than other item types due to the complexities of
              quantifying text. However, recent developments in artificial
              intelligence for text analysis permit quantitative indices to
              represent cognitive sources of difficulty. The current study
              attempts to identify generative components for the Graduate
              Record Examination paragraph comprehension items through the
              cognitive decomposition of item difficulty. Text comprehension
              and decision processes accounted for a significant amount of the
              variance in item difficulties. The decision model variables
              contributed significantly to variance in item difficulties,
              whereas the text representation variables did not. Implications
              for score interpretation and future possibilities for item
              generation are discussed.",
  journal  = "Applied psychological measurement",
  volume   =  30,
  number   =  5,
  pages    = "394--411",
  year     =  2006,
  issn     = "0146-6216",
  doi      = "10.1177/0146621606288554"
}

@ARTICLE{Daniel2010-mb,
  title    = "Designing Cognitive Complexity in Mathematical {Problem-Solving}
              Items",
  author   = "Daniel, R C and Embretson, S E",
  journal  = "Applied psychological measurement",
  volume   =  34,
  number   =  5,
  pages    = "348--364",
  year     =  2010,
  keywords = "aptitude and achievement in; cognitive complexity level is;
              cognitive psychology; important in measuring both; is rarely
              based on; item difficulty; item response theory; item writing;
              large-; research; scale testing; vary in cognitive complexity;
              yet designing items to",
  issn     = "0146-6216",
  doi      = "10.1177/0146621609349801"
}

@INCOLLECTION{Leighton2013-pn,
  title     = "Learning sciences, cognitive models, and automatic item
               generation",
  booktitle = "Automatic item generation: Theory and practice",
  author    = "Leighton, Jacqueline P",
  editor    = "Gierl, M J and Haladyna, Thomas M",
  publisher = "Routledge",
  year      =  2013,
  address   = "New York, NY"
}

@ARTICLE{Bejar1991-vx,
  title   = "A generative approach to the modeling of isomorphic hidden-figure
             items",
  author  = "Bejar, Isaac I",
  journal = "Applied psychological measurement",
  volume  =  15,
  number  =  2,
  pages   = "129--137",
  year    =  1991,
  issn    = "0146-6216"
}

@ARTICLE{Whitely1980-gh,
  title    = "Multicomponent latent trait models for ability tests",
  author   = "Whitely, Susan E",
  journal  = "Psychometrika",
  volume   =  45,
  number   =  4,
  pages    = "479--494",
  year     =  1980,
  keywords = "ability measurement; information-processing models; latent trait
              models;automatic item generation",
  issn     = "0033-3123",
  doi      = "10.1007/BF02293610"
}

@ARTICLE{Embretson1999-xe,
  title    = "Generating items during testing: Psychometric issues and models",
  author   = "Embretson, Susan E",
  journal  = "Psychometrika",
  volume   =  64,
  number   =  4,
  pages    = "407--433",
  year     =  1999,
  keywords = "automatic item generation",
  issn     = "0033-3123"
}

@MISC{Bejar1996-ry,
  title     = "Generative response modeling: Leveraging the computer as a test
               delivery medium",
  author    = "Bejar, Isaac I",
  abstract  = "Generative response modeling is an approach to test development
               and response modeling that calls for the creation of items in
               such a way that the parameters of the items on some response
               model can be anticipated through knowledge of the psychological
               processes and knowledge required to respond to the item. That
               is, the computer would not merely retrieve an item from a
               database, as is the case in adaptive testing, but would compose
               it, or assist in doing so, according to the desired
               specifications. This approach to assessment has implications for
               both the economics and validity of computer administered tests.
               To illustrate the concept, a system for measuring writing skills
               is outlined in which the examinee is expected to rewrite
               sentences, rather than just recognize errors in a sentence,
               using a multiple-choice format. The possibility of estimating
               the psychometric parameters of items based on a psychological
               analysis of the response process is examined, and shown to be
               feasible. A Monte Carlo study with 100 simulated examinees at
               each of 6 ability levels is presented, which investigated the
               possibility of compensating for that imprecision when estimating
               ability or proficiency. It is concluded that a generative
               approach is feasible, and can be a mechanism for taking
               advantage of the considerable investment required for
               computer-based testing.",
  publisher = "ETS",
  year      =  1996,
  address   = "Princeton, NJ",
  keywords  = "automatic item generation"
}

@ARTICLE{Bejar1990-nd,
  title    = "Spatial task analysis of a three-dimensional spatial task",
  author   = "Bejar, Isaac I",
  journal  = "Applied psychological measurement",
  volume   =  14,
  number   =  3,
  pages    = "237--245",
  year     =  1990,
  keywords = "automatic item generation",
  issn     = "0146-6216"
}

@ARTICLE{Hornke1986-nd,
  title    = "{Rule-Based} Item Bank Construction and Evaluation Within the
              Linear Logistic Framework",
  author   = "Hornke, L F and Habon, M W",
  abstract = "In cognition research, item writing rules are consid ered a
              necessary prerequisite of item banking. A set of 636 items was
              constructed using prespecified cognitive operations. An
              evaluation of test data from some 7,400 examinees revealed 446
              homogeneous items. Some items had to be discarded because of
              printing flaws, and others because of operation complexion or
              other well-describable reasons. However, cognitive operations
              explained item difficulty parameters quite well; further
              cross-validation research may contribute to an item writing
              approach which attempts to bring psychological theory and
              psychometric models closer together. This will eventually free
              item construction from item writer idiosyncrasies.",
  journal  = "Applied psychological measurement",
  volume   =  10,
  number   =  4,
  pages    = "369--380",
  year     =  1986,
  keywords = "automatic item generation",
  issn     = "0146-6216",
  doi      = "10.1177/014662168601000405"
}

@ARTICLE{Baker1993-xc,
  title   = "Sensitivity of the Linear Logistic Test Model to Misspecification
             of the Weight Matrix",
  author  = "Baker, F B",
  journal = "Applied psychological measurement",
  volume  =  17,
  number  =  3,
  pages   = "201--210",
  year    =  1993,
  issn    = "0146-6216",
  doi     = "10.1177/014662169301700301"
}

@INCOLLECTION{Gierl2013-do,
  title     = "Automatic item generation: An introduction",
  booktitle = "Automatic item generation: Theory and practice",
  author    = "Gierl, M J",
  editor    = "Gierl, M J and Haladyna, Thomas M",
  publisher = "Routledge",
  year      =  2013,
  address   = "New York, NY"
}

@ARTICLE{Lord1977-qq,
  title    = "A {Broad-Range} Tailored Test of Verbal Ability",
  author   = "Lord, F M",
  abstract = "Two parallel forms of a broad-range tailored test of verbal
              ability have been built. The test is appro priate from fifth
              grade through graduate school. Simulated test administrations
              indicate that the 25- item tailored test is at least as good as a
              compar able 50-item conventional test. At most ability levels,
              the tailored test measures much better. An offer is made to
              provide upon request item charac teristic curve parameters for
              690 widely used Coop erative Test items, in order to facilitate
              research.",
  journal  = "Applied psychological measurement",
  volume   =  1,
  number   =  1,
  pages    = "95--100",
  year     =  1977,
  issn     = "0146-6216",
  doi      = "10.1177/014662167700100115"
}

@ARTICLE{Cornsweet1962-rn,
  title   = "The staircase-method in psychophysics",
  author  = "Cornsweet, Tom N",
  journal = "The American journal of psychology",
  volume  =  75,
  number  =  3,
  pages   = "485--491",
  year    =  1962,
  issn    = "0002-9556"
}

@BOOK{Fechner1889-yx,
  title     = "Elemente der Psychophysik",
  author    = "Fechner, G T",
  publisher = "Breitkopf and H{\"a}rtel",
  edition   = "2nd ed.",
  year      =  1889,
  address   = "Leipzig, Germany"
}

@ARTICLE{Levitt1971-bf,
  title   = "Transformed up-down methods in psychoacoustics",
  author  = "Levitt, H",
  journal = "The Journal of the Acoustical Society of America",
  volume  =  49,
  number  = "2B",
  pages   = "467--477",
  year    =  1971,
  issn    = "0001-4966"
}

@ARTICLE{Latu2002-ol,
  title    = "Computerised adaptive testing",
  author   = "Latu, Elisapesi and Chapman, Elaine",
  abstract = "Considers the potential of computer adaptive testing (CAT).
              Discusses the use of CAT instead of traditional paper and pencil
              tests, identifies decisions that impact the efficacy of CAT, and
              concludes that CAT is beneficial when used to its full potential
              on certain types of tests. (LRW)",
  journal  = "British journal of educational technology: journal of the Council
              for Educational Technology",
  volume   =  33,
  number   =  5,
  pages    = "619--622",
  year     =  2002,
  issn     = "0007-1013",
  doi      = "10.1111/1467-8535.00296"
}

@BOOK{Baker1992-kt,
  title     = "Item response theory: Parameter estimation techniques",
  author    = "Baker, F B",
  publisher = "Marcel Dekker",
  year      =  1992,
  address   = "New York, NY"
}

@ARTICLE{Ponocny2002-ya,
  title    = "Nonparametric goodness-of-fit tests for the Rasch model",
  author   = "Ponocny, Ivo",
  abstract = "A Monte Carlo algorithm realizing a family of nonparametric tests
              for the Rasch model is intro- duced which are conditional on the
              item and subject marginals. The algorithm is based on random
              changes of elements of data matrices without changing the
              maxginals; most powerful tests against all alternative hypotheses
              are given for which a monotone characteristic may be computed
              from the data matrix; alterna- tives may also be composed.
              Computation times are long, but exact p-values are approximated
              with the quality of approximation only depending on calculation
              time, but not on the number of persons. The power and the
              flexibility of the procedure is demonstrated by means of an
              empirical example where, among oth- ers, indicators for increased
              item similarities, the existence of subscales, violations of
              sufficiency of the raw score as well as learning processes were
              found. Many of the features described are implemented in the
              program T-Rasch 1.0 by Ponocny and Ponocny-Seliger (1999).",
  journal  = "Psychometrika",
  volume   =  67,
  number   =  2,
  pages    = "315--315",
  year     =  2002,
  keywords = "exact tests; goodness-of-fit tests; irt; nonparametric tests;
              rasch model",
  issn     = "0033-3123",
  doi      = "10.1007/BF02294849"
}

@INCOLLECTION{De_Boeck2004-pu,
  title     = "Descriptive and explanatory response models",
  booktitle = "Explanatory item response models: A generalized linear and
               nonlinear approach",
  author    = "de Boeck, Paul and Wilson, Mark",
  publisher = "Springer",
  pages     = "43--74",
  year      =  2004,
  address   = "New York, NY",
  isbn      = "9780387402758",
  doi       = "10.1007/978-1-4757-3990-9"
}

@MISC{Rust_undated-so,
  title  = "Item Response Theory and Computerised Adaptive Testing",
  author = "Rust, John and Cek, Iva and Sun, Luning and Kosinski, Michal"
}

@MISC{Chalmers2015-mx,
  title  = "Package `mirt'",
  author = "Chalmers, Phil and Pritikin, Joshua and Robitzsch, Alexander and
            Zoltak, Mateusz",
  year   =  2015
}

@ARTICLE{Rizopoulos2015-wj,
  title  = "Package ` ltm '",
  author = "Rizopoulos, Dimitris",
  year   =  2015
}

@ARTICLE{Gosling2003-bt,
  title    = "A very brief measure of the {Big-Five} personality domains",
  author   = "Gosling, Samuel D and Rentfrow, Peter J and Swann, William B",
  abstract = "When time is limited, researchers may be faced with the choice of
              using an extremely brief measure of the Big-Five personality
              dimensions or using no measure at all. To meet the need for a
              very brief measure, 5 and 10-item inventories were developed and
              evaluated. Although somewhat inferior to standard multi-item
              instruments, the instruments reached adequate levels in terms of:
              (a) convergence with widely used Big-Five measures in self,
              observer, and peer reports, (b) test-retest reliability, (c)
              patterns of predicted external correlates, and (d) convergence
              between self and observer ratings. On the basis of these tests, a
              10-item measure of the Big-Five dimensions is offered for
              situations where very short measures are needed, personality is
              not the primary topic of interest, or researchers can tolerate
              the somewhat diminished psychometric properties associated with
              very brief measures. ?? 2003 Elsevier Science (USA). All rights
              reserved.",
  journal  = "Journal of research in personality",
  volume   =  37,
  number   =  6,
  pages    = "504--528",
  year     =  2003,
  issn     = "0092-6566",
  pmid     = "6406",
  doi      = "10.1016/S0092-6566(03)00046-1"
}

@ARTICLE{Kidd2007-cu,
  title    = "Individual differences in auditory abilities",
  author   = "Kidd, Gary R and Watson, Charles S and Gygi, Brian",
  abstract = "Performance on 19 auditory discrimination and identification
              tasks was measured for 340 listeners with normal hearing. Test
              stimuli included single tones, sequences of tones,
              amplitude-modulated and rippled noise, temporal gaps, speech, and
              environmental sounds. Principal components analysis and
              structural equation modeling of the data support the existence of
              a general auditory ability and four specific auditory abilities.
              The specific abilities are (1) loudness and duration (overall
              energy) discrimination; (2) sensitivity to temporal envelope
              variation; (3) identification of highly familiar sounds (speech
              and nonspeech); and (4) discrimination of unfamiliar simple and
              complex spectral and temporal patterns. Examination of Scholastic
              Aptitude Test (SAT) scores for a large subset of the population
              revealed little or no association between general or specific
              auditory abilities and general intellectual ability. The findings
              provide a basis for research to further specify the nature of the
              auditory abilities. Of particular interest are results suggestive
              of a familiar sound recognition (FSR) ability, apparently
              specialized for sound recognition on the basis of limited or
              distorted information. This FSR ability is independent of normal
              variation in both spectral-temporal acuity and of general
              intellectual ability.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  122,
  number   =  1,
  pages    = "418--435",
  year     =  2007,
  issn     = "0001-4966",
  pmid     = "17614500",
  doi      = "10.1121/1.4743842"
}

@ARTICLE{Rohde2007-zn,
  title    = "Predicting academic achievement with cognitive ability",
  author   = "Rohde, Treena Eileen and Thompson, Lee Anne",
  abstract = "The purpose of the present study is to explain variation in
              academic achievement with general cognitive ability and specific
              cognitive abilities. Grade point average, Wide Range Achievement
              Test III scores, and SAT scores represented academic achievement.
              The specific cognitive abilities of interest were: working
              memory, processing speed, and spatial ability. General cognitive
              ability was measured with the Raven's Advanced Progressive
              Matrices and the Mill Hill Vocabulary Scales. When controlling
              for working memory, processing speed, and spatial ability, in a
              sample of 71 young adults (29 males), measures of general
              cognitive ability continued to add to the prediction of academic
              achievement, but none of the specific cognitive abilities
              accounted for additional variance in academic achievement after
              controlling for general cognitive ability. However, processing
              speed and spatial ability continued to account for a significant
              amount of additional variance when predicting scores for the
              mathematical portion of the SAT while holding general cognitive
              ability constant. ?? 2006 Elsevier Inc. All rights reserved.",
  journal  = "Intelligence",
  volume   =  35,
  number   =  1,
  pages    = "83--92",
  year     =  2007,
  keywords = "Academic achievement; Intelligence; Spatial ability",
  issn     = "0160-2896",
  doi      = "10.1016/j.intell.2006.05.004"
}

@ARTICLE{Corrigall2013-ff,
  title    = "Music Training, Cognition, and Personality",
  author   = "Corrigall, Kathleen A and Schellenberg, E Glenn and Misura,
              Nicole M",
  journal  = "Frontiers in psychology",
  volume   =  4,
  number   = "April",
  year     =  2013,
  keywords = "cognition; individual differences; music lessons; music training;
              personality",
  issn     = "1664-1078",
  doi      = "10.3389/fpsyg.2013.00222"
}

@ARTICLE{Saberi1997-vg,
  title    = "Evaluation of maximum-likelihood estimators in nonintensive
              auditory psychophysics",
  author   = "Saberi, K and Green, David M",
  abstract = "This is a brief report on the use of maximum-likelihood (ML)
              estimators in auditory psychophysics. Slope parameters of
              psychometric functions are characterized for three nonintensive
              auditory tasks: forced-choice discrimination of interaural time
              differences (delta ITD), frequency (delta f), and duration (delta
              t). Using these slope estimates, the ML method is implemented and
              threshold estimates are obtained for the three tasks and compared
              with previously published data. delta ITD thresholds were
              additionally measured for human observers by means of two other
              psychophysical procedures: the constant-stimuli (CS) and the
              2-down 1-up methods (Wetherill \& Levitt, 1965). Standard errors
              were smallest for the ML method. Finally, simulations showed ML
              estimates to be more efficient than the CS and k-down 1-up
              procedures for k = 2 to 5. For up-down procedures, efficiency was
              highest for k values of 3 and 4. The entropy (Shannon, 1949) of
              ML estimates was the smallest of the simulated procedures, but
              poorer than ideal by 0.5 bits.",
  journal  = "Perception \& psychophysics",
  volume   =  59,
  number   =  6,
  pages    = "867--876",
  year     =  1997,
  issn     = "0031-5117",
  pmid     = "9270361",
  doi      = "10.3758/BF03205504"
}

@ARTICLE{Butkovic2015-hm,
  title   = "Personality related traits as predictors of music practice:
             Underlying environmental and genetic influences",
  author  = "Butkovic, Ana and Ull{\'e}n, Fredrik and Mosing, Miriam a",
  journal = "Personality and individual differences",
  volume  =  74,
  number  = "July",
  pages   = "133--138",
  year    =  2015,
  issn    = "0191-8869",
  doi     = "10.1016/j.paid.2014.10.006"
}

@ARTICLE{Zimmerman1990-ce,
  title    = "{Self-Regulated} Learning and Academic Achievement: An Overview",
  author   = "Zimmerman, Barry J",
  abstract = "Educational researchers have begun recently to identify and study
              key processes through which students self-regulate their academic
              learning. In this overview, I present a general definition of
              self-regulated academic learning and identify the distinctive
              features of this capability for acquiring knowledge and skill.
              Drawing on subsequent articles in this journal issue as well as
              my research with colleagues, I discuss how the study of component
              processes contributes to our growing understanding of the
              distinctive features of students' self-regulated learning.
              Finally, the implications of self-regulated learning perspective
              on students' learning and achievement are considered.",
  journal  = "Educational psychologist",
  volume   =  25,
  number   =  1,
  pages    = "3--17",
  year     =  1990,
  issn     = "0046-1520",
  doi      = "10.1207/s15326985ep2501"
}

@ARTICLE{Theorell2015-as,
  title    = "Predictors of continued playing or singing - from childhood and
              adolescence to adult years",
  author   = "Theorell, T and Lennartsson, A-K and Madison, G and Mosing, M a
              and Ull{\'e}n, Fredrik",
  journal  = "Acta paediatrica",
  volume   =  104,
  number   =  3,
  pages    = "274--284",
  year     =  2015,
  keywords = "age; family background; music school; sex",
  issn     = "0365-1436, 0803-5253",
  doi      = "10.1111/apa.12870"
}

@MISC{Mair2015-pr,
  title  = "Package ` eRm '",
  author = "Mair, Patrick and Hatzinger, Reinhold and Maier, Marco J and Rusch,
            Thomas",
  year   =  2015
}

@PHDTHESIS{ONeill1996-wd,
  title  = "Factors influencing children's motivation and achievement during
            the first year of instrumental music tuition",
  author = "O'Neill, Susan A",
  year   =  1996,
  school = "Unpublished PhD thesis, Keele University, UK"
}

@INCOLLECTION{ONeill1997-tq,
  title     = "The role of practice in children's early musical performance
               achievement",
  booktitle = "Does practice make perfect? Current theory and research on
               instrumental music practice",
  author    = "O'Neill, Susan A",
  editor    = "Jorgensen, H and Lehmann, A C",
  publisher = "Norges Musikhogskule",
  pages     = "53--70",
  year      =  1997,
  address   = "Oslo, Norway"
}

@INCOLLECTION{Dweck1999-qu,
  title     = "Mastery-oriented thinking",
  booktitle = "Coping",
  author    = "Dweck, Carol S and Sorich, Lisa A",
  editor    = "Snyder, C R",
  publisher = "Oxford University Press",
  year      =  1999,
  address   = "New York, NY"
}

@ARTICLE{Robins2002-yk,
  title    = "Implicit {Self-Theories} in the Academic Domain: Implications for
              Goal Orientation, Attributions, Affect, and {Self-Esteem} Change",
  author   = "Robins, Richard W and Pals, Jennifer L",
  abstract = "This study supported hypotheses derived from Dweck's model about
              the implications of two implicit self-theories: Entity theorists
              believe their intelligence is fixed, whereas Incremental
              theorists believe their intelligence can be increased. Findings
              showed no normative change in implicit self-theories from high
              school through college and relatively stable individual
              differences during college. Entity theorists tended to adopt
              performance goals, whereas Incremental theorists tended to adopt
              learning goals. In terms of attributions, affect, and behavioral
              response to challenge, Entity theorists displayed a helpless
              response pattern and Incremental theorists displayed a
              mastery-oriented response pattern. Finally, Entity theorists
              declined in self-esteem during college whereas Incremental
              theorists increased self-esteem, and path analyses showed that
              this effect was mediated by goal orientation and the helpless
              versus mastery response patterns. ABSTRACT FROM AUTHOR Copyright
              of Self \& Identity is the property of Psychology Press (UK) and
              its content may not be copied or emailed to multiple sites or
              posted to a listserv without the copyright holder's express
              written permission. However, users may print, download, or email
              articles for individual use. This abstract may be abridged. No
              warranty is given about the accuracy of the copy. Users should
              refer to the original published version of the material for the
              full abstract. (Copyright applies to all Abstracts); This study
              supported hypotheses derived from Dweck's model about the
              implications of two implicit self-theories: Entity theorists
              believe their intelligence is fixed, whereas Incremental
              theorists believe their intelligence can be increased. Findings
              showed no normative change in implicit self-theories from high
              school through college and relatively stable individual
              differences during college. Entity theorists tended to adopt
              performance goals, whereas Incremental theorists tended to adopt
              learning goals. In terms of attributions, affect, and behavioral
              response to challenge, Entity theorists displayed a helpless
              response pattern and Incremental theorists displayed a
              mastery-oriented response pattern. Finally, Entity theorists
              declined in self-esteem during college whereas Incremental
              theorists increased self-esteem, and path analyses showed that
              this effect was mediated by goal orientation and the helpless
              versus mastery response patterns. ABSTRACT FROM AUTHOR Copyright
              of Self \& Identity is the property of Psychology Press (UK) and
              its content may not be copied or emailed to multiple sites or
              posted to a listserv without the copyright holder's express
              written permission. However, users may print, download, or email
              articles for individual use. This abstract may be abridged. No
              warranty is given about the accuracy of the copy. Users should
              refer to the original published version of the material for the
              full abstract. (Copyright applies to all Abstracts)",
  journal  = "Self and identity: the journal of the International Society for
              Self and Identity",
  volume   =  1,
  number   =  4,
  pages    = "313--336",
  year     =  2002,
  issn     = "1529-8868",
  doi      = "10.1080/15298860290106805"
}

@ARTICLE{Hong1999-xe,
  title    = "Implicit theories, attributions, and coping: A meaning system
              approach",
  author   = "Hong, Ying-Yi and Chiu, Chi-Yue and Dweck, Carol S and Lin,
              Derrick M-S and Wan, Wendy",
  journal  = "Journal of personality and social psychology",
  volume   =  77,
  number   =  3,
  pages    = "588--599",
  year     =  1999,
  keywords = "mastery orientation",
  issn     = "0022-3514"
}

@ARTICLE{Cury1996-pg,
  title   = "Personal and Situational Factors Influencing Intrinsic Interest of
             Adolescent Girls in School Physical Education: a structural
             equation modelling analysis",
  author  = "Cury, Fran{\c c}ois and Biddle, Stuart and Famose, Jean-Pierre and
             Goudas, Marios and Sarrazin, Philippe and Durand, Marc",
  journal = "Educational psychology review",
  volume  =  16,
  number  =  3,
  pages   = "305--315",
  year    =  1996,
  issn    = "1040-726X, 0144-3410",
  doi     = "10.1080/0144341960160307"
}

@ARTICLE{Elliott1988-qz,
  title    = "Goals: an approach to motivation and achievement",
  author   = "Elliott, E S and Dweck, C S",
  abstract = "This study tested a framework in which goals are proposed to be
              central determinants of achievement patterns. Learning goals, in
              which individuals seek to increase their competence, were
              predicted to promote challenge-seeking and a mastery-oriented
              response to failure regardless of perceived ability. Performance
              goals, in which individuals seek to gain favorable judgments of
              their competence or avoid negative judgments, were predicted to
              produce challenge-avoidance and learned helplessness when
              perceived ability was low and to promote certain forms of
              risk-avoidance even when perceived ability was high.
              Manipulations of relative goal value (learning vs. performance)
              and perceived ability (high vs. low) resulted in the predicted
              differences on measures of task choice, performance during
              difficulty, and spontaneous verbalizations during difficulty.
              Particularly striking was the way in which the performance
              goal-low perceived ability condition produced the same pattern of
              strategy deterioration, failure attribution, and negative affect
              found in naturally occurring learned helplessness. Implications
              for theories of motivation and achievement are discussed.",
  journal  = "Journal of personality and social psychology",
  volume   =  54,
  number   =  1,
  pages    = "5--12",
  year     =  1988,
  issn     = "0022-3514",
  pmid     = "3346808",
  doi      = "10.1037/0022-3514.54.1.5"
}

@ARTICLE{Dupeyrat2005-ju,
  title    = "Implicit theories of intelligence, goal orientation, cognitive
              engagement, and achievement: A test of Dweck's model with
              returning to school adults",
  author   = "Dupeyrat, Caroline and Marin{\'e}, Claudette",
  abstract = "This study tested and extended Dweck's social-cognitive theory of
              motivation with adults who deliberately chose to face the
              challenge of returning to school. We examined the relationships
              among beliefs (implicit theories) on the nature of intelligence,
              goal orientation, cognitive engagement in learning, and
              achievement using path analyses. Findings were generally
              consistent with Dweck's theoretical predictions. Striving for
              competence improvement (mastery goals) had a positive impact on
              learning activities and outcomes, while striving to demonstrate
              competence (performance goals) or to avoid effort (work
              avoidance) had a negative influence on learning and achievement.
              Additionally, data suggested that mastery goals had a positive
              influence on academic achievement through the mediation of effort
              expenditure. The predicted effects of implicit theories of
              intelligence on goal orientation and cognitive engagement in
              learning, however, failed to emerge. Results are discussed in
              relation to their general theoretical implications and with
              regard to the specific characteristics of returning to school
              adults. \copyright{} 2004 Elsevier Inc. All rights reserved.",
  journal  = "Contemporary educational psychology",
  volume   =  30,
  number   =  1,
  pages    = "43--59",
  year     =  2005,
  keywords = "Achievement; Effort; Goal orientation; Implicit theories of
              intelligence; Learning strategies; Returning to school students;
              Work avoidance;Dweck review",
  issn     = "0361-476X",
  doi      = "10.1016/j.cedpsych.2004.01.007"
}

@INCOLLECTION{Henderson1990-fq,
  title     = "Achievement and motivation in adolescence: A new model and data",
  booktitle = "At the Threshold: The Developing Adolescent",
  author    = "Henderson, V and Dweck, Carol S",
  abstract  = "Adolescents embody the best hopes of American society. Their
               vital role in shaping our future lends particular significance
               to their success in negotiating the passage from childhood to
               adulthood, while their intensity and visibility often make them
               barometers of social change. It is all the more remarkable,
               then, that this critical period has only recently captured the
               full attention of researchers.At the Threshold presents the
               long-awaited findings of the Carnegie Foundation study on
               adolescence. It offers a comprehensive overview of what
               investigators are learning about normal development and provides
               an interdisciplinary synthesis of research into the biological,
               social, and psychological changes occurring during this key
               stage in the life span. While focusing on the contexts of
               adolescent life - social and ethnic, family and school, leisure
               and work-it also addresses how researchers are doing in the
               effort to understand the intersection of processes that initiate
               and sustain adolescent development and to characterize the
               extraordinary changes that occur during these years.Contrary to
               popular belief, large numbers of young people continue to mature
               into productive members of society. At the Threshold seeks to
               allow professionals and nonprofessionals alike important access
               to the reality of normal adolescent experience. The authors
               recognize that only if we begin to understand and clearly
               articulate the parameters of successful adolescent development
               can we hope to intervene with those individuals whose lives seem
               aimed toward unsatisfactory futures.",
  publisher = "Harvard University Press",
  edition   = "Feldman, S",
  year      =  1990,
  address   = "Cambridge, MA",
  isbn      = "9780674050358"
}

@ARTICLE{Diener1980-qv,
  title    = "An analysis of learned helplessness: {II}. The processing of
              success",
  author   = "Diener, C I and Dweck, C S",
  abstract = "Helpless children attribute their failures to lack of ability and
              view them as insurmountable. Mastery-oriented children, in
              contrast, tend to emphasize motivational factors and to view
              failure as surmountable. Although the performance of the two
              groups is usually identical during success of prior to failure,
              past research suggests that these groups may well differ in the
              degree to which they perceive that their successes are replicable
              and hence that their failures are avoidable. The present study
              was concerned with the nature of such differences. Children
              performed a task on which they encountered success and then
              failure. Half were asked a series of questions about their
              performance after success and half after failure. Striking
              differences emerged: Compared to mastery-oriented children,
              helpless children underestimated the number of success (and
              overestimated the number of failures), did not view successes as
              indicative of ability, and did not expect the successes to
              continue. subsequent failure led them to devalue ;their
              performance but left the mastery-oriented children undaunted.
              Thus, for helpless children, successes are less salient, less
              predictive, and less enduring--less successful.",
  journal  = "Journal of personality and social psychology",
  volume   =  39,
  number   =  5,
  pages    = "940--952",
  year     =  1980,
  issn     = "0022-3514",
  pmid     = "7441483",
  doi      = "10.1037/0022-3514.39.5.940"
}

@ARTICLE{Dweck1975-av,
  title    = "The role of expectations and attributions in the alleviation of
              learned helplessness",
  author   = "Dweck, Carol S",
  abstract = "The purpose of the investigation was to determine whether
              altering attributions\textbackslashnfor failure would enable
              learned helpless children to deal more effectively with failure
              in an experimental problem-solving situation. Twelve children
              with extreme reactions to failure were identified and were given
              intensive, relatively long-term experience with one of two
              training procedures. It was hypothesized that a procedure which
              taught the helpless children to take responsibility for failure
              and to attribute it to lack of effort would result in unimpaired
              performance following failure in the criterion situation, but
              that a procedure which provided success experiences only (as in
              many programmed learning and behavior modification programs)
              would lead to changes of a lesser magnitude. The results revealed
              that following training, the subjects in the Success Only
              Treatment continued to evidence a severe deterioration in
              performance after failure, while subjects in the Attribution
              Retraining Treatment\textbackslashnmaintained or improved their
              performance. In addition, the subjects in the latter condition
              showed an increase in the degree to which they emphasized
              insufficient motivation versus ability as a determinant of
              failure.",
  journal  = "Journal of personality and social psychology",
  volume   =  31,
  number   =  4,
  pages    = "674--685",
  year     =  1975,
  issn     = "0022-3514",
  doi      = "10.1037/h0077149"
}

@ARTICLE{Licht1984-zh,
  title    = "Determinants of academic achievement: The interaction of
              children's achievement orientations with skill area",
  author   = "Licht, Barbara G and Dweck, Carol S",
  abstract = "Proposes a motivational analysis to help account for individual
              (e.g., sex) differences in different academic areas (e.g.,
              mathematical vs verbal areas). It is proposed that certain
              academic areas (e.g., mathematics) are more likely than others
              (e.g., verbal) to pose difficulties at the start of new units and
              that the necessity of surmounting difficulties favors certain
              achievement orientations. To test the hypothesis that children's
              academic orientations interact with the acquisition demands of
              academic material to determine performance, 57 male and 37 female
              5th graders, who were classified as helpless or mastery oriented
              on the basis of their attributions, were assigned to 1 of 2
              learning conditions. One condition involved programmed confusion
              during learning, while the other was a no-confusion condition.
              When the learning task contained somewhat confusing material in
              the initial sections (even though it was irrelevant to what was
              to be learned), Ss with a mastery oriented attributional style
              significantly outperformed those with a helpless style. However,
              when the identical task was presented without the confusing
              material, both groups learned with equal facility. Results
              support the notion that achievement differences can result from
              the fit between children's achievement orientations and the
              demands of particular skill areas. (44 ref)",
  journal  = "Developmental psychology",
  volume   =  20,
  number   =  4,
  pages    = "628--636",
  year     =  1984,
  issn     = "0012-1649"
}

@ARTICLE{Mueller1998-ue,
  title    = "Praise for intelligence can undermine children's motivation and
              performance",
  author   = "Mueller, C M and Dweck, C S",
  abstract = "Praise for ability is commonly considered to have beneficial
              effects on motivation. Contrary to this popular belief, six
              studies demonstrated that praise for intelligence had more
              negative consequences for students' achievement motivation than
              praise for effort. Fifth graders praised for intelligence were
              found to care more about performance goals relative to learning
              goals than children praised for effort. After failure, they also
              displayed less task persistence, less task enjoyment, more
              low-ability attributions, and worse task performance than
              children praised for effort. Finally, children praised for
              intelligence described it as a fixed trait more than children
              praised for hard work, who believed it to be subject to
              improvement. These findings have important implications for how
              achievement is best encouraged, as well as for more theoretical
              issues, such as the potential cost of performance goals and the
              socialization of contingent self-worth.",
  journal  = "Journal of personality and social psychology",
  volume   =  75,
  number   =  1,
  pages    = "33--52",
  year     =  1998,
  issn     = "0022-3514",
  pmid     = "9686450",
  doi      = "10.1037/0022-3514.75.1.33"
}

@ARTICLE{Mangels2006-dl,
  title    = "Why do beliefs about intelligence influence learning success? A
              social cognitive neuroscience model",
  author   = "Mangels, Jennifer a and Butterfield, Brady and Lamb, Justin and
              Good, Catherine and Dweck, Carol S",
  abstract = "Students' beliefs and goals can powerfully influence their
              learning success. Those who believe intelligence is a fixed
              entity (entity theorists) tend to emphasize 'performance goals,'
              leaving them vulnerable to negative feedback and likely to
              disengage from challenging learning opportunities. In contrast,
              students who believe intelligence is malleable (incremental
              theorists) tend to emphasize 'learning goals' and rebound better
              from occasional failures. Guided by cognitive neuroscience models
              of top-down, goal-directed behavior, we use event-related
              potentials (ERPs) to understand how these beliefs influence
              attention to information associated with successful error
              correction. Focusing on waveforms associated with conflict
              detection and error correction in a test of general knowledge, we
              found evidence indicating that entity theorists oriented
              differently toward negative performance feedback, as indicated by
              an enhanced anterior frontal P3 that was also positively
              correlated with concerns about proving ability relative to
              others. Yet, following negative feedback, entity theorists
              demonstrated less sustained memory-related activity (left
              temporal negativity) to corrective information, suggesting
              reduced effortful conceptual encoding of this material-a
              strategic approach that may have contributed to their reduced
              error correction on a subsequent surprise retest. These results
              suggest that beliefs can influence learning success through
              top-down biasing of attention and conceptual processing toward
              goal-congruent information.",
  journal  = "Social cognitive and affective neuroscience",
  volume   =  1,
  number   =  2,
  pages    = "75--86",
  year     =  2006,
  keywords = "achievement motivation; dm; episodic memory; p3a; toi",
  issn     = "1749-5016, 1749-5024",
  pmid     = "17392928",
  doi      = "10.1093/scan/nsl013"
}

@ARTICLE{Ullen2014-zr,
  title    = "Psychometric properties and heritability of a new online test for
              musicality, the Swedish Musical Discrimination Test",
  author   = "Ull{\'e}n, Fredrik and Mosing, Miriam A and Holm, Linus and
              Eriksson, Helene and Madison, Guy",
  abstract = "We examine, in 6881 twin individuals, the psychometric properties
              of a new test (the Swedish Musical Discrimination Test, SMDT)
              that was developed to tap auditory discrimination of musical
              stimuli. The SMDT consists of three subtests measuring
              discrimination of melodies, rhythms, and single pitches,
              respectively. Mean test taking times for the subtests were
              3.0-4.6. min. Reliability and internal consistency were good with
              Cronbach's alpha values and Spearman-Brown split-half
              reliabilities between .79 and .89. Subtests correlated positively
              (r values .27-41). Criterion validity was demonstrated in three
              ways: individuals that had played a musical instrument scored
              higher than individuals that had not (Cohen's d .38-63);
              individuals that had taken music lessons scored higher than
              individuals that had not (Cohen's d .35-60); finally, total hours
              of musical training and SMDT scores correlated (r values .14-28)
              among those participants that had played an instrument. Lastly,
              twin modelling revealed moderate heritability estimates for the
              three sub-scales. We conclude that the SMDT has good psychometric
              characteristics, short test taking time, and may serve as a
              useful complement to existing tests of musical ability.
              \copyright{} 2014 The Authors.",
  journal  = "Personality and individual differences",
  volume   =  63,
  pages    = "87--93",
  year     =  2014,
  keywords = "Expertise; Music; Psychological testing; Sensory discrimination;
              Training",
  issn     = "0191-8869",
  doi      = "10.1016/j.paid.2014.01.057"
}

@ARTICLE{Birnbaum1969-be,
  title   = "Statistical theory for logistic mental test models with a prior
             distribution of ability",
  author  = "Birnbaum, A",
  journal = "Journal of mathematical psychology",
  volume  =  6,
  number  =  2,
  pages   = "258--276",
  year    =  1969,
  issn    = "0022-2496"
}

@PHDTHESIS{Urry1970-zi,
  title   = "A Monte Carlo investigation of logistic mental test models",
  author  = "Urry, V W",
  year    =  1970,
  address = "West Lafayette, IN",
  school  = "Doctoral dissertation, Purdue University"
}

@INPROCEEDINGS{Iversen2008-sx,
  title     = "The Beat Alignment Test ({BAT)}: Surveying beat processing
               abilities in the general population",
  booktitle = "Proceedings of the 10th International Conference on Music
               Perception and Cognition",
  author    = "Iversen, John R and Patel, Aniruddh D",
  editor    = "Miyazaki, K and Hiraga, Y and Adachi, M and Nakajima, Y and
               Tsuzaki, M",
  abstract  = "The ability to perceive a musical beat (and move in synchrony
               with it) seems widespread, but we currently lack normative data
               on the distribution of this ability in musically untrained
               individuals. To aid in the survey of beat processing abilities
               in the general population, as well as to attempt to identify and
               differentiate impairments in beat processing, we have developed
               a psychophysical test called the Beat Alignment Test (BAT). The
               BAT is intended to complement existing tests of rhythm
               processing by directly examining beat perception in isolation
               from beat synchronization. The goals of the BAT are 1) to study
               the distribution of beat-based processing abilities in the
               normal population and 2) to provide a way to search for ``rhythm
               deaf'' individuals, who have trouble with beat processing in
               music though they are not tone deaf. The BAT is easily
               implemented and it is our hope that it is widely adopted. Data
               from a pilot study of 30 individuals is presented.",
  pages     = "465--468",
  year      =  2008,
  address   = "Sapporo, Japan",
  isbn      = "9784990420802"
}

@ARTICLE{Grassi2009-pk,
  title    = "{MLP}: a {MATLAB} toolbox for rapid and reliable auditory
              threshold estimation",
  author   = "Grassi, Massimo and Soranzo, Alessandro",
  abstract = "In this article, we present MLP, a MATLAB toolbox enabling
              auditory thresholds estimation via the adaptive maximum
              likelihood procedure proposed by David Green (1990, 1993). This
              adaptive procedure is particularly appealing for those
              psychologists who need to estimate thresholds with a good degree
              of accuracy and in a short time. Together with a description of
              the toolbox, the present text provides an introduction to the
              threshold estimation theory and a theoretical explanation of the
              maximum likelihood adaptive procedure. MLP comes with a graphical
              interface, and it is provided with several built-in, classic
              psychoacoustics experiments ready to use at a mouse click.",
  journal  = "Behavior research methods",
  volume   =  41,
  number   =  1,
  pages    = "20--28",
  year     =  2009,
  issn     = "1554-351X",
  pmid     = "19182120",
  doi      = "10.3758/BRM.41.1.20"
}

@ARTICLE{Trainor1994-tg,
  title    = "Key membership and implied harmony in Western tonal music:
              developmental perspectives",
  author   = "Trainor, Laurel J and Trehub, Sandra E",
  abstract = "We investigated the role of key membership and implied harmony in
              adults' and children's perception of tone sequences. Listeners
              were evaluated on their ability to detect three types of changes
              in one note of a well-structured Western tonal melody. In one
              change (out-of-key) the new note was not in the basis key, in
              another (out-of-harmony) it was in the key but not in the implied
              harmony, and in the third (within-harmony) it was in both the key
              and the implied harmony. Adults and 7-year-olds performed better
              on the out-of-key and out-of-harmony changes than on the
              within-harmony change, reflecting their implicit knowledge of key
              membership and implied harmony. Five-year-olds performed better
              on the out-of-key change than on the other two changes,
              reflecting the influence of key membership but not implied
              harmony. We consider the developmental precedence of key
              membership over implied harmony in the context of cross-cultural
              and theoretical perspectives.",
  journal  = "Perception \& psychophysics",
  volume   =  56,
  number   =  2,
  pages    = "125--132",
  year     =  1994,
  issn     = "0031-5117",
  pmid     = "7971113",
  doi      = "10.3758/BF03213891"
}

@MISC{Trainor1992-ly,
  title   = "A Comparison of Infants' and Adults' Sensitivity to Western
             Musical Structure",
  author  = "Trainor, Laurel J and Trehub, Sandra E",
  journal = "Journal of Experimental Psychology: Human Perception and
             Performance",
  volume  =  18,
  number  =  2,
  pages   = "394--402",
  year    =  1992
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dowling1971-qe,
  title    = "Contour, interval, and pitch recognition in memory for melodies",
  author   = "Dowling, W Jay and Fujitani, D S",
  abstract = "Melodic contour (the sequence of ups and downs in a melody,
              regardless of interval size) expresses those aspects of a melody
              that are most essential to manipulation of that melody in various
              musical structures, e.g., folktunes and fugues. This is
              demonstrated by brief analyses of actual music. Two experiments
              demonstrate the role of melodic contour recognition in memory for
              melodies. Experiment 1 (2$\times$3 factorial design) involved
              short-term memory with comparison melodies either transposed or
              not transposed from the key of the standard. Separate groups had
              the tasks of distinguishing (a) between same and different
              melodies; (b) between same melodies and ones with only the same
              contour; and (c) between melodies with the same contour and
              different ones. The effects of transposition and task and their
              interaction were significant (p<0.001). Untransposed melodies
              were recognized by their exact pitches, so that tasks (a) and (b)
              were equally easy. Contour recognition was more important with
              transposed melodies, so that task (b) was very difficult, and
              tasks (a) and (c) were easier. Task (c) was about equally
              difficult under both conditions. Experiment 2 involved
              recognition of distorted versions of familiar folktunes having
              the same length and rhythmic structure. In ascending order of
              recognizability, these distortions preserved merely the harmonic
              basis of the melody, the melodic contour, and the contour plus
              the relative sizes of successive intervals between notes
              (chi‐square = 50.4, p<0.001).",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  49,
  number   = "2B",
  pages    = "524--531",
  year     =  1971,
  issn     = "0001-4966",
  pmid     = "5541747",
  doi      = "10.1121/1.1912382"
}

@INCOLLECTION{Brittin2000-oa,
  title     = "Perception and recall of melodic and rhythmic patterns: Effects
               of example length and tonal/rhythmic variety",
  booktitle = "Texas music education research 2000",
  author    = "Brittin, Ruth V",
  editor    = "Mizener, Charlotte",
  publisher = "Texas Music Educators Association",
  pages     = "17--25",
  year      =  2000,
  address   = "Austin, TX"
}

@ARTICLE{Dowling1978-ga,
  title   = "Scale and contour: Two components of a theory of memory for
             melodies",
  author  = "Dowling, W Jay",
  journal = "Psychological review",
  volume  =  85,
  number  =  4,
  pages   = "341--354",
  year    =  1978,
  issn    = "0033-295X"
}

@ARTICLE{Akiva-Kabiri2009-eq,
  title    = "Memory for tonal pitches: A music-length effect hypothesis",
  author   = "Akiva-Kabiri, Lilach and Vecchi, Tomaso and Granot, Roni and
              Basso, Demis and Sch{\"o}n, Daniele",
  abstract = "One of the most studied effects of verbal working memory (WM) is
              the influence of the length of the words that compose the list to
              be remembered. This work aims to investigate the nature of
              musical WM by replicating the word length effect in the musical
              domain. Length and rate of presentation were manipulated in a
              recognition task of tone sequences. Results showed significant
              effects for both factors (length and presentation rate) as well
              as their interaction, suggesting the existence of different
              strategies (e.g., chunking and rehearsal) for the immediate
              memory of musical information, depending upon the length of the
              sequences.",
  journal  = "Annals of the New York Academy of Sciences",
  volume   =  1169,
  pages    = "266--269",
  year     =  2009,
  keywords = "Length effect; Music; Pitch tone; Working memory",
  issn     = "0077-8923",
  pmid     = "19673790",
  doi      = "10.1111/j.1749-6632.2009.04787.x"
}

@INCOLLECTION{Baddeley2000-oe,
  title     = "Short-term and working memory",
  booktitle = "The Oxford handbook of memory",
  author    = "Baddeley, Alan D",
  publisher = "Oxford University Press",
  pages     = "77--92",
  year      =  2000,
  address   = "Oxford, England"
}

@ARTICLE{Mullensiefen2011-ca,
  title   = "Polynomial functions as a representation of melodic phrase contour",
  author  = "M{\"u}llensiefen, Daniel and Wiggins, G A",
  journal = "Systematic Musicology Empirical and Theoretical Studies",
  number  =  1940,
  pages   = "63--88",
  year    =  2011
}

@PHDTHESIS{Harrison2015-jb,
  title  = "Constructing computerised adaptive tests of musical listening
            abilities",
  author = "Harrison, Peter M C",
  year   =  2015,
  school = "Master's dissertation, Goldsmiths, University of London"
}

@BOOK{De_Ayala2009-xn,
  title     = "The theory and practice of item response theory",
  author    = "de Ayala, Rafael Jaime",
  publisher = "The Guilford Press",
  year      =  2009,
  address   = "New York, NY"
}

@ARTICLE{Engle1978-mm,
  title    = "Memory processes among bridge players of differing expertise",
  author   = "Engle, Randall W and Bukstel, Lee H",
  abstract = "Studied the mnemonic and perceptual abilities of contract-bridge
              players of differing ability levels. Four 27-36 yr old Ss
              (expert, life master, average player, and novice) were
              administered 3 tasks to explore possible differences in
              performance between the players. A tournament-simulation task
              required Ss to play 10 hands, after which a surprise test was
              given for the cards in each hand of the 10 deals. A memory task
              required that Ss reconstruct a briefly presented stimulus
              containing 4 bridge hands of either structured or unstructured
              arrangement. The perception task required that Ss reconstruct
              stimuli similar to those used in the memory task after brief
              glances at the stimulus. Results confirm the findings of research
              on chess players in that performance in the structured components
              of each task varied uniformly according to level of expertise but
              that performance in the unstructured component of each task
              showed little difference in level of expertise. It is argued that
              bridge players with ``supranormal'' memory are able to use their
              prior experience to configure and chunk information in more
              efficient ways than players of less expertise. (13 ref) (PsycINFO
              Database Record (c) 2010 APA, all rights reserved).",
  journal  = "The American journal of psychology",
  volume   =  91,
  number   =  4,
  pages    = "673--689",
  year     =  1978,
  keywords = "*Ability Level; *Games; *Memory; Human; Learning \& Memory
              [2343]; level of playing ability, memory for briefly prese",
  issn     = "0002-9556, 0278-016X",
  doi      = "10.2307/1421515"
}

@ARTICLE{Gobet1998-yn,
  title    = "Expert chess memory: revisiting the chunking hypothesis",
  author   = "Gobet, F and Simon, H A",
  abstract = "After reviewing the relevant theory on chess expertise, this
              paper re-examines experimentally the finding of Chase and Simon
              (1973a) that the differences in ability of chess players at
              different skill levels to copy and to recall positions are
              attributable to the experts' storage of thousands of chunks
              (patterned clusters of pieces) in long-term memory. Despite
              important differences in the experimental apparatus, the data of
              the present experiments regarding latencies and chess relations
              between successively placed pieces are highly correlated with
              those of Chase and Simon. We conclude that the two-second
              inter-chunk interval used to define chunk boundaries is robust,
              and that chunks have psychological reality. We discuss the
              possible reasons why Masters in our new study used substantially
              larger chunks than the Master of the 1973 study, and extend the
              chunking theory to take account of the evidence for large
              retrieval structures (templates) in long-term memory.",
  journal  = "Memory",
  volume   =  6,
  number   =  3,
  pages    = "225--255",
  year     =  1998,
  issn     = "0965-8211",
  pmid     = "9709441",
  doi      = "10.1080/741942359"
}

@ARTICLE{Reitman1976-qr,
  title    = "Skilled perception in Go: Deducing memory structures from
              inter-response times",
  author   = "Reitman, Judith S",
  abstract = "Experts appear able to handle much larger amounts of specialized
              information than nonexperts, and handle it without an apparent
              superior memory capacity. This finding, based on research on
              chess players with chess information, was replicated on Go
              players with Go information. Assuming this superiority occurs
              because the experts process chunks of information through their
              limited capacities rather than individual elements, the question
              then becomes one of defining what the chunks are and how they are
              related. To this end, the technique of partitioning recall and
              reproduction data into chunks on the basis of inter-response
              times (IRTs) (introduced in their work on chess by Chase and
              Simon, 1973) was applied to the reproduction and recall of Go
              patterns by a Go Master and a Go beginner. Unlike its application
              in chess, no single IRT was able to produce consistent, veridical
              chunks for either Go player. Subsequent analysis of the
              underlying assumptions of the technique showed it to be limited
              to only those patterns that can be partitioned into a linear set
              of chunks, not nested chunks, and to situations in which
              retrieval and overt recall of each chunk is completed before
              retrieval of the next chunk. In a supplementary task, the Master
              Go player indicated that the Go patterns were not seen as linear
              chunks nor as strictly nested hierarchies, but rather as
              overlapping clusters. IRTs were found to be correlated with this
              structure, but were not reliable enough to reflect its details.",
  journal  = "Cognitive psychology",
  volume   =  8,
  number   =  3,
  pages    = "336--356",
  year     =  1976,
  issn     = "0010-0285",
  doi      = "10.1016/0010-0285(76)90011-6"
}

@PHDTHESIS{Bandura1985-fa,
  title  = "The relationship of conceptions of intelligence and achievement
            goals to achievement-related cognition, affect and behaviour",
  author = "Bandura, M and Dweck, Carol S",
  year   =  1985,
  school = "Unpublished manuscript, Harvard University"
}

@BOOK{Dweck2000-pj,
  title     = "Self-theories: Their role in motivation, personality, and
               development",
  author    = "Dweck, Carol S",
  publisher = "Psychology Press",
  year      =  2000,
  address   = "Philadelphia, PA"
}

@ARTICLE{Dweck1995-qv,
  title    = "Implicit Theories and Their Role in Judgments and Reactions: A
              Word From Two Perspectives",
  author   = "Dweck, Carol S and Chiu, Chi-Yue and Hong, Ying-Yi",
  abstract = "In this target article, we present evidence for a new model of
              individual differences in judgments and reactions. The model
              holds that people's implicit theories about human attributes
              structure the way they understand and react to human actions and
              outcomes. We review reserach showing that when people believe
              that attributes (such as intellignece or moral character) are
              fixed, trait-like entities (an entity theory), they tend to
              understand outcomes and actions in terms of these fixed traits
              (``I failed the test because I am dumb'' or ``He stole the bread
              because he is dishonest''). In contrast, when people believe that
              attributes are more dynamic, malleable, and developable (an
              incremental theory), they tend to focus less on braod traits and,
              instead, tend to understand outcomes and actions in terms of more
              specific behavioral or pschological mediators (``I failed the
              test because of my effort or strategy'' or ``He stole the bread
              because he was desperate''). The two frameworks also appear to
              foster different reactions: helpless versus master-oriented
              responses to personal setbacks and an emphasis on retribution
              versus education or rehabilitation for transgressions. These
              findings are discusssed in terms of their implications for
              personality, motivation, and social perception.",
  journal  = "Psychological inquiry",
  volume   =  6,
  number   =  4,
  pages    = "267--285",
  year     =  1995,
  issn     = "1047-840X",
  pmid     = "7394652",
  doi      = "10.1207/s15327965pli0604\_1"
}

@ARTICLE{Doran2007-xl,
  title    = "Estimating the multilevel Rasch model: With the lme4 package",
  author   = "Doran, Harold and Bates, Douglas and Bliese, Paul and Dowling,
              Maritza",
  abstract = "Traditional Rasch estimation of the item and student parameters
              via marginal maximum likelihood, joint maximum likelihood or
              conditional maximum likelihood, assume individuals in clustered
              settings are uncorrelated and items within a test that share a
              grouping structure are also uncorrelated. These assumptions are
              often violated, particularly in educational testing situations,
              in which students are grouped into classrooms and many test items
              share a common grouping structure, such as a content strand or a
              reading passage. Consequently, one possible approach is to
              explicitly recognize the clustered nature of the data and
              directly incorporate random effects to account for the various
              dependencies. This article demonstrates how the multilevel Rasch
              model can be estimated using the functions in R for mixed-effects
              models with crossed or partially crossed random effects. We
              demonstrate how to model the following hierarchical data
              structures: a) individuals clustered in similar settings (e.g.,
              classrooms, schools), b) items nested within a particular group
              (such as a content strand or a reading passage), and c) how to
              estimate a teacher $\times$ content strand interaction.",
  journal  = "Journal of statistical software",
  volume   =  20,
  number   =  2,
  pages    = "1--18",
  year     =  2007,
  keywords = "generalized linear mixed models; item response theory; sparse
              matrix techniques;IRT;lmer",
  issn     = "1548-7660",
  doi      = "10.1111/j.1467-9868.2007.00600.x"
}

@ARTICLE{Carey2015-xs,
  title    = "Generality and specificity in the effects of musical expertise on
              perception and cognition",
  author   = "Carey, Daniel and Rosen, Stuart and Krishnan, Saloni and Pearce,
              Marcus T and Shepherd, Alex and Aydelott, Jennifer and Dick,
              Frederic",
  abstract = "Performing musicians invest thousands of hours becoming experts
              in a range of perceptual, attentional, and cognitive skills. The
              duration and intensity of musicians' training - far greater than
              that of most educational or rehabilitation programs - provides a
              useful model to test the extent to which skills acquired in one
              particular context (music) generalize to different domains. Here,
              we asked whether the instrument-specific and more
              instrument-general skills acquired during professional
              violinists' and pianists' training would generalize to superior
              performance on a wide range of analogous (largely non-musical)
              skills, when compared to closely matched non-musicians.
              Violinists and pianists outperformed non-musicians on
              fine-grained auditory psychophysical measures, but surprisingly
              did not differ from each other, despite the different demands of
              their instruments. Musician groups did differ on a tuning system
              perception task: violinists showed clearest biases towards the
              tuning system specific to their instrument, suggesting that
              long-term experience leads to selective perceptual benefits given
              a training-relevant context. However, we found only weak evidence
              of group differences in non-musical skills, with musicians
              differing marginally in one measure of sustained auditory
              attention, but not significantly on auditory scene analysis or
              multi-modal sequencing measures. Further, regression analyses
              showed that this sustained auditory attention metric predicted
              more variance in one auditory psychophysical measure than did
              musical expertise. Our findings suggest that specific musical
              expertise may yield distinct perceptual outcomes within contexts
              close to the area of training. Generalization of expertise to
              relevant cognitive domains may be less clear, particularly where
              the task context is non-musical.",
  journal  = "Cognition",
  volume   =  137,
  pages    = "81--105",
  month    =  apr,
  year     =  2015,
  keywords = "Cognition; Expertise; Generalization; Musicians; Perception",
  issn     = "0010-0277, 1873-7838",
  pmid     = "25618010",
  doi      = "10.1016/j.cognition.2014.12.005"
}

@BOOK{Wing1961-gp,
  title     = "Standardised tests of musical intelligence",
  author    = "Wing, H D",
  publisher = "National Foundation for Educational Research",
  year      =  1961,
  address   = "The Mere, England",
  keywords  = "musical aptitude"
}

@ARTICLE{Radvansky1995-xi,
  title    = "Timbre Reliance in Nonmusicians' and Musicians' Memory for
              Melodies",
  author   = "Radvansky, Gabriel A and Fleming, Kevin J and Simmons, Julie A",
  abstract = "Tested R. S. Wolpert's (1990) claim that musicians and
              nonmusicians differ in their memory for melodies because
              nonmusicians' memory performance reflects a greater use of the
              timbre dimension to make recognition decisions. In Exp 1, with 32
              nonmusicians, and in Exp 2, with 24 musicians, Ss identified
              which of 2 test melodies, a target and a distractor, was heard
              previously. On one half of the trials, the target melody was in
              the same timbre as the original, and the distractor was in a
              different timbre. For the other half of the trials, the
              distractor melody was in the same timbre as the original, and the
              target melody was in a different timbre. Timbre changes
              differentially affected neither musicians' nor nonmusicians'
              memory for melodies. Melody pairs and practice melodies are
              appended.",
  journal  = "Music perception",
  volume   =  13,
  number   =  2,
  pages    = "127--140",
  year     =  1995,
  issn     = "0730-7829"
}

@ARTICLE{Demorest2008-qw,
  title    = "Lost in translation: An enculturation effect in music memory
              performance",
  author   = "Demorest, Steven M and Morrison, Steven J and Beken, M{\"u}nir N
              and Jungbluth, Denise",
  journal  = "Music perception",
  volume   =  25,
  number   =  3,
  pages    = "223",
  year     =  2008,
  keywords = "melodic memory",
  issn     = "0730-7829"
}

@ARTICLE{Korenman2004-cy,
  title    = "The role of familiarity in episodic memory and metamemory for
              music",
  author   = "Korenman, Lisa M and Peynircioglu, Zehra F",
  abstract = "Participants heard music snippets of varying melodic and
              instrumental familiarity paired with animal-name titles. They
              then recalled the target when given either the melody or the
              title as a cue, or they gave name feeling-of-knowing (FOK)
              ratings. In general, recall for titles was better than it was for
              melodies, and recall was enhanced with increasing melodic
              familiarity of both the cues and the targets. Accuracy of FOK
              ratings, but not magnitude, also increased with increasing
              familiarity. Although similar ratings were given after melody and
              title cues, accuracy was better with title cues. Finally,
              knowledge of the real titles of the familiar music enhanced
              recall but had, by and large, no effect on the FOK ratings.",
  journal  = "Journal of experimental psychology. Learning, memory, and
              cognition",
  volume   =  30,
  number   =  4,
  pages    = "917--922",
  year     =  2004,
  issn     = "0278-7393",
  pmid     = "15238033",
  doi      = "10.1037/0278-7393.30.4.917"
}

@ARTICLE{McAuley2004-ep,
  title    = "Play it again: Did this melody occur more frequently or was it
              heard more recently? The role of stimulus familiarity in episodic
              recognition of music",
  author   = "McAuley, J Devin and Stevens, Catherine and Humphreys, Michael S",
  abstract = "Episodic recognition of novel and familiar melodies was examined
              by asking participants to make judgments about the recency and
              frequency of presentation of melodies over the course of two days
              of testing. For novel melodies, recency judgments were poor and
              participants often confused the number of presentations of a
              melody with its day of presentation; melodies heard frequently
              were judged as have been heard more recently than they actually
              were. For familiar melodies, recency judgments were much more
              accurate and the number of presentations of a melody helped
              rather than hindered performance. Frequency judgments were
              generally more accurate than recency judgments and did not
              demonstrate the same interaction with musical familiarity.
              Overall, these findings suggest that (1) episodic recognition of
              novel melodies is based more on a generalized ``feeling of
              familiarity'' than on a specific episodic memory, (2) frequency
              information contributes more strongly to this generalized memory
              than recency information, and (3) the formation of an episodic
              memory for a melody depends either on the overall familiarity of
              the stimulus or the availability of a verbal label. ?? 2004
              Elsevier B.V. All rights reserved.",
  journal  = "Acta psychologica",
  volume   =  116,
  number   =  1,
  pages    = "93--108",
  year     =  2004,
  keywords = "Episodic memory; Melody recognition; Music",
  issn     = "0001-6918",
  pmid     = "15111232",
  doi      = "10.1016/j.actpsy.2004.02.001"
}

@BOOK{Gaston1957-wg,
  title     = "A test of musicality: Manual of Directions",
  author    = "Gaston, E T",
  publisher = "Odell's Instrumental Service",
  year      =  1957,
  address   = "Lawrence, KA",
  keywords  = "musicality"
}

@ARTICLE{Dowling2008-kq,
  title    = "Melody recognition at fast and slow tempos: Effects of age,
              experience, and familiarity",
  author   = "Dowling, W Jay and Bartlett, James C and Halpern, Andrea R and
              Andrews, Melinda W",
  journal  = "Perception \& psychophysics",
  volume   =  70,
  number   =  3,
  pages    = "496--502",
  year     =  2008,
  keywords = "melodic recognition",
  issn     = "0031-5117",
  pmid     = "18717396",
  doi      = "10.3758/PP"
}

@BOOK{Drake1957-no,
  title     = "Drake musical aptitude tests",
  author    = "Drake, R M",
  publisher = "Science Research Associates",
  year      =  1957,
  address   = "Chicago, IL",
  keywords  = "musical ability;musical aptitude"
}

@ARTICLE{Williamson2010-xb,
  title    = "Musicians' and nonmusicians' short-term memory for verbal and
              musical sequences: comparing phonological similarity and pitch
              proximity",
  author   = "Williamson, Victoria J and Baddeley, Alan D and Hitch, Graham J",
  abstract = "Language-music comparative studies have highlighted the potential
              for shared resources or neural overlap in auditory short-term
              memory. However, there is a lack of behavioral methodologies for
              comparing verbal and musical serial recall. We developed a visual
              grid response that allowed both musicians and nonmusicians to
              perform serial recall of letter and tone sequences. The new
              method was used to compare the phonological similarity effect
              with the impact of an operationalized musical equivalent-pitch
              proximity. Over the course of three experiments, we found that
              short-term memory for tones had several similarities to verbal
              memory, including limited capacity and a significant effect of
              pitch proximity in nonmusicians. Despite being vulnerable to
              phonological similarity when recalling letters, however,
              musicians showed no effect of pitch proximity, a result that we
              suggest might reflect strategy differences. Overall, the findings
              support a limited degree of correspondence in the way that verbal
              and musical sounds are processed in auditory short-term memory.",
  journal  = "Memory \& cognition",
  volume   =  38,
  number   =  2,
  pages    = "163--175",
  year     =  2010,
  keywords = "melodic memory",
  issn     = "0090-502X",
  pmid     = "20173189",
  doi      = "10.3758/MC.38.2.163"
}

@ARTICLE{Halpern1995-rc,
  title    = "Aging and experience in the recognition of musical transpositions",
  author   = "Halpern, Andrea R and Bartlett, James C and Dowling, W Jay",
  journal  = "Psychology and aging",
  volume   =  10,
  number   =  3,
  pages    = "325--342",
  year     =  1995,
  keywords = "melodic memory",
  issn     = "0882-7974"
}

@ARTICLE{Vispoel1997-uj,
  title    = "Computerized adaptive and fixed-item testing of music listening
              skill: A comparison of efficiency, precision, and concurrent
              validity",
  author   = "Vispoel, Walter P and Wang, Tianyou and Bleiler, Timothy",
  abstract = "We evaluated the efficiency, precision, and concurrent validity
              of results obtained from adaptive and fired-item music listening
              tests in three studies: (a) a computer simulation study in which
              each of 2,200 simulees completed a computerized adaptive tonal
              memory test, a computerized fired-item tonal memory test
              constructed from items in the adaptive test pool and two
              standardized group-administered tonal memory tests; (b) a live
              testing study in which each of 204 examinees took the
              computerized adaptive test and the standardized tests; and (c) a
              live testing study in which randomly equivalent groups took
              either the computerized adaptive test (n = 86) or the
              computerized fired-item test (n = 86). The adaptive music test
              required 50\% to 93\% fewer items to match the reliability and
              concurrent validity of the fired-item tests, and it yielded
              higher levels of reliability and concurrent validity than the
              fired-item tests when test length was held constant. These
              findings suggest that computerized adaptive tests, which
              typically have been limited to visually produced items, may also
              be well suited for measuring skills that require aurally produced
              items.",
  journal  = "Journal of Educational Measurement",
  volume   =  34,
  number   =  1,
  pages    = "43--63",
  year     =  1997,
  issn     = "1745-3984",
  doi      = "10.1111/j.1745-3984.1997.tb00506.x"
}

@BOOK{Gordon1982-sg,
  title     = "Intermediate measures of music audiation",
  author    = "Gordon, Edwin E",
  publisher = "G.I.A. Publications",
  year      =  1982,
  address   = "Chicago, IL",
  keywords  = "IMMA"
}

@BOOK{Gordon1979-em,
  title     = "Primary measures of music audiation",
  author    = "Gordon, Edwin E",
  publisher = "G.I.A. Publications",
  year      =  1979,
  address   = "Chicago, IL",
  keywords  = "PMMA"
}

@ARTICLE{Roby1962-xa,
  title    = "A Study in the Correlation of Music Theory Grades with the
              ``Seashore Measures of Musical Talents'' and the ``Aliferis Music
              Achievement Test''",
  author   = "Roby, A Richard",
  journal  = "Journal of Research in Music Education",
  volume   =  10,
  number   =  2,
  pages    = "137--142",
  year     =  1962,
  keywords = "Seashore review",
  issn     = "0022-4294",
  doi      = "10.2307/3343997"
}

@ARTICLE{McGinnis1928-aq,
  title    = "Seashore's Measures of Musical Ability Applied to Children of the
              {Pre-School} Age",
  author   = "McGinnis, Esther",
  journal  = "The American journal of psychology",
  volume   =  40,
  number   =  4,
  pages    = "620--623",
  year     =  1928,
  keywords = "atomistic;validity",
  issn     = "0002-9556"
}

@ARTICLE{Dowling1981-uy,
  title    = "The importance of interval information in long-term memory for
              melodies",
  author   = "Dowling, W Jay and Bartlett, James C",
  abstract = "Four experiments examined the roles of melodic contour and pitch
              interval information in recognition memory for melodies. In Exps
              I and II 48 16--17 yr old females and 53 undergraduates heard
              excerpts from Beethoven string quartets, and subsequently
              attempted to detect copies of input melodies (targets) as well as
              related items, which resembled input items with respect to
              contour and rhythm, but not pitch intervals. Targets were
              recognized significantly better than ``relateds,'' which were
              recognized only slightly more often than lures. Exp III (41
              undergraduates) replicated this finding with novel, randomly
              generated melodies. All 3 experiments support substantial
              retention of information regarding pitch intervals, as well as
              contour, over a retention interval of several minutes. Exp IV (25
              Ss) examined short (5 sec) and long (31 sec) retention interval
              conditions. Contour information dominated performance with the
              short delay, but not with the long delay, where performance
              resembled that of the prior long-term memory experiments. While
              interval information is difficult to encode, it is apparently
              retained with high efficiency in long-term memory. (16 ref)",
  journal  = "Psychomusicology: A journal of research in music cognition",
  volume   =  1,
  number   =  1,
  pages    = "30--49",
  year     =  1981,
  keywords = "melodic memory"
}

@ARTICLE{Stewart2011-il,
  title     = "Characterizing congenital amusia",
  author    = "Stewart, Lauren",
  abstract  = "The ability to make sense of the music in our environment
               involves sophisticated cognitive mechanisms that, for most
               people, are acquired effortlessly and in early life. A special
               population of individuals, with a disorder termed congenital
               amusia, report lifelong difficulties in this regard. Exploring
               the nature of this developmental disorder provides a window onto
               the cognitive architecture of typical musical processing, as
               well as allowing a study of the relationship between processing
               of music and other domains, such as language. The present
               article considers findings concerning pitch discrimination,
               pitch memory, contour processing, experiential aspects of music
               listening in amusia, and emerging evidence concerning the
               neurobiology of the disorder. A simplified model of melodic
               processing is outlined, and possible loci of the cognitive
               deficit are discussed.",
  journal   = "The Quarterly journal of experimental psychology",
  publisher = "Psychology Press",
  volume    =  64,
  number    =  4,
  pages     = "625--638",
  month     =  apr,
  year      =  2011,
  keywords  = "Acoustic Stimulation; Auditory Perceptual Disorders; Auditory
               Perceptual Disorders: diagnosis; Auditory Perceptual Disorders:
               physiopathology; Humans; Models; Music; Music: psychology; Pitch
               Discrimination; Pitch Discrimination: physiology; Psychological",
  language  = "en",
  issn      = "0033-555X, 1747-0226",
  pmid      = "21409740",
  doi       = "10.1080/17470218.2011.552730"
}

@ARTICLE{Sandell1995-hz,
  title    = "Roles for spectral centroid and other factors in determining
              ''blended'' instrument pairings in orchestration",
  author   = "Sandell, G J",
  abstract = "Three perceptual experiments using natural-sounding instrument
              tones arranged in concurrently sounding pairs investigate a
              problem of orchestration: what factors determine selection of
              instruments to achieve various degrees of blend (fusion of
              multiple timbres into a single timbral image). The principal
              finding concerns the spectral centroid of the instruments (the
              midpoint of the spectral energy distribution). Blend worsened as
              a function of the overall centroid height of the combination (the
              centroid of the composite spectrum of the pair) or as the amount
              of difference between the centroids of the two instruments
              increased. Slightly different results were found depending on
              whether the instruments were on the same pitch or separated by a
              minor third. For unisons, composite centroid, attack similarity,
              and loudness envelope correlation accounted for 51\% of the
              variance of blend. For minor thirds, centroid difference,
              composite centroid, attack similarity, and synchrony of offset
              accounted for 63\% of the variance of blend. In a third
              experiment, instruments were manipulated to have different
              centroid levels to test if centroid made an independent
              contribution to blend. The results show that changes in centroid
              affect blend even when that is the only aspect of the sound that
              is changing. The findings create the potential for an approach to
              orchestration based on abstract properties of sound as a
              substitute for the traditional approach of teaching entirely by
              example.",
  journal  = "Music perception",
  volume   =  13,
  number   =  2,
  pages    = "209--246",
  year     =  1995,
  keywords = "perceptual segregation frequency-modulation simult",
  issn     = "0730-7829",
  doi      = "10.2307/40285694"
}

@ARTICLE{Gaver1993-pb,
  title     = "What in the World Do We Hear?: An Ecological Approach to
               Auditory Event Perception",
  author    = "Gaver, William W",
  abstract  = "Everyday listening is the experience of hearing events in the
               world rather than sounds per se. In this article, I take an
               ecological approach to everyday listening to overcome
               constraints on its study implied by more traditional approaches.
               In particular, I am concerned with developing a new framework
               for describing sound in terms of audible source attributes. An
               examination of the continuum of structured energy from event to
               audition suggests that sound conveys information about events at
               locations in an environment. Qualitative descriptions of the
               physics of sound~producing events, complemented by protocol
               studies, suggest a tripartite division of sound-producing events
               into those involving vibrating solids, gasses, or liquids.
               Within each of these categories, basic-level events are defined
               by the simple interactions that can cause these materials to
               sound, whereas more complex events can be described in terms of
               temporal patterning, compound, or hybrid sources. The results of
               these investigations are u...",
  journal   = "Ecological psychology: a publication of the International
               Society for Ecological Psychology",
  publisher = "Lawrence Erlbaum Associates, Inc.",
  volume    =  5,
  number    =  1,
  pages     = "1--29",
  month     =  mar,
  year      =  1993,
  language  = "en",
  issn      = "1040-7413",
  doi       = "10.1207/s15326969eco0501\_1"
}

@INCOLLECTION{Stevens2009-co,
  title     = "Universals in music processing",
  booktitle = "The Oxford handbook of music psychology",
  author    = "Stevens, Catherine and Byron, Tim",
  editor    = "Hallam, Susan and Cross, Ian and Thaut, Michael",
  publisher = "Oxford University Press",
  chapter   =  2,
  year      =  2009,
  address   = "New York, NY"
}

@ARTICLE{Gregory1990-gm,
  title    = "Listening to Polyphonic Music",
  author   = "Gregory, A H",
  abstract = "Listeners heard short extracts of polyphonic music, and had to
              decide whether or not a subsequent melody was present in the
              polyphonic excerpt. For many of the excerpts accuracy of
              recognition was high, suggesting that the different melodic lines
              in polyphony can be perceived simultaneously. If one melody was
              at a higher pitch than another it was more easily recognised, and
              there were differences in the recognisability of individual
              melodies. When these factors were held constant, recognition was
              more accurate if the melodies were closely related in key, in the
              same pitch range, had simul- taneous note onsets and were
              differentiated in timbre. Within the same pitch range melodies
              having the same tempo were better recognised, but in different
              pitch ranges then differences in tempo improved recognition
              accuracy. Three melodic lines seemed to be as easily
              discriminated as two in the excerpt studied.",
  journal  = "Psychology of Music",
  volume   =  18,
  number   =  2,
  pages    = "163--170",
  month    =  oct,
  year     =  1990,
  keywords = "polyphony;timbre",
  issn     = "0305-7356",
  doi      = "10.1177/0305735690182005"
}

@ARTICLE{Collins2016-oy,
  title    = "Developing and evaluating computational models of musical style",
  author   = "Collins, Tom and Laney, Robin and Willis, Alistair and
              Garthwaite, Paul H",
  journal  = "Artificial intelligence for engineering design, analysis and
              manufacturing: AI EDAM",
  volume   =  30,
  number   =  1,
  pages    = "16--43",
  year     =  2016,
  keywords = "computational model; musical creativity; stylistic composition",
  issn     = "0890-0604",
  doi      = "10.1017/S0890060414000687"
}

@INPROCEEDINGS{Pearce2005-ly,
  title     = "Methods for combining statistical models of music",
  booktitle = "Proceedings of the Second International Conference on Computer
               Music Modeling and Retrieval",
  author    = "Pearce, Marcus T and Conklin, Darrell and Wiggins, G A",
  abstract  = "The paper concerns the use of multiple viewpoint representation
               schemes for prediction with statistical models of monophonic
               music. We present an experimental comparison of the performance
               of two techniques for combining predictions within the multiple
               viewpoint framework. The results demonstrate that a new
               technique based on a weighted geometric mean outperforms
               existing techniques. This finding is discussed in terms of
               previous research in machine learning.",
  publisher = "Springer",
  pages     = "295--312",
  year      =  2005,
  address   = "Berlin, Germany",
  issn      = "0302-9743"
}

@ARTICLE{Conklin1995-qt,
  title    = "Multiple viewpoint systems for music prediction",
  author   = "Conklin, Darrell and Witten, Ian H",
  abstract = "This paper examines the prediction and generation of music using
              a multiple view-point system, a collection of independent views
              of the musical surface each of which models a specific type of
              musical phenomena. Both the general style and a particular piece
              are modeled using dual short-term and long-term theories, and the
              model is created using machine learning techniques on a corpus of
              musical examples. The models are used for analysis and
              prediction, and we conjecture that highly predictive theories
              will also generate original, acceptable, works. Although the
              quality of the works generated is hard to quantify objectively,
              the predictive power of models can be measured by the notion of
              entropy, or unpredictability. Highly predictive theories will
              produce low-entropy estimates of a musical language. The methods
              developed are applied to the Bach chorale melodies.
              Multiple-viewpoint systems are learned from a sample of 95
              chorales, estimates of entropy are produced, and a predictive
              theory is used to generate new, unseen pieces.",
  journal  = "Journal of New Music Research",
  volume   =  24,
  number   =  1,
  pages    = "51--73",
  year     =  1995,
  issn     = "0929-8215",
  doi      = "10.1080/09298219508570672"
}

@ARTICLE{Witten1994-lb,
  title    = "Comparing Human and Computational Models of Music Prediction",
  author   = "Witten, Ian H and Manzara, Leonard C and Conklin, Darrell",
  journal  = "Computer Music Journal",
  volume   =  18,
  number   =  1,
  pages    = "70--80",
  year     =  1994,
  keywords = "music prediction"
}

@INPROCEEDINGS{Herremans2014-qk,
  title     = "Sampling the extrema from statistical models of music with
               variable neighbourhood search",
  booktitle = "Proceedings {ICMC|SMC|2014}",
  author    = "Herremans, Dorien and Sorensen, Kenneth and Conklin, Darrell",
  pages     = "1096--1103",
  year      =  2014,
  keywords  = "sampling;statistical modelling of music",
  isbn      = "9789604661374"
}

@ARTICLE{Gordon1961-rz,
  title   = "A study to determine the effects of training and practice on Drake
             Musical Aptitude Test scores",
  author  = "Gordon, Edwin E",
  journal = "Journal of research in music education",
  volume  =  9,
  number  =  1,
  pages   = "63--74",
  year    =  1961
}

@ARTICLE{Potter2007-yg,
  title    = "Towards greater objectivity in music theory: Information-dynamic
              analysis of minimalist Music",
  author   = "Potter, Keith S and Wiggins, G A and Pearce, Marcus T",
  abstract = "We present evidence for a relationship between two objective
              measures of the information dynamics of music and points of
              structural importance in the music as analysed by an expert
              musicologist. Our approach is motivated by ecological validity:
              rather than taking musical stimuli and artificially simplifying
              them to make their study tractable, we have sought and found
              music which is appropriate to our study. We give a novel,
              detailed analysis of one piece, Glass' Gradus, and show how the
              analysis corresponds with the information dynamics of the piece
              as heard. To show that this correspondence generalises, at least
              to music in a similar style by the same composer, we go on to
              analyse Glass' Two Pages. We suggest that this research provides
              further evidence that information-dynamic modelling is a
              worthwhile approach to the study of music cognition and also has
              the potential, if automated, to be a powerful tool to increase
              objectivity in data-based music analysis.",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  volume   =  11,
  number   =  2,
  pages    = "295--324",
  year     =  2007,
  issn     = "1029-8649",
  doi      = "10.1177/102986490701100207"
}

@BOOK{Bentley1966-wl,
  title     = "Measures of musical abilities",
  author    = "Bentley, A",
  publisher = "George A. Harrap",
  year      =  1966,
  address   = "London, England",
  keywords  = "musical aptitude;musical ability"
}

@ARTICLE{Rohrmeier2012-qo,
  title     = "Predictive information processing in music cognition. A critical
               review",
  author    = "Rohrmeier, Martin A and Koelsch, Stefan",
  abstract  = "Expectation and prediction constitute central mechanisms in the
               perception and cognition of music, which have been explored in
               theoretical and empirical accounts. We review the scope and
               limits of theoretical accounts of musical prediction with
               respect to feature-based and temporal prediction. While the
               concept of prediction is unproblematic for basic single-stream
               features such as melody, it is not straight-forward for
               polyphonic structures or higher-order features such as formal
               predictions. Behavioural results based on explicit and implicit
               (priming) paradigms provide evidence of priming in various
               domains that may reflect predictive behaviour. Computational
               learning models, including symbolic (fragment-based),
               probabilistic/graphical, or connectionist approaches, provide
               well-specified predictive models of specific features and
               feature combinations. While models match some experimental
               results, full-fledged music prediction cannot yet be modelled.
               Neuroscientific results regarding the early right-anterior
               negativity (ERAN) and mismatch negativity (MMN) reflect
               expectancy violations on different levels of processing
               complexity, and provide some neural evidence for different
               predictive mechanisms. At present, the combinations of neural
               and computational modelling methodologies are at early stages
               and require further research. \copyright{} 2012 Elsevier B.V.",
  journal   = "International journal of psychophysiology: official journal of
               the International Organization of Psychophysiology",
  publisher = "Elsevier B.V.",
  volume    =  83,
  number    =  2,
  pages     = "164--175",
  year      =  2012,
  keywords  = "Computational modelling; ERAN; Expectancy; Expectation; MMN;
               Music cognition; N-gram model; Neuroimaging; Prediction;
               Probabilistic model; Simple recurrent network",
  issn      = "0167-8760",
  pmid      = "22245599",
  doi       = "10.1016/j.ijpsycho.2011.12.010"
}

@INPROCEEDINGS{Rohrmeier2008-jo,
  title     = "Statistical properties of tonal harmony in Bach's chorales",
  booktitle = "Proceedings of the 10th International Conference on Music
               Perception and Cognition",
  author    = "Rohrmeier, Martin A and Cross, Ian",
  abstract  = "This study aims to contribute empirical computational results to
               the understanding of tonality and harmonic structure. It
               analyses aspects of tonal harmony and harmonic patterns based on
               a statistical, computational corpus analysis of Bach's chorales.
               This is carried out using a novel heuristic method of
               segmentation developed specifically for that purpose. Analyses
               of distributions of single pc sets, chord classes and pc set
               transitions reveal very different structural patterns in both
               modes, many, but not all of which accord with standard music
               theory. In addition, most frequent chord transitions are found
               to exhibit a large degree of asymmetry, or, directedness, in way
               that for two pc sets A,B the transition frequencies
               f(A$\rightarrow$B) and f(B$\rightarrow$A) may differ to a large
               extent. Distributions of unigrams and bigrams are found to
               follow a Zipf distribution, i.e. decay in frequency roughly
               according to 1/x2 which implies that the majority of the musical
               structure is governed by a few frequent elements. The findings
               provide evidence for an underlying harmonic syntax which results
               in distinct statistical patterns. A subsequent respective
               antecedent and consequent hierarchical cluster analysis of pc
               sets based on patterns finds that this information suffices to
               group chords into meaningful functional groups solely on
               intrinsic statistical grounds without regard to pitch content.",
  pages     = "619--627",
  year      =  2008,
  address   = "Sapporo, Japan"
}

@INPROCEEDINGS{Rohrmeier2007-ki,
  title     = "A generative grammar approach to diatonic harmonic structure",
  booktitle = "Proceedings of the 4th Sound and Music Computing Conference
               ({SMC} 07)",
  author    = "Rohrmeier, Martin A",
  abstract  = "This paper aims to give a hierarchical, genera- tive account of
               diatonic harmony progressions and proposes a generative
               phrase-structure grammar. The formalism ac- counts for
               structural properties of key, functional, scale and surface
               level. Being related to linguistic approaches in generative
               syntax and to the hierarchical account of tonality in the
               generative theory of tonal music (GTTM) [1], cadence-based
               harmony contexts and its elaborations are formalised. This
               approach covers cases of modulation, tonicisation and some
               aspects of large-scale harmonic form, and may be applied to
               large sets of diatonic compositions. Potential applications may
               rise in computational harmonic and corpus analysis, as well as
               in the music psychological investigation of tonal cognition.",
  year      =  2007
}

@ARTICLE{Rohrmeier2011-nl,
  title     = "Incidental and online learning of melodic structure",
  author    = "Rohrmeier, Martin A and Rebuschat, Patrick and Cross, Ian",
  abstract  = "The cognition of music, like that of language, is partly rooted
               in enculturative processes of implicit and incidental learning.
               Musicians and nonmusicians alike are commonly found to possess
               detailed implicit knowledge of musical structure which is
               acquired incidentally through interaction with large samples of
               music. This paper reports an experiment combining the
               methodology of artificial grammar learning with musical
               acquisition of melodic structure. Participants acquired
               knowledge of grammatical melodic structures under incidental
               learning conditions in both experimental and untrained control
               conditions. Subsequent analysis indicates a large effect of
               unsupervised online learning in the experimental and control
               group throughout the course of the testing phase suggesting an
               effective ongoing learning process. Musicians did not outperform
               nonmusicians, indicating that musical expertise is not
               advantageous for the learning of a new, unfamiliar melodic
               system. Confidence ratings suggest that participants became
               aware of the knowledge guiding their classification performance
               despite the incidental learning conditions. ?? 2010 Elsevier
               Inc.",
  journal   = "Consciousness and cognition",
  publisher = "Elsevier Inc.",
  volume    =  20,
  number    =  2,
  pages     = "214--222",
  year      =  2011,
  keywords  = "Artificial grammar learning; Implicit learning; Incidental
               learning; Melody; Music perception; Online-learning effect;
               Unsupervised learning",
  issn      = "1053-8100",
  pmid      = "20832338",
  doi       = "10.1016/j.concog.2010.07.004"
}

@INPROCEEDINGS{Rohrmeier2009-ax,
  title     = "Tacit tonality: Implicit learning of context-free harmonic
               structure",
  booktitle = "Proceedings of the 7th Triennial Conference of the European
               Society for the Cognitive Sciences of Music ({ESCOM} 2009)",
  author    = "Rohrmeier, Martin A and Cross, Ian",
  abstract  = "Musical knowledge, like native language knowledge, is largely
               implicit, being represented without awareness of its complex
               structures and incidentally acquired through interaction with a
               large number of samples. Two experiments explore implicit
               learning of hierarchical harmonic structures of different
               complexity employing an artificial grammar learning paradigm.
               The experiments consisted of an incidental learning phase using
               a distraction task, and a testing phase employing the process
               dissociation procedure paradigm (Jacoby, 1991). Participants
               performed significantly above chance and recognised adjacent and
               long-distance dependencies in both experiments. Confidence
               ratings and inclusion/exclusion response patterns suggest that
               both implicit structure knowledge and explicit judgment
               knowledge are in operation. Participants recognised stimuli with
               deep structures that appeared in the learning phase better than
               new structures for the more complex grammar, whereas there was
               no such difference for the simpler grammar. They performed
               significantly better for the less complex grammar which
               indicates that grammatical complexity affects learnability and
               recognition performance. The results conform to other
               experimental findings that musicians and nonmusicians are able
               to perceive long-distance dependencies and embedded structures
               in tonal harmony.",
  pages     = "443--452",
  year      =  2009,
  address   = "Jyv{\"a}skyl{\"a}, Finland"
}

@ARTICLE{Rohrmeier2012-fe,
  title    = "Implicit learning of recursive context-free grammars",
  author   = "Rohrmeier, Martin A and Fu, Qiufang and Dienes, Zoltan",
  abstract = "Context-free grammars are fundamental for the description of
              linguistic syntax. However, most artificial grammar learning
              experiments have explored learning of simpler finite-state
              grammars, while studies exploring context-free grammars have not
              assessed awareness and implicitness. This paper explores the
              implicit learning of context-free grammars employing features of
              hierarchical organization, recursive embedding and long-distance
              dependencies. The grammars also featured the distinction between
              left- and right-branching structures, as well as between centre-
              and tail-embedding, both distinctions found in natural languages.
              People acquired unconscious knowledge of relations between
              grammatical classes even for dependencies over long distances, in
              ways that went beyond learning simpler relations (e.g. n-grams)
              between individual words. The structural distinctions drawn from
              linguistics also proved important as performance was greater for
              tail-embedding than centre-embedding structures. The results
              suggest the plausibility of implicit learning of complex
              context-free structures, which model some features of natural
              languages. They support the relevance of artificial grammar
              learning for probing mechanisms of language learning and
              challenge existing theories and computational models of implicit
              learning.",
  journal  = "PloS one",
  volume   =  7,
  number   =  10,
  year     =  2012,
  issn     = "1932-6203",
  pmid     = "23094021",
  doi      = "10.1371/journal.pone.0045885"
}

@ARTICLE{Rohrmeier2013-wo,
  title    = "Artificial grammar learning of melody is constrained by melodic
              inconsistency: Narmour's principles affect melodic learning",
  author   = "Rohrmeier, Martin A and Cross, Ian",
  abstract = "Considerable evidence suggests that people acquire artificial
              grammars incidentally and implicitly, an indispensable capacity
              for the acquisition of music or language. However, less research
              has been devoted to exploring constraints affecting incidental
              learning. Within the domain of music, the extent to which
              Narmour's (1990) melodic principles affect implicit learning of
              melodic structure was experimentally explored. Extending previous
              research (Rohrmeier, Rebuschat \& Cross, 2011), the identical
              finite-state grammar is employed having terminals (the alphabet)
              manipulated so that melodies generated systematically violated
              Narmour's principles. Results indicate that Narmour-inconsistent
              melodic materials impede implicit learning. This further
              constitutes a case in which artificial grammar learning is
              affected by prior knowledge or processing constraints.",
  journal  = "PloS one",
  volume   =  8,
  number   =  7,
  year     =  2013,
  issn     = "1932-6203",
  pmid     = "23874388",
  doi      = "10.1371/journal.pone.0066174"
}

@INCOLLECTION{Rohrmeier2014-lf,
  title     = "Implicit learning and recursion",
  booktitle = "Language and Recursion",
  author    = "Rohrmeier, Martin A and Dienes, Z and Guo, X and Fu, Q",
  editor    = "Lowenthal, Francis and Lefebvre, Laurent",
  abstract  = "Implicit learning research has focused on learning simple
               structures, such as chunks, even though such structures do not
               capture the richness of real-world human accomplishments. In
               particular, music and language exhibit certain recursive
               features that cannot be captured by regular grammars, let alone
               mechanisms that learn only chunks. We show in the domains of
               music, language, poetry and movement that people can implicitly
               learn recursive grammars in ways that go beyond learning chunks
               or mere repetition patterns. This is supported by the fact that
               participants are found to generalise from training materials to
               novel sequences following the underlying rules. In this context
               we further propose a parsimony argument that states that
               although performance on new test items can always be explained
               by a catch-all finite-state or chunking mechanism, such
               explanations can be more complex than postulating learning a
               supra-finite-state mechanism in that they may postulate
               considerably more rules or states than necessary to explain
               learning. This is especially true when the finite-state rather
               than supra-finite-state mechanism, in order to perform on the
               test material, needs to acquire states or chunks not required
               for learning the training material. We highlight both the
               strength and weakness of our current evidence in this regard.",
  pages     = "1--24",
  year      =  2014,
  doi       = "10.1007/978-1-4614-9414-0\_6"
}

@ARTICLE{Rohrmeier2008-vk,
  title    = "Learning on the fly: Computational modelling of an unsupervised
              online-learning effect",
  author   = "Rohrmeier, Martin A",
  journal  = "Learning",
  number   = "April 2011",
  pages    = "2019--2019",
  year     =  2008,
  keywords = "artificial grammar learning; computational modelling; model;
              n-gram; neural network; online learning; unsupervised learning",
  doi      = "10.1080/01619560802222327"
}

@ARTICLE{Whorley2010-qr,
  title    = "Development of techniques for the computational modelling of
              harmony",
  author   = "Whorley, R and Wiggins, G A and Rhodes, C and Pearce, Marcus T",
  abstract = "This research is concerned with the development of
              repre-sentational and modelling techniques employed in the
              construction of statistical models of four-part harmony. Multiple
              viewpoint systems have been chosen to represent both surface and
              underlying musical structure, and it is this framework, along
              with Prediction by Partial Match (PPM), which will be developed
              during this work. Two versions of the framework are described,
              starting with the strictest possible application of multiple
              viewpoints and PPM, and then extending and generalising a little.
              Some implementation details are reported, as are some preliminary
              results.",
  journal  = "First International Conference on Computational Creativity",
  pages    = "11--15",
  year     =  2010
}

@ARTICLE{Conklin2001-fb,
  title    = "Representation and discovery of multiple viewpoint patterns",
  author   = "Conklin, Darrell and Anagnostopoulou, Christina",
  abstract = "An important problem in computational music analysis is the
              representation and automated discovery of recurrent patterns. In
              this paper we present a new method for pattern representation and
              discovery in a large corpus of music. Using the formalism of
              multiple viewpoints, music is viewed as multiple streams of
              description derived from the basic surface representation.
              Patterns are discovered within viewpoint sequences derived from
              the corpus for selected viewpoints. A statistical method is used
              to restrict attention to only those patterns which occur much
              more frequently than expected, where expectation is based on a
              Markov model of viewpoint elements. The concept of the longest
              significant patterns in a corpus is introduced. The method
              presented in this paper is designed to rapidly enumerate all
              longest significant patterns within a large corpus. An
              application of the method to the Bach chorales is presented.",
  journal  = "International Computer Music Conference",
  pages    = "479--485",
  year     =  2001
}

@ARTICLE{Conklin2003-cs,
  title    = "Music generation from statistical models",
  author   = "Conklin, Darrell",
  abstract = "This paper discusses the use of statisticalmodels for the
              problemofmusical style imitation. Statisticalmodels are created
              from extant pieces in a stylistic corpus, and have an objective
              goal which is to accurately classify new pieces. The process of
              music generation is equated with the problem of sampling from a
              statistical model. In principle there is no need to make the
              classical distinction between analytic and synthetic models of
              music. This paper presents several methods for sampling from an
              analytic statistical model, and proposes a new approach that
              maintains the intra opus pattern repetition within an extant
              piece. A major component of creativity is the adaptation of
              extant art works, and this is also an efficient way to sample
              pieces from complex statistical models.",
  journal  = "Proceedings of the AISB 2003 Symposium on Artificial Intelligence
              and Creativity in the Arts and Sciences",
  pages    = "30--35",
  year     =  2003
}

@ARTICLE{Rohrmeier2011-hr,
  title    = "Towards a generative syntax of tonal harmony",
  author   = "Rohrmeier, Martin A",
  abstract = "This paper aims to propose a hierarchical, generative account of
              diatonic harmonic progressions and suggest a set of
              phrase-structure grammar rules. It argues that the structure of
              harmonic progressions exceeds the simplicity of the Markovian
              transition tables and proposes a set of rules to account for
              harmonic progressions with respect to key structure, functional
              and scale degree features as well as modulations. Harmonic
              structure is argued to be at least one subsystem in whichWestern
              tonal music exhibits recursion and hierarchical organization that
              may provide a link to overarching linguistic generative grammar
              on a structural and potentially cognitive level.",
  journal  = "Journal of Mathematics \& Music. Mathematical and Computational
              Approaches to Music Theory, Analysis, Composition and Performance",
  volume   =  5,
  number   =  1,
  pages    = "35--53",
  year     =  2011,
  keywords = "1; 3; ams classification; ccs; context-free grammar; cr category
              numbers; f1; f4; generative grammar; harmony; language; mcs;
              music and; music cognition; music syntax; music theory;
              recursion; tonal music",
  issn     = "1745-9737",
  doi      = "10.1080/17459737.2011.573676"
}

@ARTICLE{Abdallah2009-pp,
  title    = "Information Dynamics: Patterns of expectation and surprise in the
              perception of music",
  author   = "Abdallah, Samer and Plumbley, Mark",
  journal  = "Connection science",
  volume   =  21,
  number   = "2-3",
  pages    = "89--117",
  year     =  2009,
  keywords = "environments; fonts; numbering (Authors:; references citation;
              source file coding; submission
              instructions;expectation;information dynamics",
  issn     = "0954-0091",
  doi      = "10.1080/09540090xxxxxxxxxxxx"
}

@ARTICLE{Conklin2013-ua,
  title   = "Multiple viewpoint systems for music classification",
  author  = "Conklin, Darrell",
  journal = "Journal of New Music Research",
  volume  =  42,
  number  =  1,
  pages   = "19--26",
  year    =  2013,
  issn    = "0929-8215",
  doi     = "10.1080/09298215.2013.776611"
}

@BOOK{Gordon1965-oe,
  title     = "Musical aptitude profile",
  author    = "Gordon, Edwin E",
  publisher = "Houghton Mifflin",
  year      =  1965,
  address   = "Boston, MA",
  keywords  = "musical aptitude"
}

@ARTICLE{Gordon1986-bz,
  title    = "Final Results of a {Two-Year} Longitudinal Predictive Validity
              Study of the Instrument Timbre Preference Test and the Musical
              Aptitude Profile",
  author   = "Gordon, Edwin E",
  journal  = "Bulletin of the Council for Research in Music Education",
  volume   =  89,
  pages    = "8--17",
  year     =  1986,
  keywords = "Gordon;MAP;longitudinal;musical aptitude;predictive validity"
}

@BOOK{Seashore1960-cw,
  title     = "Seashore measures of musical talents",
  author    = "Seashore, C E and Lewis, L and Saetveit, J G",
  publisher = "The Psychological Corporation",
  year      =  1960,
  address   = "New York, NY",
  keywords  = "musical aptitude"
}

@ARTICLE{Brown1928-uf,
  title    = "The reliability and validity of the Seashore Tests of Musical
              Talent",
  author   = "Brown, A W",
  abstract = "An introductory section states the claims made for the tests by
              their author and the results of the two studies heretofore made
              upon them. In the present study the six tests were given twice,
              four months apart, to about 108 junior and senior high school
              students. The reliability coefficients were 0.71 for pitch, 0.65
              for intensity, 0.48 for time, 0.43 for consonance, 0.59 for
              memory, and 0.29 for rhythm, with probable errors from 0.03 to
              0.06. Musical instructors ranked the subjects on innate musical
              ability (reliability of ranking, 0.94 by re-ranking after four
              months); the average test score correlated o.38 with these ranks,
              memory alone correlating 0.41 and all the rest below 0.18.
              Intercorrelations between age, test score, teachers' ranks and
              intelligence rating (Army Alpha and Otis) ranged from 0.38 to
              -.34; of the 15 intercorrelations among the tests themselves, 3
              were above 0.30. Partialling out age and intelligence from the
              correlation between test score and teachers' ranks lowered it
              from 0.38 to 0.35.",
  journal  = "The Journal of applied psychology",
  volume   =  12,
  number   =  5,
  pages    = "468--476",
  year     =  1928,
  keywords = "Seashore;predictive validity",
  issn     = "0021-9010"
}

@ARTICLE{Gordon1984-yt,
  title   = "A longitudinal predictive validity study of the intermediate
             measures of music audiation",
  author  = "Gordon, Edwin E",
  journal = "Bulletin of the Council for Research in Music Education",
  volume  =  78,
  pages   = "1--23",
  year    =  1984
}

@TECHREPORT{Gordon1965-zq,
  title  = "The Musical Aptitude Profile: A new and unique musical aptitude
            test battery",
  author = "Gordon, Edwin E",
  volume =  6,
  pages  = "12--16",
  year   =  1965
}

@ARTICLE{Colwell1991-jy,
  title    = "Edwin Gordon's contribution: An appraisal",
  author   = "Colwell, Richard and Abrahams, F",
  journal  = "The Quarterly Journal of Music Teaching and Learning",
  volume   =  2,
  number   = "1/2",
  pages    = "19--36",
  year     =  1991,
  keywords = "Gordon;critique"
}

@ARTICLE{Highsmith1929-de,
  title    = "Selecting musical talent",
  author   = "Highsmith, J A",
  abstract = "The investigation was made to determine the prognostic value of
              the Seashore Measures of Musical Talent for students entering a
              school of music. It also attempted to determine the value of
              intelligence tests (Terman Group Test of Mental Ability and
              Thurstone Psychological Examination) in predicting success in
              various courses required of students of the School of Music of
              the North Carolina College for Women. The tests were given to 59
              girls who entered the School of Music in September, 1922. The
              criteria used were marks in music courses and the relative length
              of time students remained in college. It was found that partial
              correlation of applied music marks and Seashore test scores, when
              intelligence is held constant, is .175, whereas the correlation
              between applied music marks and intelligence test scores is .423.
              The conclusions reached in this investigation are: (1) the
              validity of the Seashore tests when measured by success in music
              as expressed in school marks is very low (r = .312); (2) scores
              on the Seashore tests, taken singly or as a whole, show
              practically no relationship to students' abilities in musical
              performance; (3) intelligence tests gave a better prediction (r =
              .423) of success in music than did the Seashore tests.",
  journal  = "The Journal of applied psychology",
  volume   =  13,
  number   =  5,
  pages    = "486--493",
  year     =  1929,
  keywords = "Seashore;musical ability;predictive validity",
  issn     = "0021-9010"
}

@MISC{Gordon1969-vm,
  title        = "Intercorrelations among Musical Aptitude Profile and Seashore
                  Measures of Musical Talents Subtests",
  booktitle    = "Journal of Research in Music Education",
  author       = "Gordon, Edwin E",
  year         =  1969,
  howpublished = "\url{http://www.jstor.org/stable/3343874?loginSuccess=true&seq=1#page_scan_tab_contents}",
  keywords     = "Gordon's MAP;Seashore;musical aptitude"
}

@TECHREPORT{Karma1983-xq,
  title    = "Selecting Students to Music Instruction",
  author   = "Karma, Kai",
  volume   =  75,
  pages    = "23--32",
  year     =  1983,
  keywords = "atomistic;holistic;musical aptitude;selection for training"
}

@ARTICLE{Tarrell1965-km,
  title    = "An Investigation of the Validity of the ``Musical Aptitude
              Profile''",
  author   = "Tarrell, Vernon V",
  journal  = "Journal of Research in Music Education",
  volume   =  13,
  number   =  4,
  pages    = "195--206",
  year     =  1965,
  keywords = "Gordon's MAP;validity"
}

@ARTICLE{Carson1994-on,
  title    = "1000 Years Before Parsons: Vocational Psychology in Classical
              Islam",
  author   = "Carson, Andrew D and Altai, Nazar M",
  journal  = "The Career development quarterly",
  volume   =  43,
  number   =  2,
  pages    = "197--206",
  month    =  dec,
  year     =  1994,
  keywords = "history of musical ability",
  issn     = "0889-4019",
  doi      = "10.1002/j.2161-0045.1994.tb00858.x"
}

@ARTICLE{Gordon1979-eu,
  title   = "Developmental music aptitude as measured by the Primary Measures
             of Music Audiation",
  author  = "Gordon, Edwin E",
  journal = "Psychology of Music",
  volume  =  7,
  number  =  1,
  pages   = "42--49",
  year    =  1979
}

@ARTICLE{Gordon1986-gl,
  title    = "A Factor analysis of the Musical Aptitude Profile, the Primary
              Measures of Music Audiation, and the Intermediate Measures of
              Music Audiation",
  author   = "Gordon, Edwin E",
  journal  = "Bulletin of the Council for Research in Music Education",
  volume   = "Spring",
  number   =  87,
  pages    = "17--25",
  year     =  1986,
  keywords = "Seashore review",
  issn     = "0010-9894"
}

@ARTICLE{Carson1995-ib,
  title  = "Fallen Flat ? And What Can We Do About It ?",
  author = "Carson, Andrew D",
  pages  = "311--327",
  year   =  1995
}

@ARTICLE{Davies1971-un,
  title    = "New tests of musical aptitude",
  author   = "Davies, J B",
  journal  = "British journal of psychology",
  volume   =  62,
  number   =  4,
  pages    = "557--565",
  year     =  1971,
  keywords = "Seashore;avoiding cultural bias;cultural bias;musical
              aptitude;non-musical material",
  issn     = "0007-1269"
}

@ARTICLE{Carson1998-dm,
  title    = "Why has musical aptitude assessment fallen flat? And what can we
              do about it?",
  author   = "Carson, A D",
  abstract = "Tests of musical aptitudes are reviewed. Despite decades of
              research and at least modest evidence for the validity of such
              tests (particularly regarding their ability to assess a
              mechanical-acoustic factor), the objective assessment of musical
              aptitudes is not part of the standard career assessment battery.
              Reasons for this situation are suggested. A renewed effort to
              develop musical aptitude tests is recommended, particularly along
              the lines already established through the research programs of
              Karma (1994), Dowling and Harwood (1986), and Vispoel (1992).",
  journal  = "Journal of Career Assessment",
  volume   =  6,
  number   =  3,
  pages    = "311--327",
  month    =  jun,
  year     =  1998,
  issn     = "1069-0727",
  doi      = "10.1177/106907279800600303"
}

@ARTICLE{Van_Deventer2009-re,
  title   = "David Temperley: Music and Probability, Cambridge, {MA}, {MIT}
             Press (2007)",
  author  = "van Deventer, P",
  journal = "Musicae scientiae: the journal of the European Society for the
             Cognitive Sciences of Music",
  volume  =  13,
  number  =  2,
  pages   = "471--473",
  year    =  2009,
  issn    = "1029-8649",
  doi     = "10.1177/102986490901300214"
}

@ARTICLE{Pearce2006-iq,
  title    = "Expectation in melody: The influence of context and learning",
  author   = "Pearce, Marcus T and Wiggins, G A",
  abstract = "THE IMPLICATION-REALIZATION (IR) theory (Narmour, 1990) posits
              two cognitive systems involved in the generation of melodic
              expectations: The first consists of a limited number of symbolic
              rules that are held to be innate and universal; the second
              reflects the top-down influences of acquired stylistic knowledge.
              Aspects of both systems have been implemented as quantitative
              models in research which has yielded empirical support for both
              components of the theory (Cuddy \& Lunny, 1995; Krumhansl, 1995a,
              1995b; Schellenberg, 1996, 1997). However, there is also evidence
              that the imple- mented bottom-up rules constitute too inflexible
              a model to account for the influence of the musical experience of
              the listener and the melodic context in which expectations are
              elicited. A theory is presented, according to which both
              bottom-up and top-down descriptions of observed patterns of
              melodic expectation may be accounted for in terms of the
              induction of statistical regularities in existing musical
              repertoires. A computational model that embodies this theory is
              developed and used to rean- alyze existing experimental data on
              melodic expectancy. The results of three experiments with
              increasingly com- plex melodic stimuli demonstrate that this
              model is capa- ble of accounting for listeners' expectations as
              well as or better than the two-factor model of Schellenberg
              (1997).",
  journal  = "Music perception",
  volume   =  23,
  number   =  5,
  pages    = "377--405",
  year     =  2006,
  issn     = "0730-7829",
  doi      = "10.1525/mp.2006.23.5.377"
}

@ARTICLE{Pearce2012-xe,
  title    = "Music cognition and the cognitive sciences",
  author   = "Pearce, Marcus T and Rohrmeier, Martin A",
  abstract = "Why should music be of interest to cognitive scientists, and what
              role does it play in human cognition? We review three factors
              that make music an important topic for cognitive scientific
              research. First, music is a universal human trait fulfilling
              crucial roles in everyday life. Second, music has an important
              part to play in ontogenetic development and human evolution.
              Third, appreciating and producing music simultaneously engage
              many complex perceptual, cognitive, and emotional processes,
              rendering music an ideal object for studying the mind. We propose
              an integrated status for music cognition in the Cognitive
              Sciences and conclude by reviewing challenges and big questions
              in the field and the way in which these reflect recent
              developments.",
  journal  = "Topics in cognitive science",
  volume   =  4,
  number   =  4,
  pages    = "468--484",
  year     =  2012,
  keywords = "Cognitive science; Development; Evolution; Music; Music
              cognition; Perception",
  issn     = "1756-8757",
  pmid     = "23060125",
  doi      = "10.1111/j.1756-8765.2012.01226.x"
}

@ARTICLE{Wiggins2009-rj,
  title    = "Computational modelling of music cognition and musical creativity",
  author   = "Wiggins, G A and Pearce, Marcus T and M{\"u}llensiefen, Daniel",
  abstract = "This chapter is about computational modelling of the process of
              musical composition, based on a cognitive model of human
              behaviour. The idea is to try to study not only the requirements
              for a computer system which is capable of musical composition,
              but also to relate it to human behaviour during the same process,
              so that it may, perhaps, work in the same way as a human
              composer, but also so that it may, more likely, help us
              understand how human composers work. Pearce et al. (2002) give a
              fuller discussion of the motivations behind this endeavour. We
              take a purist approach to our modelling: we are aiming,
              ultimately, at a computer system which we can claim to be
              creative. Therefore, we must address in advance the criticism
              that usually arises in these circumstances: ``a computer can't be
              creative because it can only do what it has explicitly been
              programmed to do''. This argument does not hold, because, with
              the advent of machine learning, it is no longer true that a
              computer is limited to what its programmer explicitly tells it,
              especially in an unsupervised learning task like composition (as
              compared with the usually-supervised task of learning, say, the
              piano). Thus, a creative system based on machine learning can, in
              principle, be given credit for creative output, much as Wolfgang
              Amadeus Mozart is deemed the creator of the Magic Flute, and not
              Leopold Mozart,Wolfgang's father, teacher and de facto agent.",
  pages    = "1--25",
  year     =  2009,
  doi      = "10.1093/oxfordhb/9780199792030.013.0019"
}

@ARTICLE{Pearce2004-ws,
  title    = "Improved methods for statistical modelling of monophonic music",
  author   = "Pearce, Marcus T and Wiggins, G A",
  abstract = "N-Gram based models have been used for a variety of musical tasks
              including computer-assisted composition, machine improvisation,
              music information retrieval, stylistic analysis and cognitive
              modelling. We present an application- independent evaluation of
              some recent techniques for improving the performance of a
              subclass of n-gram models on a range of monophonic music data. We
              have applied these techniques incrementally to eight melodic
              datasets using cross entropy computed by 10-fold cross-validation
              on each dataset as our performance metric. The results
              demonstrate that significant and consistent improvements in
              performance are afforded by several of the evaluated techniques.
              We discuss the results in terms of previous research carried out
              in the field of data compression and with natural language and
              music corpora and conclude by presenting some impor- tant
              directions for future research. 1",
  journal  = "Journal of New Music Research",
  volume   =  33,
  number   =  4,
  pages    = "367--385",
  year     =  2004,
  issn     = "0929-8215",
  doi      = "10.1080/0929821052000343840"
}

@ARTICLE{Pearce2007-ac,
  title    = "Evaluating cognitive models of musical composition",
  author   = "Pearce, Marcus T and Wiggins, G A",
  abstract = "We present a method for the evaluation of creative systems. We
              deploy a learning-based percceptual model of musical melodic
              listening in the generation of tonal melodies and evaluate its
              output quantitatively and objectively, using human judges. Then
              we show how the system can be enhanced by the application of
              mathematical methods over data supplied by the judges. The
              outcome to some extent addresses the criticisms of the experts.
              We suggest that this is a first step on the road to autonomously
              learning, introspective, creative systems.",
  journal  = "Proceedings of the 4th international joint workshop on
              computational creativity",
  pages    = "73--80",
  year     =  2007
}

@ARTICLE{Pearce2012-xw,
  title    = "Auditory expectation: The information dynamics of music
              perception and cognition",
  author   = "Pearce, Marcus T and Wiggins, G A",
  abstract = "Following in a psychological and musicological tradition
              beginning with Leonard Meyer, and continuing through David Huron,
              we present a functional, cognitive account of the phenomenon of
              expectation in music, grounded in computational, probabilistic
              modeling. We summarize a range of evidence for this approach,
              from psychology, neuroscience, musicology, linguistics, and
              creativity studies, and argue that simulating expectation is an
              important part of understanding a broad range of human faculties,
              in music and beyond.",
  journal  = "Topics in cognitive science",
  volume   =  4,
  number   =  4,
  pages    = "625--652",
  year     =  2012,
  keywords = "Aesthetics; Creativity; Expectation; Musical melody; Pitch;
              Prediction; Probabilistic modeling; Segmentation",
  issn     = "1756-8757",
  pmid     = "22847872",
  doi      = "10.1111/j.1756-8765.2012.01214.x"
}

@ARTICLE{Pearce2002-yt,
  title    = "Aspects of a Cognitive Theory of Creativity in Musical
              Composition",
  author   = "Pearce, Marcus T and Wiggins, G A",
  abstract = "While music perception is frequently studied in psychological or
              cognitive scientific research, composition is given far less
              attention and, in either case, musical creativity is rarely
              discussed. In this paper we attempt to address this imbalance.
              Our overall goal is to arrive at a clearer understanding of the
              psychological mechanisms which support creativity in musical
              composition. We adopt a cognitive scientific approach to
              attaining this goal and accordingly our theory is derived from
              psychological studies of human composers at work. Our
              investigation is pitched at the computational (rather than the
              algorithmic or implementational) level(s) of description. Five
              tentative hypotheses are presented which form the basis of a
              cognitive theory of creativity in musical composition. Each of
              these hypotheses makes a specific claim about the functional
              characteristics of the cognitive processes which support
              creativity in musical composition. They are motivated by previous
              research in a number of areas (in particular the psychological,
              musicological and computational literature) which we discuss in
              detail. Following the cognitive scientific approach, we are
              engaged in the implementation of the theory as a computational
              model and the development of a framework for the objective
              evaluation of the behaviour of the implemented model. We describe
              how this framework may be used to refute or corroborate the
              hypotheses.",
  journal  = "ECAI'02 Workshop on Creative Systems",
  pages    = "17--24",
  year     =  2002
}

@PHDTHESIS{Pearce2005-bm,
  title    = "The construction and evaluation of statistical models of melodic
              structure in music perception and composition",
  author   = "Pearce, Marcus T",
  abstract = "The prevalent approach to developing cognitive models of music
              perception and composition is to construct systems of symbolic
              rules and constraints on the basis of extensive music-theoretic
              and music-analytic knowledge. The the- sis proposed in this
              dissertation is that statistical models which acquire knowl- edge
              through the induction of regularities in corpora of existing
              music can, if examined with appropriate methodologies, provide
              significant insights into the cognitive processing involved in
              music perception and composition. This claim is examined in three
              stages. First, a number of statistical modelling techniques drawn
              from the fields of data compression, statistical language
              modelling and machine learning are subjected to empirical
              evaluation in the context of se- quential prediction of pitch
              structure in unseen melodies. This investigation results in a
              collection of modelling strategies which together yield
              significant performance improvements over existing methods. In
              the second stage, these statistical systems are used to examine
              observed patterns of expectation col- lected in previous
              psychological research on melody perception. In contrast to
              previous accounts of this data, the results demonstrate that
              these patterns of expectation can be accounted for in terms of
              the induction of statistical regu- larities acquired through
              exposure to music. In the final stage of the present research,
              the statistical systems developed in the first stage are used to
              examine the intrinsic computational demands of the task of
              composing a stylistically suc- cessful melody. The results
              suggest that the systems lack the degree of expres- sive power
              needed to consistently meet the demands of the task. In contrast
              to previous research, however, the methodological framework
              developed for the evaluation of computationalmodels of
              composition enables a detailed empirical examination and
              comparison of suchmodels which facilitates the identification and
              resolution of their weaknesses.",
  year     =  2005,
  address  = "London, UK",
  school   = "City University, London"
}

@ARTICLE{Pearce2010-wg,
  title    = "The role of expectation and probabilistic learning in auditory
              boundary perception: A model comparison",
  author   = "Pearce, Marcus T and M{\"u}llensiefen, Daniel and Wiggins, G A",
  abstract = "Grouping and boundary perception are central to many aspects of
              sensory processing in cognition. We present a comparative study
              of recently published computational models of boundary perception
              in music. In doing so, we make three contributions. First, we
              hypothesise a relationship between expectation and grouping in
              auditory perception, and introduce a novel information-theoretic
              model of perceptual segmentation to test the hypothesis. Although
              we apply the model to musical melody, it is applicable in
              principle to sequential grouping in other areas of cognition.
              Second, we address a methodological consideration in the analysis
              of ambiguous stimuli that produce different percepts between
              individuals. We propose and demonstrate a solution to this
              problem, based on clustering of participants prior to analysis.
              Third, we conduct the first comparative analysis of
              probabilistic-learning and rule-based models of perceptual
              grouping in music. In spite of having only unsupervised exposure
              to music, the model performs comparably to rule-based models
              based on expert musical knowledge, supporting a role for
              probabilistic learning in perceptual segmentation of music.",
  journal  = "Perception",
  volume   =  39,
  number   =  10,
  pages    = "1365--1389",
  year     =  2010,
  issn     = "0301-0066",
  pmid     = "21180358",
  doi      = "10.1068/p6507"
}

@ARTICLE{Pearce2010-yc,
  title    = "Unsupervised statistical learning underpins computational,
              behavioural, and neural manifestations of musical expectation",
  author   = "Pearce, Marcus T and Ruiz, Mar{\'\i}a Herrojo and Kapasi, Selina
              and Wiggins, G A and Bhattacharya, Joydeep",
  abstract = "The ability to anticipate forthcoming events has clear
              evolutionary advantages, and predictive successes or failures
              often entail significant psychological and physiological
              consequences. In music perception, the confirmation and violation
              of expectations are critical to the communication of emotion and
              aesthetic effects of a composition. Neuroscientific research on
              musical expectations has focused on harmony. Although harmony is
              important in Western tonal styles, other musical traditions,
              emphasizing pitch and melody, have been rather neglected. In this
              study, we investigated melodic pitch expectations elicited by
              ecologically valid musical stimuli by drawing together
              computational, behavioural, and electrophysiological evidence.
              Unlike rule-based models, our computational model acquires
              knowledge through unsupervised statistical learning of sequential
              structure in music and uses this knowledge to estimate the
              conditional probability (and information content) of musical
              notes. Unlike previous behavioural paradigms that interrupt a
              stimulus, we devised a new paradigm for studying auditory
              expectation without compromising ecological validity. A strong
              negative correlation was found between the probability of notes
              predicted by our model and the subjectively perceived degree of
              expectedness. Our electrophysiological results showed that
              low-probability notes, as compared to high-probability notes,
              elicited a larger (i) negative ERP component at a late time
              period (400-450 ms), (ii) beta band (14-30 Hz) oscillation over
              the parietal lobe, and (iii) long-range phase synchronization
              between multiple brain regions. Altogether, the study
              demonstrated that statistical learning produces
              information-theoretic descriptions of musical notes that are
              proportional to their perceived expectedness and are associated
              with characteristic patterns of neural activity. \copyright{}
              2009 Elsevier Inc. All rights reserved.",
  journal  = "NeuroImage",
  volume   =  50,
  number   =  1,
  pages    = "302--313",
  year     =  2010,
  issn     = "1053-8119",
  pmid     = "20005297",
  doi      = "10.1016/j.neuroimage.2009.12.019"
}

@ARTICLE{Nadal2011-xp,
  title     = "The Copenhagen Neuroaesthetics conference: Prospects and
               pitfalls for an emerging field",
  author    = "Nadal, Marcos and Pearce, Marcus T",
  abstract  = "Neuroaesthetics is a young field of research concerned primarily
               with the neural basis of cognitive and affective processes
               engaged when an individual takes an aesthetic or artistic
               approach towards a work of art, a non-artistic object or a
               natural phenomenon. In September 2009, the Copenhagen
               Neuroaesthetics Conference brought together leading researchers
               in the field to present and discuss current advances. We
               summarize some of the principal themes of the conference,
               placing neuroaesthetics in a historical context and discussing
               its scope and relation to other disciplines. We also identify
               what we believe to be the key outstanding questions, the main
               pitfalls and challenges faced by the field, and some promising
               avenues for future research. ?? 2011 Elsevier Inc.",
  journal   = "Brain and cognition",
  publisher = "Elsevier Inc.",
  volume    =  76,
  number    =  1,
  pages     = "172--183",
  year      =  2011,
  keywords  = "Aesthetic appreciation; Art; Brain; Dance; Music;
               Neuroaesthetics; Neuroimaging; Painting",
  issn      = "0278-2626",
  pmid      = "21334125",
  doi       = "10.1016/j.bandc.2011.01.009"
}

@ARTICLE{Pearce2002-xl,
  title    = "Motivations and Methodologies for Automation of the Compositional
              Process",
  author   = "Pearce, Marcus T and Meredith, David and Wiggins, G A",
  abstract = "Our aim in this paper is to clarify the range of motivations that
              have inspired the development of computer programs for the
              composition of music. We consider this to be important since
              different methodologies are appropriate for different motivations
              and goals. We argue that a widespread failure to specify the
              motivations and goals involved has lead to a methodological
              malaise in music related research. A brief consideration of some
              of the earliest at- tempts to produce computational systems for
              the composition of music leads us to identify four activities
              involving the development of computer programs which compose
              music each of which is inspired by different practical or
              theoretical motivations. These activities are algorithmic
              composition, the design of compositional tools, the com-
              putational modelling of musical styles and the computational
              modelling of music cognition. We consider these four motivations
              in turn, illustrating the problems that have arisen from failing
              to distinguish between them. We propose a terminology that
              clearly differentiates the activities defined by the four
              motivations and present methodological suggestions for research
              in each domain. While it is clearly important for researchers to
              embrace developments in related disciplines, we argue that
              research in the four domains will continue to stagnate unless the
              motivations and aims of research projects are clearly stated and
              appropriate methodologies are adopted for developing and
              evaluating systems that compose music.",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  volume   =  6,
  number   =  2,
  pages    = "119--147",
  year     =  2002,
  issn     = "1029-8649",
  doi      = "10.1177/102986490200600203"
}

@ARTICLE{Pearce2011-ij,
  title    = "Time-series analysis of music: perceptual and information
              dynamics",
  author   = "Pearce, Marcus T",
  journal  = "Empirical musicology review: EMR",
  volume   =  6,
  number   =  2,
  pages    = "125--130",
  year     =  2011,
  keywords = "emotion; experience; focused on static analyses; g iven that
              music; information dynamics; is fundamentally temporal in; it is
              surprising how; modelling; much research in music; musical works;
              nature; of the experience of; on the; perception; perception and
              cognition has; structure; the dynamics of musical"
}

@INPROCEEDINGS{Pearce2008-nn,
  title     = "A Comparison of Statistical and {Rule-Based} Models of Melodic
               Segmentation",
  booktitle = "{ISMIR}",
  author    = "Pearce, Marcus T and M{\"u}llensiefen, Daniel and Wiggins, G A",
  pages     = "89--94",
  year      =  2008
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Bates2010-xi,
  title        = "lme4: Mixed-effects modeling with {R}",
  author       = "Bates, Douglas",
  abstract     = "lme4: Mixed-eﬀects modeling with R",
  year         =  2010,
  howpublished = "\url{http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf}"
}

@ARTICLE{Baayen2008-tz,
  title    = "Analyzing linguistic data: A practical introduction to statistics
              using {R}",
  author   = "Baayen, R H",
  abstract = "Statistical analysis is a useful skill for linguists and
              psycholinguists, allowing them to understand the quantitative
              structure of their data. This textbook provides a straightforward
              introduction to the statistical analysis of language. Designed
              for linguists with a non-mathematical background, it clearly
              introduces the basic principles and methods of statistical
              analysis, using 'R', the leading computational statistics
              programme. The reader is guided step-by-step through a range of
              real data sets, allowing them to analyse acoustic data, construct
              grammatical trees for a variety of languages, quantify register
              variation in corpus linguistics, and measure experimental data
              using state-of-the-art models. The visualization of data plays a
              key role, both in the initial stages of data exploration and
              later on when the reader is encouraged to criticize various
              models. Containing over 40 exercises with model answers, this
              book will be welcomed by all linguists wishing to learn more
              about working with and presenting quantitative data.",
  journal  = "Processing",
  volume   =  2,
  number   =  3,
  pages    = "353",
  year     =  2008,
  keywords = "R; linguistics; psycholinguistics; statistics",
  issn     = "0896-8659, 1750-8657",
  doi      = "10.1558/sols.v2i3.471"
}

@ARTICLE{Law2012-zd,
  title    = "Assessing musical abilities objectively: Construction and
              validation of the Profile of Music Perception Skills",
  author   = "Law, Lily N C and Zentner, Marcel",
  journal  = "PloS one",
  volume   =  7,
  number   =  12,
  pages    = "1--15",
  year     =  2012,
  keywords = "listening tests; musical ability",
  doi      = "10.1371/journal.pone.0052508"
}

@ARTICLE{Ruddock2005-vk,
  title    = "' {I} am unmusical!': the verdict of self-judgement",
  author   = "Ruddock, E",
  journal  = "International Journal of Music Education",
  volume   =  23,
  number   =  1,
  pages    = "9--22",
  year     =  2005,
  keywords = "giftedness; self-view; talent;musicality;self-judgement",
  issn     = "0255-7614",
  doi      = "10.1177/0255761405050927"
}

@INPROCEEDINGS{Edwards2000-bn,
  title     = "Development of a standard test of musical ability for
               participants in auditory interface testing",
  booktitle = "Proceedings of the 2000 International Conference on Auditory
               Display",
  author    = "Edwards, Alistair D N and Challis, Ben P and Hankinson, John C K
               and Pirie, Fiona L",
  year      =  2000,
  keywords  = "auditory interface; evaluation; musical ability; musician;
               testing;musical ability;test"
}

@ARTICLE{Vaughn2000-uz,
  title    = "Music and Mathematics: Modest Support for the {Oft-Claimed}
              Relationship",
  author   = "Vaughn, Kathryn",
  abstract = "Explores three meta-analyses investigating the relationship
              between music and mathematics on: (1) correlational studies
              (n=20); (2) experimental training studies (n=6) instructing
              students in music performance, then testing them on mathematics
              skills; and (3) experimental studies (n=15) investigating whether
              listening to background music during a mathematics test elevated
              test scores. (CMK)",
  journal  = "Journal of Aesthetic Education",
  volume   =  34,
  number   = "3/4",
  pages    = "149",
  year     =  2000,
  issn     = "0021-8510",
  doi      = "10.2307/3333641"
}

@ARTICLE{Mosing2014-sm,
  title    = "Practice Does Not Make Perfect: No Causal Effect of Music
              Practice on Music Ability",
  author   = "Mosing, M a and Madison, G and Pedersen, N L and Kuja-Halkola, R
              and Ull{\'e}n, Fredrik",
  abstract = "The relative importance of nature and nurture for various forms
              of expertise has been intensely debated. Music proficiency is
              viewed as a general model for expertise, and associations between
              deliberate practice and music proficiency have been interpreted
              as supporting the prevailing idea that long-term deliberate
              practice inevitably results in increased music ability. Here, we
              examined the associations (rs = .18--.36) between music practice
              and music ability (rhythm, melody, and pitch discrimination) in
              10,500 Swedish twins. We found that music practice was
              substantially heritable (40\%--70\%). Associations between music
              practice and music ability were predominantly genetic, and,
              contrary to the causal hypothesis, nonshared environmental
              influences did not contribute. There was no difference in ability
              within monozygotic twin pairs differing in their amount of
              practice, so that when genetic predisposition was controlled for,
              more practice was no longer associated with better music skills.
              These findings suggest that music practice may not causally
              influence music ability and that genetic variation among
              individuals affects both ability and inclination to practice.",
  journal  = "Psychological science",
  year     =  2014,
  keywords = "14; 18; 5; causality; differen-; expertise; heritability;
              intensely debated questions in; music ability; one of the most;
              practice; received 2; revision accepted 6; training;
              twin;innate;musical ability;twins",
  issn     = "0956-7976",
  pmid     = "25079217",
  doi      = "10.1177/0956797614541990"
}

@ARTICLE{Ruthsatz2008-ol,
  title    = "Becoming an expert in the musical domain: It takes more than just
              practice",
  author   = "Ruthsatz, Joanne and Detterman, Douglas and Griscom, William S
              and Cirullo, Britney a",
  abstract = "Previous research has supported the theory that acquisition of
              expertise in any domain is possible for healthy individuals with
              sufficient deliberate practice, but such an extreme environmental
              position brings the existence of innate talent into question. The
              present study investigates the effects of both environmental
              factors and talent on expert performance in both high school and
              conservatory-level musicians. Audition scores and accumulated
              practice time were recorded, and correlated with scores on
              Gordon's Advanced Measures of Music Audiation and Raven's
              Progressive Matrices. Higher-level musicians report significantly
              higher mean levels on innate characteristics such as general
              intelligence and music audiation, in addition to higher levels of
              accumulated practice time. These factors together accounted for
              more of the variance in music performance than practice alone. A
              multi-factor view is thus shown to be the best explanation for
              the acquisition of musical expertise. \copyright{} 2007 Elsevier
              Inc. All rights reserved.",
  journal  = "Intelligence",
  volume   =  36,
  number   =  4,
  pages    = "330--338",
  year     =  2008,
  keywords = "Domain-specific skills; Expert performance; Intelligence; Musical
              domain; Practice;general intelligence;innate;musical
              ability;practice",
  issn     = "0160-2896",
  doi      = "10.1016/j.intell.2007.08.003"
}

@ARTICLE{Ericsson_K2005-gz,
  title    = "Giftedness viewed from the expert-performance perspective",
  author   = "Ericsson, K, Anders and Nandogopal, Kiruthiga and Roring, Roy W",
  abstract = "Traditional conceptions of giftedness assume that only talented
              individuals possess the necessary gifts required to reach the
              highest levels of performance. This article describes an
              alternative view that expert performance results from acquired
              cogni-tive and physiological adaptations due to extended
              deliberate practice. A review of evidence, such as historical
              increases in performance, the requirement of years of daily
              deliberate practice, and structural changes in the mediating
              mechanisms, questions the existence of individual differences
              that impose innate limits on per-formance attainable with
              deliberate practice. The proposed framework describes how the
              processes mediating normal development of ability and everyday
              skill acquisition differ from the extended acquisition of
              reproducibly superior (expert) performance and how perceived
              ``giftedness'' gives children access to superior train-ing
              resources, resulting in developmental advantages.",
  journal  = "Journal for the Education of the Gifted",
  volume   =  28,
  number   = "3/4",
  pages    = "287--311",
  year     =  2005,
  keywords = "deliberate practice;musical ability",
  issn     = "0162-3532"
}

@ARTICLE{Ericsson1993-pi,
  title    = "The role of deliberate practice in the acquisition of expert
              performance",
  author   = "Ericsson, K Anders and Krampe, Ralf T and Tesch-R{\"o}mer,
              Clemens",
  abstract = "The theoretical framework presented in this article explains
              expert performance as the end result of individuals' prolonged
              efforts to improve performance while negotiating motivational and
              external constraints. In most domains of expertise, individuals
              begin in their childhood a regimen of effortful activities
              (deliberate practice) designed to optimize improvement.
              Individual differences, even among elite performers, are closely
              related to assessed amounts of deliberate practice. Many
              characteristics once believed to reflect innate talent are
              actually the result of intense practice extended for a minimum of
              10 yrs. Analysis of expert performance provides unique evidence
              on the potential and limits of extreme environmental adaptation
              and learning.",
  journal  = "Psychological review",
  volume   =  100,
  number   =  3,
  pages    = "363--406",
  year     =  1993,
  keywords = "deliberate practice;musical achievement;musical aptitude",
  issn     = "0033-295X",
  pmid     = "2140",
  arxivid  = "http://doi.apa.org/psycinfo/1993-40718-001",
  doi      = "10.1037/0033-295X.100.3.363"
}

@ARTICLE{Yang2014-am,
  title    = "A Longitudinal Study on Children's Music Training Experience and
              Academic Development",
  author   = "Yang, Hua and Ma, Weiyi and Gong, Diankun and Hu, Jiehui and Yao,
              Dezhong",
  abstract = "This study examined the relation between long-term music training
              and child development based on 250 Chinese elementary school
              students' academic development of first language (L1), second
              language (L2), and mathematics. We found that musician children
              outperformed non-musician children only on musical achievement
              and second language development. Additionally, although music
              training appeared to be correlated with children's final academic
              development of L1, L2, and mathematics, it did not independently
              contribute to the development of L1 or mathematical skills. Our
              findings suggest caution in interpreting the positive findings on
              the non-musical cognitive benefits of music learning.",
  journal  = "Scientific reports",
  volume   =  4,
  pages    = "5854",
  year     =  2014,
  issn     = "2045-2322",
  pmid     = "25068398",
  doi      = "10.1038/srep05854"
}

@MISC{Guerra2009-in,
  title    = "Supporting user-oriented analysis for multi-view domain-specific
              visual languages",
  author   = "Guerra, Esther and de Lara, Juan and Malizia, Alessio and
              D{\'\i}az, Paloma",
  abstract = "The integration of usable and flexible analysis support in
              modelling environments is a key success factor in Model-Driven
              Development. In this paradigm, models are the core asset from
              which code is automatically generated, and thus ensuring model
              correctness is a fundamental quality control activity. For this
              purpose, a common approach is to transform the system models into
              formal semantic domains for verification. However, if the
              analysis results are not shown in a proper way to the end-user
              (e.g. in terms of the original language) they may become useless.
              In this paper we present a novel DSVL called BaVeL that
              facilitates the flexible annotation of verification results
              obtained in semantic domains to different formats, including the
              context of the original language. BaVeL is used in combination
              with a consistency framework, providing support for all steps in
              a verification process: acquisition of additional input data,
              transformation of the system models into semantic domains,
              verification, and flexible annotation of analysis results. The
              approach has been validated analytically by the cognitive
              dimensions framework, and empirically by its implementation and
              application to several DSVLs. Here we present a case study of a
              notation in the area of Digital Libraries, where the analysis is
              performed by transformations into Petri nets and a process
              algebra. \copyright{} 2008 Elsevier B.V. All rights reserved.",
  journal  = "Information and Software Technology",
  volume   =  51,
  number   =  4,
  pages    = "769--784",
  year     =  2009,
  keywords = "Back-annotation; Consistency; Domain-specific visual languages;
              Formal methods; Model transformation; Modelling environments",
  issn     = "0950-5849",
  arxivid  = "cond-mat/0402594v3",
  doi      = "10.1016/j.infsof.2008.09.005"
}

@ARTICLE{Krampe1996-tw,
  title    = "Maintaining excellence: Deliberate practice and elite performance
              in young and older pianists",
  author   = "Krampe, Ralf Th and Ericsson, K Anders",
  abstract = "Two studies investigated the role of deliberate practice in the
              maintenance of cognitive-motor skills in expert and accomplished
              amateur pianists. Older expert and amateur pianists showed the
              normal pattern of large age-related reductions in standard
              measures of general processing speed. Performance on
              music-related tasks showed similar age-graded decline for amateur
              pianists but not for expert pianists, whose average performance
              level was only slightly below that of young expert pianists. The
              degree of maintenance of relevant pianistic skills for older
              expert pianists was predicted by the amount of deliberate
              practice during later adulthood. The role of deliberate practice
              in the active maintenance of superior domain-specific performance
              in spite of general age-related decline is discussed.",
  journal  = "Journal of experimental psychology. General",
  volume   =  125,
  number   =  4,
  pages    = "331--359",
  year     =  1996,
  keywords = "deliberate practice;musical ability",
  issn     = "0096-3445"
}

@ARTICLE{Coon1989-vr,
  title    = "Genetic and environmental determinants of musical ability in
              twins",
  author   = "Coon, Hilary and Carey, Gregory",
  journal  = "Behavior genetics",
  volume   =  19,
  number   =  2,
  pages    = "183--193",
  month    =  mar,
  year     =  1989,
  keywords = "genetics;musical ability;twins",
  issn     = "0001-8244",
  doi      = "10.1007/BF01065903"
}

@ARTICLE{Young1976-nx,
  title    = "A Longitudinal Comparison of Four Music Achievement and Music
              Aptitude Tests",
  author   = "Young, William T",
  abstract = "768 sixth-grade students enrolled in eight separate middle
              schools in the cities of Odessa, Henderson, and Gladewater,
              Texas, were given the Tonal Imagery and Rhythm Imagery tests from
              the Musical Aptitude Profile along with the complete Measures of
              Musical Abilities battery. After a year and a half of
              instrumental study, Music Achievement Test, Part 2 and Iowa Tests
              of Music Literacy, Level One were administered to all students
              remaining in the programs. Results of the study indicated the MAP
              Tonal Imagery was the most efficacious of the aptitude tests,
              while the ITML battery possessed the highest validity for
              measuring music achievement, based on teachers' subjective
              performance ratings. Interrelationships among certain achievement
              subtests were rather high, indicating that in some cases two
              subtests were measuring similar areas of achievement. Using these
              as a guide, it was possible to select a group of subtests from
              both the MAT and ITML batteries that were relatively unrelated
              and at the same time agreed satisfactorily with the teachers'
              professional judgments of their students.",
  journal  = "Journal of Research in Music Education",
  volume   =  24,
  number   =  3,
  pages    = "97",
  month    =  23,
  year     =  1976,
  keywords = "musical aptitude;prediction",
  issn     = "0022-4294",
  doi      = "10.2307/3345153"
}

@ARTICLE{Hufstader1974-tj,
  title    = "Predicting Success in Beginning Instrumental Music through Use of
              Selected Tests",
  author   = "Hufstader, Ronald A",
  abstract = "The purpose of this study was to investigate the possibility of
              using several different variables as predictors of success in
              beginning instrumental music. The variables were: tests of
              musical aptitude, academic achievement, intelligence, and
              psychomotor skills measured by a tapping board, a tachistoscope,
              a visual choice reaction timer, and a rotary pursuit apparatus. A
              discriminant function analysis was used to analyze the data. All
              variables were found to make a unique contribution to the
              prediction of success in beginning instrumental music.",
  journal  = "Journal of Research in Music Education",
  volume   =  22,
  number   =  1,
  pages    = "52",
  month    =  jan,
  year     =  1974,
  keywords = "musical aptitude;prediction",
  issn     = "0022-4294",
  doi      = "10.2307/3344618"
}

@BOOK{Boyle1987-jr,
  title     = "Measurement and Evaluation of Musical Experiences",
  author    = "Boyle, J David and Radocy, Rudolf E",
  abstract  = "Test, measurement, and evaluation data are not viewed as a
               panacea for music education, but there is little question that
               the use of valid and reliable data from such can provide music
               teachers, administrators, counselors, and therapists with both
               broader and stronger bases for decision making relevant to music
               instruction and learning. Judicious use of these data ultimately
               will facilitate instructional improvement, increase students'
               learning, and foster students' positive affective/aesthetic
               experiences through music.",
  publisher = "Schirmer Books",
  pages     = "332",
  year      =  1987,
  address   = "New York, NY",
  keywords  = "education;musical ability;musical aptitude;standardised testing",
  isbn      = "9780028703008"
}

@BOOK{Seashore1919-yc,
  title     = "The psychology of musical talent",
  author    = "Seashore, C E",
  publisher = "Silver, Burdett and Company",
  year      =  1919,
  address   = "Boston, MA",
  keywords  = "aptitude testing;listening tests"
}

@BOOK{Anderson1938-ta,
  title     = "The Letters of Mozart and His Family, Volume {I}",
  author    = "Anderson, Emily",
  publisher = "Macmillan and Co., Limited",
  year      =  1938,
  address   = "London",
  keywords  = "Leopold;Mozart;letters"
}

@ARTICLE{Hantz1992-hq,
  title    = "Effects of Musical Training and Absolute Pitch on the Neural
              Processing of Melodic Intervals: A {P3} {Event-Related} Potential
              Study",
  author   = "Hantz, Edwin C and Crummer, Garry C and Wayman, John W and
              Walton, Joseph P and Frisina, Robert D",
  abstract = "During perceptual tasks involving the discrimination of musical
              inter- vals, event-related potentials, specifically the P3, were
              measured for three subject groups: musicians without absolute
              pitch, musicians with absolute pitch, and nonmusicians. The two
              interval-discrimination tasks were a simple two-note contour task
              and a difficult interval-size dis- crimination task. Clear
              effects on the neural waveforms were found for both training and
              the presence of the absolute pitch ability. In general, training
              increases the amplitude and shortens the latency of the P3, while
              the absolute pitch ability reduces the amplitude and shortens the
              latency, or eliminates the P3 altogether. The absolute pitch
              effect may be due to the use of a long-term memory strategy
              involved in the correct per- formance of the discrimination task
              rather than performing the task by updating working memory each
              time a target occurs. Finally, these data are contrasted with
              those from studies involving sine tones and timbre-
              discrimination tasks. Introduction",
  journal  = "Music perception",
  volume   =  10,
  number   =  1,
  pages    = "25--42",
  year     =  1992,
  issn     = "0730-7829"
}

@ARTICLE{Prior1988-wg,
  title    = "Processing of timbre and rhythm in musicians and non-musicians",
  author   = "Prior, M and Troup, G A",
  abstract = "Expert musicians and non-musicians of similar educational and
              social class background were compared in two experiments
              involving perception of timbre and rhythm. In Experiment 1 where
              dichotic monitoring for the sound of the violin was required,
              there was a practice effect but no ear or group differences. The
              rhythm monitoring experiment produced a group by ear interaction
              with musicians faster on the right ear than the left and faster
              than non-musicians on the right ear only. Analysis of strategies
              reported by subjects showed that verbal labelling did not
              apparently influence laterality. Lack of evidence for individual
              laterality effects reinforces the claim that with stringent
              experimental and subject controls there is minimal evidence for
              musicians non-musician laterality effects.",
  journal  = "Cortex; a journal devoted to the study of the nervous system and
              behavior",
  volume   =  24,
  number   =  3,
  pages    = "451--456",
  year     =  1988,
  issn     = "0010-9452",
  pmid     = "3191728"
}

@ARTICLE{Tervaniemi2006-gg,
  title    = "Sound processing in amateur musicians and nonmusicians:
              event-related potential and behavioral indices",
  author   = "Tervaniemi, Mari and Castaneda, Anu and Knoll, Monja and Uther,
              Maria",
  journal  = "Neuroreport",
  volume   =  17,
  number   =  11,
  pages    = "1225--1228",
  year     =  2006,
  keywords = "ERP;location;musical expertise",
  issn     = "0959-4965"
}

@ARTICLE{Crummer1994-sc,
  title    = "Neural processing of musical timbre by musicians, nonmusicians,
              and musicians possessing absolute pitch",
  author   = "Crummer, G C and Walton, J P and Wayman, J W and Hantz, E C and
              Frisina, R D",
  abstract = "Cognitive event-related potentials (ERPs) were measured during a
              timbre discrimination task from three subject groups varying in
              musical experience. The P3 component of the ERP was recorded from
              musicians with absolute pitch, musicians without absolute pitch,
              and nonmusicians during a task comprising timbres of varying
              difficulty. The three-timbre series, all of which consisted of
              the same pitch, were (1) string instruments in the same family
              (cello and viola), (2) flutes made of different materials (silver
              and wood), and (3) instruments of slightly different size (B-flat
              versus F tubas). The amplitude and latency of the P3 component
              varied systematically as a function of musical experience and
              type of timbre discrimination. The difficult timbre task resulted
              in mean P3 amplitudes which were larger for musicians relative to
              nonmusicians, however P3 amplitudes were similar for the two
              additional timbre series. The mean P3 latencies for musicians
              were shorter when compared to nonmusicians across all three
              series. In comparison, the AP subjects displayed the shortest
              mean P3 latencies, but had smaller P3 amplitudes relative to both
              musicians and nonmusicians. The implications of these findings
              suggest that perceptual tasks involving one of the fundamental
              building blocks of music, namely timbre, does elicit differential
              brain activity from memory or information processing systems from
              subjects with varying degrees of musical training.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  95,
  number   = "5 Pt 1",
  pages    = "2720--2727",
  year     =  1994,
  keywords = "behavioural;musical expertise;timbre",
  issn     = "0001-4966",
  pmid     = "8207143",
  doi      = "10.1121/1.409840"
}

@ARTICLE{Sloboda2001-ih,
  title   = "Functions of music in everyday life: an exploratory study using
             the experience sampling method",
  author  = "Sloboda, John a and Neill, Susan a O and Ivaldi, Antonia",
  journal = "Musicae scientiae: the journal of the European Society for the
             Cognitive Sciences of Music",
  volume  =  5,
  number  =  1,
  pages   = "9--32",
  year    =  2001,
  issn    = "1029-8649",
  doi     = "10.1177/102986490100500102"
}

@ARTICLE{Tervaniemi2005-yi,
  title    = "Pitch discrimination accuracy in musicians vs nonmusicians: an
              event-related potential and behavioral study",
  author   = "Tervaniemi, Mari and Just, Viola and Koelsch, Stefan and Widmann,
              Andreas and Schr{\"o}ger, Erich",
  abstract = "Previously, professional violin players were found to
              automatically discriminate tiny pitch changes, not discriminable
              by nonmusicians. The present study addressed the pitch processing
              accuracy in musicians with expertise in playing a wide selection
              of instruments (e.g., piano; wind and string instruments). Of
              specific interest was whether also musicians with such divergent
              backgrounds have facilitated accuracy in automatic and/or
              attentive levels of auditory processing. Thirteen professional
              musicians and 13 nonmusicians were presented with frequent
              standard sounds and rare deviant sounds (0.8, 2, or 4\% higher in
              frequency). Auditory event-related potentials evoked by these
              sounds were recorded while first the subjects read a self-chosen
              book and second they indicated behaviorally the detection of
              sounds with deviant frequency. Musicians detected the pitch
              changes faster and more accurately than nonmusicians. The N2b and
              P3 responses recorded during attentive listening had larger
              amplitude in musicians than in nonmusicians. Interestingly, the
              superiority in pitch discrimination accuracy in musicians over
              nonmusicians was observed not only with the 0.8\% but also with
              the 2\% frequency changes. Moreover, also nonmusicians detected
              quite reliably the smallest pitch changes of 0.8\%. However, the
              mismatch negativity (MMN) and P3a recorded during a reading
              condition did not differentiate musicians and nonmusicians. These
              results suggest that musical expertise may exert its effects
              merely at attentive levels of processing and not necessarily
              already at the preattentive levels.",
  journal  = "Experimental brain research. Experimentelle Hirnforschung.
              Experimentation cerebrale",
  volume   =  161,
  number   =  1,
  pages    = "1--10",
  month    =  feb,
  year     =  2005,
  keywords = "Acoustic Stimulation; Acoustic Stimulation: methods; Adult;
              Evoked Potentials, Auditory; Evoked Potentials, Auditory:
              physiology; Female; Humans; Male; Music; Pitch Discrimination;
              Pitch Discrimination: physiology; Reaction Time; Reaction Time:
              physiology;ERP;behavioural;musicians;nonmusicians;pitch
              discrimination",
  issn     = "0014-4819",
  pmid     = "15551089",
  doi      = "10.1007/s00221-004-2044-5"
}

@ARTICLE{Gabrielsson1996-qp,
  title    = "Emotional expression in music performance: Between the
              performer's intention and the listener's experience",
  author   = "Gabrielsson, Alf and Juslin, Patrik N",
  abstract = "The fastener design for the transfer of concentrated transverse
              (out of plane, pull-out) loads to random glass fiber reinforced
              thermoset polymers was investigated. The elastic material
              properties, void content,a nd glass content of the composite were
              determined and a finite element model was used to analyze and
              compare the performance of the various washer designs for
              reducing the stress and strain levels near the edge of the washer
              at a bolted joint. Experimental studies were conducted to verify
              the finite element model.",
  journal  = "Psychology of Music",
  volume   =  24,
  pages    = "68--91",
  year     =  1996,
  keywords = "early signs;musical ability",
  issn     = "1059-6011",
  pmid     = "803973233",
  arxivid  = "0803973233",
  doi      = "0803973233"
}

@ARTICLE{Trainor1993-rm,
  title    = "Musical context effects in infants and adults: Key distance",
  author   = "Trainor, Laurel J and Trehub, Sandra E",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  19,
  number   =  3,
  pages    = "615--626",
  year     =  1993,
  keywords = "key distance;melodic memory",
  issn     = "0096-1523"
}

@ARTICLE{Levitin2012-tw,
  title     = "What Does It Mean to Be Musical?",
  author    = "Levitin, Daniel J",
  abstract  = "Music can be seen as a model system for understanding gene ??
               environment interactions and how these can influence
               neurocognitive development. The concept of musicality, however,
               is underspecified and not well understood. Here, I propose a
               framework for defining musicality to provide a foundation for
               studying the contributions of biological and environmental
               factors. ?? 2012 Elsevier Inc.",
  journal   = "Neuron",
  publisher = "Elsevier Inc.",
  volume    =  73,
  number    =  4,
  pages     = "633--637",
  year      =  2012,
  keywords  = "musicality",
  issn      = "0896-6273",
  pmid      = "22365540",
  doi       = "10.1016/j.neuron.2012.01.017"
}

@ARTICLE{Rohrmeier2012-zj,
  title    = "Implicit learning and acquisition of music",
  author   = "Rohrmeier, Martin A and Rebuschat, Patrick",
  abstract = "Implicit learning is a core process for the acquisition of a
              complex, rule-based environment from mere interaction, such as
              motor action, skill acquisition, or language. A body of evidence
              suggests that implicit knowledge governs music acquisition and
              perception in nonmusicians and musicians, and that both expert
              and nonexpert participants acquire complex melodic, harmonic, and
              other features from mere exposure. While current findings and
              computational modeling largely support the learning of chunks,
              some results indicate learning of more complex structures.
              Despite the body of evidence, more research is required to
              support the cross-cultural validity of implicit learning and to
              show that core and more complex music theoretical features are
              acquired implicitly.",
  journal  = "Topics in cognitive science",
  volume   =  4,
  number   =  4,
  pages    = "525--553",
  year     =  2012,
  keywords = "Cognitive modelling; Computational modelling; Implicit learning;
              Incidental learning; Music; Music cognition; Musical acquisition;
              Statistical learning",
  issn     = "1756-8757",
  pmid     = "23060126",
  doi      = "10.1111/j.1756-8765.2012.01223.x"
}

@ARTICLE{Dyson1984-bt,
  title    = "A figural approach to the role of melodic contour in melody
              recognition",
  author   = "Dyson, M C and Watkins, A J",
  abstract = "These experiments looked at specific components of melodic
              contour, reversals in pitch, and nonreversals, using a short-term
              recognitionmemoryparadigm. Listeners found it easier to dis-
              criminate between same and different melody pairs if changes
              occurred at contour reversals. This result was independent of
              rate of presentation, suggesting that the salience of upper and
              lower reversals is not attributable to a form of perceptual
              streaming. These results suggest an analogy between auditory and
              visual contours. If melodic contour is represented as a series of
              pitches extending over time, then reversals can be interpreted as
              ``comers'' and nonreversals \&s ``slopes.'' The results are
              consistent with a global strategy of perceptual analysis whereby
              comers are moresalient because they ``define the figure.'' An
              alternative explanation is that the melodies are processed in a
              way that is similar to the processing of the intonation pattern
              of speech. These contour feature effects were drastically reduced
              when the second melody was transposed and/or following a
              familiarization procedure. This last result is attributed to a
              more detailed perceptual analysis being performedunder these
              conditions, a process that is less influenced by contour
              features, reversals in pitch, playa part in the recognition of
              untransposed novel melodies, these features are not prevalent in
              the recognition of transposed and morefamiliar sequences.",
  journal  = "Perception \& psychophysics",
  volume   =  35,
  number   =  5,
  pages    = "477--488",
  year     =  1984,
  issn     = "0031-5117",
  pmid     = "6462874",
  doi      = "10.3758/BF03203924"
}

@ARTICLE{Hallam2003-ix,
  title    = "Conceptions of musical ability",
  author   = "Hallam, Susan and Prince, Vanessa",
  pages    = "1--22",
  year     =  2003,
  keywords = "Continuing and Professional Education;musicality",
  issn     = "1321-103X",
  doi      = "10.1177/1321103X030200010101"
}

@ARTICLE{Idson1978-rh,
  title    = "A bidimensional model of pitch in the recognition of melodies",
  author   = "Idson, Wendy L and Massaro, D W",
  journal  = "Perception \& psychophysics",
  volume   =  24,
  number   =  6,
  pages    = "551--565",
  year     =  1978,
  keywords = "melody recognition",
  issn     = "0031-5117"
}

@ARTICLE{Freedman1999-tb,
  title    = "The role of diatonicism in the abstraction and representation of
              contour and interval information",
  author   = "Freedman, Eric G",
  abstract = "Examined the relative contributions of contour and interval
              information during the abstraction of novel diatonic and
              nondiatonic sequences in 3 experiments. A total of 159 college
              students with and without musical experience participated as
              listeners. Listeners recognized the melodic contours of melodies
              held over an extended retention interval. Listeners used the
              diatonic context to recognize both the contour and interval
              information. In nondiatonic contexts, listeners relied
              predominantly on the contour information. Musically experienced
              listeners could recognize both the contour and interval
              information, whereas musically inexperienced listeners relied
              predominantly on the contour information. Recognition of melodic
              contour remained relatively accurate during a 24-hr retention
              interval. The results indicate that the diatonic scale mediated
              the abstraction of interval information. Listeners seemed to
              acquire a musical schema for diatonic melodies. (PsycINFO
              Database Record (c) 2004 APA, all rights reserved)",
  journal  = "Music perception",
  volume   =  16,
  number   =  3,
  pages    = "365--387",
  year     =  1999,
  keywords = "Abstraction; Experience Level; Human; Music Perception; Musical
              Ability; Pitch (Frequency); Pitch Discrimination; US; college
              students with vs without musical experienc; contributions of
              contour \& interval information du",
  issn     = "0730-7829"
}

@MISC{Mullensiefen2013-xh,
  title     = "Goldsmiths Musical Sophistication Index ({Gold-MSI}) v1.0:
               Technical Report and Documentation Revision 0.3",
  author    = "M{\"u}llensiefen, Daniel and Gingras, Bruno and Stewart, Lauren
               and Musil, Jason",
  publisher = "Goldsmiths, University of London",
  year      =  2013
}

@ARTICLE{Massaro1980-ng,
  title    = "The role of tone height, melodic contour, and tone chroma in
              melody recognition",
  author   = "Massaro, D W and Kallman, H J and Kelly, J L",
  abstract = "The present experiments assessed the contribution of tone height,
              melodic contour, and tone chroma to melody recognition. Rather
              than using highly familiar folk songs as in earlier studies,
              subjects were taught new melodies. Novel melodies were used to
              (a) more precisely control potential cues (e.g., rhythm) that are
              not of present interest, (b) eliminate unison intervals that
              cannot be transformed appropriately, (c) provide a direct
              analysis of the nature of confusion errors, (d) test whether
              recently learned melodies are recognized differently than highly
              overlearned melodies, and (e) evaluate the extent to which
              practice in the experimental task alters the process of
              recognition. The results replicate previous studies using
              familiar folk songs. Transformations of the original melodies
              were accurately recognized when tone height was violated, but
              both melodic contour and tone chroma were maintained. Violating
              both tone height and contour while maintaining chroma produced
              extremely poor recognition. Performance was intermediate when
              just melodic contour was preserved. There is now good evidence to
              support the idea that melodic contour and tone chroma, in
              addition to tone height, contribute to recognition of both highly
              familiar and recently learned melodies.",
  journal  = "Journal of experimental psychology. Human learning and memory",
  volume   =  6,
  number   =  1,
  pages    = "77--90",
  year     =  1980,
  issn     = "0096-1515",
  pmid     = "7373245",
  doi      = "10.1037/0278-7393.6.1.77"
}

@ARTICLE{Trainor2014-jt,
  title    = "Explaining the high voice superiority effect in polyphonic music:
              Evidence from cortical evoked potentials and peripheral auditory
              models",
  author   = "Trainor, Laurel J and Marie, C{\'e}line and Bruce, Ian C and
              Bidelman, Gavin M",
  abstract = "Natural auditory environments contain multiple
              simultaneously-sounding objects and the auditory system must
              parse the incoming complex sound wave they collectively create
              into parts that represent each of these individual objects. Music
              often similarly requires processing of more than one voice or
              stream at the same time, and behavioral studies demonstrate that
              human listeners show a systematic perceptual bias in processing
              the highest voice in multi-voiced music. Here, we review studies
              utilizing event-related brain potentials (ERPs), which support
              the notions that (1) separate memory traces are formed for two
              simultaneous voices (even without conscious awareness) in
              auditory cortex and (2) adults show more robust encoding (i.e.,
              larger ERP responses) to deviant pitches in the higher than in
              the lower voice, indicating better encoding of the former.
              Furthermore, infants also show this high-voice superiority
              effect, suggesting that the perceptual dominance observed across
              studies might result from neurophysiological characteristics of
              the peripheral auditory system. Although musically untrained
              adults show smaller responses in general than musically trained
              adults, both groups similarly show a more robust cortical
              representation of the higher than of the lower voice. Finally,
              years of experience playing a bass-range instrument reduces but
              does not reverse the high voice superiority effect, indicating
              that although it can be modified, it is not highly neuroplastic.
              Results of new modeling experiments examined the possibility that
              characteristics of middle-ear filtering and cochlear dynamics
              (e.g., suppression) reflected in auditory nerve firing patterns
              might account for the higher-voice superiority effect.
              Simulations show that both place and temporal AN coding schemes
              well-predict a high-voice superiority across a wide range of
              interval spacings and registers. Collectively, we infer an
              innate, peripheral origin for the higher-voice superiority
              observed in human ERP and psychophysical music listening studies.
              \copyright{} 2013 Elsevier B.V.",
  journal  = "Hearing research",
  volume   =  308,
  pages    = "60--70",
  year     =  2014,
  issn     = "0378-5955",
  pmid     = "23916754",
  doi      = "10.1016/j.heares.2013.07.014"
}

@ARTICLE{Stankov1980-ju,
  title    = "Human abilities revealed through auditory tests",
  author   = "Stankov, L and Horn, J L",
  abstract = "Used established findings from studies of visual, musical, and
              speech perception abilities to guide the construction of auditory
              ability tests. 44 measures based on these tests were obtained
              from a sample of 241 adult males (mean age 25.64 yrs).
              Correlation and factorial analyses were used to indicate
              structural interrelationships and relationships with education,
              musical experience, general intelligence, and age. The results
              indicate separate capacities for Auditory Verbal Comprehension,
              Auditory Immediate Memory, Temporal Tracking, Auditory Cognition
              of Relationships, Discrimination Among Sound Patterns, Speech
              Perception Under Distraction/Distortion, and Maintaining and
              Judging Rhythm. (61 ref) (PsycINFO Database Record (c) 2006 APA,
              all rights reserved). \copyright{} 1980 American Psychological
              Association.",
  journal  = "Journal of education \& psychology",
  volume   =  72,
  number   =  1,
  pages    = "21--44",
  year     =  1980,
  issn     = "0022-0590, 0022-0663",
  pmid     = "7372913",
  doi      = "10.1037/0022-0663.72.1.21"
}

@ARTICLE{Dowling1971-rp,
  title   = "Recognition of inversions of melodies and melodic contours",
  author  = "Dowling, W Jay",
  journal = "Perception \& psychophysics",
  volume  =  9,
  number  =  3,
  pages   = "348--349",
  year    =  1971,
  issn    = "0031-5117",
  doi     = "10.3758/BF03212663"
}

@ARTICLE{Bejar2003-qb,
  title    = "A feasibility study of on-the-fly item generation in adaptive
              testing",
  author   = "Bejar, Isaac I and Lawless, Ren{\'e} R and Morley, Mary E and
              Wagner, Michael E and Bennett, Randy E and Revuelta, Javier",
  abstract = "The goal of this study was to assess the feasibility of an
              approach to adaptive testing using item models based on the
              quantitative section of the Graduate Record Examination (GRE)
              test. An item model is a means of generating items that are
              isomorphic, that is, equivalent in content and equivalent
              psychometrically. Item models, like items, are calibrated by
              fitting an IRT response model. The resulting set of parameter
              estimates is imputed to all the items generated by the model. An
              on-the-fly adaptive test tailors the test to examinees and
              presents instances of an item model rather than independently
              developed items. A simulation study was designed to explore the
              effect an on-the-fly test design would have on score precision
              and bias as a function of the level of item model isomorphicity.
              In addition, two types of experimental tests were administered --
              an experimental, on-the-fly, adaptive quantitative-reasoning test
              as well as an experimental quantitative-reasoning linear test
              consisting of items based on item models. Results of the
              simulation study showed that under different levels of
              isomorphicity, there was no bias, but precision of measurement
              was eroded at some level. However, the comparison of
              experimental, on-the-fly adaptive test scores with the GRE test
              scores closely matched the test-retest correlation observed under
              operational conditions. Analyses of item functioning on the
              experimental linear test forms suggested that a high level of
              isomorphicity across items within models was achieved. The
              current study provides a promising first step toward significant
              cost reduction and theoretical improvement in test creation
              methodology for educational assessment.",
  journal  = "The Journal of Technology, Learning and Assessment",
  volume   =  2,
  number   =  3,
  year     =  2003,
  keywords = "adaptive testing;automatic item generation",
  issn     = "1540-2525"
}

@PHDTHESIS{Ollen2006-db,
  title  = "A criterion-related validity test of selected indicators of musical
            sophistication using expert ratings",
  author = "Ollen, Joy E",
  year   =  2006,
  school = "Ohio State University"
}

@ARTICLE{Wallentin2010-gi,
  title    = "The Musical Ear Test, a new reliable test for measuring musical
              competence",
  author   = "Wallentin, Mikkel and Nielsen, Andreas H{\o}jlund and
              Friis-Olivarius, Morten and Vuust, Christian and Vuust, Peter",
  abstract = "This paper reports results from three experiments using the
              Musical Ear Test (MET), a new test designed for measuring musical
              abilities in both musicians and non-musicians in an objective way
              with a relatively short how the MET is capable of clearly
              distinguishing between duration (<20. min.). In the first
              experiment we show a group of professional musicians and a group
              of non-musicians. In the second experiment we demonstrate that
              results from the MET are strongly correlated with measures of
              musical expertise obtained using an imitation test. In the third
              experiment we show that the MET also clearly distinguishes groups
              of non-musicians, amateurs and professional musicians. The test
              is found to have a large internal consistency (Cronbach alpha:
              0.87). We further show a correlation with amount of practice
              within the group of professionals as well as a correlation with a
              forward digit span test. \copyright{} 2010 Elsevier Inc.",
  journal  = "Learning and individual differences",
  volume   =  20,
  number   =  3,
  pages    = "188--196",
  year     =  2010,
  keywords = "Melody; Musical abilities; Musical expertise; Rhythm; Testing",
  issn     = "1041-6080",
  doi      = "10.1016/j.lindif.2010.02.004"
}

@ARTICLE{Patton2014-nv,
  title    = "Bootstrap standard errors for maximum likelihood ability
              estimates when item parameters are unknown",
  author   = "Patton, J M and Cheng, Ying and Yuan, K-H and Diao, Q",
  journal  = "Educational and psychological measurement",
  volume   =  74,
  number   =  4,
  pages    = "697--712",
  year     =  2014,
  keywords = "ability estimation; bootstrap; item response theory; standard
              error",
  issn     = "0013-1644",
  doi      = "10.1177/0013164413511083"
}

@ARTICLE{Bigand2006-ik,
  title    = "Are we ``experienced listeners''? A review of the musical
              capacities that do not depend on formal musical training",
  author   = "Bigand, E and Poulin-Charronnat, B",
  abstract = "The present paper reviews a set of studies designed to
              investigate different aspects of the capacity for processing
              Western music. This includes perceiving the relationships between
              a theme and its variations, perceiving musical tensions and
              relaxations, generating musical expectancies, integrating local
              structures in large-scale structures, learning new compositional
              systems and responding to music in an emotional (affective) way.
              The main focus of these studies was to evaluate the influence of
              intensive musical training on these capacities. The overall set
              of data highlights that some musical capacities are acquired
              through exposure to music without the help of explicit training.
              These capacities reach such a degree of sophistication that they
              enable untrained listeners to respond to music as ``musically
              experienced listeners'' do. ?? 2005 Elsevier B.V. All rights
              reserved.",
  journal  = "Cognition",
  volume   =  100,
  number   =  1,
  pages    = "100--130",
  year     =  2006,
  keywords = "Emotion; Implicit learning; Music cognition; Musical expertise;
              Musical priming",
  issn     = "0010-0277",
  pmid     = "16412412",
  doi      = "10.1016/j.cognition.2005.11.007"
}

@ARTICLE{Dweck1986-yj,
  title    = "Motivational processes affecting learning",
  author   = "Dweck, Carol S",
  abstract = "Describes how motivational processes influence a child's
              acquisition, transfer, and use of knowledge and skills. Recent
              research within the social-cognitive framework illustrates
              adaptive and maladaptive motivational patterns, and a
              research-based model of motivational processes is presented that
              shows how the particular performance or learning goals children
              pursue on cognitive tasks shape their reactions to success and
              failure and influence the quality of their cognitive performance.
              Implications for practice and the design of interventions to
              change maladaptive motivational processes are outlined. It is
              suggested that motivational patterns may contribute to gender
              differences in mathematics achievement and that empirically based
              interventions may prevent current achievement discrepancies and
              provide a basis for more effective socialization. (79 ref)
              (PsycINFO Database Record (c) 2012 APA, all rights reserved)",
  journal  = "The American psychologist",
  volume   =  41,
  number   =  10,
  pages    = "1040--1048",
  year     =  1986,
  issn     = "0003-066X",
  doi      = "10.1037/0003-066X.41.10.1040"
}

@TECHREPORT{Magis2016-sj,
  title  = "Package `catR'",
  author = "Magis, David and Raiche, Gilles and Barrada, Juan Ramon",
  year   =  2016
}

@ARTICLE{Rentfrow2003-ay,
  title    = "The do re mi's of everyday life: The structure and personality
              correlates of music preferences",
  author   = "Rentfrow, Peter J and Gosling, Samuel D",
  abstract = "The present research examined individual differences in music
              preferences. A series of 6 studies investigated lay beliefs about
              music, the structure underlying music preferences, and the links
              between music preferences and personality. The data indicated
              that people consider music an important aspect of their lives and
              listening to music an activity they engaged in frequently. Using
              multiple samples, methods, and geographic regions, analyses of
              the music preferences of over 3,500 individuals converged to
              reveal 4 music-preference dimensions: Reflective and Complex,
              Intense and Rebellious, Upbeat and Conventional, and Energetic
              and Rhythmic. Preferences for these music dimensions were related
              to a wide array of personality dimensions (e.g., Openness),
              self-views (e.g., political orientation), and cognitive abilities
              (e.g., verbal IQ).",
  journal  = "Journal of personality and social psychology",
  volume   =  84,
  number   =  6,
  pages    = "1236--1256",
  year     =  2003,
  issn     = "0022-3514",
  pmid     = "12793587",
  doi      = "10.1037/0022-3514.84.6.1236"
}

@ARTICLE{Schellenberg2011-yo,
  title    = "Examining the association between music lessons and intelligence",
  author   = "Schellenberg, E Glenn",
  abstract = "This article is an author response to Bialystok's (2011) and
              Hargreaves and Aksentijevic's (2011) commentaries on Schellenberg
              (2011).",
  journal  = "British journal of psychology",
  volume   =  102,
  number   =  3,
  pages    = "283--302",
  year     =  2011,
  issn     = "0007-1269, 2044-8295",
  pmid     = "21751990",
  doi      = "10.1111/j.2044-8295.2010.02000.x"
}

@ARTICLE{DeWitt1986-fc,
  title    = "Recognition of novel melodies after brief delays",
  author   = "DeWitt, L A and Crowder, Robert G",
  abstract = "Three experiments on the recognition of short melodies
              investigated the influence of contour and interval information
              (respectively, the pattern of changes in pitch direction and the
              ordered sequence of pitch distances in a melody). Subjects rated
              pairs of melodies as ``same'' or ``different'' on a five-point
              scale. Six conditions were defined by two delays (short, 1 sec;
              and long, 30 sec) and three item types (target, related, and
              lure). In Target pairs, the second melody retained the contour
              and interval information of the first melody, being an exact
              transposition to another key. In Related pairs, only the contour
              information was retained, while in the Lure pairs neither contour
              nor interval information was retained. In conformity with the
              reports of Dowling and Bartlett (1981), the results indicated
              that contour information had a larger influence on recognition at
              short delays, whereas interval information had a relatively
              larger influence at long delays. The results are also consistent
              with an alternative interpretation stressing the importance of
              tonality/modality information in melody recognition at long
              delays",
  journal  = "Music perception",
  volume   =  3,
  number   =  3,
  pages    = "259--274",
  year     =  1986,
  issn     = "0730-7829"
}

@ARTICLE{Plantinga2005-vu,
  title    = "Memory for melody: Infants use a relative pitch code",
  author   = "Plantinga, Judy and Trainor, Laurel J",
  abstract = "Pitch perception is fundamental to melody in music and prosody in
              speech. Unlike many animals, the vast majority of human adults
              store melodic information primarily in terms of relative not
              absolute pitch, and readily recognize a melody whether rendered
              in a high or a low pitch range. We show that at 6 months infants
              are also primarily relative pitch processors. Infants
              familiarized with a melody for 7 days preferred, on the eighth
              day, to listen to a novel melody in comparison to the
              familiarized one, regardless of whether the melodies at test were
              presented at the same pitch as during familiarization or
              transposed up or down by a perfect fifth (7/12th of an octave) or
              a tritone (1/2 octave). On the other hand, infants showed no
              preference for a transposed over original-pitch version of the
              familiarized melody, indicating that either they did not remember
              the absolute pitch, or it was not as salient to them as the
              relative pitch.",
  journal  = "Cognition",
  volume   =  98,
  number   =  1,
  pages    = "1--11",
  year     =  2005,
  keywords = "Auditory perception; Development; Infants; Pitch",
  issn     = "0010-0277",
  pmid     = "16297673",
  doi      = "10.1016/j.cognition.2004.09.008"
}

@ARTICLE{Zagorsky2007-cx,
  title    = "Do you have to be smart to be rich? The impact of {IQ} on wealth,
              income and financial distress",
  author   = "Zagorsky, Jay L",
  abstract = "How important is intelligence to financial success? Using the
              NLSY79, which tracks a large group of young U.S. baby boomers,
              this research shows that each point increase in IQ test scores
              raises income by between $234 and $616 per year after holding a
              variety of factors constant. Regression results suggest no
              statistically distinguishable relationship between IQ scores and
              wealth. Financial distress, such as problems paying bills, going
              bankrupt or reaching credit card limits, is related to IQ scores
              not linearly but instead in a quadratic relationship. This means
              higher IQ scores sometimes increase the probability of being in
              financial difficulty. ?? 2007 Elsevier Inc. All rights reserved.",
  journal  = "Intelligence",
  volume   =  35,
  number   =  5,
  pages    = "489--501",
  year     =  2007,
  keywords = "Finances; IQ; Income; Intelligence; Net worth; Personal wealth",
  issn     = "0160-2896",
  doi      = "10.1016/j.intell.2007.02.003"
}

@ARTICLE{Schellenberg2006-ir,
  title    = "Long-term positive associations between music lessons and {IQ}",
  author   = "Schellenberg, E Glenn",
  abstract = "In Study 1 (N 147), duration of music lessons was correlated
              positively with IQ and with academic ability among 6- to
              11-year-olds, even when potential confounding variables (i.e.,
              family income, parents' education, involvement in nonmusical
              activities) were held constant. In Study 2 (N 150), similar but
              weaker associations between playing music in childhood and
              intellectual functioning were evident among undergraduates. In
              both studies, there was no evidence that musical involvement had
              stronger associations with some aspects of cognitive ability
              (e.g., mathematical, spatial--temporal, verbal) than with others.
              These results indicate that formal exposure to music in childhood
              is associated positively with IQ and with academic performance
              and that such associations are small but general and long
              lasting.",
  journal  = "Journal of educational psychology",
  volume   =  98,
  number   =  2,
  pages    = "457--468",
  year     =  2006,
  keywords = "cognitive development; intellectual development; intelligence;
              musical training; positive",
  issn     = "0022-0663",
  doi      = "10.1037/0022-0663.98.2.457"
}

@ARTICLE{Cuddy1981-sz,
  title    = "Perception of structure in short melodic sequences",
  author   = "Cuddy, Lola L and Cohen, Annabel J and Mewhort, D J K",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  7,
  number   =  4,
  pages    = "869--883",
  year     =  1981,
  keywords = "melodic memory;melodic recognition",
  issn     = "0096-1523"
}

@ARTICLE{Dweck1988-ec,
  title    = "A social-cognitive approach to motivation and personality",
  author   = "Dweck, Carol S and Leggett, Ellen L",
  abstract = "Past work has documented and described major patterns of adaptive
              and maladaptive behavior: the mastery-oriented and the helpless
              patterns. In this article, we present a research-based model that
              accounts for these patterns in terms ofunderlying psychological
              processes. The model specifies how individuals' implicit theories
              orient them toward particular goals and bow these goals set up
              the different patterns. Indeed, we show how each feature
              (cognitive, affective, and behavioral) of the adaptive and
              maladaptive patterns can be seen to follow directly from
              different goals. We then exam- ine the generality of the model
              and use it to illuminate phenomena in a wide variety of domains.
              Finally, we place the model in its broadest context and examine
              its implications for our undentand- ing of motivational and
              personality processes. The",
  journal  = "Psychological review",
  volume   =  95,
  number   =  2,
  pages    = "256--273",
  year     =  1988,
  issn     = "0033-295X",
  doi      = "10.1037/0033-295X.95.2.256"
}

@ARTICLE{Mullensiefen2014-vy,
  title    = "The musicality of non-musicians: An index for assessing musical
              sophistication in the general population",
  author   = "M{\"u}llensiefen, Daniel and Gingras, Bruno and Musil, Jason and
              Stewart, Lauren",
  abstract = "Musical skills and expertise vary greatly in Western societies.
              Individuals can differ in their repertoire of musical behaviours
              as well as in the level of skill they display for any single
              musical behaviour. The types of musical behaviours we refer to
              here are broad, ranging from performance on an instrument and
              listening expertise, to the ability to employ music in functional
              settings or to communicate about music. In this paper, we first
              describe the concept of 'musical sophistication' which can be
              used to describe the multi-faceted nature of musical expertise.
              Next, we develop a novel measurement instrument, the Goldsmiths
              Musical Sophistication Index (Gold-MSI) to assess self-reported
              musical skills and behaviours on multiple dimensions in the
              general population using a large Internet sample (n = 147,636).
              Thirdly, we report results from several lab studies,
              demonstrating that the Gold-MSI possesses good psychometric
              properties, and that self-reported musical sophistication is
              associated with performance on two listening tasks. Finally, we
              identify occupation, occupational status, age, gender, and wealth
              as the main socio-demographic factors associated with musical
              sophistication. Results are discussed in terms of theoretical
              accounts of implicit and statistical music learning and with
              regard to social conditions of sophisticated musical engagement.",
  journal  = "PloS one",
  volume   =  9,
  number   =  2,
  year     =  2014,
  issn     = "1932-6203",
  pmid     = "24586929",
  doi      = "10.1371/journal.pone.0089642"
}

@ARTICLE{Hallam2010-jl,
  title    = "21st Century Conceptions of Musical Ability",
  author   = "Hallam, Susan",
  abstract = "This study explored conceptions of musical ability using an
              inventory derived from previous qualitative research.
              Participants included 102 musicians, 95 educators, 132 adult
              amateur musicians, 60 adults who were not actively engaged in
              making music, 193 children actively engaged in making music in
              addition to their engagement with the school curriculum and 71
              children with no engagement with music outside of the school
              curriculum. Overall, musical ability was most strongly perceived
              as relating to a sense of rhythm, followed by the ability to
              understand and interpret the music, express thoughts and feelings
              through sound, being able to communicate through sound,
              motivation to engage with music, personal commitment to music,
              and being able to successfully engage musically with others.
              Least important were having technical skills, being able to
              compose or improvise, being able to read music, and understanding
              musical concepts and musical structures. Factor analysis revealed
              six factors which differentiated between the six sample groups,
              with the musicians (professional, amateur and children) and
              non-musicians demonstrating that musical ability is perceived in
              complex ways which depend on the environment within which
              individuals are located, and their particular musical experiences
              or lack of them.",
  journal  = "Psychology of Music",
  volume   =  38,
  number   =  3,
  pages    = "308--330",
  year     =  2010,
  keywords = "musicality",
  issn     = "0305-7356",
  doi      = "10.1177/0305735609351922"
}

@ARTICLE{Correa2004-pk,
  title    = "Endogenous temporal orienting of attention in detection and
              discrimination tasks",
  author   = "Correa, Angel and Lupi{\'a}{\~n}ez, Juan and Milliken, Bruce and
              Tudela, P{\'\i}o",
  abstract = "Endogenous temporal-orienting effects were studied using a cuing
              paradigm in which the cue indicated the time interval during
              which the target was most likely to appear. Temporal-orienting
              effects were defined by lower reaction times (RTs) when there was
              a match between the temporal expectancy for a target (early or
              late) and the time interval during which the target actually
              appeared than when they mismatched. Temporal-orienting effects
              were found for both early and late expectancies with a detection
              task in Experiment 1. However, catch trials were decisive in
              whether temporal-orienting effects were observed in the
              early-expectancy condition. No temporal-orienting effects were
              found in the discrimination task. In Experiments 2A and 2B,
              temporal-orienting effects were observed in the discrimination
              task; however, they were larger when temporal expectancy was
              manipulated between blocks, rather than within blocks.",
  journal  = "Perception \& psychophysics",
  volume   =  66,
  number   =  2,
  pages    = "264--278",
  year     =  2004,
  issn     = "0031-5117",
  pmid     = "15129748",
  doi      = "10.3758/BF03194878"
}

@ARTICLE{Rimmele2011-ug,
  title   = "Auditory target detection is affected by implicit temporal and
             spatial expectations",
  author  = "Rimmele, Johanna and Jolsvai, Hajnal and Sussman, Elyse",
  journal = "Journal of cognitive neuroscience",
  volume  =  23,
  number  =  5,
  pages   = "1136--1147",
  year    =  2011,
  issn    = "0898-929X",
  doi     = "10.1162/jocn.2010.21437"
}

@ARTICLE{Prince2009-ma,
  title    = "The effect of task and pitch structure on pitch-time interactions
              in music",
  author   = "Prince, Jon B and Schmuckler, Mark a and Thompson, William F",
  abstract = "Musical pitch-time relations were explored by investigating the
              effect of temporal variation on pitch perception. In Experiment
              1, trained musicians heard a standard tone followed by a tonal
              context and then a comparison tone. They then performed one of
              two tasks. In the cognitive task, they indicated whether the
              comparison tone was in the key of the context. In the perceptual
              task, they judged whether the comparison tone was higher or lower
              than the standard tone. For both tasks, the comparison tone
              occurred early, on time, or late with respect to temporal
              expectancies established by the context. Temporal variation did
              not affect accuracy in either task. Experiment 2 used the
              perceptual task and varied the pitch structure by employing
              either a tonal or an atonal context. Temporal variation did not
              affect accuracy for tonal contexts, but did for atonal contexts.
              Experiment 3 replicated these results and controlled potential
              confounds. We argue that tonal contexts bias attention toward
              pitch and eliminate effects of temporal variation, whereas atonal
              contexts do not, thus fostering pitch-time interactions.",
  journal  = "Memory \& cognition",
  volume   =  37,
  number   =  3,
  pages    = "368--381",
  year     =  2009,
  issn     = "0090-502X",
  pmid     = "19246351",
  doi      = "10.3758/MC.37.3.368"
}

@ARTICLE{Escoffier2010-pa,
  title    = "Unattended musical beats enhance visual processing",
  author   = "Escoffier, Nicolas and Sheng, Darren Yeo Jian and Schirmer,
              Annett",
  abstract = "The present study investigated whether and how a musical rhythm
              entrains a listener's visual attention. To this end, participants
              were presented with pictures of faces and houses and indicated
              whether picture orientation was upright or inverted. Participants
              performed this task in silence or with a musical rhythm playing
              in the background. In the latter condition, pictures could occur
              off-beat or on a rhythmically implied, silent beat. Pictures
              presented without the musical rhythm and off-beat were responded
              to more slowly than pictures presented on-beat. This effect was
              comparable for faces and houses. Together these results indicate
              that musical rhythm both synchronizes and facilitates concurrent
              stimulus processing. \copyright{} 2010 Elsevier B.V.",
  journal  = "Acta psychologica",
  volume   =  135,
  number   = "January 2016",
  pages    = "12--16",
  year     =  2010,
  keywords = "Dynamic attending theory; Evolution; Social",
  issn     = "0001-6918",
  pmid     = "20451167",
  doi      = "10.1016/j.actpsy.2010.04.005"
}

@ARTICLE{Jones2002-wd,
  title   = "Temporal aspects of stimulus-driven attending in dynamic arrays",
  author  = "Jones, Mari Riess and Moynihan, Heather and Mackenzie, Noah and
             Puente, Jennifer",
  journal = "Psychological science",
  volume  =  13,
  number  =  4,
  pages   = "313--319",
  year    =  2002,
  issn    = "0956-7976",
  doi     = "10.1111/1467-9280.00458"
}

@ARTICLE{Schroger2015-qx,
  title   = "Bridging prediction and attention in current research on
             perception and action",
  author  = "Schr{\"o}ger, Erich and Kotz, Sonja A and SanMiguel, Iria",
  journal = "Brain research",
  volume  =  1626,
  pages   = "1--13",
  year    =  2015,
  issn    = "0006-8993",
  doi     = "10.1016/j.brainres.2015.08.037"
}

@ARTICLE{Bauer2014-qu,
  title     = "The auditory dynamic attending theory revisited: A closer look
               at the pitch comparison task",
  author    = "Bauer, Anna-Katharina R and Jaeger, Manuela and Thorne, Jeremy D
               and Bendixen, Alexandra and Debener, Stefan",
  abstract  = "The dynamic attending theory as originally proposed by Jones,
               1976. Psychol. Rev. 83(5), 323-355 posits that tone sequences
               presented at a regular rhythm entrain attentional oscillations
               and thereby facilitate the processing of sounds presented in
               phase with this rhythm. The increased interest in neural
               correlates of dynamic attending requires robust behavioral
               indicators of the phenomenon. Here we aimed to replicate and
               complement the most prominent experimental implementation of
               dynamic attending (Jones et al., 2002. Psychol. Sci. 13(4),
               313-319). The paradigm uses a pitch comparison task in which two
               tones, the initial and the last of a longer series, have to be
               compared. In-between the two, distractor tones with variable
               pitch are presented, at a regular pace. A comparison tone
               presented in phase with the entrained rhythm is hypothesized to
               lead to better behavioral performance. Aiming for a conceptual
               replication, four different variations of the original paradigm
               were created which were followed by an exact replication
               attempt. Across all five experiments, only 40 of the 140 tested
               participants showed the hypothesized pattern of an inverted
               U-shaped profile in task accuracy, and the group average effects
               did not replicate the pattern reported by Jones et al., 2002.
               Psychol. Sci. 13(4), 313-319 in any of the five experiments.
               However, clear evidence for a relationship between musicality
               and overall behavioral performance was found. This study casts
               doubt on the suitability of the pitch comparison task for
               demonstrating auditory dynamic attending. We discuss alternative
               tasks that have been shown to support dynamic attending theory,
               thus lending themselves more readily to studying its neural
               correlates. This article is part of a Special Issue entitled SI:
               Prediction and Attention. This article is part of a Special
               Issue entitled SI: Prediction and Attention.",
  journal   = "Brain research",
  publisher = "Elsevier",
  volume    =  368,
  number    =  1658,
  pages     = "20130401",
  year      =  2014,
  keywords  = "Entrainment; Musicality; Replication; Temporal expectation;
               temporal expectation",
  issn      = "0006-8993, 1872-6240",
  pmid      = "25934332",
  doi       = "10.1016/j.brainres.2015.04.032"
}

@ARTICLE{Bartholomew1998-lw,
  title    = "Scaling unobservable constructs in social science",
  author   = "Bartholomew, David J",
  journal  = "Applied statistics",
  volume   =  47,
  number   =  1,
  pages    = "1--13",
  year     =  1998,
  keywords = "attitude scaling; factor analysis; latent; latent class models;
              latent trait models; logit; measurement; probit model; variable
              models",
  issn     = "0035-9254"
}

@ARTICLE{Seale2020-og,
  title     = "From passive to informed: mechanical mechanisms of seed
               dispersal",
  author    = "Seale, Madeleine and Nakayama, Naomi",
  abstract  = "Plant dispersal mechanisms rely on anatomical and morphological
               adaptations for the use of physical or biological dispersal
               vectors. Recently, studies of interactions between the dispersal
               unit and physical environment have uncovered fluid dynamic
               mechanisms of seed flight, protective measures against fire, and
               release mechanisms of explosive dispersers. Although
               environmental conditions generally dictate dispersal distances,
               plants are not purely passive players in these processes.
               Evidence suggests that some plants may enact informed dispersal,
               where dispersal-related traits are modified according to the
               environment. This can occur via developmental regulation, but
               also on shorter timescales via structural remodelling in
               relation to water availability and temperature. Linking
               interactions between dispersal mechanisms and environmental
               conditions will be essential to fully understand population
               dynamics and distributions.",
  journal   = "The New phytologist",
  publisher = "Wiley Online Library",
  volume    =  225,
  number    =  2,
  pages     = "653--658",
  month     =  jan,
  year      =  2020,
  keywords  = "bet-hedging; biomechanics; diaspore; dispersal; heteromorphism;
               informed dispersal; seed",
  language  = "en",
  issn      = "0028-646X, 1469-8137",
  pmid      = "31403702",
  doi       = "10.1111/nph.16110"
}

@ARTICLE{Cummins2018-dh,
  title     = "A separated vortex ring underlies the flight of the dandelion",
  author    = "Cummins, Cathal and Seale, Madeleine and Macente, Alice and
               Certini, Daniele and Mastropaolo, Enrico and Viola, Ignazio
               Maria and Nakayama, Naomi",
  abstract  = "Wind-dispersed plants have evolved ingenious ways to lift their
               seeds1,2. The common dandelion uses a bundle of drag-enhancing
               bristles (the pappus) that helps to keep their seeds aloft. This
               passive flight mechanism is highly effective, enabling seed
               dispersal over formidable distances3,4; however, the physics
               underpinning pappus-mediated flight remains unresolved. Here we
               visualized the flow around dandelion seeds, uncovering an
               extraordinary type of vortex. This vortex is a ring of
               recirculating fluid, which is detached owing to the flow passing
               through the pappus. We hypothesized that the circular disk-like
               geometry and the porosity of the pappus are the key design
               features that enable the formation of the separated vortex ring.
               The porosity gradient was surveyed using microfabricated disks,
               and a disk with a similar porosity was found to be able to
               recapitulate the flow behaviour of the pappus. The porosity of
               the dandelion pappus appears to be tuned precisely to stabilize
               the vortex, while maximizing aerodynamic loading and minimizing
               material requirements. The discovery of the separated vortex
               ring provides evidence of the existence of a new class of fluid
               behaviour around fluid-immersed bodies that may underlie
               locomotion, weight reduction and particle retention in
               biological and manmade structures.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  562,
  number    =  7727,
  pages     = "414--418",
  month     =  oct,
  year      =  2018,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "30333579",
  doi       = "10.1038/s41586-018-0604-2"
}

@ARTICLE{Seale2017-rm,
  title     = "{BRC1} expression regulates bud activation potential but is not
               necessary or sufficient for bud growth inhibition in Arabidopsis",
  author    = "Seale, Madeleine and Bennett, Tom and Leyser, Ottoline",
  abstract  = "The degree of shoot branching in Arabidopsis is determined by
               the activation of axillary buds. Bud activity is regulated by
               diverse environmental and developmental signals, often mediated
               via plant hormones, including auxin, strigolactone and
               cytokinin. The transcription factor BRANCHED1 (BRC1) has been
               proposed to integrate these regulatory signals. This idea is
               based on increased branching in brc1 mutants, the effects of
               bud-regulating hormones on BRC1 expression, and a general
               correlation between BRC1 expression and bud growth inhibition.
               These data demonstrate the important role of BRC1 in shoot
               branching, but here we show that in Arabidopsis this correlation
               can be broken. Buds lacking BRC1 expression can remain inhibited
               and sensitive to inhibition by strigolactone. Furthermore, buds
               with high BRC1 transcript levels can be active. Based on these
               data, we propose that BRC1 regulates bud activation potential in
               concert with an auxin transport-based mechanism underpinning bud
               activity. In the context of strigolactone-mediated bud
               regulation, our data suggest a coherent feed-forward loop in
               which strigolactone treatment reduces the probability of bud
               activation by parallel effects on BRC1 transcription and the
               shoot auxin transport network.",
  journal   = "Development",
  publisher = "dev.biologists.org",
  volume    =  144,
  number    =  9,
  pages     = "1661--1673",
  month     =  may,
  year      =  2017,
  keywords  = "Auxin; BRANCHED1; Bud growth inhibition; Shoot branching;
               Strigolactone",
  language  = "en",
  issn      = "0950-1991, 1477-9129",
  pmid      = "28289131",
  doi       = "10.1242/dev.145649",
  pmc       = "PMC5450845"
}

@ARTICLE{Seale2018-jl,
  title     = "Design principles of hair-like structures as biological machines",
  author    = "Seale, Madeleine and Cummins, Cathal and Viola, Ignazio Maria
               and Mastropaolo, Enrico and Nakayama, Naomi",
  abstract  = "Hair-like structures are prevalent throughout biology and
               frequently act to sense or alter interactions with an organism's
               environment. The overall shape of a hair is simple: a long,
               filamentous object that protrudes from the surface of an
               organism. This basic design, however, can confer a wide range of
               functions, owing largely to the flexibility and large surface
               area that it usually possesses. From this simple structural
               basis, small changes in geometry, such as diameter, curvature
               and inter-hair spacing, can have considerable effects on
               mechanical properties, allowing functions such as
               mechanosensing, attachment, movement and protection. Here, we
               explore how passive features of hair-like structures, both
               individually and within arrays, enable diverse functions across
               biology. Understanding the relationships between form and
               function can provide biologists with an appreciation for the
               constraints and possibilities on hair-like structures.
               Additionally, such structures have already been used in
               biomimetic engineering with applications in sensing, water
               capture and adhesion. By examining hairs as a functional
               mechanical unit, geometry and arrangement can be rationally
               designed to generate new engineering devices and ideas.",
  journal   = "Journal of the Royal Society, Interface / the Royal Society",
  publisher = "royalsocietypublishing.org",
  volume    =  15,
  number    =  142,
  month     =  may,
  year      =  2018,
  keywords  = "biomechanics; biomimetics; hair; living machines; sensors;
               structure--function",
  language  = "en",
  issn      = "1742-5689, 1742-5662",
  pmid      = "29848593",
  doi       = "10.1098/rsif.2018.0206",
  pmc       = "PMC6000178"
}

@ARTICLE{Bennett2016-hp,
  title     = "Strigolactone regulates shoot development through a core
               signalling pathway",
  author    = "Bennett, Tom and Liang, Yueyang and Seale, Madeleine and Ward,
               Sally and M{\"u}ller, D{\"o}rte and Leyser, Ottoline",
  abstract  = "Strigolactones are a recently identified class of hormone that
               regulate multiple aspects of plant development. The DWARF14
               (D14) $\alpha$/$\beta$ fold protein has been identified as a
               strigolactone receptor, which can act through the SCFMAX2
               ubiquitin ligase, but the universality of this mechanism is not
               clear. Multiple proteins have been suggested as targets for
               strigolactone signalling, including both direct proteolytic
               targets of SCFMAX2, and downstream targets. However, the
               relevance and importance of these proteins to strigolactone
               signalling in many cases has not been fully established. Here we
               assess the contribution of these targets to strigolactone
               signalling in adult shoot developmental responses. We find that
               all examined strigolactone responses are regulated by SCFMAX2
               and D14, and not by other D14-like proteins. We further show
               that all examined strigolactone responses likely depend on
               degradation of SMXL proteins in the SMXL6 clade, and not on the
               other proposed proteolytic targets BES1 or DELLAs. Taken
               together, our results suggest that in the adult shoot, the
               dominant mode of strigolactone signalling is D14-initiated,
               MAX2-mediated degradation of SMXL6-related proteins. We confirm
               that the BRANCHED1 transcription factor and the PIN-FORMED1
               auxin efflux carrier are plausible downstream targets of this
               pathway in the regulation of shoot branching, and show that BRC1
               likely acts in parallel to PIN1.",
  journal   = "Biology open",
  publisher = "bio.biologists.org",
  volume    =  5,
  number    =  12,
  pages     = "1806--1820",
  month     =  dec,
  year      =  2016,
  keywords  = "Shoot branching; Signal transduction; Strigolactone",
  language  = "en",
  issn      = "2046-6390",
  pmid      = "27793831",
  doi       = "10.1242/bio.021402",
  pmc       = "PMC5200909"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Friedman2021-zc,
  title     = "Consonance preferences within an unconventional tuning system",
  author    = "Friedman, Ronald S and Kowalewski, Douglas A and Vuvan,
               Dominique T and Neill, W Trammell",
  abstract  = "Recently,, found that individuals perceive chords with spectra
               resembling a harmonic series as more consonant. This is
               consistent with their vocal similarity hypothesis (VSH), the
               notion that the experience of consonance is based on an evolved
               preference for sounds that …",
  journal   = "Music Perception",
  publisher = "University of California Press",
  volume    =  38,
  number    =  3,
  pages     = "313--330",
  year      =  2021,
  doi       = "10.1525/mp.2021.38.3.313"
}

@ARTICLE{Sears2021-dk,
  title     = "Triadic patterns across classical and popular music corpora:
               stylistic conventions, or characteristic idioms?",
  author    = "Sears, David R W and Forrest, David",
  abstract  = "Many musical traditions ? from Western art, to popular and
               commercial ? organize pitch phenomena around a referential pitch
               class (or tonic) and feature triads and seventh chords. As a
               result, triadic progressions associated with one tradition
               sometimes resurface in others. How, then, are we to distinguish
               between the conventional harmonic patterns that span several
               time periods, and the characteristic idioms that delimit a
               single period?This essay presents a comparative study of triadic
               progressions in four data sets comprised of expert harmonic
               annotations: Annotated Beethoven Corpus (ABC), Theme and
               Variation Encodings with Roman Numerals (TAVERN), Rolling
               Stone-200 (RS-200), and McGill Billboard (Billboard). Using
               methods for counting, filtering, and ranking multichord
               expressions, we reveal conventional and characteristic
               progressions and examine broad trends over time. We also include
               an accompanying standalone application that allows users to
               adjust various stages of the model pipeline and export the data
               for further exploration and analysis.",
  journal   = "Journal of Mathematics \& Music. Mathematical and Computational
               Approaches to Music Theory, Analysis, Composition and
               Performance",
  publisher = "Taylor \& Francis",
  pages     = "1--14",
  month     =  jun,
  year      =  2021,
  keywords  = "To read",
  issn      = "1745-9737",
  doi       = "10.1080/17459737.2021.1925762"
}

@ARTICLE{Hunt2021-dd,
  title     = "Formalizing planning and information search in naturalistic
               decision-making",
  author    = "Hunt, L T and Daw, N D and Kaanders, P and MacIver, M A and
               Mugan, U and Procyk, E and Redish, A D and Russo, E and Scholl,
               J and Stachenfeld, K and Wilson, C R E and Kolling, N",
  abstract  = "Decisions made by mammals and birds are often temporally
               extended. They require planning and sampling of
               decision-relevant information. Our understanding of such
               decision-making remains in its infancy compared with simpler,
               forced-choice paradigms. However, recent advances in algorithms
               supporting planning and information search provide a lens
               through which we can explain neural and behavioral data in these
               tasks. We review these advances to obtain a clearer
               understanding for why planning and curiosity originated in
               certain species but not others; how activity in the medial
               temporal lobe, prefrontal and cingulate cortices may support
               these behaviors; and how planning and information search may
               complement each other as means to improve future action
               selection. Decision-making often involves temporally extended
               planning and information search. This Review discusses recent
               theoretical frameworks that have been used to study such
               naturalistic decision-making and its neural basis.",
  journal   = "Nature neuroscience",
  publisher = "Nature Publishing Group",
  pages     = "1--14",
  month     =  jun,
  year      =  2021,
  keywords  = "To read",
  language  = "en",
  issn      = "1097-6256",
  doi       = "10.1038/s41593-021-00866-w"
}

@ARTICLE{Agres2021-fo,
  title     = "Music, Computing, and Health: A Roadmap for the Current and
               Future Roles of Music Technology for Health Care and
               {Well-Being}",
  author    = "Agres, Kat R and Schaefer, Rebecca S and Volk, Anja and van
               Hooren, Susan and Holzapfel, Andre and Dalla Bella, Simone and
               M{\"u}ller, Meinard and de Witte, Martina and Herremans, Dorien
               and Ramirez Melendez, Rafael and Neerincx, Mark and Ruiz,
               Sebastian and Meredith, David and Dimitriadis, Theo and Magee,
               Wendy L",
  abstract  = "The fields of music, health, and technology have seen
               significant interactions in recent years in developing music
               technology for health care and well-being. In an effort to
               strengthen the collaboration between the involved disciplines,
               the workshop ?Music, Computing, and Health? was held to discuss
               best practices and state-of-the-art at the intersection of these
               areas with researchers from music psychology and neuroscience,
               music therapy, music information retrieval, music technology,
               medical technology (medtech), and robotics. Following the
               discussions at the workshop, this article provides an overview
               of the different methods of the involved disciplines and their
               potential contributions to developing music technology for
               health and well-being. Furthermore, the article summarizes the
               state of the art in music technology that can be applied in
               various health scenarios and provides a perspective on
               challenges and opportunities for developing music technology
               that (1) supports person-centered care and evidence-based
               treatments, and (2) contributes to developing standardized,
               large-scale research on music-based interventions in an
               interdisciplinary manner. The article provides a resource for
               those seeking to engage in interdisciplinary research using
               music-based computational methods to develop technology for
               health care, and aims to inspire future research directions by
               evaluating the state of the art with respect to the challenges
               facing each field.",
  journal   = "Music \& Science",
  publisher = "SAGE Publications Ltd",
  volume    =  4,
  pages     = "2059204321997709",
  month     =  jan,
  year      =  2021,
  issn      = "2059-2043",
  doi       = "10.1177/2059204321997709"
}

@ARTICLE{Camarena2022-je,
  title     = "Pleasantness Ratings of Musical Dyads in Cochlear Implant Users",
  author    = "Camarena, Andres and Manchala, Grace and Papadopoulos, Julianne
               and O'Connell, Samantha R and Goldsworthy, Raymond L",
  abstract  = "Cochlear implants have been used to restore hearing to more than
               half a million people around the world. The restored hearing
               allows most recipients to understand spoken speech without
               relying on visual cues. While speech comprehension in quiet is
               generally high for recipients, many complain about the sound of
               music. The present study examines consonance and dissonance
               perception in nine cochlear implant users and eight people with
               no known hearing loss. Participants completed web-based
               assessments to characterize low-level psychophysical
               sensitivities to modulation and pitch, as well as higher-level
               measures of musical pleasantness and speech comprehension in
               background noise. The underlying hypothesis is that sensitivity
               to modulation and pitch, in addition to higher levels of musical
               sophistication, relate to higher-level measures of music and
               speech perception. This hypothesis tested true with strong
               correlations observed between measures of modulation and pitch
               with measures of consonance ratings and speech recognition.
               Additionally, the cochlear implant users who were the most
               sensitive to modulations and pitch, and who had higher musical
               sophistication scores, had similar pleasantness ratings as those
               with no known hearing loss. The implication is that better
               coding and focused rehabilitation for modulation and pitch
               sensitivity will broadly improve perception of music and speech
               for cochlear implant users.",
  journal   = "Brain Sciences",
  publisher = "Multidisciplinary Digital Publishing Institute (MDPI)",
  volume    =  12,
  number    =  1,
  month     =  jan,
  year      =  2022,
  language  = "en",
  doi       = "10.3390/brainsci12010033",
  pmc       = "PMC8773901"
}

@ARTICLE{Iigaya2021-tv,
  title    = "Aesthetic preference for art can be predicted from a mixture of
              low- and high-level visual features",
  author   = "Iigaya, Kiyohito and Yi, Sanghyun and Wahle, Iman A and
              Tanwisuth, Koranis and O'Doherty, John P",
  abstract = "It is an open question whether preferences for visual art can be
              lawfully predicted from the basic constituent elements of a
              visual image. Here, we developed and tested a computational
              framework to investigate how aesthetic values are formed. We show
              that it is possible to explain human preferences for a visual art
              piece based on a mixture of low- and high-level features of the
              image. Subjective value ratings could be predicted not only
              within but also across individuals, using a regression model with
              a common set of interpretable features. We also show that the
              features predicting aesthetic preference can emerge
              hierarchically within a deep convolutional neural network trained
              only for object recognition. Our findings suggest that human
              preferences for art can be explained at least in part as a
              systematic integration over the underlying visual features of an
              image.",
  journal  = "Nature human behaviour",
  month    =  may,
  year     =  2021,
  keywords = "To read",
  language = "en",
  issn     = "2397-3374",
  pmid     = "34017097",
  doi      = "10.1038/s41562-021-01124-6"
}

@ARTICLE{De_Villa_undated-st,
  title  = "{GENERATING} {MUSICAL} {CONTINUATIONS} {WITH} {REPETITION}",
  author = "de Villa, Sebastian Velez and Andrew, M and Rohrmeier, Martin"
}

@ARTICLE{Makin2019-hn,
  title    = "Ten common statistical mistakes to watch out for when writing or
              reviewing a manuscript",
  author   = "Makin, Tamar R and Orban de Xivry, Jean-Jacques",
  abstract = "Inspired by broader efforts to make the conclusions of scientific
              research more robust, we have compiled a list of some of the most
              common statistical mistakes that appear in the scientific
              literature. The mistakes have their origins in ineffective
              experimental designs, inappropriate analyses and/or flawed
              reasoning. We provide advice on how authors, reviewers and
              readers can identify and resolve these mistakes and, we hope,
              avoid them in the future.",
  journal  = "eLife",
  volume   =  8,
  month    =  oct,
  year     =  2019,
  keywords = "analysis; causality; neuroscience; none; null results; p-hacking;
              power; statistics",
  language = "en",
  issn     = "2050-084X",
  pmid     = "31596231",
  doi      = "10.7554/eLife.48175",
  pmc      = "PMC6785265"
}

@ARTICLE{Wilson2019-qy,
  title    = "Ten simple rules for the computational modeling of behavioral
              data",
  author   = "Wilson, Robert C and Collins, Anne Ge",
  abstract = "Computational modeling of behavior has revolutionized psychology
              and neuroscience. By fitting models to experimental data we can
              probe the algorithms underlying behavior, find neural correlates
              of computational variables and better understand the effects of
              drugs, illness and interventions. But with great power comes
              great responsibility. Here, we offer ten simple rules to ensure
              that computational modeling is used with care and yields
              meaningful insights. In particular, we present a
              beginner-friendly, pragmatic and details-oriented introduction on
              how to relate models to data. What, exactly, can a model tell us
              about the mind? To answer this, we apply our rules to the
              simplest modeling techniques most accessible to beginning
              modelers and illustrate them with examples and code available
              online. However, most rules apply to more advanced techniques.
              Our hope is that by following our guidelines, researchers will
              avoid many pitfalls and unleash the power of computational
              modeling on their own data.",
  journal  = "eLife",
  volume   =  8,
  month    =  nov,
  year     =  2019,
  keywords = "computational modeling; model fitting; neuroscience;
              reproducibility; validation",
  language = "en",
  issn     = "2050-084X",
  pmid     = "31769410",
  doi      = "10.7554/eLife.49547",
  pmc      = "PMC6879303"
}

@INCOLLECTION{Temperley2013-fg,
  title     = "Computational models of music cognition",
  booktitle = "The Psychology of Music",
  author    = "Temperley, David",
  editor    = "Deutsch, Diana",
  abstract  = "In recent decades, computational research has assumed an
               increasingly important role in the study of cognition. Computer
               modeling is generally regarded as one of the three main
               approaches along with experimental psychology and
               neuroscience---that comprise the interdisciplinary field of
               ``cognitive science.'' It is no surprise, then, that
               computational work has become an important part of the field of
               music cognition as well. What follows is a survey of some
               important research in computational modeling of music cognition.
               We begin with problems of perception or information
               processing---problems of extracting various kinds of information
               from music as it is heard. Here we focus primarily on two
               especially well-studied problems, keyfinding and meter-finding,
               but briefly consider several other problems as well. We then
               turn to three other broad issues: the modeling of musical
               experience, the modeling of performance, and the modeling of
               composition. (PsycINFO Database Record (c) 2016 APA, all rights
               reserved)",
  publisher = "Elsevier Academic Press",
  pages     = "327--368",
  year      =  2013,
  address   = "San Diego, CA, US",
  doi       = "10.1016/B978-0-12-381460-9.00008-0"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Mavromatis2006-si,
  title     = "A hidden Markov model of melody production in Greek church chant",
  author    = "Mavromatis, Panayotis",
  abstract  = "… Ayuda; Cambiar idioma Idioma catal{\`a}. Cambiar. A Hidden
               Markov Model of Melody Production in greek Church Chant .
               Autores: Panayotis Mavromatis ; Localizaci{\'o}n: Computing in
               musicology: a directory of research, ISSN 1057-9478, Nº 14,
               2006, p{\'a}gs. 93-112; Idioma: espa{\~n}ol. Fundaci{\'o}n …",
  journal   = "Computing in musicology: a directory of research",
  publisher = "Center for Computer Assisted Research in the Humanities",
  number    =  14,
  pages     = "93--112",
  year      =  2006
}

@BOOK{Farrell2018-id,
  title     = "Computational modeling of cognition and behavior",
  author    = "Farrell, Simon and Lewandowsky, Stephan",
  abstract  = "Computational modeling is now ubiquitous in psychology, and
               researchers who are not modelers may find it increasingly
               difficult to follow the theoretical developments in their field.
               This book presents an integrated framework for the development
               and application of models in psychology and related disciplines.
               Researchers and students are given the knowledge and tools to
               interpret models published in their area, as well as to develop,
               fit, and test their own models. Both the development of models
               and key features of any model are covered, as are the
               applications of models in a variety of domains across the
               behavioural sciences. A number of chapters are devoted to
               fitting models using maximum likelihood and Bayesian estimation,
               including fitting hierarchical and mixture models. Model
               comparison is described as a core philosophy of scientific
               inference, and the use of models to understand theories and
               advance scientific discourse is explained.",
  publisher = "Cambridge University Press",
  month     =  feb,
  year      =  2018,
  address   = "Cambridge, UK",
  language  = "en",
  isbn      = "9781108548243"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Jacoby2020-qo,
  title     = "Cross-cultural work in music cognition: Challenges, insights,
               and recommendations",
  author    = "Jacoby, Nori and Margulis, Elizabeth Hellmuth and Clayton,
               Martin and Hannon, Erin and Honing, Henkjan and Iversen, John
               and Klein, Tobias Robert and Mehr, Samuel A and Pearson, Lara
               and Peretz, Isabelle and {Others}",
  abstract  = "Many foundational questions in the psychology of music require
               cross-cultural approaches, yet the vast majority of work in the
               field to date has been conducted with Western participants and
               Western music. For cross-cultural research to thrive, it will
               require …",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  37,
  number    =  3,
  pages     = "185--195",
  year      =  2020,
  issn      = "0730-7829"
}

@ARTICLE{Stevens2012-ca,
  title     = "Music perception and cognition: a review of recent
               cross-cultural research",
  author    = "Stevens, Catherine J",
  abstract  = "Experimental investigations of cross-cultural music perception
               and cognition reported during the past decade are described. As
               globalization and Western music homogenize the world musical
               environment, it is imperative that diverse music and musical
               contexts are documented. Processes of music perception include
               grouping and segmentation, statistical learning and sensitivity
               to tonal and temporal hierarchies, and the development of tonal
               and temporal expectations. The interplay of auditory, visual,
               and motor modalities is discussed in light of synchronization
               and the way music moves via emotional response. Further research
               is needed to test deep-rooted psychological assumptions about
               music cognition with diverse materials and groups in dynamic
               contexts. Although empirical musicology provides keystones to
               unlock musical structures and organization, the psychological
               reality of those theorized structures for listeners and
               performers, and the broader implications for theories of music
               perception and cognition, awaits investigation.",
  journal   = "Topics in cognitive science",
  publisher = "Wiley",
  volume    =  4,
  number    =  4,
  pages     = "653--667",
  month     =  oct,
  year      =  2012,
  language  = "en",
  issn      = "1756-8757, 1756-8765",
  pmid      = "22811369",
  doi       = "10.1111/j.1756-8765.2012.01215.x"
}

@ARTICLE{Henrich2010-mn,
  title     = "Most people are not {WEIRD}",
  author    = "Henrich, Joseph and Heine, Steven J and Norenzayan, Ara",
  abstract  = "To understand human psychology, behavioural scientists must stop
               doing most of their experiments on Westerners, argue Joseph
               Henrich, Steven J. Heine and Ara Norenzayan.",
  journal   = "Nature",
  publisher = "Nature Publishing Group",
  volume    =  466,
  number    =  7302,
  pages     = "29--29",
  month     =  jun,
  year      =  2010,
  language  = "en",
  issn      = "0028-0836",
  doi       = "10.1038/466029a"
}

@ARTICLE{Juslin2013-zz,
  title     = "From everyday emotions to aesthetic emotions: towards a unified
               theory of musical emotions",
  author    = "Juslin, Patrik N",
  abstract  = "The sound of music may arouse profound emotions in listeners.
               But such experiences seem to involve a 'paradox', namely that
               music--an abstract form of art, which appears removed from our
               concerns in everyday life--can arouse emotions - biologically
               evolved reactions related to human survival. How are these
               (seemingly) non-commensurable phenomena linked together? Key is
               to understand the processes through which sounds are imbued with
               meaning. It can be argued that the survival of our ancient
               ancestors depended on their ability to detect patterns in
               sounds, derive meaning from them, and adjust their behavior
               accordingly. Such an ecological perspective on sound and emotion
               forms the basis of a recent multi-level framework that aims to
               explain emotional responses to music in terms of a large set of
               psychological mechanisms. The goal of this review is to offer an
               updated and expanded version of the framework that can explain
               both 'everyday emotions' and 'aesthetic emotions'. The revised
               framework--referred to as BRECVEMA--includes eight mechanisms:
               Brain Stem Reflex, Rhythmic Entrainment, Evaluative
               Conditioning, Contagion, Visual Imagery, Episodic Memory,
               Musical Expectancy, and Aesthetic Judgment. In this review, it
               is argued that all of the above mechanisms may be directed at
               information that occurs in a 'musical event' (i.e., a specific
               constellation of music, listener, and context). Of particular
               significance is the addition of a mechanism corresponding to
               aesthetic judgments of the music, to better account for typical
               'appreciation emotions' such as admiration and awe.
               Relationships between aesthetic judgments and other mechanisms
               are reviewed based on the revised framework. It is suggested
               that the framework may contribute to a long-needed
               reconciliation between previous approaches that have
               conceptualized music listeners' responses in terms of either
               'everyday emotions' or 'aesthetic emotions'.",
  journal   = "Physics of life reviews",
  publisher = "Elsevier",
  volume    =  10,
  number    =  3,
  pages     = "235--266",
  month     =  sep,
  year      =  2013,
  keywords  = "Aesthetics; Arousal; Emotion; Listening; Music; Theory",
  language  = "en",
  issn      = "1571-0645, 1873-1457",
  pmid      = "23769678",
  doi       = "10.1016/j.plrev.2013.05.008"
}

@ARTICLE{Huron2011-ql,
  title     = "Why is sad music pleasurable? A possible role for prolactin",
  author    = "Huron, David",
  abstract  = "A hedonic theory of music and sadness is proposed. Some
               listeners report that nominally sad music genuinely makes them
               feel sad. It is suggested that, for these listeners, sad affect
               is evoked through a combination of empathetic responses to sad
               acoustic features, learned associations, and cognitive
               rumination. Among those listeners who report sad feelings, some
               report an accompanying positive affect, whereas others report
               the experience to be solely negative. Levels of the hormone
               prolactin increase when sad ? producing a consoling
               psychological effect suggestive of a homeostatic function. It is
               proposed that variations in prolactin levels might account for
               the variability in individual hedonic responses. Specifically,
               it is conjectured that high prolactin concentrations are
               associated with pleasurable music-induced sadness, whereas low
               prolactin concentrations are associated with unpleasant
               music-induced sadness.",
  journal   = "Musicae scientiae: the journal of the European Society for the
               Cognitive Sciences of Music",
  publisher = "SAGE Publications Ltd",
  volume    =  15,
  number    =  2,
  pages     = "146--158",
  month     =  jul,
  year      =  2011,
  issn      = "1029-8649",
  doi       = "10.1177/1029864911401171"
}

@ARTICLE{Eerola2018-rk,
  title    = "An integrative review of the enjoyment of sadness associated with
              music",
  author   = "Eerola, Tuomas and Vuoskoski, Jonna K and Peltola, Henna-Riikka
              and Putkinen, Vesa and Sch{\"a}fer, Katharina",
  abstract = "The recent surge of interest towards the paradoxical pleasure
              produced by sad music has generated a handful of theories and an
              array of empirical explorations on the topic. However, none of
              these have attempted to weigh the existing evidence in a
              systematic fashion. The present work puts forward an integrative
              framework laid out over three levels of explanation - biological,
              psycho-social, and cultural - to compare and integrate the
              existing findings in a meaningful way. First, we review the
              evidence pertinent to experiences of pleasure associated with sad
              music from the fields of neuroscience, psychophysiology, and
              endocrinology. Then, the psychological and interpersonal
              mechanisms underlying the recognition and induction of sadness in
              the context of music are combined with putative explanations
              ranging from social surrogacy and nostalgia to feelings of being
              moved. Finally, we address the cultural aspects of the paradox -
              the extent to which it is embedded in the Western notion of music
              as an aesthetic, contemplative object - by synthesising findings
              from history, ethnography, and empirical studies. Furthermore, we
              complement these explanations by considering the particularly
              significant meanings that sadness portrayed in art can evoke in
              some perceivers. Our central claim is that one cannot attribute
              the enjoyment of sadness fully to any one of these levels, but to
              a chain of functionalities afforded by each level. Each
              explanatory level has several putative explanations and its own
              shift towards positive valence, but none of them deliver the full
              transformation from a highly negative experience to a fully
              enjoyable experience alone. The current evidence within this
              framework ranges from weak to non-existent at the biological
              level, moderate at the psychological level, and suggestive at the
              cultural level. We propose a series of focussed topics for future
              investigation that would allow to deconstruct the drivers and
              constraints of the processes leading to pleasurable music-related
              sadness.",
  journal  = "Physics of life reviews",
  volume   =  25,
  pages    = "100--121",
  month    =  aug,
  year     =  2018,
  keywords = "Emotions; Enjoyment; Hedonic shift; Music; Pleasure; Sadness",
  language = "en",
  issn     = "1571-0645, 1873-1457",
  pmid     = "29198528",
  doi      = "10.1016/j.plrev.2017.11.016"
}

@ARTICLE{Chmiel2017-bg,
  title     = "Back to the inverted-U for music preference: A review of the
               literature",
  author    = "Chmiel, Anthony and Schubert, Emery",
  abstract  = "This study investigated the inverted-U model of preference for
               music as a function of collative variables (especially
               familiarity and complexity) over the last 115 years. The results
               of 57 studies on music preference were categorized according to
               their patterns of preference. Fifty of the 57 studies (87.7\%)
               were categorized as compatible with an overarching (segmented)
               inverted-U model, while the results of five studies (8.8\%) were
               interpreted as mixed, showing both compatible and incompatible
               results. Two studies (3.5\%) were categorized as completely
               incompatible with the model. In contrast to authors who describe
               the model as defunct, this review has observed that studies
               producing results compatible with the inverted-U are still
               prevalent. We propose that while there may be inconsistencies
               with Berlyne?s psychobiological theory from a scientific,
               arousal-based standpoint, the inverted-U model is able to
               explain a considerable amount of data. Rather, it seems that
               research interests have moved elsewhere, but caution is urged in
               asserting denial or dismissal of the relationship in music
               preference research.",
  journal   = "Psychology of Music",
  publisher = "SAGE Publications Ltd",
  volume    =  45,
  number    =  6,
  pages     = "886--909",
  month     =  nov,
  year      =  2017,
  issn      = "0305-7356",
  doi       = "10.1177/0305735617697507"
}

@ARTICLE{Juslin2008-km,
  title    = "Emotional responses to music: the need to consider underlying
              mechanisms",
  author   = "Juslin, Patrik N and V{\"a}stfj{\"a}ll, Daniel",
  abstract = "Research indicates that people value music primarily because of
              the emotions it evokes. Yet, the notion of musical emotions
              remains controversial, and researchers have so far been unable to
              offer a satisfactory account of such emotions. We argue that the
              study of musical emotions has suffered from a neglect of
              underlying mechanisms. Specifically, researchers have studied
              musical emotions without regard to how they were evoked, or have
              assumed that the emotions must be based on the ``default''
              mechanism for emotion induction, a cognitive appraisal. Here, we
              present a novel theoretical framework featuring six additional
              mechanisms through which music listening may induce emotions: (1)
              brain stem reflexes, (2) evaluative conditioning, (3) emotional
              contagion, (4) visual imagery, (5) episodic memory, and (6)
              musical expectancy. We propose that these mechanisms differ
              regarding such characteristics as their information focus,
              ontogenetic development, key brain regions, cultural impact,
              induction speed, degree of volitional influence, modularity, and
              dependence on musical structure. By synthesizing theory and
              findings from different domains, we are able to provide the first
              set of hypotheses that can help researchers to distinguish among
              the mechanisms. We show that failure to control for the
              underlying mechanism may lead to inconsistent or
              non-interpretable findings. Thus, we argue that the new framework
              may guide future research and help to resolve previous
              disagreements in the field. We conclude that music evokes
              emotions through mechanisms that are not unique to music, and
              that the study of musical emotions could benefit the emotion
              field as a whole by providing novel paradigms for emotion
              induction.",
  journal  = "Behavioral and brain sciences",
  volume   =  31,
  number   =  5,
  pages    = "559--75; discussion 575--621",
  month    =  oct,
  year     =  2008,
  keywords = "affect; arousal; brain; emotion; induction; mechanism; memory;
              music; theory",
  language = "en",
  issn     = "0140-525X, 1469-1825",
  pmid     = "18826699",
  doi      = "10.1017/S0140525X08005293"
}

@ARTICLE{Jacoby2019-ib,
  title     = "Universal and non-universal features of musical pitch perception
               revealed by singing",
  author    = "Jacoby, Nori and Undurraga, Eduardo A and McPherson, Malinda J
               and Vald{\'e}s, Joaqu{\'\i}n and Ossand{\'o}n, Tom{\'a}s and
               McDermott, Josh H",
  abstract  = "Musical pitch perception is argued to result from nonmusical
               biological constraints and thus to have similar characteristics
               across cultures, but its universality remains unclear. We probed
               pitch representations in residents of the Bolivian Amazon-the
               Tsimane', who live in relative isolation from Western culture-as
               well as US musicians and non-musicians. Participants sang back
               tone sequences presented in different frequency ranges. Sung
               responses of Amazonian and US participants approximately
               replicated heard intervals on a logarithmic scale, even for
               tones outside the singing range. Moreover, Amazonian and US
               reproductions both deteriorated for high-frequency tones even
               though they were fully audible. But whereas US participants
               tended to reproduce notes an integer number of octaves above or
               below the heard tones, Amazonians did not, ignoring the note
               ``chroma'' (C, D, etc.). Chroma matching in US participants was
               more pronounced in US musicians than non-musicians, was not
               affected by feedback, and was correlated with similarity-based
               measures of octave equivalence as well as the ability to match
               the absolute f0 of a stimulus in the singing range. The results
               suggest the cross-cultural presence of logarithmic scales for
               pitch, and biological constraints on the limits of pitch, but
               indicate that octave equivalence may be culturally contingent,
               plausibly dependent on pitch representations that develop from
               experience with particular musical systems. VIDEO ABSTRACT.",
  journal   = "Current biology",
  publisher = "Elsevier",
  volume    =  29,
  number    =  19,
  pages     = "3229--3243.e12",
  month     =  oct,
  year      =  2019,
  keywords  = "Tsimane'; absolute pitch; bio-musicology; cross-cultural
               psychology; mental scales; music cognition; octave equivalence;
               pitch; relative pitch; singing",
  language  = "en",
  issn      = "0960-9822, 1879-0445",
  pmid      = "31543451",
  doi       = "10.1016/j.cub.2019.08.020"
}

@ARTICLE{Agrawal2021-za,
  title     = "Time-of-day practices echo circadian physiological arousal: An
               enculturated embodied practice in Hindustani classical music",
  author    = "Agrawal, Tanushree and Shanahan, Daniel and Huron, David and
               Keller, Hannah",
  abstract  = "Traditionally, various Hindustani (North Indian) ragas have been
               performed at specific times of day, such as dawn, dusk, midday,
               and evening. Human physiology also exhibits common circadian
               patterns, with reduced arousal at night, rising during the
               morning, culminating in peak arousal, and then declining arousal
               towards the end of the day. This raises the question of how and
               whether the musical features of ragas for each time of day are
               related to these circadian patterns of arousal. We formally
               examined associations between traditionally designated
               time-of-day classifications and musical features from 65
               Hindustani raga performances. Our results showed that only
               pitch-related features are predictive of time-of-day
               classifications. Surprisingly, non-pitch factors known to
               correlate with arousal, such as tempo, did not covary with raga
               time-of-day practices. In general, the results are consistent
               with rules for North Indian raga performances described by
               Vishnu Narayan Bhatkhande (1860?1936) that emphasize the
               presence or prevalence of particular tones in the raga. The
               results point to a combination of enculturated and embodied
               influences in conveying musical arousal. Specifically, they
               suggest that while time-of-day-related raga listening practices
               may have been initially influenced by embodied processes, they
               have ultimately been reshaped by pitch-related cultural norms.",
  journal   = "Musicae scientiae: the journal of the European Society for the
               Cognitive Sciences of Music",
  publisher = "SAGE Publications Ltd",
  pages     = "10298649211020053",
  month     =  jun,
  year      =  2021,
  keywords  = "To read",
  issn      = "1029-8649",
  doi       = "10.1177/10298649211020053"
}

@ARTICLE{Morfi2021-gw,
  title     = "Deep perceptual embeddings for unlabelled animal sound events",
  author    = "Morfi, Veronica and Lachlan, Robert F and Stowell, Dan",
  abstract  = "Evaluating sound similarity is a fundamental building block in
               acoustic perception and computational analysis. Traditional
               data-driven analyses of perceptual similarity are based on
               heuristics or simplified linear models, and are thus limited.
               Deep learning embeddings, often using triplet networks, have
               been useful in many fields. However, such networks are usually
               trained using large class-labelled datasets. Such labels are not
               always feasible to acquire. We explore data-driven neural
               embeddings for sound event representation when class labels are
               absent, instead utilising proxies of perceptual similarity
               judgements. Ultimately, our target is to create a perceptual
               embedding space that reflects animals' perception of sound. We
               create deep perceptual embeddings for bird sounds using triplet
               models. In order to deal with the challenging nature of triplet
               loss training with the lack of class-labelled data, we utilise
               multidimensional scaling (MDS) pretraining, attention pooling,
               and a triplet mining scheme. We also evaluate the advantage of
               triplet learning compared to learning a neural embedding from a
               model trained on MDS alone. Using computational proxies of
               similarity judgements, we demonstrate the feasibility of the
               method to develop perceptual models for a wide range of data
               based on behavioural judgements, helping us understand how
               animals perceive sounds.",
  journal   = "The Journal of the Acoustical Society of America",
  publisher = "Acoustical Society of America",
  volume    =  150,
  number    =  1,
  pages     = "2--11",
  month     =  jul,
  year      =  2021,
  issn      = "0001-4966",
  doi       = "10.1121/10.0005475"
}

@ARTICLE{You2021-qe,
  title    = "Contextual prediction modulates musical tension: Evidence from
              behavioral and neural responses",
  author   = "You, Siqi and Sun, Lijun and Li, Xiaoqing and Yang, Yufang",
  abstract = "Tension is a bridge between music structure and emotion. It is
              known that tension is affected by prediction in music listening
              as music unfolds. Combining behavioral and neural responses, the
              current research investigated how musical predictions influence
              tension in the process of prediction build-up based on musical
              context (anticipatory stage) and its integration with upcoming
              stimuli (integration stage). The results showed that, at the
              anticipatory stage, compared with high-prediction conditions, in
              low-prediction conditions tension curve changed faster and
              unstable, and a larger N5 in ERP response was elicited.
              Furthermore, at the integration stage, compared with congruent
              conditions, in incongruent conditions the behavioral rating of
              tension were higher regardless of the predictability of the final
              chord; a right negativity and P600 were elicited, and the
              amplitude of P600 was modulated by the predictability of the
              final chord. These results indicated that the effect of
              prediction on tension was modulated by contextual predictability.
              The findings provide a more comprehensive view on how musical
              prediction affects musical tension.",
  journal  = "Brain and cognition",
  volume   =  152,
  pages    = "105771",
  month    =  jul,
  year     =  2021,
  keywords = "Anticipatory processing; Contextual prediction; EEG; Integrated
              processing; Tension;To read",
  language = "en",
  issn     = "0278-2626, 1090-2147",
  pmid     = "34217125",
  doi      = "10.1016/j.bandc.2021.105771"
}

@UNPUBLISHED{De_Cheveigne2021-au,
  title    = "Why is the perceptual octave stretched? An account based on
              mismatched time constants within the auditory brainstem",
  author   = "de Cheveign{\'e}, Alain",
  abstract = "This paper suggests an explanation for listener's greater
              tolerance to positive than negative mistuning of the higher tone
              within an octave pair. It hypothesizes a neu- ral circuit tuned
              to cancel the lower tone, that also cancels the higher tone if
              that tone is in tune. Imperfect cancellation is the cue to
              mistuning of the octave. The circuit involves two pathways, one
              delayed with respect to the other, that feed a
              coincidence-counting neuron via excitatory and inhibitory
              synapses. A mismatch between the time constants of these two
              synapses results in an asymmetry in sen- sitivity to mismatch.
              Specifically, if the time constant of the delayed pathway is
              greater than that of the direct pathway, there is a greater
              tolerance to positive than to negative mistuning, which can lead
              to a perceptual``stretch'' of the octave. The model is applicable
              to both harmonic and -- with qualification -- melodic oc- taves.
              The paper describes the model and reviews the evidence from
              auditory psychophysics and physiology in favor -- or against --
              it.",
  month    =  jul,
  year     =  2021,
  keywords = "To read",
  doi      = "10.31234/osf.io/3aqsz"
}

@ARTICLE{Perlman1996-zc,
  title     = "An experimental study of internal interval standards in Javanese
               and Western musicians",
  author    = "Perlman, Marc and Krumhansl, Carol L",
  abstract  = "Six Javanese and six Western musicians performed a
               magnitude-estimation task using 36 melodic intervals ranging
               from 60 to 760 cents at 20-cent increments. Several musicians
               displayed well-defined regions of confusion in which a range of
               intervals was assigned approximately equal magnitude estimates.
               The results suggest that these listeners assimilate the
               intervals to a set of internal interval standards. No evidence
               for assimilation was found for other musicians in both groups,
               some of whom made highly accurate estimates. For the Javanese
               musicians who showed assimilation to internal interval
               standards, the regions corresponded to the two Javanese tuning
               systems, slendro and pelog. For the Western musicians, the
               regions corresponded to the equal-tempered scale. The relatively
               wider regions of confusion for the Javanese musicians may
               reflect the greater variability of intonation in Java. In
               addition, the Javanese musicians seemed able to choose between
               internal interval standards based on the two tuning systems.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  14,
  number    =  2,
  pages     = "95--116",
  month     =  dec,
  year      =  1996,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.2307/40285714"
}

@ARTICLE{Singh2021-ag,
  title     = "The Sympathetic Plot, Its Psychological Origins, and
               Implications for the Evolution of Fiction",
  author    = "Singh, Manvir",
  abstract  = "The sympathetic plot?featuring a goal-directed protagonist who
               confronts obstacles, overcomes them, and wins rewards?is
               ubiquitous. Here, I propose that it recurs because it
               entertains, engaging two sets of psychological mechanisms.
               First, it triggers mechanisms for learning about obstacles and
               how to overcome them. It builds interest by confronting a
               protagonist with a problem and induces satisfaction when the
               problem is solved. Second, it evokes sympathetic joy. It
               establishes the protagonist as an ideal cooperative partner
               pursuing a goal, appealing to mechanisms for helping. When the
               protagonist succeeds, they receive rewards, and audiences feel
               sympathetic joy, an emotion normally triggered when
               beneficiaries triumph. The capacities underlying the sympathetic
               plot evolved for learning and cooperation before being co-opted
               for entertainment.",
  journal   = "Emotion review: journal of the International Society for
               Research on Emotion",
  publisher = "SAGE Publications",
  volume    =  13,
  number    =  3,
  pages     = "183--198",
  month     =  jul,
  year      =  2021,
  keywords  = "To read",
  issn      = "1754-0739",
  doi       = "10.1177/17540739211022824"
}

@ARTICLE{Hall2021-li,
  title     = "A model of large-scale thematic structure",
  author    = "Hall, Edward T R and Pearce, Marcus T",
  abstract  = "The coherent organisation of thematic material into large-scale
               structures within a composition is an important concept in both
               traditional and cognitive theories of music. However, empirical
               evidence supporting their perception is scarce. Providing a more
               nuanced approach, this paper introduces a computational model of
               hypothesised cognitive mechanisms underlying perception of
               large-scale thematic structure. Repetition detection based on
               statistical learning forms the model's foundation, hypothesising
               that predictability arising from repetition creates perceived
               thematic coherence. Measures are produced that characterise
               structural properties of a corpus of 623 monophonic
               compositions. Exploratory analysis reveals the extent to which
               these measures vary systematically and independently.",
  journal   = "Journal of New Music Research",
  publisher = "Routledge",
  volume    =  50,
  number    =  3,
  pages     = "220--241",
  month     =  may,
  year      =  2021,
  issn      = "0929-8215",
  doi       = "10.1080/09298215.2021.1930062"
}

@ARTICLE{Eerola2022-fm,
  title     = "Register impacts perceptual consonance through roughness and
               sharpness",
  author    = "Eerola, Tuomas and Lahdelma, Imre",
  abstract  = "The perception of consonance and dissonance in intervals and
               chords is influenced by psychoacoustic and cultural factors.
               Past research has provided conflicting observations about the
               role of frequency in assessing musical consonance that may stem
               from comparisons of limited frequency bands without much
               theorizing or modeling. Here we examine the effect of register
               on perceptual consonance of chords. Based on two acoustic
               principles, we predict a decrease in consonance at low
               frequencies (roughness) and a decrease of consonance at high
               frequencies (sharpness). Due to these two separate principles,
               we hypothesize that frequency will have a curvilinear impact on
               consonance. A selection of tetrads varying in consonance were
               presented in seven registers spanning 30 to 2600 Hz. Fifty-five
               participants rated the stimuli in an online experiment. The
               effect of register on consonance ratings was clear and largely
               according to the predictions; The low registers impacted
               consonance negatively and the highest two registers also
               received significantly lower consonance ratings than the middle
               registers. The impact of register on consonance could be
               accurately described with a cubic relationship. Overall, the
               influence of roughness was more pronounced on consonance ratings
               than sharpness. Together, these findings clarify previous
               empirical efforts to model the effect of frequency on consonance
               through basic acoustic principles. They further suggest that a
               credible account of consonance and dissonance in music needs to
               incorporate register.",
  journal   = "Psychonomic bulletin \& review",
  publisher = "Springer",
  volume    =  29,
  number    =  3,
  pages     = "800--808",
  month     =  jun,
  year      =  2022,
  keywords  = "Consonance; Dissonance; Harmonicity; Perception; Register;
               Roughness;To read",
  language  = "en",
  issn      = "1069-9384, 1531-5320",
  pmid      = "34921342",
  doi       = "10.3758/s13423-021-02033-5"
}

@ARTICLE{Moss2021-ya,
  title     = "Discovering Tonal Profiles with Latent Dirichlet Allocation",
  author    = "Moss, Fabian C and Rohrmeier, Martin",
  abstract  = "Music analysis, in particular harmonic analysis, is concerned
               with the way pitches are organized in pieces of music, and a
               range of empirical applications have been developed, for
               example, for chord recognition or key finding. Naturally, these
               approaches rely on some operationalization of the concepts they
               aim to investigate. In this study, we take a complementary
               approach and discover latent tonal structures in an unsupervised
               manner. We use the topic model Latent Dirichlet Allocation and
               apply it to a large historical corpus of musical pieces from the
               Western classical tradition. This method conceives topics as
               distributions of pitch classes without assuming a priori that
               they correspond to either chords, keys, or other harmonic
               phenomena. To illustrate the generative process assumed by the
               model, we create an artificial corpus with arbitrary parameter
               settings and compare the sampled pieces to real compositions.
               The results we obtain by applying the topic model to the musical
               corpus show that the inferred topics have music-theoretically
               meaningful interpretations. In particular, topics cover
               contiguous segments on the line of fifths and mostly correspond
               to diatonic sets. Moreover, tracing the prominence of topics
               over the course of music history over ?600 years reflects
               changes in the ways pitch classes are employed in musical
               compositions and reveals particularly strong changes at the
               transition from common-practice to extended tonality in the 19th
               century.",
  journal   = "Music \& Science",
  publisher = "SAGE Publications Ltd",
  volume    =  4,
  pages     = "20592043211048827",
  month     =  jan,
  year      =  2021,
  keywords  = "To read",
  issn      = "2059-2043",
  doi       = "10.1177/20592043211048827"
}

@UNPUBLISHED{Jacoby2021-xp,
  title    = "Universality and cross-cultural variation in mental
              representations of music revealed by global comparison of rhythm
              priors",
  author   = "Jacoby, Nori and Polak, Rainer and Grahn, Jessica and Cameron,
              Daniel J and Lee, Kyung M and Godoy, Ricardo and Undurraga,
              Eduardo A and Huanca, Tomas and Thalwitzer, Timon and Doumbia,
              Noumouk{\'e} and al., Et",
  abstract = "Music is present in every known society, yet varies from place to
              place. What is universal to the perception of music? We measured
              a signature of mental representations of rhythm in 923
              participants from 39 participant groups in 15 countries across 5
              continents, spanning urban societies, indigenous populations, and
              online participants. Listeners reproduced random ``seed''
              rhythms; their reproductions were fed back as the stimulus (as in
              the game of ``telephone''), such that their biases (the prior)
              could be estimated from the distribution of reproductions. Every
              tested group showed a prior with peaks at integer ratio rhythms,
              suggesting that discrete rhythm ``categories'' at small integer
              ratios are universal. The occurrence and relative importance of
              different integer ratio categories varied across groups, often
              reflecting local musical systems. However, university students
              and online participants in non-Western countries tended to
              resemble Western participants, underrepresenting the variability
              otherwise evident across cultures. The results suggest the
              universality of discrete mental representations of music while
              showing their interaction with culture-specific traditions.",
  month    =  jul,
  year     =  2021,
  keywords = "categorical perception; cognitive science; cross-cultural
              research; music; rhythm",
  doi      = "10.31234/osf.io/b879v"
}

@ARTICLE{Ferreri2021-gs,
  title    = "Dopamine modulations of reward-driven music memory consolidation",
  author   = "Ferreri, Laura and Mas-Herrero, Ernest and Cardona, Gemma and
              Zatorre, Robert J and Antonijoan, Rosa M and Valle, Marta and
              Riba, Jordi and Ripoll{\'e}s, Pablo and Rodriguez-Fornells,
              Antoni",
  abstract = "Music listening provides one of the most significant abstract
              rewards for humans because hearing music activates the
              dopaminergic mesolimbic system. Given the strong link between
              reward, dopamine, and memory, we aimed here to investigate the
              hypothesis that dopamine-dependent musical reward can drive
              memory improvements. Twenty-nine healthy participants of both
              sexes provided reward ratings of unfamiliar musical excerpts that
              had to be remembered following a consolidation period under three
              separate conditions: after the ingestion of a dopaminergic
              antagonist, a dopaminergic precursor, or a placebo. Linear mixed
              modeling of the intervention data showed that the effect of
              reward on memory-i.e., the greater the reward experienced while
              listening to the musical excerpts, the better the memory
              recollection performance-was modulated by both dopaminergic
              signaling and individual differences in reward processing.
              Greater pleasure was consistently associated with better memory
              outcomes in participants with high sensitivity to musical reward,
              but this effect was lost when dopaminergic signaling was
              disrupted in participants with average or low musical hedonia.
              Our work highlights the flexibility of the human dopaminergic
              system, which can enhance memory formation not only through
              explicit and/or primary reinforcers but also via abstract and
              aesthetic rewards such as music.",
  journal  = "Annals of the New York Academy of Sciences",
  month    =  jul,
  year     =  2021,
  keywords = "dopamine; memory; music; pleasure; reward;To read",
  language = "en",
  issn     = "0077-8923, 1749-6632",
  pmid     = "34247392",
  doi      = "10.1111/nyas.14656"
}

@ARTICLE{Baskerville1965-oa,
  title     = "Estimation of dry weight of tree components and total standing
               crop in conifer stands",
  author    = "Baskerville, G L",
  abstract  = "The distribution of dry weight among six tree components is
               shown for balsam fir from 1 to 10 inches in diameter at breast
               height. Component dry weight and total standing crop are
               estimated and compared for a 0.2?acre plot using methods based
               on every?tree summation, stand tables, and several short?cut
               techniques based on ?average? trees. It is concluded that the
               average tree approach is useful only where a rough estimate of
               total biomass is desired.",
  journal   = "Ecology",
  publisher = "Wiley",
  volume    =  46,
  number    =  6,
  pages     = "867--869",
  month     =  nov,
  year      =  1965,
  issn      = "0012-9658, 1939-9170",
  doi       = "10.2307/1934021"
}

@ARTICLE{Eerola2021-tm,
  title    = "Being moved by listening to unfamiliar sad music induces
              reward-related hormonal changes in empathic listeners",
  author   = "Eerola, Tuomas and Vuoskoski, Jonna K and Kautiainen, Hannu and
              Peltola, Henna-Riikka and Putkinen, Vesa and Sch{\"a}fer,
              Katharina",
  abstract = "Many people enjoy sad music, and the appeal for tragedy is
              widespread among the consumers of film and literature. The
              underlying mechanisms of such aesthetic experiences are not well
              understood. We tested whether pleasure induced by sad, unfamiliar
              instrumental music is explained with a homeostatic or a reward
              theory, each of which is associated with opposite patterns of
              changes in the key hormones. Sixty-two women listened to sad
              music (or nothing) while serum was collected for subsequent
              measurement of prolactin (PRL) and oxytocin (OT) and stress
              marker (cortisol and adrenocorticotropic hormone) concentrations.
              Two groups of participants were recruited on the basis of low and
              high trait empathy. In the high empathy group, PRL and OT levels
              were significantly lower with music compared with no music. And
              compared to the low empathy group, the high empathy individuals
              reported an increase of positive mood and higher ratings of being
              moved with music. None of the stress markers showed any changes
              across the conditions or the groups. These hormonal changes,
              inconsistent with the homeostatic theory proposed by Huron,
              exhibit a pattern expected of general reward. Our findings
              illuminate how unfamiliar and low arousal music may give rise to
              pleasurable experiences.",
  journal  = "Annals of the New York Academy of Sciences",
  month    =  jul,
  year     =  2021,
  keywords = "being moved; cortisol; music; oxytocin; prolactin; sadness;To
              read",
  language = "en",
  issn     = "0077-8923, 1749-6632",
  pmid     = "34273130",
  doi      = "10.1111/nyas.14660"
}

@INPROCEEDINGS{Brinkman2021-dz,
  title     = "{Cross-Cultural} Corpus Creation and Statistical Tendencies in
               Music",
  booktitle = "8th International Conference on Digital Libraries for Musicology",
  author    = "Brinkman, Andrew and Huron, David",
  abstract  = "The notion that some musical features can be found in a majority
               of cultures across the globe has garnered scholarly attention
               within the past decade [6, 29]. However, the lack of both large
               and diverse musical corpora has made furthering work on this
               topic difficult. This paper addresses this issue by testing four
               purported statistical tendencies in melodic organization across
               four substantial samples of culturally diverse music. Three
               corpora include musical samples of European, Native American,
               and Chinese folk music. The fourth, a new corpus devised
               specifically for the purposes of this study, is a corpus of
               cross-cultural folk music including material from nearly 700
               sampled audio recordings collected from 44 distinct cultures.
               The creation of this corpus involved establishing clear
               guidelines on how to parse audio materials, how to define a
               musical ``phrase'', and how to transcribe musical information
               (e.g. pitch and duration). While the primary purpose of this
               paper is to contribute to the dialogue on corpus creation
               techniques involving culturally diverse music, results for the
               testing of all four hypotheses are included. Results are
               consistent with a number of broad statistical tendencies in
               musical phrases that are evident above chance levels, and are
               common across the repertoires sampled. These include the
               tendency for small over large pitch movements, for large leaps
               to ascend, for musical phrases to fall in pitch, and for phrases
               to begin with an initial pitch rise. Limitations of our corpus
               creation methods and empirical tests are highlighted.",
  publisher = "Association for Computing Machinery",
  pages     = "14--22",
  series    = "DLfM '21",
  month     =  jul,
  year      =  2021,
  address   = "New York, NY, USA",
  keywords  = "empirical musicology, cross-culture, folk music, corpus
               creation;To read",
  location  = "Virtual Conference, GA, USA",
  isbn      = "9781450384292",
  doi       = "10.1145/3469013.3469016"
}

@INPROCEEDINGS{Giannos2021-op,
  title     = "Symbolic Encoding of Simultaneities: Re-designing the General
               Chord Type Representation",
  booktitle = "8th International Conference on Digital Libraries for Musicology",
  author    = "Giannos, Konstantinos and Cambouropoulos, Emilios",
  abstract  = "Encoding note simultaneities (chords) has been approached in
               different ways, such as Roman numerals for tonal harmony, or
               pitch class sets encountered in atonal and non-tonal music. A
               novel chord representation, the General Chord Type (GCT)
               representation, was developed to be adaptable to a broad variety
               of harmonic idioms from tonal to atonal. Given a binary
               classification of intervals into consonant or dissonant, GCT
               rearranges the notes of a given simultaneity such that the base
               of the chord encoding is consonant. This study proposes a
               refined elegant version of the GCT algorithm that takes into
               account a graded raking of intervallic consonance, maintains the
               core characteristics of GCT and resolves known problems such as
               certain types of chord ambiguities (more than one chord types
               for a single pitch collection) and orderings of intervals (wrong
               base/root and chord extensions).To evaluate the performance of
               the new version, common tonal chords, whose encodings are well
               established, are compared with encodings from both versions, as
               well with other existing encoding systems. In the novel
               algorithm, ambiguous outputs are reduced significantly,
               inversions are correctly identified, and foreign chord notes are
               organised towards the most dissonant top end of the encodings.
               The algorithm performs well in atonal contexts by encoding
               Tn-Types with great accuracy.",
  publisher = "Association for Computing Machinery",
  pages     = "67--74",
  series    = "DLfM '21",
  month     =  jul,
  year      =  2021,
  address   = "New York, NY, USA",
  keywords  = "symbolic music data, chord encoding, harmony, computational
               music analysis, automatic chord analysis;To read",
  location  = "Virtual Conference, GA, USA",
  isbn      = "9781450384292",
  doi       = "10.1145/3469013.3469022"
}

@UNPUBLISHED{Smit2021-ql,
  title    = "No evidence for a universal effect of major versus minor music on
              emotions in Papua New Guinea",
  author   = "Smit, Eline A and Milne, Andrew J and Sarvasy, Hannah and Dean,
              Roger",
  abstract = "Music is a vital part of most cultures and has a strong impact on
              emotions. In Western cultures, emotive valence (happiness and
              sadness) is strongly influenced by major and minor melodies and
              harmony (chords and their progressions). Yet, how pitch and
              harmony affect our emotions, and to what extent these effects are
              culturally mediated or universal, is hotly debated. Here, we
              report an experiment conducted in a remote cloud forest region of
              Papua New Guinea, across several communities with similar
              traditional music but differing levels of exposure to
              Western-influenced tonal music. One hundred and seventy
              participants were presented with pairs of major and minor
              cadences (chord progressions) and melodies, and chose which of
              them made them happier. The experiment was repeated by 60
              non-musicians and 19 musicians in Sydney, Australia. Bayesian
              analyses show that, for cadences, there is strong evidence that
              major induced greater reported happiness than minor in every
              community except one: the community with minimal exposure to
              Western-like music. For melodies, there is strong evidence that
              those with higher mean pitch (major melodies) induced greater
              happiness than those with lower mean pitch (minor melodies) in
              only one of the three PNG communities and in both Sydney groups.
              The results show that the emotive valence of major and minor is
              strongly associated with exposure to Western-influenced music and
              culture, and there is no evidence for universality.",
  month    =  jul,
  year     =  2021,
  keywords = "cross-cultural; emotion; harmony; major; minor; music perception;
              pitch; universality; valence;To read",
  doi      = "10.31234/osf.io/x7sjf"
}

@ARTICLE{Armitage2021-dy,
  title     = "Automatic responses to musical intervals: Contrasts in acoustic
               roughness predict affective priming in Western listeners",
  author    = "Armitage, James and Lahdelma, Imre and Eerola, Tuomas",
  abstract  = "The aim of the present study is to determine which acoustic
               components of harmonic consonance and dissonance influence
               automatic responses in a simple cognitive task. In a series of
               affective priming experiments, eight pairs of musical intervals
               were used to measure the influence of acoustic roughness and
               harmonicity on response times in a word-classification task
               conducted online. Interval pairs that contrasted in roughness
               induced a greater degree of affective priming than pairs that
               did not contrast in terms of their roughness. Contrasts in
               harmonicity did not induce affective priming. A follow-up
               experiment used detuned intervals to create higher levels of
               roughness contrasts. However, the detuning did not lead to any
               further increase in the size of the priming effect. More
               detailed analysis suggests that the presence of priming in
               intervals is binary: in the negative primes that create
               congruency effects the intervals' fundamentals and overtones
               coincide within the same equivalent rectangular bandwidth (i.e.,
               the minor and major seconds). Intervals that fall outside this
               equivalent rectangular bandwidth do not elicit priming effects,
               regardless of their dissonance or negative affect. The results
               are discussed in the context of recent developments in
               consonance/dissonance research and vocal similarity.",
  journal   = "The Journal of the Acoustical Society of America",
  publisher = "Acoustical Society of America",
  volume    =  150,
  number    =  1,
  pages     = "551--560",
  month     =  jul,
  year      =  2021,
  keywords  = "To read",
  issn      = "0001-4966",
  doi       = "10.1121/10.0005623"
}

@ARTICLE{Lieck2021-tf,
  title    = "Discretisation and continuity: The emergence of symbols in
              communication",
  author   = "Lieck, Robert and Rohrmeier, Martin",
  abstract = "Vocal signalling systems, as used by humans and various non-human
              animals, exhibit discrete and continuous properties that can
              naturally be used to express discrete and continuous information,
              such as distinct words to denote objects in the world and
              prosodic features to convey the emotions of the speaker. However,
              continuous aspects are not always expressed with the continuous
              properties of an utterance but are frequently categorised into
              discrete symbols. While the existence of symbols in communication
              is self-evident, the emergence of discretisation from a
              continuous space is not well understood. In this paper, we
              investigate the emergence of discrete symbols in regions with a
              continuous semantics by simulating the learning process of two
              agents that acquire a shared signalling system. The task is
              formalised as a reinforcement learning problem with a continuous
              form and meaning space. We identify two causes for the emergence
              of discretisation that do not originate in discrete semantics: 1)
              premature convergence to sub-optimal signalling conventions and
              2) topological mismatch between the continuous form space and the
              continuous semantic space. The insights presented in this paper
              shed light on the origins of discrete symbols, whose existence is
              assumed by a large body of research concerned with the emergence
              of syntactic structures and meaning in language.",
  journal  = "Cognition",
  volume   =  215,
  pages    = "104787",
  month    =  oct,
  year     =  2021,
  keywords = "Communication games; Reinforcement learning; Language evolution;
              Symbol grounding; Discretisation;To read",
  issn     = "0010-0277",
  doi      = "10.1016/j.cognition.2021.104787"
}

@ARTICLE{Eerola2021-sg,
  title    = "Being moved by listening to unfamiliar sad music induces
              reward-related hormonal changes in empathic listeners",
  author   = "Eerola, Tuomas and Vuoskoski, Jonna K and Kautiainen, Hannu and
              Peltola, Henna-Riikka and Putkinen, Vesa and Sch{\"a}fer,
              Katharina",
  abstract = "Many people enjoy sad music, and the appeal for tragedy is
              widespread among the consumers of film and literature. The
              underlying mechanisms of such aesthetic experiences are not well
              understood. We tested whether pleasure induced by sad, unfamiliar
              instrumental music is explained with a homeostatic or a reward
              theory, each of which is associated with opposite patterns of
              changes in the key hormones. Sixty-two women listened to sad
              music (or nothing) while serum was collected for subsequent
              measurement of prolactin (PRL) and oxytocin (OT) and stress
              marker (cortisol and adrenocorticotropic hormone) concentrations.
              Two groups of participants were recruited on the basis of low and
              high trait empathy. In the high empathy group, PRL and OT levels
              were significantly lower with music compared with no music. And
              compared to the low empathy group, the high empathy individuals
              reported an increase of positive mood and higher ratings of being
              moved with music. None of the stress markers showed any changes
              across the conditions or the groups. These hormonal changes,
              inconsistent with the homeostatic theory proposed by Huron,
              exhibit a pattern expected of general reward. Our findings
              illuminate how unfamiliar and low arousal music may give rise to
              pleasurable experiences.",
  journal  = "Annals of the New York Academy of Sciences",
  month    =  jul,
  year     =  2021,
  keywords = "being moved; cortisol; music; oxytocin; prolactin; sadness;To
              read",
  language = "en",
  issn     = "0077-8923, 1749-6632",
  pmid     = "34273130",
  doi      = "10.1111/nyas.14660"
}

@ARTICLE{Eerola2021-wj,
  title     = "The anatomy of consonance/dissonance: Evaluating acoustic and
               cultural predictors across multiple datasets with chords",
  author    = "Eerola, Tuomas and Lahdelma, Imre",
  abstract  = "Acoustic and musical components of consonance and dissonance
               perception have been recently identified. This study expands the
               range of predictors of consonance and dissonance by three
               analytical operations. In Experiment 1, we identify the
               underlying structure of a number of central predictors of
               consonance and dissonance extracted from an extensive dataset of
               chords using a hierarchical cluster analysis. Four feature
               categories are identified largely confirming the existing three
               categories (roughness, harmonicity, familiarity), including
               spectral envelope as an additional category separate from these.
               In Experiment 2, we evaluate the current model of
               consonance/dissonance by Harrison and Pearce by an analysis of
               three previously published datasets. We use linear mixed models
               to optimize the choice of predictors and offer a revised model.
               We also propose and assess a number of new predictors
               representing familiarity. In Experiment 3, the model by Harrison
               and Pearce and our revised model are evaluated with nine
               datasets that provide empirical mean ratings of consonance and
               dissonance. The results show good prediction rates for the
               Harrison and Pearce model (62\%) and a still significantly
               better rate for the revised model (73\%). In the revised model,
               the harmonicity predictor of Harrison and Pearce?s model is
               replaced by Stolzenburg?s model, and a familiarity predictor
               coded through a simplified classification of chords replaces the
               original corpus-based model. The inclusion of spectral envelope
               as a new category is a minor addition to account for the
               consonance/dissonance ratings. With respect to the anatomy of
               consonance/dissonance, we analyze the collinearity of the
               predictors, which is addressed by principal component analysis
               of all predictors in Experiment 3. This captures the harmonicity
               and roughness predictors into one component; overall, the three
               components account for 66\% of the consonance/dissonance
               ratings, where the dominant variance explained comes from
               familiarity (46.2\%), followed by roughness/harmonicity
               (19.3\%).",
  journal   = "Music \& Science",
  publisher = "SAGE Publications Ltd",
  volume    =  4,
  month     =  jan,
  year      =  2021,
  issn      = "2059-2043",
  doi       = "10.1177/20592043211030471"
}

@ARTICLE{Bones2014-xf,
  title     = "Phase locked neural activity in the human brainstem predicts
               preference for musical consonance",
  author    = "Bones, Oliver and Hopkins, Kathryn and Krishnan, Ananthanarayan
               and Plack, Christopher J",
  abstract  = "When musical notes are combined to make a chord, the closeness
               of fit of the combined spectrum to a single harmonic series (the
               'harmonicity' of the chord) predicts the perceived consonance
               (how pleasant and stable the chord sounds; McDermott, Lehr, \&
               Oxenham, 2010). The distinction between consonance and
               dissonance is central to Western musical form. Harmonicity is
               represented in the temporal firing patterns of populations of
               brainstem neurons. The current study investigates the role of
               brainstem temporal coding of harmonicity in the perception of
               consonance. Individual preference for consonant over dissonant
               chords was measured using a rating scale for pairs of
               simultaneous notes. In order to investigate the effects of
               cochlear interactions, notes were presented in two ways: both
               notes to both ears or each note to different ears. The
               electrophysiological frequency following response (FFR),
               reflecting sustained neural activity in the brainstem
               synchronised to the stimulus, was also measured. When both notes
               were presented to both ears the perceptual distinction between
               consonant and dissonant chords was stronger than when the notes
               were presented to different ears. In the condition in which both
               notes were presented to the both ears additional low-frequency
               components, corresponding to difference tones resulting from
               nonlinear cochlear processing, were observable in the FFR
               effectively enhancing the neural harmonicity of consonant chords
               but not dissonant chords. Suppressing the cochlear envelope
               component of the FFR also suppressed the additional frequency
               components. This suggests that, in the case of consonant chords,
               difference tones generated by interactions between notes in the
               cochlea enhance the perception of consonance. Furthermore,
               individuals with a greater distinction between consonant and
               dissonant chords in the FFR to individual harmonics had a
               stronger preference for consonant over dissonant chords.
               Overall, the results provide compelling evidence for the role of
               neural temporal coding in the perception of consonance, and
               suggest that the representation of harmonicity in phase locked
               neural firing drives the perception of consonance.",
  journal   = "Neuropsychologia",
  publisher = "Elsevier",
  volume    =  58,
  pages     = "23--32",
  month     =  may,
  year      =  2014,
  keywords  = "Auditory brainstem; Frequency following response; Harmonicity;
               Individual differences; Musical consonance; Pitch;To read",
  language  = "en",
  issn      = "0028-3932, 1873-3514",
  pmid      = "24690415",
  doi       = "10.1016/j.neuropsychologia.2014.03.011",
  pmc       = "PMC4040538"
}

@ARTICLE{Wagner2021-zz,
  title    = "No evidence for attraction to consonance in budgerigars
              (Melopsittacus undulatus) from a place preference paradigm",
  author   = "Wagner, Bernhard and Bowling, Daniel and Hoeschele, Marisa",
  abstract = "Author(s): Wagner, Bernhard; Bowling, Daniel; Hoeschele, Marisa |
              Abstract: Tone combinations with small integer frequency ratios
              are perceived as pleasant and are referred to as ``consonant''.
              Human consonance preference has been connected to preference for
              sounds, such as the human voice, that inherently contain
              consonant intervals via the harmonic series. As such, we might
              expect other species with harmonic vocalizations to also show
              attraction to consonance. We tested budgerigars and humans in a
              place preference test. Subjects could freely spend time with
              consonant or dissonant versions of a piano melody. Time spent
              with stimulus types was used as a measure of attraction. Human
              females spent more time with consonant stimuli but males showed
              no preference. In budgerigars neither sex showed a preference.
              This did not change when repeating the experiment with consonant
              and dissonant versions of budgerigar sounds. The amount of
              nonlinearity in budgerigar vocalizations can explain these
              results engendering relevant implications for future
              cross-species consonance studies.",
  journal  = "Proceedings of the Annual Meeting of the Cognitive Science
              Society",
  volume   =  43,
  number   =  43,
  year     =  2021,
  keywords = "Social and Behavioral Sciences",
  issn     = "1069-7977"
}

@ARTICLE{Herff2021-dc,
  title    = "Hierarchical syntactic structure predicts listeners' sequence
              completion in music",
  author   = "Herff, Steffen A and Harasim, Daniel and Cecchetti, Gabriele and
              Finkensiep, Christoph and Rohrmeier, Martin Alois",
  abstract = "Author(s): Herff, Steffen A; Harasim, Daniel; Cecchetti,
              Gabriele; Finkensiep, Christoph; Rohrmeier, Martin Alois |
              Abstract: Studies in psycho-linguistics have provided compelling
              evidence that theoretical syntactic structures have cognitive
              correlates that inform and influence language perception.
              Generative grammar models also present a principled way to
              represent a plethora of hierarchical structures outside the
              domain of language. Hierarchical aspects of musical structure, in
              particular, are often described through grammar models. Whether
              such models carry perceptual relevance in music, however,
              requires further study. To address the descriptive adequacy of a
              grammar model in music, unfamiliar musical phrases consisting of
              chord progressions within the Jazz idiom were used, and zero to
              three chords were cut from the end of each phrase. A total of 150
              participants were then presented with these stimuli and asked to
              provide a Closure Response, that is to predict how many more
              chords (0, 1, 2, or 3) were expected before the chord progression
              was complete. Simultaneously, a grammar model of hierarchical
              structure as well as a bigram model were trained over a corpus of
              150 expert-annotated Jazz tunes. The models were then used to
              estimate probability distributions of Closure Responses in the
              stimuli presented to the participants. Bayesian mixed-effects
              models reveal that the models carry predictive value for the
              participants' response distributions and that the hierarchical
              model contains incremental predictive information over the bigram
              model. The present results suggest that -- akin to language --
              hierarchical relationships between musical events have a
              cognitive correlate, which influences the perception and
              interpretation of music.",
  journal  = "Proceedings of the Annual Meeting of the Cognitive Science
              Society",
  volume   =  43,
  number   =  43,
  year     =  2021,
  keywords = "Social and Behavioral Sciences",
  issn     = "1069-7977"
}

@ARTICLE{Harasim2021-ro,
  title    = "The Learnability of Goal-directedness in Jazz Music",
  author   = "Harasim, Daniel and O'Donnell, Timothy and Rohrmeier, Martin
              Alois",
  abstract = "Author(s): Harasim, Daniel; O'Donnell, Timothy; Rohrmeier, Martin
              Alois | Abstract: Musicians and listeners perceive dependency
              structures between musical events such as chords and keys. Music
              theory postulates the goal-directedness of such dependencies,
              which manifests in formal grammar models as right-headed
              (head-final, left-branching) phrase structure. Goal-directedness
              has a direct cognitive interpretation; dependencies that point
              forward in time can be understood as creating expectation, and
              the empirical correlates of this relationship are a topic of
              current psychological research. This study presents a
              computational grammar model that represents the abstract concept
              of headedness but does not encode properties specific to music.
              Bayesian grammar learning is applied to infer a grammar for Jazz
              and its headedness proportions from a corpus of Jazz-chord
              sequences. The results show that the inferred grammar is
              right-headed. A second simulation using artificial data was
              conducted to verify the correct functionality of the headedness
              induction. The goal-directedness of Jazz harmony is thus
              demonstrated to be learnable without music-specific prior
              knowledge.",
  journal  = "Proceedings of the Annual Meeting of the Cognitive Science
              Society",
  volume   =  43,
  number   =  43,
  year     =  2021,
  keywords = "Social and Behavioral Sciences",
  issn     = "1069-7977"
}

@ARTICLE{Hartshorne2018-wy,
  title     = "A critical period for second language acquisition: Evidence from
               2/3 million English speakers",
  author    = "Hartshorne, Joshua K and Tenenbaum, Joshua B and Pinker, Steven",
  abstract  = "Children learn language more easily than adults, though when and
               why this ability declines have been obscure for both empirical
               reasons (underpowered studies) and conceptual reasons (measuring
               the ultimate attainment of learners who started at different
               ages cannot by itself reveal changes in underlying learning
               ability). We address both limitations with a dataset of
               unprecedented size (669,498 native and non-native English
               speakers) and a computational model that estimates the
               trajectory of underlying learning ability by disentangling
               current age, age at first exposure, and years of experience.
               This allows us to provide the first direct estimate of how
               grammar-learning ability changes with age, finding that it is
               preserved almost to the crux of adulthood (17.4 years old) and
               then declines steadily. This finding held not only for
               ``difficult'' syntactic phenomena but also for ``easy''
               syntactic phenomena that are normally mastered early in
               acquisition. The results support the existence of a
               sharply-defined critical period for language acquisition, but
               the age of offset is much later than previously speculated. The
               size of the dataset also provides novel insight into several
               other outstanding questions in language acquisition.",
  journal   = "Cognition",
  publisher = "Elsevier",
  volume    =  177,
  pages     = "263--277",
  month     =  aug,
  year      =  2018,
  keywords  = "Critical period; L2 acquisition; Language acquisition",
  language  = "en",
  issn      = "0010-0277, 1873-7838",
  pmid      = "29729947",
  doi       = "10.1016/j.cognition.2018.04.007",
  pmc       = "PMC6559801"
}

@UNPUBLISHED{McBride2021-aa,
  title    = "Convergent evolution in a large cross-cultural database of
              musical scales",
  author   = "McBride, John and Tlusty, Tsvi",
  abstract = "Scales, sets of discrete pitches used to generate melodies, are
              thought to be one of the most universal features of music.
              Despite this, we know relatively little about how cross-cultural
              diversity, or how scales have evolved. We remedy this, in part,
              we assemble a cross-cultural database of empirical scale data,
              collected over the past century by various ethnomusicologists. We
              provide statistical analyses to highlight that certain intervals
              (e.g., the octave) are used frequently across cultures. Despite
              some diversity among scales, it is the similarities across
              societies which are most striking. Most scales are found close to
              equidistant 5- and 7-note scales; for 7-note scales this accounts
              for less than 1\% of all possible scales. In addition to
              providing these data and statistical analyses, we review how they
              may be used to explore the causes for convergent evolution in
              scales.",
  journal  = "PsyArXiv",
  month    =  jul,
  year     =  2021,
  keywords = "cross-cultural; cultural evolution; music; scales;To read",
  doi      = "10.31234/osf.io/eh5b3"
}

@ARTICLE{Liu2021-bp,
  title     = "Prominence and Expectation in Speech and Music Through the Lens
               of Pitch Processing",
  author    = "Liu, Xiaoluan",
  abstract  = "Speech and music reflect extraordinary aspects of human
               cognitive abilities. Pitch, as an important parameter in the
               auditory domain, has been the focus of previous research on the
               relations between speech and music. The present study continues
               this line of research by focusing on two aspects of pitch
               processing: pitch prominence and melodic expectation.
               Specifically, we examined the perceived boundary of prominence
               for focus/accent in speech and music, plus the comparison
               between the pitch expectation patterns of music and speech.
               Speech (Mandarin Chinese) and music stimuli were created with
               different interval steps that increased from 1 semitone to 12
               semitones from the third to the fourth word/note of a
               sentence/melody. The results showed that ratings of both
               accent/focus and expectation/surprise increased with increasing
               semitone distance from the baseline (though this pattern was
               mixed with tonal stability profiles for the melodies).
               Nevertheless, the perceived boundary of prominence was different
               for music and speech, with the boundary for detecting prominence
               in speech higher than that in music. Expectation also showed
               different patterns for speech and music. The results thus favor
               the suggestion that speech prosody and music melody tend to
               require specialized pitch patterns unique to their own
               respective communication purposes.",
  journal   = "Frontiers in psychology",
  publisher = "Frontiers Media SA",
  volume    =  12,
  year      =  2021,
  keywords  = "To read",
  language  = "en",
  doi       = "10.3389/fpsyg.2021.620640",
  pmc       = "PMC8295923"
}

@UNPUBLISHED{Kvam2021-eg,
  title    = "A unified theory of discrete and continuous responding",
  author   = "Kvam, Peter D and Marley, A A J and Heathcote, Andrew, Phd",
  abstract = "Understanding the cognitive processes underlying choice requires
              theories that can disentangle the representation of stimuli from
              the processes that map these representations onto observed
              responses. We develop a dynamic theory of how stimuli are mapped
              onto discrete (choice) and continuous response scales. It
              proposes that the mapping from stimuli to the input to an
              evidence accumulation process is accomplished using multiple
              reference points or ``anchors''. Evidence is accumulated until a
              threshold amount for a particular response is obtained, with the
              relative balance of support for each anchor at that time
              determining the response. We tested this Multiple Anchored
              Accumulation Theory (MAAT) using the results of two experiments
              requiring discrete or continuous responses to line length and
              color stimuli. We manipulated the number of options for discrete
              responses, the number of different stimuli, and the similarity
              amongst them, and compared the outcomes to continuous response
              conditions. We show that MAAT accounts for several key phenomena:
              more accurate choices and more skewed response distributions near
              the ends of a response scale; a decrease in accuracy and response
              speed as the number of discrete choice options increases; and
              longer response times and lower accuracy when discrete responses
              were more similar to one another. Our empirical and modeling
              results suggest that discrete and continuous response tasks can
              share a common evidence representation, and that the decision
              process is sensitive to the perceived similarity among the
              response options.",
  month    =  jul,
  year     =  2021,
  keywords = "absolute identification; cognitive modeling; computational
              modeling; continuous report; decision making; perception;To read",
  doi      = "10.31234/osf.io/dkybt"
}

@ARTICLE{Morgenstern2021-by,
  title    = "An image-computable model of human visual shape similarity",
  author   = "Morgenstern, Yaniv and Hartmann, Frieder and Schmidt, Filipp and
              Tiedemann, Henning and Prokott, Eugen and Maiello, Guido and
              Fleming, Roland W",
  abstract = "Shape is a defining feature of objects, and human observers can
              effortlessly compare shapes to determine how similar they are.
              Yet, to date, no image-computable model can predict how visually
              similar or different shapes appear. Such a model would be an
              invaluable tool for neuroscientists and could provide insights
              into computations underlying human shape perception. To address
              this need, we developed a model ('ShapeComp'), based on over 100
              shape features (e.g., area, compactness, Fourier descriptors).
              When trained to capture the variance in a database of >25,000
              animal silhouettes, ShapeComp accurately predicts human shape
              similarity judgments between pairs of shapes without fitting any
              parameters to human data. To test the model, we created carefully
              selected arrays of complex novel shapes using a Generative
              Adversarial Network trained on the animal silhouettes, which we
              presented to observers in a wide range of tasks. Our findings
              show that incorporating multiple ShapeComp dimensions facilitates
              the prediction of human shape similarity across a small number of
              shapes, and also captures much of the variance in the multiple
              arrangements of many shapes. ShapeComp outperforms both
              conventional pixel-based metrics and state-of-the-art
              convolutional neural networks, and can also be used to generate
              perceptually uniform stimulus sets, making it a powerful tool for
              investigating shape and object representations in the human
              brain.",
  journal  = "PLoS computational biology",
  volume   =  17,
  number   =  6,
  pages    = "e1008981",
  month    =  jun,
  year     =  2021,
  keywords = "To read",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "34061825",
  doi      = "10.1371/journal.pcbi.1008981",
  pmc      = "PMC8195351"
}

@ARTICLE{Nitzan2021-nv,
  title         = "{LARGE}: {Latent-Based} Regression through {GAN} Semantics",
  author        = "Nitzan, Yotam and Gal, Rinon and Brenner, Ofir and Cohen-Or,
                   Daniel",
  abstract      = "We propose a novel method for solving regression tasks using
                   few-shot or weak supervision. At the core of our method is
                   the fundamental observation that GANs are incredibly
                   successful at encoding semantic information within their
                   latent space, even in a completely unsupervised setting. For
                   modern generative frameworks, this semantic encoding
                   manifests as smooth, linear directions which affect image
                   attributes in a disentangled manner. These directions have
                   been widely used in GAN-based image editing. We show that
                   such directions are not only linear, but that the magnitude
                   of change induced on the respective attribute is
                   approximately linear with respect to the distance traveled
                   along them. By leveraging this observation, our method turns
                   a pre-trained GAN into a regression model, using as few as
                   two labeled samples. This enables solving regression tasks
                   on datasets and attributes which are difficult to produce
                   quality supervision for. Additionally, we show that the same
                   latent-distances can be used to sort collections of images
                   by the strength of given attributes, even in the absence of
                   explicit supervision. Extensive experimental evaluations
                   demonstrate that our method can be applied across a wide
                   range of domains, leverage multiple latent direction
                   discovery frameworks, and achieve state-of-the-art results
                   in few-shot and low-supervision settings, even when compared
                   to methods designed to tackle a single task.",
  month         =  jul,
  year          =  2021,
  keywords      = "To read",
  archivePrefix = "arXiv",
  eprint        = "2107.11186",
  primaryClass  = "cs.CV",
  arxivid       = "2107.11186"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cazden1945-lv,
  title     = "Musical Consonance and Dissonance: A Cultural Criterion",
  author    = "Cazden, Norman",
  abstract  = "… The neat and logical formulations of the natural sciences have
               little bearing on musical consonance and dissonance … For the
               evidence called upon by natural science has been inadequate. It
               has left out of account the decisive historical and cultural
               factors …",
  journal   = "Journal of Aesthetics and Art Criticism",
  publisher = "JSTOR",
  volume    =  4,
  number    =  1,
  pages     = "3",
  month     =  sep,
  year      =  1945,
  issn      = "0021-8529, 1540-6245",
  doi       = "10.2307/426253"
}

@BOOK{Helmholtz1875-fm,
  title     = "On the sensations of tone as a physiological basis for the
               theory of music",
  author    = "Helmholtz, Hermann L F",
  publisher = "Longmans, Green and Co",
  year      =  1875,
  address   = "New York"
}

@ARTICLE{Mantell2013-hd,
  title    = "Vocal imitation of song and speech",
  author   = "Mantell, James T and Pfordresher, Peter Q",
  abstract = "We report four experiments that explored the cognitive bases of
              vocal imitation. Specifically, we investigated the accuracy with
              which normal individuals vocally imitated the pitch-time
              trajectories of spoken sentences and sung melodies, presented in
              their original form and with phonetic information removed.
              Overall, participants imitated melodies more accurately than
              sentences with respect to absolute pitch but not with respect to
              relative pitch or timing (overall duration). Notably, the
              presence of phonetic information facilitated imitation of both
              melodies and speech. Analyses of individual differences across
              studies suggested that the accuracy of imitating song predicts
              accuracy of imitating speech. Overall, these results do not
              accord with accounts of modular pitch processing that emphasize
              information encapsulation.",
  journal  = "Cognition",
  volume   =  127,
  number   =  2,
  pages    = "177--202",
  month    =  may,
  year     =  2013,
  keywords = "To read",
  language = "en",
  issn     = "0010-0277, 1873-7838",
  pmid     = "23454792",
  doi      = "10.1016/j.cognition.2012.12.008"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Carcagno2019-tk,
  title    = "Consonance perception beyond the traditional existence region of
              pitch",
  author   = "Carcagno, Samuele and Lakhani, Saday and Plack, Christopher J",
  abstract = "Some theories posit that the perception of consonance is based on
              neural periodicity detection, which is dependent on accurate
              phase locking of auditory nerve fibers to features of the
              stimulus waveform. In the current study, 15 listeners were asked
              to rate the pleasantness of complex tone dyads (2 note chords)
              forming various harmonic intervals and bandpass filtered in a
              high-frequency region (all components >5.8 kHz), where phase
              locking to the rapid stimulus fine structure is thought to be
              severely degraded or absent. The two notes were presented to
              opposite ears. Consonant intervals (minor third and perfect
              fifth) received higher ratings than dissonant intervals (minor
              second and tritone). The results could not be explained in terms
              of phase locking to the slower waveform envelope because the
              preference for consonant intervals was higher when the stimuli
              were harmonic, compared to a condition in which they were made
              inharmonic by shifting their component frequencies by a constant
              offset, so as to preserve their envelope periodicity. Overall the
              results indicate that, if phase locking is indeed absent at
              frequencies greater than ∼5 kHz, neural periodicity detection is
              not necessary for the perception of consonance.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  146,
  number   =  4,
  pages    = "2279",
  month    =  oct,
  year     =  2019,
  language = "en",
  issn     = "0001-4966, 1520-8524",
  pmid     = "31671967",
  doi      = "10.1121/1.5127845"
}

@ARTICLE{Verhoef2021-fu,
  title    = "Melodic Universals Emerge or Are Sustained Through Cultural
              Evolution",
  author   = "Verhoef, Tessa and Ravignani, Andrea",
  abstract = "To understand why music is structured the way it is, we need an
              explanation that accounts for both the universality and
              variability found in musical traditions. Here we test whether
              statistical universals that have been identified for melodic
              structures in music can emerge as a result of cultural adaptation
              to human biases through iterated learning. We use data from an
              experiment in which artificial whistled systems, where sounds
              produced with a slide whistle were learned by human participants
              and transmitted multiple times from person to person. These sets
              of whistled signals needed to be memorised and recalled and the
              reproductions of one participant were used as the input set for
              the next. We tested for the emergence of seven different melodic
              features, such as discrete pitches, motivic patterns, or phrase
              repetition, and found some evidence for the presence of most of
              these statistical universals. We interpret this as promising
              evidence that, similarly to rhythmic universals, iterated
              learning experiments can also unearth melodic statistical
              universals. More, ideally cross-cultural, experiments are
              nonetheless needed. Simulating the cultural transmission of
              artificial proto-musical systems can help unravel the origins of
              universal tendencies in musical structures.",
  journal  = "Frontiers in psychology",
  volume   =  12,
  pages    = "3158",
  year     =  2021,
  keywords = "To read",
  issn     = "1664-1078",
  doi      = "10.3389/fpsyg.2021.668300"
}

@ARTICLE{Bidelman2009-gx,
  title    = "Neural correlates of consonance, dissonance, and the hierarchy of
              musical pitch in the human brainstem",
  author   = "Bidelman, Gavin M and Krishnan, Ananthanarayan",
  abstract = "Consonant and dissonant pitch relationships in music provide the
              foundation of melody and harmony, the building blocks of Western
              tonal music. We hypothesized that phase-locked neural activity
              within the brainstem may preserve information relevant to these
              important perceptual attributes of music. To this end, we
              measured brainstem frequency-following responses (FFRs) from
              nonmusicians in response to the dichotic presentation of nine
              musical intervals that varied in their degree of consonance and
              dissonance. Neural pitch salience was computed for each response
              using temporally based autocorrelation and harmonic pitch sieve
              analyses. Brainstem responses to consonant intervals were more
              robust and yielded stronger pitch salience than those to
              dissonant intervals. In addition, the ordering of neural pitch
              salience across musical intervals followed the hierarchical
              arrangement of pitch stipulated by Western music theory. Finally,
              pitch salience derived from neural data showed high
              correspondence with behavioral consonance judgments (r = 0.81).
              These results suggest that brainstem neural mechanisms mediating
              pitch processing show preferential encoding of consonant musical
              relationships and, furthermore, preserve the hierarchical pitch
              relationships found in music, even for individuals without formal
              musical training. We infer that the basic pitch relationships
              governing music may be rooted in low-level sensory processing and
              that an encoding scheme that favors consonant pitch relationships
              may be one reason why such intervals are preferred behaviorally.",
  journal  = "The Journal of Neuroscience",
  volume   =  29,
  number   =  42,
  pages    = "13165--13171",
  month    =  oct,
  year     =  2009,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "19846704",
  doi      = "10.1523/JNEUROSCI.3900-09.2009",
  pmc      = "PMC2804402"
}

@ARTICLE{Pelofi2021-jf,
  title    = "Asymmetry in scales enhances learning of new musical structures",
  author   = "Pelofi, Claire and Farbood, Morwaread M",
  abstract = "Despite the remarkable variability music displays across
              cultures, certain recurrent musical features motivate the
              hypothesis that fundamental cognitive principles constrain the
              way music is produced. One such feature concerns the structure of
              musical scales. The vast majority of musical cultures use scales
              that are not uniformly symmetric-that is, scales that contain
              notes spread unevenly across the octave. Here we present evidence
              that the structure of musical scales has a substantial impact on
              how listeners learn new musical systems. Three experiments were
              conducted to test the hypothesis that nonuniformity facilitates
              the processing of melodies. Novel melodic stimuli were composed
              based on artificial grammars using scales with different levels
              of symmetry. Experiment 1 tested the acquisition of tonal
              hierarchies and melodic regularities on three different 12-tone
              equal-tempered scales using a finite-state grammar. Experiments 2
              and 3 used more flexible Markov-chain grammars and were designed
              to generalize the effect to 14-tone and 16-tone equal-tempered
              scales. The results showed that performance was significantly
              enhanced by scale structures that specified the tonal space by
              providing unique intervallic relations between notes. These
              results suggest that the learning of novel musical systems is
              modulated by the symmetry of scales, which in turn may explain
              the prevalence of nonuniform scales across musical cultures.",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  118,
  number   =  31,
  month    =  aug,
  year     =  2021,
  keywords = "expectancies; musical cultures; musical scale; syntactic
              learning; universals;To read",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "34326245",
  doi      = "10.1073/pnas.2014725118"
}

@ARTICLE{McPherson2020-xn,
  title     = "Perceptual fusion of musical notes by native Amazonians suggests
               universal representations of musical intervals",
  author    = "McPherson, Malinda J and Dolan, Sophia E and Durango, Alex and
               Ossandon, Tomas and Vald{\'e}s, Joaqu{\'\i}n and Undurraga,
               Eduardo A and Jacoby, Nori and Godoy, Ricardo A and McDermott,
               Josh H",
  abstract  = "Music perception is plausibly constrained by universal
               perceptual mechanisms adapted to natural sounds. Such
               constraints could arise from our dependence on harmonic
               frequency spectra for segregating concurrent sounds, but
               evidence has been circumstantial. We measured the extent to
               which concurrent musical notes are misperceived as a single
               sound, testing Westerners as well as native Amazonians with
               limited exposure to Western music. Both groups were more likely
               to mistake note combinations related by simple integer ratios as
               single sounds ('fusion'). Thus, even with little exposure to
               Western harmony, acoustic constraints on sound segregation
               appear to induce perceptual structure on note combinations.
               However, fusion did not predict aesthetic judgments of intervals
               in Westerners, or in Amazonians, who were indifferent to
               consonance/dissonance. The results suggest universal perceptual
               mechanisms that could help explain cross-cultural regularities
               in musical systems, but indicate that these mechanisms interact
               with culture-specific influences to produce musical phenomena
               such as consonance.",
  journal   = "Nature communications",
  publisher = "nature.com",
  volume    =  11,
  number    =  1,
  pages     = "2786",
  month     =  jun,
  year      =  2020,
  language  = "en",
  issn      = "2041-1723",
  pmid      = "32493923",
  doi       = "10.1038/s41467-020-16448-6",
  pmc       = "PMC7270137"
}

@INBOOK{Patton2018-fv,
  title     = "Hermann von Helmholtz",
  booktitle = "The Stanford Encyclopedia of Philosophy",
  author    = "Patton, Lydia",
  editor    = "Zalta, Edward N",
  publisher = "Metaphysics Research Lab, Stanford University",
  edition   = "Winter 2018",
  year      =  2018,
  keywords  = "To read"
}

@ARTICLE{Fritsche2020-ri,
  title    = "A Bayesian and efficient observer model explains concurrent
              attractive and repulsive history biases in visual perception",
  author   = "Fritsche, Matthias and Spaak, Eelke and de Lange, Floris P",
  abstract = "Human perceptual decisions can be repelled away from (repulsive
              adaptation) or attracted towards recent visual experience
              (attractive serial dependence). It is currently unclear whether
              and how these repulsive and attractive biases interact during
              visual processing and what computational principles underlie
              these history dependencies. Here we disentangle repulsive and
              attractive biases by exploring their respective timescales. We
              find that perceptual decisions are concurrently attracted towards
              the short-term perceptual history and repelled from stimuli
              experienced up to minutes into the past. The temporal pattern of
              short-term attraction and long-term repulsion cannot be captured
              by an ideal Bayesian observer model alone. Instead, it is well
              captured by an ideal observer model with efficient encoding and
              Bayesian decoding of visual information in a slowly changing
              environment. Concurrent attractive and repulsive history biases
              in perceptual decisions may thus be the consequence of the need
              for visual processing to simultaneously satisfy constraints of
              efficiency and stability.",
  journal  = "eLife",
  volume   =  9,
  month    =  jun,
  year     =  2020,
  keywords = "Bayesian inference; efficient coding; history biases; human;
              neuroscience; sensory adaptation; serial dependence; visual
              perception;To read",
  language = "en",
  issn     = "2050-084X",
  pmid     = "32479264",
  doi      = "10.7554/eLife.55389",
  pmc      = "PMC7286693"
}

@UNPUBLISHED{Mok2021-fk,
  title    = "Web-based Psychoacoustics: Hearing Screening, Infrastructure, and
              Validation",
  author   = "Mok, Brittany A and Viswanathan, Vibha and Borjigin, Agudemu and
              Singh, Ravinderjit and Kafi, Homeira and Bharadwaj, Hari M",
  abstract = "Anonymous web-based experiments are increasingly and successfully
              used in many domains of behavioral research. However, online
              studies of auditory perception, especially of psychoacoustic
              phenomena pertaining to low-level sensory processing, are
              challenging because of limited available control of the
              acoustics, and the unknown hearing status of participants. Here,
              we outline our approach to mitigate these challenges and validate
              our procedures by comparing web-based measurements to labbased
              data on a range of classic psychoacoustic tasks. Individual tasks
              were created using jsPsych, an open-source javascript front-end
              library. Dynamic sequences of psychoacoustic tasks were
              implemented using Django, an open-source library for web
              applications, and combined with consent pages, questionnaires,
              and debriefing pages. Subjects were recruited via Prolific, a
              web-based human-subject marketplace. Guided by a meta-analysis of
              normative data, we developed and validated a screening procedure
              to select participants for (putative) normal-hearing status; this
              procedure combined thresholding of scores in a suprathreshold
              cocktail-party task with filtering based on survey responses.
              Headphone use was standardized by supplementing procedures from
              prior literature with a binaural hearing task. Individuals
              meeting all criteria were re-invited to complete a range of
              classic psychoacoustic tasks. Performance trends observed in
              re-invited participants were in excellent agreement with
              lab-based data for fundamental frequency discrimination, gap
              detection, sensitivity to interaural time delay and level
              difference, comodulation masking release, word identification,
              and consonant confusions. Our results suggest that web-based
              psychoacoustics is a viable complement to lab-based research.
              Source code for our infrastructure is also provided. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.05.10.443520",
  month    =  may,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.05.10.443520"
}

@UNPUBLISHED{Zhao2021-qz,
  title    = "Robust and efficient online auditory psychophysics with the right
              auditory hygiene",
  author   = "Zhao, Sijia and Brown, Christopher A and Holt, Lori L and Dick,
              Frederic",
  abstract = "Most human auditory psychophysics research has been conducted
              with extreme `auditory hygiene' in carefully controlled
              environments, with calibrated audio equipment, and potentially
              hours of repetitive testing with expert listeners. The
              incompatibility of web-based platforms with such experimental
              regimes would seem to preclude online auditory psychophysical
              paradigms, where success may hinge on absolute sound presentation
              level, reliably estimated perceptual thresholds, and sustained
              motivation and attention. Here, we introduce and validate a set
              of procedures that address these challenges and facilitate
              successful online auditory psychophysics. First, we establish a
              simple means of setting sound presentation levels where online
              participants serve as their own sound level meter. Across a set
              of three experiments conducted in person, we demonstrate the
              stability and robustness of this volume setting procedure both
              `in the wild' and in controlled settings. Second, we test
              participants' tone-in-noise thresholds using widely adopted
              online experiment platforms, and demonstrate that reliable
              threshold estimates can be derived in approximately one minute of
              testing. Third, using these sound level setting and thresholding
              procedures to establish participant-specific stimulus conditions,
              we show that frequency- selective attention can be reliably
              demonstrated in individual participants with an online
              implementation of the classic, yet challenging, probe signal
              psychophysics paradigm. Finally, we show how threshold and
              attentional measures relate to well-validated assays of
              participants' in-task motivation, fatigue, and confidence. This
              demonstrates the promise of asking new questions in auditory
              neuroscience with classic, yet challenging, online psychophysics
              paradigms. Code for implementing the tests is publicly available
              through Pavlovia ([pavlovia.org][1]) and Gorilla (gorilla.sc).
              \#\#\# Competing Interest Statement The authors have declared no
              competing interest. [1]: http://pavlovia.org",
  journal  = "bioRxiv",
  pages    = "2021.07.17.452796",
  month    =  jul,
  year     =  2021,
  keywords = "To read",
  language = "en",
  doi      = "10.1101/2021.07.17.452796"
}

@UNPUBLISHED{Mok2021-pp,
  title    = "Web-based Psychoacoustics: Hearing Screening, Infrastructure, and
              Validation",
  author   = "Mok, Brittany A and Viswanathan, Vibha and Borjigin, Agudemu and
              Singh, Ravinderjit and Kafi, Homeira and Bharadwaj, Hari M",
  abstract = "Anonymous web-based experiments are increasingly and successfully
              used in many domains of behavioral research. However, online
              studies of auditory perception, especially of psychoacoustic
              phenomena pertaining to low-level sensory processing, are
              challenging because of limited available control of the
              acoustics, and the unknown hearing status of participants. Here,
              we outline our approach to mitigate these challenges and validate
              our procedures by comparing web-based measurements to labbased
              data on a range of classic psychoacoustic tasks. Individual tasks
              were created using jsPsych, an open-source javascript front-end
              library. Dynamic sequences of psychoacoustic tasks were
              implemented using Django, an open-source library for web
              applications, and combined with consent pages, questionnaires,
              and debriefing pages. Subjects were recruited via Prolific, a
              web-based human-subject marketplace. Guided by a meta-analysis of
              normative data, we developed and validated a screening procedure
              to select participants for (putative) normal-hearing status; this
              procedure combined thresholding of scores in a suprathreshold
              cocktail-party task with filtering based on survey responses.
              Headphone use was standardized by supplementing procedures from
              prior literature with a binaural hearing task. Individuals
              meeting all criteria were re-invited to complete a range of
              classic psychoacoustic tasks. Performance trends observed in
              re-invited participants were in excellent agreement with
              lab-based data for fundamental frequency discrimination, gap
              detection, sensitivity to interaural time delay and level
              difference, comodulation masking release, word identification,
              and consonant confusions. Our results suggest that web-based
              psychoacoustics is a viable complement to lab-based research.
              Source code for our infrastructure is also provided. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.05.10.443520",
  month    =  may,
  year     =  2021,
  keywords = "To read",
  language = "en",
  doi      = "10.1101/2021.05.10.443520"
}

@ARTICLE{Ashley2002-zk,
  title     = "Do[n't] change a hair for me: The art of jazz rubato",
  author    = "Ashley, Richard",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  19,
  number    =  3,
  pages     = "311--332",
  month     =  mar,
  year      =  2002,
  keywords  = "To read",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2002.19.3.311"
}

@ARTICLE{Cannon2021-pv,
  title    = "How Beat Perception Co-opts Motor Neurophysiology",
  author   = "Cannon, Jonathan J and Patel, Aniruddh D",
  abstract = "Beat perception offers cognitive scientists an exciting
              opportunity to explore how cognition and action are intertwined
              in the brain even in the absence of movement. Many believe the
              motor system predicts the timing of beats, yet current models of
              beat perception do not specify how this is neurally implemented.
              Drawing on recent insights into the neurocomputational properties
              of the motor system, we propose that beat anticipation relies on
              action-like processes consisting of precisely patterned neural
              time-keeping activity in the supplementary motor area (SMA),
              orchestrated and sequenced by activity in the dorsal striatum. In
              addition to synthesizing recent advances in cognitive science and
              motor neuroscience, our framework provides testable predictions
              to guide future work.",
  journal  = "Trends in cognitive sciences",
  volume   =  25,
  number   =  2,
  pages    = "137--150",
  month    =  feb,
  year     =  2021,
  keywords = "basal ganglia; beat perception; motor system; music cognition;
              supplementary motor area;To read",
  language = "en",
  issn     = "1364-6613, 1879-307X",
  pmid     = "33353800",
  doi      = "10.1016/j.tics.2020.11.002"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cannon2020-gq,
  title     = "{PIPPET}: A Bayesian framework for generalized entrainment to
               stochastic rhythms",
  author    = "Cannon, J",
  abstract  = "When presented with complex rhythmic auditory stimuli, humans
               are able to track underlying temporal structure (eg, a
               ``beat''), both covertly and with their movements. This capacity
               goes far beyond that of a simple entrained oscillator, drawing
               on contextual and enculturated …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2020,
  keywords  = "To read"
}

@ARTICLE{Cannon2021-nm,
  title    = "Expectancy-based rhythmic entrainment as continuous Bayesian
              inference",
  author   = "Cannon, Jonathan",
  abstract = "When presented with complex rhythmic auditory stimuli, humans are
              able to track underlying temporal structure (e.g., a ``beat''),
              both covertly and with their movements. This capacity goes far
              beyond that of a simple entrained oscillator, drawing on
              contextual and enculturated timing expectations and adjusting
              rapidly to perturbations in event timing, phase, and tempo.
              Previous modeling work has described how entrainment to rhythms
              may be shaped by event timing expectations, but sheds little
              light on any underlying computational principles that could unify
              the phenomenon of expectation-based entrainment with other brain
              processes. Inspired by the predictive processing framework, we
              propose that the problem of rhythm tracking is naturally
              characterized as a problem of continuously estimating an
              underlying phase and tempo based on precise event times and their
              correspondence to timing expectations. We present two inference
              problems formalizing this insight: PIPPET (Phase Inference from
              Point Process Event Timing) and PATIPPET (Phase and Tempo
              Inference). Variational solutions to these inference problems
              resemble previous ``Dynamic Attending'' models of perceptual
              entrainment, but introduce new terms representing the dynamics of
              uncertainty and the influence of expectations in the absence of
              sensory events. These terms allow us to model multiple
              characteristics of covert and motor human rhythm tracking not
              addressed by other models, including sensitivity of error
              corrections to inter-event interval and perceived tempo changes
              induced by event omissions. We show that positing these novel
              influences in human entrainment yields a range of testable
              behavioral predictions. Guided by recent neurophysiological
              observations, we attempt to align the phase inference framework
              with a specific brain implementation. We also explore the
              potential of this normative framework to guide the interpretation
              of experimental data and serve as building blocks for even richer
              predictive processing and active inference models of timing.",
  journal  = "PLoS computational biology",
  volume   =  17,
  number   =  6,
  pages    = "e1009025",
  month    =  jun,
  year     =  2021,
  keywords = "To read",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "34106918",
  doi      = "10.1371/journal.pcbi.1009025",
  pmc      = "PMC8216548"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Large2016-wy,
  title     = "A neurodynamic account of musical tonality",
  author    = "Large, Edward W and Kim, Ji Chul and Flaig, Nicole Kristine and
               Bharucha, Jamshed J and Krumhansl, Carol Lynne",
  abstract  = "Science since antiquity has asked whether mathematical
               relationships among acoustic frequencies govern musical
               relationships. Psychophysics rejected frequency ratio theories,
               focusing on sensory phenomena predicted by linear analysis of
               sound. Cognitive psychologists have since focused on long-term
               exposure to the music of one's culture and short-term
               sensitivity to statistical regularities. Today evidence is
               rapidly mounting that oscillatory neurodynamics is an important
               source of nonlinear auditory responses. This …",
  journal   = "Music Perception: An Interdisciplinary Journal",
  publisher = "University of California Press",
  volume    =  33,
  number    =  3,
  pages     = "319--331",
  year      =  2016,
  keywords  = "To read"
}

@UNPUBLISHED{Andersen2021-vn,
  title    = "Play in Predictive Minds: A Cognitive Theory of Play",
  author   = "Andersen, Marc M and Roepstorff, Andreas",
  abstract = "Play occurs universally in human beings, and it has been a
              subject of considerable academic scrutiny for over 100 years. In
              this article, we propose a cognitive theory of play building on
              recent advances in cognitive and computational neuroscience that
              portray the human brain as an advanced prediction machine.
              Central to the theory is the idea that when an agent is free from
              the demands of certain competing cognitive systems, it may
              deliberately seek out and create surprising situations that
              gravitate towards sweet-spots of relative complexity. We argue
              that this framework can explain why humans play and why playing
              is so fun and rewarding.",
  month    =  feb,
  year     =  2021,
  keywords = "Learning; Niche Construction; Play; Predictive Processing;
              Surprise",
  doi      = "10.31234/osf.io/u86qy"
}

@ARTICLE{Tabas2021-st,
  title    = "Neural modelling of the encoding of fast frequency modulation",
  author   = "Tabas, Alejandro and von Kriegstein, Katharina",
  abstract = "Frequency modulation (FM) is a basic constituent of vocalisation
              in many animals as well as in humans. In human speech, short
              rising and falling FM-sweeps of around 50 ms duration, called
              formant transitions, characterise individual speech sounds. There
              are two representations of FM in the ascending auditory pathway:
              a spectral representation, holding the instantaneous frequency of
              the stimuli; and a sweep representation, consisting of neurons
              that respond selectively to FM direction. To-date computational
              models use feedforward mechanisms to explain FM encoding.
              However, from neuroanatomy we know that there are massive
              feedback projections in the auditory pathway. Here, we found that
              a classical FM-sweep perceptual effect, the sweep pitch shift,
              cannot be explained by standard feedforward processing models. We
              hypothesised that the sweep pitch shift is caused by a predictive
              feedback mechanism. To test this hypothesis, we developed a novel
              model of FM encoding incorporating a predictive interaction
              between the sweep and the spectral representation. The model was
              designed to encode sweeps of the duration, modulation rate, and
              modulation shape of formant transitions. It fully accounted for
              experimental data that we acquired in a perceptual experiment
              with human participants as well as previously published
              experimental results. We also designed a new class of stimuli for
              a second perceptual experiment to further validate the model.
              Combined, our results indicate that predictive interaction
              between the frequency encoding and direction encoding neural
              representations plays an important role in the neural processing
              of FM. In the brain, this mechanism is likely to occur at early
              stages of the processing hierarchy.",
  journal  = "PLoS computational biology",
  volume   =  17,
  number   =  3,
  pages    = "e1008787",
  month    =  mar,
  year     =  2021,
  keywords = "To read",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "33657098",
  doi      = "10.1371/journal.pcbi.1008787",
  pmc      = "PMC7959405"
}

@ARTICLE{Pressing2002-bs,
  title     = "Black Atlantic rhythm: Its computational and transcultural
               foundations",
  author    = "Pressing, Jeff",
  abstract  = "The ``Black Atlantic'' rhythmic diaspora, be it realized in
               jazz, blues, gospel, reggae, rock, candombl{\'e}{\'e}, cumbia,
               hip-hop or whatever, seems to have widespread capacity to
               facilitate dance, engagement, social interaction, expression and
               catharsis. This article examines the reasons for this. Black
               Atlantic rhythm is founded on the idea of groove or feel, which
               forms a kinetic framework for reliable prediction of events and
               time pattern communication, its power cemented by repetition and
               engendered movement. Overlaid on this are characteristic devices
               that include syncopation, overlay,displacement, off-beat
               phrasing, polyrhythm/polymeter, hocketing, heterophony, swing,
               speech-based rhythms, and call-and-response. Using an
               evolutionary argument, I point out here that nearly all of these
               have at their heart the establishment of perceptual multiplicity
               or rivalry, affecting expectation, which acts as either a
               message or a message enhancement technique (via increased
               engagement and focusing of attention), or both. The causal path
               for the remaining devices is based on adopting structures shared
               with speech, notably prosody, conversational interaction, and
               narrative. Several examples illustrate how, particularly in jazz
               and jazz-related forms, extensions and relatively complex
               creative adaptations of traditional African and African
               diasporic rhythmic techniques are a natural consequence of a
               culture of questioning and reflection that encompasses
               maintenance of historical reference and accommodation to
               innovation.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  19,
  number    =  3,
  pages     = "285--310",
  month     =  mar,
  year      =  2002,
  keywords  = "To read",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2002.19.3.285"
}

@ARTICLE{Friberg2002-cj,
  title     = "Swing ratios and ensemble timing in jazz performance: Evidence
               for a common rhythmic pattern",
  author    = "Friberg, Anders and Sundstr{\"o}{\"o}m, Andreas",
  abstract  = "The timing in jazz ensemble performances was investigated in
               order to approach the question of what makes the music
               ``swing.'' One well-known aspect of swing is that consecutive
               eighth notes are performed as long-short patterns. The exact
               duration ratio (the swing ratio) of the long-short pattern has
               been largely unknown. In this study, the swing ratio produced by
               drummers on the ride cymbal was measured. Three well-known jazz
               recordings and a play-along record were used. A substantial and
               gradual variation of the drummers' swing ratio with respect to
               tempo was observed. At slow tempi, the swing ratio was as high
               as 3.5:1, whereas at fast tempi it reached 1:1. The
               often-mentioned ``triple-feel,'' that is, a ratio of 2:1, was
               present only at a certain tempo. The absolute duration of the
               short note in the long-short pattern was constant at about 100
               ms for medium to fast tempi, suggesting a practical limit on
               tone duration that may be due to perceptual factors. Another
               aspect of swing is the soloist's timing in relation to the
               accompaniment. For example, a soloist can be characterized as
               playing ``behind the beat.'' In the second part, the swing ratio
               of the soloist and its relation to the cymbal accompaniment was
               measured from the same recordings. In slow tempi, the soloists
               were mostly playing their downbeats after the cymbal but were
               synchronized with the cymbal at the off-beats. This implied that
               the swing ratio of the soloist was considerably smaller than the
               cymbal accompaniment in slow tempi. It may give an impression of
               ``playing behind'' but at the same time keep the synchrony with
               the accompaniment at the off-beat positions. Finally, the
               possibilities of using computer tools in jazz pedagogy are
               discussed.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  19,
  number    =  3,
  pages     = "333--349",
  month     =  mar,
  year      =  2002,
  keywords  = "To read",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2002.19.3.333"
}

@ARTICLE{Larson2002-ev,
  title     = "Musical forces, melodic expectation, and jazz melody",
  author    = "Larson, Steve",
  abstract  = "I review the theoretical and experimental literature on musical
               forces and melodic expectation, showing important connections
               between that work and the work of leading jazz theorists. I then
               show how ideas derived from that work may help us understand a
               few passages of recorded jazz. The examples include two
               compositions (the ``heads'' to Charlie Parker's ``Confirmation''
               and Toshiko Akiyoshi's ``I Ain't Gonna Ask No More'') and a few
               improvised passages (by Bill Evans and Charlie Parker). Viewing
               these examples in terms of what cognitive science tells us about
               melodic expectation clarifies their rhetorical and gestural
               ``meanings.'' Furthermore, these same examples can help us test
               those same theories of melodic expectation------multiple
               regression analysis of the frequency with which certain patterns
               are completed within these same examples provides an empirical
               test of assertions derived from the literature reviewed.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  19,
  number    =  3,
  pages     = "351--385",
  month     =  mar,
  year      =  2002,
  keywords  = "To read",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2002.19.3.351"
}

@ARTICLE{Iyer2002-mt,
  title     = "Embodied mind, situated cognition, and expressive microtiming in
               {African-American} music",
  author    = "Iyer, Vijay",
  abstract  = "The dual theories of embodied mind and situated cognition, in
               which physical/temporal embodiment and physical/social/cultural
               environment contribute crucially to the structure of mind, are
               brought to bear on issues in music perception. It is argued that
               cognitive universals grounded in human bodily experience are
               tempered by the cultural specificity that constructs the role of
               the body in musical performance. Special focus is given to
               microrhythmic techniques in specific forms of African-American
               music, using audio examples created by the author or sampled
               from well-known jazz recordings.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  19,
  number    =  3,
  pages     = "387--414",
  month     =  mar,
  year      =  2002,
  keywords  = "To read",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2002.19.3.387"
}

@ARTICLE{Collier2002-pi,
  title     = "A study of timing in two Louis Armstrong solos",
  author    = "Collier, Geoffrey L and Collier, James Lincoln",
  abstract  = "For years musicians and critics have made statements about the
               nature of swing in jazz in general and the playing of Louis
               Armstrong in particular, based on the evidence of their ears. In
               order to quantify these issues, precise timing analyses of two
               mid-tempo solos by Louis Armstrong were analyzed, focusing in
               particular on stop-time sections. Two key elements of swing were
               analyzed; placement of the downbeats, and the swing or triplet
               ratio. For these solos, Armstrong played fairly close to on the
               beat, with a swing ratio of about 1.6 to 1.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  19,
  number    =  3,
  pages     = "463--483",
  month     =  mar,
  year      =  2002,
  keywords  = "To read",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2002.19.3.463"
}

@ARTICLE{Johnson-Laird2002-kd,
  title     = "How jazz musicians improvise",
  author    = "Johnson-Laird, P N",
  abstract  = "This article defends the view that theories of creativity should
               be computable and that only three sorts of algorithm can be
               creative. It proposes a central principle of algorithmic demands
               for jazz improvisation: a division of labor in terms of
               computational power occurs between the creation of chord
               sequences for improvisation and the creation of melodic
               improvisations in real time. An algorithm for producing chord
               sequences must be computationally powerful, that is, it calls
               for a working memory or a notation of intermediate results.
               Improvisation depends on the ability to extemporize new melodies
               that fit the chord sequence. The corresponding algorithm must
               operate rapidly in real time, and so it minimizes the
               computational load on working memory. The principle of
               algorithmic demands is supported by analysis and a computer
               model.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  19,
  number    =  3,
  pages     = "415--442",
  month     =  mar,
  year      =  2002,
  keywords  = "To read",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2002.19.3.415"
}

@ARTICLE{Busse2002-sf,
  title     = "Toward objective measurement and evaluation of jazz piano
               performance via {MIDI-based} groove quantize templates",
  author    = "Busse, Walter Gerard",
  abstract  = "The purpose of this study was to (a) objectively measure and
               analyze performance deviations from mechanical regularity for
               three jazz pianists via MIDI-based ``groove quantize''
               procedures and (b) measure how experts rate musical examples
               incorporating these deviations as being representative of the
               swing style. The ``groove quantize'' software procedure was used
               to measure performance deviations from mechanical regularity for
               (a) note placements (timings), (b) note durations
               (articulations), and (c) note velocities (dynamics) contained in
               281 measures from 33 performances by three professional jazz
               pianists. Differences among the performers and for relationships
               between the performance variables and tempi were measured.
               Performance models or ``grooves'' were developed representative
               of each performer's style and a general swing style. For
               comparison, ``mechanical'' models were constructed on the basis
               of mathematical ratios. Forty-two judges rated the ``swing
               representativeness'' of an unaltered melody from each pianist
               and seven variations of each, four based on the derived
               performance models and three based on the mechanical model.
               Analysis revealed that four derived performance model variations
               were rated significantly more representative of the swing style
               than were the mechanical variations. Swing ratings did not
               differ significantly between an unaltered melody and variations
               based on individual performance models for two of the
               performers, suggesting that they were representative grooves.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  19,
  number    =  3,
  pages     = "443--461",
  month     =  mar,
  year      =  2002,
  keywords  = "To read",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2002.19.3.443"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Repp1992-px,
  title     = "Diversity and commonality in music performance: An analysis of
               timing microstructure in Schumann's ``Tr{\"a}umerei''",
  author    = "Repp, Bruno H",
  abstract  = "This study attempts to characterize the temporal commonalities
               and differences among distinguished pianists' interpretations of
               a well‐known piece, Robert Schumann's
               ''Tr{\"a}umerei.''Intertone onset intervals (IOIs) were measured
               in 28 recorded performances …",
  journal   = "The Journal of the Acoustical Society of America",
  publisher = "Acoustical Society of America (ASA)",
  volume    =  92,
  number    =  5,
  pages     = "2546--2568",
  month     =  nov,
  year      =  1992,
  keywords  = "To read",
  issn      = "0001-4966, 1520-8524",
  doi       = "10.1121/1.404425"
}

@ARTICLE{Repp1992-zv,
  title     = "Probing the cognitive representation of musical time: structural
               constraints on the perception of timing perturbations",
  author    = "Repp, B H",
  abstract  = "To determine whether structural factors interact with the
               perception of musical time, musically literate listeners were
               presented repeatedly with eight-bar musical excerpts, realized
               with physically regular timing on an electronic piano. On each
               trial, one or two randomly chosen time intervals were lengthened
               by a small amount, and the score. The resulting detection
               accuracy profile across all positions in each musical excerpt
               showed pronounced dips in places where lengthening would
               typically occur in an expressive (temporally modulated)
               performance. False alarm percentages indicated that certain
               tones seemed longer a priori, and these were among the ones
               whose actual lengthening was easiest to detect. The detection
               accuracy and false alarm profiles were significantly correlated
               with each other and with the temporal microstructure of expert
               performances, as measured from sound recordings by famous
               artists. Thus the detection task apparently tapped into
               listeners' musical thought and revealed their expectations about
               the temporal microstructure of music performance. These
               expectations, like the timing patterns of actual performances,
               derive from the cognitive representation of musical structure,
               as cued by a variety of systemic factors (grouping, meter,
               harmonic progression) and their acoustic correlates. No simple
               psycho-acoustic explanation of the detection accuracy profiles
               was evident. The results suggest that the perception of musical
               time is not veridical but ``warped'' by the structural
               representation. This warping may provide a natural basis for
               performance evaluation: expected timing patterns sound more or
               less regular, unexpected ones irregular. Parallels to language
               performance and perception are noted.",
  journal   = "Cognition",
  publisher = "Elsevier",
  volume    =  44,
  number    =  3,
  pages     = "241--281",
  month     =  sep,
  year      =  1992,
  keywords  = "To read",
  language  = "en",
  issn      = "0010-0277",
  pmid      = "1424494",
  doi       = "10.1016/0010-0277(92)90003-z"
}

@ARTICLE{Repp1992-ou,
  title     = "A constraint on the expressive timing of a melodic gesture:
               Evidence from performance and aesthetic judgment",
  author    = "Repp, Bruno H",
  abstract  = "Discussions of music performance often stress diversity and
               artistic freedom, yet there is general agreement that
               interpretation is not arbitrary and that there are standards
               that performances can be judged by. However, there have been few
               objective demonstrations of any extant constraints on music
               performance and judgment, particularly at the level of
               expressive microstructure. This study illustrates such a
               constraint in one specific case: the expressive timing of a
               melodic gesture that occurs repeatedly in Robert Schumann's
               famous piano piece, ``Traumerei.'' Tone onset timing
               measurements in 28 recorded performances by famous pianists
               suggest that the most common `` temporal shape'' of this
               (nominally isochronous) musical gesture is parabolic and that
               individual variations can be described largely by varying a
               single degree of freedom of the parabolic timing function. The
               aesthetic validity of this apparent constraint on local
               performance timing was investigated in a perceptual experiment.
               Listeners judged a variety of timing patterns (original
               parabolic, shifted parabolic, and nonparabolic) imposed on the
               same melodic gesture, produced on an electronic piano under
               control of a Musical Instrument Digital Interface (MIDI). The
               original parabolic patterns received the highest ratings from
               musically trained listeners. (Musically untrained listeners were
               unable to give consistent judgments.) The results support the
               hypothesis that there are classes of optimal temporal shapes for
               melodic gestures in music performance and that musically
               acculturated listeners know and expect these shapes. Being
               classes of shapes, they represent flexible constraints within
               which artistic freedom and individual preference can manifest
               themselves.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  10,
  number    =  2,
  pages     = "221--241",
  month     =  dec,
  year      =  1992,
  keywords  = "To read",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.2307/40285608"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Clayton2020-xq,
  title     = "Interpersonal Entrainment in Music Performance: Theory, Method,
               and Model",
  author    = "Clayton, Martin and Jakubowski, Kelly and Eerola, Tuomas and
               Keller, Peter E and Camurri, Antonio and Volpe, Gualtiero and
               Alborno, Paolo",
  abstract  = "Interpersonal musical entrainment---temporal synchronization and
               coordination between individuals in musical contexts---is a
               ubiquitous phenomenon related to music's social functions of
               promoting group bonding and cohesion. Mechanisms other than
               sensorimotor …",
  journal   = "Music Perception: An Interdisciplinary Journal",
  publisher = "University of California Press",
  volume    =  38,
  number    =  2,
  pages     = "136--194",
  year      =  2020,
  keywords  = "Huw Cheston"
}

@ARTICLE{Clayton2019-gm,
  title     = "Interpersonal entrainment in Indian instrumental music
               performance: Synchronization and movement coordination relate to
               tempo, dynamics, metrical and cadential structure",
  author    = "Clayton, Martin and Jakubowski, Kelly and Eerola, Tuomas",
  abstract  = "Two complementary aspects of interpersonal entrainment ?
               synchronization and movement coordination ? are explored in
               North Indian classical instrumental music, in the auditory and
               visual domains respectively. Sensorimotor synchronization (SMS)
               is explored by analysing pairwise asynchronies between the event
               onsets of instrumental soloists and their tabla accompanists,
               and the variability of asynchrony by factors including tempo,
               dynamic level and metrical position is explored. Movement
               coordination is quantified using cross wavelet transform (CWT)
               analysis of upper body movement data, and differences in CWT
               Energy are investigated in relation to the metrical and
               cadential structures of the music. The analysis demonstrates
               that SMS within this corpus varies significantly with tempo,
               event density, peak levels and leadership. Effects of metrical
               position on pairwise asynchrony are small and offer little
               support for the hypothesis of lower variability in
               synchronization on strong metrical positions; a larger
               difference was found at cadential downbeats, which show
               increased melody lead. Movement coordination is greater at
               metrical boundaries than elsewhere, and most strikingly is
               greater at cadential than at other metrical downbeats. The
               implications of these findings for understanding performer
               coordination are discussed in relation to ethnographic research
               on the genre.",
  journal   = "Musicae scientiae: the journal of the European Society for the
               Cognitive Sciences of Music",
  publisher = "SAGE Publications Ltd",
  volume    =  23,
  number    =  3,
  pages     = "304--331",
  month     =  sep,
  year      =  2019,
  keywords  = "Huw Cheston",
  issn      = "1029-8649",
  doi       = "10.1177/1029864919844809"
}

@ARTICLE{Toiviainen2021-ss,
  title         = "Analyzing multidimensional movement interaction with
                   generalized cross-wavelet transform",
  author        = "Toiviainen, Petri and Hartmann, Martin",
  abstract      = "Humans can synchronize with musical events whilst
                   coordinating their movements with others. Interpersonal
                   entrainment phenomena, such as dance, involve multiple body
                   parts and movement directions. Along with being
                   multidimensional, dance movement interaction is
                   plurifrequential, since it can occur at different
                   frequencies simultaneously. Moreover, it is prone to
                   nonstationarity, due to, for instance, displacements around
                   the dance floor. Various methodological approaches have been
                   adopted to study entrainment, but only spectrogram-based
                   techniques allow for an integral analysis thereof. This
                   article proposes an alternative approach based upon the
                   cross-wavelet transform, a technique for nonstationary and
                   plurifrequential analysis of univariate interaction. The
                   presented approach generalizes the cross-wavelet transform
                   to multidimensional signals. It allows to identify, for
                   different frequencies of movement, interaction estimates of
                   interaction and leader-follower dynamics across body parts
                   and movement directions. Further, the generalized
                   cross-wavelet transform can be used to quantify the
                   frequency-wise contribution of individual body parts and
                   movement directions to overall synchrony. The article
                   provides a thorough mathematical description of the method
                   and includes proofs of its invariance under translation,
                   rotation, and reflection. Finally, its properties and
                   performance are illustrated via examples using simulated
                   data and behavioral data collected through a mirror game
                   task and a free dance movement task.",
  month         =  apr,
  year          =  2021,
  keywords      = "Huw Cheston",
  archivePrefix = "arXiv",
  eprint        = "2104.09783",
  primaryClass  = "stat.ME",
  arxivid       = "2104.09783"
}

@ARTICLE{DellAnna2021-ln,
  title     = "Musical Interaction Reveals Music as Embodied Language",
  author    = "Dell'Anna, Alessandro and Leman, Marc and Berti, Annamaria",
  abstract  = "Life and social sciences often focus on the social nature of
               music (and language alike). In biology, for example, the three
               main evolutionary hypotheses about music (i.e., sexual
               selection, parent-infant bond, and group cohesion) stress its
               intrinsically social character (Honing et al., 2015).
               Neurobiology thereby has investigated the neuronal and hormonal
               underpinnings of musicality for more than two decades (Chanda
               and Levitin, 2013; Salimpoor et al., 2015; Mehr et al., 2019).
               In line with these approaches, the present paper aims to suggest
               that the proper way to capture the social interactive nature of
               music (and, before it, musicality), is to conceive of it as an
               embodied language, rooted in culturally adapted brain structures
               (Clarke et al., 2015; D'Ausilio et al., 2015). This proposal
               heeds Ian Cross' call for an investigation of music as an
               ``interactive communicative process'' rather than ``a
               manifestation of patterns in sound'' (Cross, 2014), with an
               emphasis on its embodied and predictive (coding) aspects (Clark,
               2016; Leman, 2016; Koelsch et al., 2019). In the present paper
               our goal is: (i) to propose a framework of music as embodied
               language based on a review of the major concepts that define
               joint musical action, with a particular emphasis on embodied
               music cognition and predictive processing, along with some
               relevant neural underpinnings; (ii) to summarize three
               experiments conducted in our laboratories (and recently
               published), which provide evidence for, and can be interpreted
               according to, the new conceptual framework. In doing so, we draw
               on both cognitive musicology and neuroscience to outline a
               comprehensive framework of musical interaction, exploring
               several aspects of making music in dyads, from a very basic
               proto-musical action, like tapping, to more sophisticated
               contexts, like playing a jazz standard and singing a hocket
               melody. Our framework combines embodied and predictive features,
               revolving around the concept of joint agency (Pacherie, 2012;
               Keller et al., 2016; Bolt and Loehr, 2017). If social
               interaction is the ``default mode'' by which human brains
               communicate with their environment (Hari et al., 2015), music
               and musicality conceived of as an embodied language may arguably
               provide a route toward its navigation.",
  journal   = "Frontiers in neuroscience",
  publisher = "frontiersin.org",
  volume    =  15,
  pages     = "667838",
  month     =  jul,
  year      =  2021,
  keywords  = "embodied music cognition; music as language; musical joint
               action; predictive coding; sense of joint agency;Huw Cheston",
  language  = "en",
  issn      = "1662-4548, 1662-453X",
  pmid      = "34335155",
  doi       = "10.3389/fnins.2021.667838",
  pmc       = "PMC8317642"
}

@ARTICLE{Juslin2003-lq,
  title     = "Five Facets of Musical Expression: A Psychologist's Perspective
               on Music Performance",
  author    = "Juslin, Patrik N",
  abstract  = "The aim of this article is to outline a psychological approach
               to expression in music performance that could help to provide a
               solid foundation for the teaching of expressive skills in music
               education. Drawing on previous research, the author suggests
               that performance expression is best conceptualized as a
               multi-dimensional phenomenon consisting of five primary
               components: (a) Generative rules that function to clarify the
               musical structure; (b) Emotional expression that serves to
               convey intended emotions to listeners; (c) Random variations
               that reflect human limitations with regard to internal
               time-keeper variance and motor delays; (d) Motion principles
               that prescribe that some aspects of the performance (e.g.
               timing) should be shaped in accordance with patterns of
               biological motion; and (e) Stylistic unexpectedness that
               involves local deviations from performance conventions. An
               analysis of performance expression in terms of these five
               components - collectively referred to as the GERMS model - has
               important implications for research and teaching of music
               performance.",
  journal   = "Psychology of Music",
  publisher = "SAGE Publications Ltd",
  volume    =  31,
  number    =  3,
  pages     = "273--302",
  month     =  jul,
  year      =  2003,
  keywords  = "To read",
  issn      = "0305-7356",
  doi       = "10.1177/03057356030313003"
}

@ARTICLE{Ternstrom2003-qw,
  title     = "Choir acoustics : an overview of scientific research published
               to date",
  author    = "Ternstr{\"o}m, Sten",
  abstract  = "Choir acoustics is but one facet of choir-related research, yet
               it is one of the most tangible. Several aspects of sound can be
               measured objectively, and such results can be related to known
               proper ...",
  journal   = "International Journal of Research in Choral Singing",
  publisher = "American Choir Directors Association",
  volume    =  1,
  number    =  1,
  pages     = "3--12",
  year      =  2003,
  keywords  = "To read",
  language  = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Morrison2011-yd,
  title     = "Intonation",
  author    = "Morrison, Steven and Fyk, Janina",
  abstract  = "Rather than an isolated ability, intonation is an amalgam of
               several sub-skills including pitch discrimination, pitch
               matching, and instrument tuning. Success at these skills depends
               on many factors including musical experience and the nature of
               the task presented. However …",
  journal   = "The science \& psychology of music performance: Creative
               strategies for teaching and learning",
  publisher = "Oxford University Press",
  year      =  2011,
  keywords  = "To read"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Davidson2005-pv,
  title     = "Bodily communication in musical performance",
  booktitle = "Musical communication",
  author    = "Davidson, Jane",
  abstract  = "Davidson , J. (2005). Bodily communication in musical
               performance. In D. Miell, R. Macdonald, \& DJ Hargreaves (Eds.),
               Musical Communication (pp. 215-237). Oxford University Press …
               Davidson , J 2005, Bodily communication in musical performance.
               in D Miell, R Macdonald …",
  publisher = "Oxford University Press",
  pages     = "215--237",
  year      =  2005,
  keywords  = "Huw Cheston"
}

@ARTICLE{Davidson2007-xb,
  title     = "Qualitative insights into the use of expressive body movement in
               solo piano performance: a case study approach",
  author    = "Davidson, Jane W",
  abstract  = "This article is a contribution to the psychology of performance,
               investigating the role of body movements both globally and
               locally in expressive musical performance. A case study of a
               single pianist is used to explore qualitative similarities and
               differences within and across different performances of a
               Beethoven bagatelle. Using observational analyses of the
               performance movements, the results reveal that the performer
               uses particular movement shapes that are specific and
               identifiable `expressive locations' within the context of a
               whole performance. These movement shapes cannot simply be
               categorized as being either intention specific or musical
               structure specific, for there are movement shapes common to
               locations across different performances and different locations
               within a performance. These expressive movements have some
               consistency over time, with the locations of the expression
               being common, but the movements being used flexibly within and
               across manner and time. The results are theorized in terms of
               how these movements may be produced.",
  journal   = "Psychology of Music",
  publisher = "SAGE Publications Ltd",
  volume    =  35,
  number    =  3,
  pages     = "381--401",
  month     =  jul,
  year      =  2007,
  keywords  = "Huw Cheston",
  issn      = "0305-7356",
  doi       = "10.1177/0305735607072652"
}

@INCOLLECTION{Goodman2002-hw,
  title     = "Ensemble performance",
  booktitle = "Musical performance: A guide to understanding",
  author    = "{Goodman} and {E}",
  editor    = "Rink, John",
  publisher = "Cambridge University Press",
  pages     = "153--167",
  year      =  2002,
  address   = "Cambridge, UK",
  keywords  = "Huw Cheston"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Cross2009-qw,
  title     = "Music as a communicative medium",
  booktitle = "The Prehistory of Language",
  author    = "Cross, I and Woodruff, G E",
  editor    = "Botha, R and Knight, C",
  abstract  = "Like language, music appears to be a universal human capacity;
               all cultures of which we have knowledge engage in something
               which, from a western perspective, seems to be music (Blacking
               1995), and all members of each culture are expected to be able
               to engage …",
  publisher = "Oxford University Press",
  pages     = "113--144",
  year      =  2009,
  address   = "Oxford, UK",
  keywords  = "Huw Cheston"
}

@ARTICLE{Cross2014-nx,
  title     = "Music and communication in music psychology",
  author    = "Cross, Ian",
  abstract  = "There is a general consensus that music is both universal and
               communicative, and musical dialogue is a key element in much
               music-therapeutic practice. However, the idea that music is a
               communicative medium has, to date, received little attention
               within the cognitive sciences, and the limited amount of
               research that addresses how and what music communicates has
               resulted in findings that appear to be of limited relevance to
               music therapy. This article will draw on ethnomusicological
               evidence and an understanding of communication derived from the
               study of speech to sketch a framework within which to situate
               and understand music as communicative practice. It will outline
               some key features of music as an interactive participatory
               medium ? including entrainment and floating intentionality ?
               that can help underpin an understanding of music as
               communicative, and that may help guide experimental approaches
               in the cognitive science of music to shed light on the processes
               involved in musical communication and on the consequences of
               engagement in communication through music for interacting
               individuals. It will suggest that the development of such
               approaches may enable the cognitive sciences to provide a more
               comprehensive, predictive understanding of music in interaction
               that could be of direct benefit to music therapy.",
  journal   = "Psychology of Music",
  publisher = "SAGE Publications Ltd",
  volume    =  42,
  number    =  6,
  pages     = "809--819",
  month     =  nov,
  year      =  2014,
  keywords  = "Huw Cheston",
  issn      = "0305-7356",
  doi       = "10.1177/0305735614543968"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Cross2015-qv,
  title     = "Music, Speech and Meaning in interaction",
  booktitle = "Music, analysis, experience: New perspectives in musical
               semiotics",
  author    = "Cross, I",
  editor    = "Maeder, C and Reybrouck, M",
  abstract  = "Music and language seem, in our western conceptions, distinct
               spheres of human activity. Each has features that the other does
               not: language can refer, and is of paramount importance in our
               transactions with each other; music lacks any referential
               exactness and …",
  publisher = "Leuven University Press",
  pages     = "19--30",
  year      =  2015,
  address   = "Leuven, Belgium",
  keywords  = "Huw Cheston"
}

@ARTICLE{Nuttall2021-cl,
  title     = "A computational exploration of melodic patterns in
               {Arab-Andalusian} music",
  author    = "Nuttall, Thomas and Casado, Miguel G and Ferraro, Andres and
               Conklin, Darrell and Caro Repetto, Rafael",
  abstract  = "Here we present a computational approach to identifying melodic
               patterns in a dataset of 145 MusicXML scores with the aim of
               contributing to centonization theory in the Moroccan tradition
               of Arab-Andalusian Music ? a theory in development by expert
               performer and researcher of this tradition, Amin Chaachoo.
               Central to his work is the definition of a set of characteristic
               patterns, or centos, for each ?ab?, or melodic mode. We apply
               three methods: TF-IDF, Maximally General Distinctive Patterns
               (MGDP) and the Structure Induction Algorithm (SIA) to identify
               characteristic patterns at the level of ?ab?. A substantial
               number of the centos proposed by Chaachoo are identified and new
               melodic patterns are retrieved. A discussion with Chaachoo about
               the obtained results promoted the elicitation of other
               categories of recurrent patterns in the tradition different from
               the centos, contributing to a deeper musicological knowledge of
               the tradition.",
  journal   = "Journal of Mathematics \& Music. Mathematical and Computational
               Approaches to Music Theory, Analysis, Composition and
               Performance",
  publisher = "Taylor \& Francis",
  volume    =  15,
  number    =  2,
  pages     = "168--180",
  month     =  may,
  year      =  2021,
  issn      = "1745-9737",
  doi       = "10.1080/17459737.2021.1917010"
}

@ARTICLE{Chmielewski2020-ec,
  title     = "An {MTurk} crisis? Shifts in data quality and the impact on
               study results",
  author    = "Chmielewski, Michael and Kucker, Sarah C",
  abstract  = "Amazon?s Mechanical Turk (MTurk) is arguably one of the most
               important research tools of the past decade. The ability to
               rapidly collect large amounts of high-quality human subjects
               data has advanced multiple fields, including personality and
               social psychology. Beginning in summer 2018, concerns arose
               regarding MTurk data quality leading to questions about the
               utility of MTurk for psychological research. We present
               empirical evidence of a substantial decrease in data quality
               using a four-wave naturalistic experimental design: pre-,
               during, and post-summer 2018. During and to some extent
               post-summer 2018, we find significant increases in participants
               failing response validity indicators, decreases in reliability
               and validity of a widely used personality measure, and failures
               to replicate well-established findings. However, these
               detrimental effects can be mitigated by using response validity
               indicators and screening the data. We discuss implications and
               offer suggestions to ensure data quality.",
  journal   = "Social psychological and personality science",
  publisher = "SAGE Publications Inc",
  volume    =  11,
  number    =  4,
  pages     = "464--473",
  month     =  may,
  year      =  2020,
  issn      = "1948-5506",
  doi       = "10.1177/1948550619875149"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Grey1977-xr,
  title     = "Multidimensional perceptual scaling of musical timbres",
  author    = "Grey, J M",
  abstract  = "Two experiments were performed to evaluate the perceptual
               relationships between 16 music instrument tones. The stimuli
               were computer synthesized based upon an analysis of actual
               instrument tones, and they were perceptually equalized for
               loudness, pitch, and duration. Experiment 1 evaluated the tones
               with respect to perceptual similarities, and the results were
               treated with multidimensional scaling techniques and hierarchic
               clustering analysis. A three‐dimensional scaling solution, well
               matching the clustering analysis, was …",
  journal   = "The Journal of the Acoustical Society of America",
  publisher = "asa.scitation.org",
  volume    =  61,
  number    =  5,
  pages     = "1270--1277",
  month     =  may,
  year      =  1977,
  language  = "en",
  issn      = "0001-4966",
  pmid      = "560400",
  doi       = "10.1121/1.381428"
}

@ARTICLE{Grey1978-ea,
  title     = "Perceptual effects of spectral modifications on musical timbres",
  author    = "Grey, John M and Gordon, John W",
  abstract  = "An experiment was performed to evaluate the effects of spectral
               modifications on the similarity structure for a set of musical
               timbres. The stimuli were 16 music instrument tones, 8 of which
               were modified in pairs. This modification consisted of
               exchanging the shape of the spectral energy distribution between
               the two tones within each pair. The three?dimensional spatial
               representation of similarities among the 16 tones was obtained
               by multidimensional scaling techniques and compared to a
               previous scaling of the original 16 unmodified tones [J. M.
               Grey, J. Acoust. Soc. Am. 61, 1270?1277 (1977)]. The pairs of
               tones which had exchanged spectral shapes in fact exchanged
               orders on the spatial axis which had been previously interpreted
               as relating to spectral shape, thereby supporting the earlier
               interpretation. The two remaining axes of the spatial solution
               also retained their original interpretations, relating to
               various temporal details of the tones. A set of formal
               quantitative models for the spectral dimension was constructed
               and tested, and the results further supported the interpretation
               of this perceptual axis.",
  journal   = "The Journal of the Acoustical Society of America",
  publisher = "Acoustical Society of America",
  volume    =  63,
  number    =  5,
  pages     = "1493--1500",
  month     =  may,
  year      =  1978,
  issn      = "0001-4966",
  doi       = "10.1121/1.381843"
}

@ARTICLE{Patil2012-wy,
  title     = "Music in our ears: the biological bases of musical timbre
               perception",
  author    = "Patil, Kailash and Pressnitzer, Daniel and Shamma, Shihab and
               Elhilali, Mounya",
  abstract  = "Timbre is the attribute of sound that allows humans and other
               animals to distinguish among different sound sources. Studies
               based on psychophysical judgments of musical timbre, ecological
               analyses of sound's physical characteristics as well as machine
               learning approaches have all suggested that timbre is a
               multifaceted attribute that invokes both spectral and temporal
               sound features. Here, we explored the neural underpinnings of
               musical timbre. We used a neuro-computational framework based on
               spectro-temporal receptive fields, recorded from over a thousand
               neurons in the mammalian primary auditory cortex as well as from
               simulated cortical neurons, augmented with a nonlinear
               classifier. The model was able to perform robust instrument
               classification irrespective of pitch and playing style, with an
               accuracy of 98.7\%. Using the same front end, the model was also
               able to reproduce perceptual distance judgments between timbres
               as perceived by human listeners. The study demonstrates that
               joint spectro-temporal features, such as those observed in the
               mammalian primary auditory cortex, are critical to provide the
               rich-enough representation necessary to account for perceptual
               judgments of timbre by human listeners, as well as recognition
               of musical instruments.",
  journal   = "PLoS computational biology",
  publisher = "journals.plos.org",
  volume    =  8,
  number    =  11,
  pages     = "e1002759",
  month     =  nov,
  year      =  2012,
  language  = "en",
  issn      = "1553-734X, 1553-7358",
  pmid      = "23133363",
  doi       = "10.1371/journal.pcbi.1002759",
  pmc       = "PMC3486808"
}

@ARTICLE{Schubert2006-zx,
  title     = "Does Timbral Brightness Scale with Frequency and Spectral
               Centroid?",
  author    = "Schubert, Emery and Wolfe, Joe",
  abstract  = "Two models that predict perceived timbral brightness in terms of
               the centroid of the frequency spectrum were investigated. One
               model simply uses the centroid of the frequency spectrum, the
               other divides this same value by the fundamental frequency: the
               latter scales the centroid of the frequency spectrum with the
               fundamental frequency. Different single tone and pitch
               combinations, presented sequentially, were compared.
               Participants were not asked to ignore pitch differences and
               intervals of greater than an octave were compared. The results
               indicate that brightness is much better correlated with
               frequency spectrum centroid (r = 0.513, p r = 0.030, p = 0.441).",
  journal   = "Acta Acustica united with Acustica",
  publisher = "ingentaconnect.com",
  volume    =  92,
  number    =  5,
  pages     = "820--825",
  year      =  2006,
  issn      = "1610-1928"
}

@ARTICLE{Athanasopoulos2021-sd,
  title    = "Harmonic organisation conveys both universal and culture-specific
              cues for emotional expression in music",
  author   = "Athanasopoulos, George and Eerola, Tuomas and Lahdelma, Imre and
              Kaliakatsos-Papakostas, Maximos",
  abstract = "Previous research conducted on the cross-cultural perception of
              music and its emotional content has established that emotions can
              be communicated across cultures at least on a rudimentary level.
              Here, we report a cross-cultural study with participants
              originating from two tribes in northwest Pakistan (Khow and
              Kalash) and the United Kingdom, with both groups being na{\"\i}ve
              to the music of the other respective culture. We explored how
              participants assessed emotional connotations of various Western
              and non-Western harmonisation styles, and whether cultural
              familiarity with a harmonic idiom such as major and minor mode
              would consistently relate to emotion communication. The results
              indicate that Western concepts of harmony are not relevant for
              participants unexposed to Western music when other emotional cues
              (tempo, pitch height, articulation, timbre) are kept relatively
              constant. At the same time, harmonic style alone has the ability
              to colour the emotional expression in music if it taps the
              appropriate cultural connotations. The preference for one
              harmonisation style over another, including the
              major-happy/minor-sad distinction, is influenced by culture.
              Finally, our findings suggest that although differences emerge
              across different harmonisation styles, acoustic roughness
              influences the expression of emotion in similar ways across
              cultures; preference for consonance however seems to be dependent
              on cultural familiarity.",
  journal  = "PloS one",
  volume   =  16,
  number   =  1,
  pages    = "e0244964",
  month    =  jan,
  year     =  2021,
  language = "en",
  issn     = "1932-6203",
  pmid     = "33439887",
  doi      = "10.1371/journal.pone.0244964",
  pmc      = "PMC7806179"
}

@ARTICLE{Hall1984-bq,
  title     = "Perception of musical interval tuning",
  author    = "Hall, Donald E and Hess, Joan Taylor",
  abstract  = "When musical intervals are altered from their usual frequency
               ratios, listeners may experience a sensation of mistuning. We
               report results of experiments in which subjects judged degrees
               of mistuning of all intervals from unison to octave, as well as
               major tenth and twelfth. Using two simultaneous tones with
               fundamental frequencies between 250 and 800 Hz and 5 to 10
               strong harmonics in each, we find: (1) just intervals, rather
               than tempered, are considered best in tune; (2) the range of
               mistunings considered acceptable generally becomes narrower when
               expressed in cents but wider when described by beat rate as we
               go from unison to octave, fifth and fourth; (3) whether that
               trend continues to sixths and thirds depends on individual
               listening strategies; and (4) the difficulty of judgment
               generally increases in going from the consonant toward the
               dissonant intervals, with the latter often eliciting only crude
               discrimination. Ability to judge mistuning with dichotic stimuli
               was also tested. We conclude that the beat rates of nearly
               coinciding harmonics provide an important clue to mistuning, but
               that a more abstract ability to judge interval size is also
               used; relative importance of the two strategies differs among
               subjects.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  2,
  number    =  2,
  pages     = "166--195",
  month     =  dec,
  year      =  1984,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.2307/40285290"
}

@ARTICLE{Ohgushi1983-jw,
  title     = "The origin of tonality and a possible explanation of the octave
               enlargement phenomenon",
  author    = "Ohgushi, K",
  abstract  = "It is known that the subjective octave is slightly larger than
               the physical octave (= 2) for a variety of tones. This paper
               presents a new idea about the physiological origin of tonality,
               and a new theory founded on recent knowledge of the auditory
               physiology, to explain the octave enlargement phenomenon for
               pure tones. The theory's predictions of the subjective octave
               agree well with psychophysical data.",
  journal   = "The Journal of the Acoustical Society of America",
  publisher = "asa.scitation.org",
  volume    =  73,
  number    =  5,
  pages     = "1694--1700",
  month     =  may,
  year      =  1983,
  language  = "en",
  issn      = "0001-4966",
  pmid      = "6863747",
  doi       = "10.1121/1.389392"
}

@ARTICLE{Dobbins1982-hf,
  title     = "Octave discrimination: an experimental confirmation of the
               ``stretched'' subjective octave",
  author    = "Dobbins, P A and Cuddy, L L",
  abstract  = "Discrimination of the musical octave was measured by the method
               of constant stimuli with roving standards and four response
               categories. For each of three musically trained listeners, and
               two of three untrained listeners, the estimated value of the
               subjective octave was ``stretched'' slightly sharper than the
               physical octave of 1200 cents. The magnitude of this stretch,
               about 20 cents on the average, replicated earlier findings
               obtained by the method of adjustment. A Thurstonian
               decision-theory model, providing iterative parametric solutions,
               generated an excellent fit to listeners' psychophysical
               functions. The present experimental task is best described by a
               noncategorical model of interval perception.",
  journal   = "The Journal of the Acoustical Society of America",
  publisher = "asa.scitation.org",
  volume    =  72,
  number    =  2,
  pages     = "411--415",
  month     =  aug,
  year      =  1982,
  language  = "en",
  issn      = "0001-4966, 1520-8524",
  pmid      = "7119283",
  doi       = "10.1121/1.388093"
}

@ARTICLE{Rasch1985-gd,
  title     = "Perception of melodic and harmonic intonation of two-part
               musical fragments",
  author    = "Rasch, Rudolf A",
  abstract  = "Short musical fragments consisting of a melody part and a
               synchronous bass part were mistuned in various ways and in
               various degrees. Mistuning was applied to the harmonic intervals
               between simultaneous tones in melody and bass (harmonic
               mistuning), which caused at the same time a mistuning of the
               melodic intervals between successive tones in the melody part
               (melodic mistuning of melody) and/or the bass part (melodic
               mistuning of bass part). The fragments were presented to
               musically trained subjects for judgments of the perceived
               quality of intonation. Results showed that the melodic mistuning
               of the melody parts had the largest disturbing effects on the
               perceived quality of intonation, followed closely by the
               harmonic mistuning. Melodic mistuning of the bass was less
               influential. It could be reasoned that the deviating interval
               size was probably of more importance in the perception of
               harmonic mistuning than the presence of beats.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  2,
  number    =  4,
  pages     = "441--458",
  month     =  jul,
  year      =  1985,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.2307/40285312"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hall1973-kz,
  title     = "The objective measurement of goodness-of-fit for tunings and
               temperaments",
  author    = "Hall, Donald",
  abstract  = "One of the classic problems of music theory is that of how best
               to tune our twelve-note chromatic scale. We have passed through
               an era of widespread automatic acceptance of equal temperament
               as the final solution. But many performers as well as scholars
               recognize today that proper treatment of Baroque and earlier
               music requires our knowing about the tunings then used. Many of
               them are described by J. Murray Barbour'I-so many, in fact, that
               most readers may despair of figuring out which unequal
               temperament to try for themselves in …",
  journal   = "Journal of Mathematics \& Music",
  publisher = "[Duke University Press, Yale University Department of Music]",
  volume    =  17,
  number    =  2,
  pages     = "274--290",
  year      =  1973,
  issn      = "1745-9737, 0022-2909",
  doi       = "10.2307/843344"
}

@ARTICLE{Roberts1984-en,
  title    = "Intonation sensitivity for traditional and nontraditional chords",
  author   = "Roberts, L A and Mathews, M V",
  abstract = "We studied listeners' intonation sensitivity to traditional
              (major and minor) and nontraditional chords. The nontraditional
              chords have frequency ratios of 3:5:7 and 5:7:9 and, like the
              major chord, have coincident upper partials and unambiguous
              fundamental basses. The center tone only of each of these four
              triads was varied from its just (integer ratio) value by -30,
              -15, 0, +15, and +30 cents. Each tone had ten partials whose
              amplitudes decreased with frequency relative to the fundamental
              (9 dB per octave). Subjects judged which chord (or chordal
              sequence) of a pair was more in tune, smooth and/or pleasant.
              Listeners' intonation sensitivity curves exhibited regular
              patterns for both traditional and nontraditional chords. However,
              our subjects divided into two groups: One group preferred chords
              in just intonation and their preferences decreased monotonically
              as the intonation deviated from just intonation; the other group
              preferred intonations that deviated from just intonation by +/-
              15 cents.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  75,
  number   =  3,
  pages    = "952--959",
  month    =  mar,
  year     =  1984,
  language = "en",
  issn     = "0001-4966",
  pmid     = "6707326",
  doi      = "10.1121/1.390560"
}

@ARTICLE{Palmer2013-ju,
  title    = "Music-color associations are mediated by emotion",
  author   = "Palmer, Stephen E and Schloss, Karen B and Xu, Zoe and
              Prado-Le{\'o}n, Lilia R",
  abstract = "Experimental evidence demonstrates robust cross-modal matches
              between music and colors that are mediated by emotional
              associations. US and Mexican participants chose colors that were
              most/least consistent with 18 selections of classical orchestral
              music by Bach, Mozart, and Brahms. In both cultures, faster music
              in the major mode produced color choices that were more
              saturated, lighter, and yellower whereas slower, minor music
              produced the opposite pattern (choices that were desaturated,
              darker, and bluer). There were strong correlations (0.89 < r <
              0.99) between the emotional associations of the music and those
              of the colors chosen to go with the music, supporting an
              emotional mediation hypothesis in both cultures. Additional
              experiments showed similarly robust cross-modal matches from
              emotionally expressive faces to colors and from music to
              emotionally expressive faces. These results provide further
              support that music-to-color associations are mediated by common
              emotional associations.",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  110,
  number   =  22,
  pages    = "8836--8841",
  month    =  may,
  year     =  2013,
  keywords = "color cognition; cross-modal associations; emotion mediation
              hypothesis; music cognition",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "23671106",
  doi      = "10.1073/pnas.1212562110",
  pmc      = "PMC3670360"
}

@ARTICLE{Shepard1988-xt,
  title     = "Toward a universal law of generalization",
  author    = "Shepard, R N",
  journal   = "Science (New York, N.Y.)",
  publisher = "American Association for the Advancement of Science (AAAS)",
  volume    =  242,
  number    =  4880,
  pages     = "944--944",
  month     =  nov,
  year      =  1988,
  keywords  = "To read",
  language  = "en",
  issn      = "0036-8075, 1095-9203",
  doi       = "10.1126/science.242.4880.944b"
}

@ARTICLE{Patel2021-vu,
  title     = "Vocal learning as a preadaptation for the evolution of human
               beat perception and synchronization",
  author    = "Patel, Aniruddh D",
  abstract  = "The human capacity to synchronize movements to an auditory beat
               is central to musical behaviour and to debates over the
               evolution of human musicality. Have humans evolved any neural
               specializations for music processing, or does music rely
               entirely on brain circuits that evolved for other reasons? The
               vocal learning and rhythmic synchronization hypothesis proposes
               that our ability to move in time with an auditory beat in a
               precise, predictive and tempo-flexible manner originated in the
               neural circuitry for complex vocal learning. In the 15 years,
               since the hypothesis was proposed a variety of studies have
               supported it. However, one study has provided a significant
               challenge to the hypothesis. Furthermore, it is increasingly
               clear that vocal learning is not a binary trait animals have or
               lack, but varies more continuously across species. In the light
               of these developments and of recent progress in the neurobiology
               of beat processing and of vocal learning, the current paper
               revises the vocal learning hypothesis. It argues that an
               advanced form of vocal learning acts as a preadaptation for
               sporadic beat perception and synchronization (BPS), providing
               intrinsic rewards for predicting the temporal structure of
               complex acoustic sequences. It further proposes that in humans,
               mechanisms of gene-culture coevolution transformed this
               preadaptation into a genuine neural adaptation for sustained
               BPS. The larger significance of this proposal is that it
               outlines a hypothesis of cognitive gene-culture coevolution
               which makes testable predictions for neuroscience, cross-species
               studies and genetics. This article is part of the theme issue
               'Synchrony and rhythm interaction: from the brain to behavioural
               ecology'.",
  journal   = "Philosophical transactions of the Royal Society of London.
               Series B, Biological sciences",
  publisher = "royalsocietypublishing.org",
  volume    =  376,
  number    =  1835,
  pages     = "20200326",
  month     =  oct,
  year      =  2021,
  keywords  = "beat; evolution; gene-culture coevolution; rhythm; synchrony;
               vocal learning",
  language  = "en",
  issn      = "0962-8436, 1471-2970",
  pmid      = "34420384",
  doi       = "10.1098/rstb.2020.0326"
}

@ARTICLE{Lenc2021-rr,
  title     = "Mapping between sound, brain and behaviour: four-level framework
               for understanding rhythm processing in humans and non-human
               primates",
  author    = "Lenc, Tomas and Merchant, Hugo and Keller, Peter E and Honing,
               Henkjan and Varlet, Manuel and Nozaradan, Sylvie",
  abstract  = "Humans perceive and spontaneously move to one or several levels
               of periodic pulses (a meter, for short) when listening to
               musical rhythm, even when the sensory input does not provide
               prominent periodic cues to their temporal location. Here, we
               review a multi-levelled framework to understanding how external
               rhythmic inputs are mapped onto internally represented metric
               pulses. This mapping is studied using an approach to quantify
               and directly compare representations of metric pulses in signals
               corresponding to sensory inputs, neural activity and behaviour
               (typically body movement). Based on this approach, recent
               empirical evidence can be drawn together into a conceptual
               framework that unpacks the phenomenon of meter into four levels.
               Each level highlights specific functional processes that
               critically enable and shape the mapping from sensory input to
               internal meter. We discuss the nature, constraints and neural
               substrates of these processes, starting with fundamental
               mechanisms investigated in macaque monkeys that enable basic
               forms of mapping between simple rhythmic stimuli and internally
               represented metric pulse. We propose that human evolution has
               gradually built a robust and flexible system upon these
               fundamental processes, allowing more complex levels of mapping
               to emerge in musical behaviours. This approach opens promising
               avenues to understand the many facets of rhythmic behaviours
               across individuals and species. This article is part of the
               theme issue 'Synchrony and rhythm interaction: from the brain to
               behavioural ecology'.",
  journal   = "Philosophical transactions of the Royal Society of London.
               Series B, Biological sciences",
  publisher = "royalsocietypublishing.org",
  volume    =  376,
  number    =  1835,
  pages     = "20200325",
  month     =  oct,
  year      =  2021,
  keywords  = "frequency-tagging; mapping; musical meter; neurophysiology;
               rhythm; transformation",
  language  = "en",
  issn      = "0962-8436, 1471-2970",
  pmid      = "34420381",
  doi       = "10.1098/rstb.2020.0325"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cohen1984-bl,
  title     = "Some effects of inharmonic partials on interval perception",
  author    = "Cohen, Elizabeth A",
  abstract  = "We have explored some of the effects of tuning intervals with
               inharmonic partials. The tones that composed the intervals had
               partials whose spacing is given by f$f_n = KA^\{\log 2n/1\}
               $where$f_n $ is the frequency of the wth partial and K = 2ɸ/Aɸ.
               We suggest that subjects can successfully (internally) assign a
               pitch to tones with a structured departure from harmonicity. We
               find that subjects appear to process intervals with nearly
               harmonic stimuli (A = 1.9-2.1) in a manner that supports the
               ``best fit'' pattern recognition theories of pitch perception.
               Subject perception of intervals whose component tones were
               stretched (A > 2.1) is best accounted for by noting the nature
               of auditory spectral resolution and by interval memory
               mechanisms. The results imply that temporal synchrony of
               harmonics becomes increasingly important to interval integrity
               after A= 2.1 and that the strength of the impression of
               conventional intervals is dependent on temporal synchrony.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  1,
  number    =  3,
  pages     = "323--349",
  month     =  apr,
  year      =  1984,
  keywords  = "To read",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.2307/40285264"
}

@INPROCEEDINGS{Plamondon2009-cp,
  title     = "Dynamic tonality: Extending the framework of tonality into the
               21st century",
  booktitle = "Proceedings of the {CMS} South Central Chapter Conference",
  author    = "Plamondon, J and Milne, A and Sethares, W",
  publisher = "University of Oklahoma",
  year      =  2009,
  address   = "Norman, OK"
}

@ARTICLE{Hansen2021-vp,
  title    = "Predictive uncertainty underlies auditory boundary perception",
  author   = "Hansen, Niels Chr and Kragness, Haley E and Vuust, Peter and
              Trainor, Laurel and Pearce, Marcus T",
  abstract = "Anticipating the future is essential for efficient perception and
              action planning. Yet the role of anticipation in event
              segmentation is understudied because empirical research has
              focused on retrospective cues such as surprise. We address this
              concern in the context of perception of musical-phrase
              boundaries. A computational model of cognitive sequence
              processing was used to control the information-dynamic properties
              of tone sequences. In an implicit, self-paced listening task (N =
              38), undergraduates dwelled longer on tones generating high
              entropy (i.e., high uncertainty) than on those generating low
              entropy (i.e., low uncertainty). Similarly, sequences that ended
              on tones generating high entropy were rated as sounding more
              complete (N = 31 undergraduates). These entropy effects were
              independent of both the surprise (i.e., information content) and
              phrase position of target tones in the original musical stimuli.
              Our results indicate that events generating high entropy
              prospectively contribute to segmentation processes in auditory
              sequence perception, independently of the properties of the
              subsequent event.",
  journal  = "Psychological science",
  pages    = "956797621997349",
  month    =  aug,
  year     =  2021,
  keywords = "entropy; grouping; music; open data; open materials; perception;
              prediction;To read",
  language = "en",
  issn     = "0956-7976, 1467-9280",
  pmid     = "34409898",
  doi      = "10.1177/0956797621997349"
}

@ARTICLE{Bianco2020-oy,
  title    = "Long-term implicit memory for sequential auditory patterns in
              humans",
  author   = "Bianco, Roberta and Harrison, Peter M C and Hu, Mingyue and
              Bolger, Cora and Picken, Samantha and Pearce, Marcus T and Chait,
              Maria",
  abstract = "Memory, on multiple timescales, is critical to our ability to
              discover the structure of our surroundings, and efficiently
              interact with the environment. We combined behavioural
              manipulation and modelling to investigate the dynamics of memory
              formation for rarely reoccurring acoustic patterns. In a series
              of experiments, participants detected the emergence of regularly
              repeating patterns within rapid tone-pip sequences. Unbeknownst
              to them, a few patterns reoccurred every ~3 min. All sequences
              consisted of the same 20 frequencies and were distinguishable
              only by the order of tone-pips. Despite this, reoccurring
              patterns were associated with a rapidly growing detection-time
              advantage over novel patterns. This effect was implicit, robust
              to interference, and persisted for 7 weeks. The results implicate
              an interplay between short (a few seconds) and long-term (over
              many minutes) integration in memory formation and demonstrate the
              remarkable sensitivity of the human auditory system to
              sporadically reoccurring structure within the acoustic
              environment.",
  journal  = "eLife",
  volume   =  9,
  month    =  may,
  year     =  2020,
  keywords = "PPM; auditory scene analysis; human; memory; neuroscience;
              perception; predictive coding; sequential pattern;My publications",
  language = "en",
  issn     = "2050-084X",
  pmid     = "32420868",
  doi      = "10.7554/eLife.56073",
  pmc      = "PMC7338054"
}

@ARTICLE{Hernandez-Olivan2021-ox,
  title         = "Music composition with Deep Learning: A review",
  author        = "Hernandez-Olivan, Carlos and Beltran, Jose R",
  abstract      = "Generating a complex work of art such as a musical
                   composition requires exhibiting true creativity that depends
                   on a variety of factors that are related to the hierarchy of
                   musical language. Music generation have been faced with
                   Algorithmic methods and recently, with Deep Learning models
                   that are being used in other fields such as Computer Vision.
                   In this paper we want to put into context the existing
                   relationships between AI-based music composition models and
                   human musical composition and creativity processes. We give
                   an overview of the recent Deep Learning models for music
                   composition and we compare these models to the music
                   composition process from a theoretical point of view. We
                   have tried to answer some of the most relevant open
                   questions for this task by analyzing the ability of current
                   Deep Learning models to generate music with creativity or
                   the similarity between AI and human composition processes,
                   among others.",
  month         =  aug,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2108.12290",
  primaryClass  = "cs.SD",
  arxivid       = "2108.12290"
}

@ARTICLE{noauthor_undated-kl,

}

@ARTICLE{Blalock2021-jg,
  title         = "Multiplying Matrices Without Multiplying",
  author        = "Blalock, Davis and Guttag, John",
  abstract      = "Multiplying matrices is among the most fundamental and
                   compute-intensive operations in machine learning.
                   Consequently, there has been significant work on efficiently
                   approximating matrix multiplies. We introduce a
                   learning-based algorithm for this task that greatly
                   outperforms existing methods. Experiments using hundreds of
                   matrices from diverse domains show that it often runs
                   $100\times$ faster than exact matrix products and $10\times$
                   faster than current approximate methods. In the common case
                   that one matrix is known ahead of time, our method also has
                   the interesting property that it requires zero
                   multiply-adds. These results suggest that a mixture of
                   hashing, averaging, and byte shuffling$-$the core operations
                   of our method$-$could be a more promising building block for
                   machine learning than the sparsified, factorized, and/or
                   scalar quantized matrix products that have recently been the
                   focus of substantial research and hardware investment.",
  month         =  jun,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2106.10860",
  primaryClass  = "cs.LG",
  arxivid       = "2106.10860"
}

@ARTICLE{Prasad2020-im,
  title     = "National Institutes of Health ({NIH}) grant awards: does past
               performance predict future success?",
  author    = "Prasad, Joni M and Shipley, Michael T and Rogers, Terry B and
               Puche, Adam C",
  abstract  = "AbstractThe NIH is the major federal biomedical research funding
               agency within the United States, and NIH funding has become a
               priority in institutional decisions on faculty recruitment,
               salary, promotion, and tenure. The implicit assumption is that
               well-funded investigators will maintain their funding success;
               however, our analysis of NIH awardees from 2000 to 2015 suggests
               that regardless of how well funded an investigator is, their
               research portfolio exhibits ``regression to the mean,'' matching
               the typical NIH funding profile within just 10--15 years. Thus,
               outperformance in past funding is not a strong predictor of
               future outperformance in funding success. This study indicates
               that faculty performance should not be solely judged upon grant
               success but should include other institutional mission
               priorities such as provision of clinical care, education, and
               service to community/profession.",
  journal   = "Palgrave communications",
  publisher = "Springer Science and Business Media LLC",
  volume    =  6,
  number    =  1,
  pages     = "1--7",
  month     =  dec,
  year      =  2020,
  copyright = "https://creativecommons.org/licenses/by/4.0",
  language  = "en",
  issn      = "2055-1045",
  doi       = "10.1057/s41599-020-0432-5"
}

@ARTICLE{Skov2019-zc,
  title     = "The nature of perception and emotion in aesthetic appreciation:
               A response to Makin's challenge to empirical aesthetics",
  author    = "Skov, Martin and Nadal, Marcos",
  abstract  = "Alexis Makin argued in a recent paper that Empirical Aesthetics
               is unable to properly advance our understanding of the
               mechanisms involved in aesthetic experience. The reason for this
               predicament, he claims, is an inability of current research
               methods to capture the psychological properties that truly
               characterize aesthetic experience, especially the unique
               perceptual and emotional processes involved in the aesthetic
               experience. We show that Makin's argument rests on assumptions
               that are at odds with scientific knowledge of the
               neurobiological mechanisms involved in the appreciation of
               sensory objects. We thereafter show that such mechanisms are
               rooted in shared neurobiological systems and operate according
               to computational principles that are common to many domains of
               experience. This casts doubt on the notion that aesthetic
               experiences constitute a distinct kind of experiences that can
               be defined according to a set of special and unique qualities.
               Finally, we discuss how attributing this specialness to
               ``aesthetic'' experiences leads Empirical Aesthetics astray from
               mainstream psychology and neuroscience. (PsycINFO Database
               Record (c) 2019 APA, all rights reserved)",
  journal   = "Psychology of Aesthetics, Creativity, and the Arts",
  publisher = "psycnet.apa.org",
  month     =  sep,
  year      =  2019,
  issn      = "1931-3896, 1931-390X",
  doi       = "10.1037/aca0000278"
}

@BOOK{Fechner2021-fv,
  title    = "Preschool of aesthetics",
  author   = "Fechner, G T",
  volume   =  1,
  year     =  2021,
  keywords = "To read"
}

@ARTICLE{Setzler2020-fe,
  title    = "Coordination and Consonance Between Interacting, Improvising
              Musicians",
  author   = "Setzler, Matthew and Goldstone, Robert",
  abstract = "Joint action (JA) is ubiquitous in our cognitive lives. From
              basketball teams to teams of surgeons, humans often coordinate
              with one another to achieve some common goal. Idealized
              laboratory studies of group behavior have begun to elucidate
              basic JA mechanisms, but little is understood about how these
              mechanisms scale up in more sophisticated and open-ended JA that
              occurs in the wild. We address this gap by examining coordination
              in a paragon domain for creative joint expression: improvising
              jazz musicians. Coordination in jazz music subserves an aesthetic
              goal: the generation of a collective musical expression
              comprising coherent, highly nuanced musical structure (e.g.,
              rhythm, harmony). In our study, dyads of professional jazz
              pianists improvised in a ``coupled,'' mutually adaptive
              condition, and an ``overdubbed'' condition that precluded mutual
              adaptation, as occurs in common studio recording practices. Using
              a model of musical tonality, we quantify the flow of rhythmic and
              harmonic information between musicians as a function of
              interaction condition. Our analyses show that mutually adapting
              dyads achieve greater temporal alignment and produce more
              consonant harmonies. These musical signatures of coordination
              were preferred by independent improvisers and naive listeners,
              who gave higher quality ratings to coupled interactions despite
              being blind to condition. We present these results and discuss
              their implications for music technology and JA research more
              generally.",
  journal  = "Open mind : discoveries in cognitive science",
  volume   =  4,
  pages    = "88--101",
  month    =  nov,
  year     =  2020,
  keywords = "distributed cognition; improvisation; joint action; music; time
              series modeling;Huw Cheston",
  language = "en",
  issn     = "2470-2986",
  pmid     = "34485792",
  doi      = "10.1162/opmi\_a\_00036",
  pmc      = "PMC8412203"
}

@ARTICLE{McPherson2020-ff,
  title    = "Perceptual fusion of musical notes by native Amazonians suggests
              universal representations of musical intervals",
  author   = "McPherson, Malinda J and Dolan, Sophia E and Durango, Alex and
              Ossandon, Tomas and Vald{\'e}s, Joaqu{\'\i}n and Undurraga,
              Eduardo A and Jacoby, Nori and Godoy, Ricardo A and McDermott,
              Josh H",
  abstract = "Music perception is plausibly constrained by universal perceptual
              mechanisms adapted to natural sounds. Such constraints could
              arise from our dependence on harmonic frequency spectra for
              segregating concurrent sounds, but evidence has been
              circumstantial. We measured the extent to which concurrent
              musical notes are misperceived as a single sound, testing
              Westerners as well as native Amazonians with limited exposure to
              Western music. Both groups were more likely to mistake note
              combinations related by simple integer ratios as single sounds
              ('fusion'). Thus, even with little exposure to Western harmony,
              acoustic constraints on sound segregation appear to induce
              perceptual structure on note combinations. However, fusion did
              not predict aesthetic judgments of intervals in Westerners, or in
              Amazonians, who were indifferent to consonance/dissonance. The
              results suggest universal perceptual mechanisms that could help
              explain cross-cultural regularities in musical systems, but
              indicate that these mechanisms interact with culture-specific
              influences to produce musical phenomena such as consonance.",
  journal  = "Nature communications",
  volume   =  11,
  number   =  1,
  pages    = "2786",
  month    =  jun,
  year     =  2020,
  language = "en",
  issn     = "2041-1723",
  pmid     = "32493923",
  doi      = "10.1038/s41467-020-16448-6",
  pmc      = "PMC7270137"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dowling2010-tt,
  title     = "Qualia as intervening variables in the understanding of music
               cognition",
  author    = "Dowling, W Jay",
  abstract  = "2 Musica Humana pear to be associated with certain experiences.
               We strive to sort out the ways in which observations of brain
               and of experience provide converging evidence for the ways in
               which we as organisms process information and come to understand
               the world. Mental experiences incorporate our
               understanding---our brain's understanding---of objects in the
               world. It is often through looking at relationships between what
               we perceive and remember, and what is objectively out there in
               the world (the stimuli), that we come to …",
  journal   = "Musica Humana",
  publisher = "labs.utdallas.edu",
  volume    =  2,
  number    =  1,
  pages     = "1--20",
  year      =  2010
}

@INPROCEEDINGS{Jiang2020-zb,
  title     = "Transformer {VAE}: A Hierarchical Model for {Structure-Aware}
               and Interpretable Music Representation Learning",
  booktitle = "{ICASSP} 2020 - 2020 {IEEE} International Conference on
               Acoustics, Speech and Signal Processing ({ICASSP})",
  author    = "Jiang, Junyan and Xia, Gus G and Carlton, Dave B and Anderson,
               Chris N and Miyakawa, Ryan H",
  abstract  = "Structure awareness and interpretability are two of the most
               desired properties of music generation algorithms.
               Structure-aware models generate more natural and coherent music
               with long-term dependencies, while interpretable models are more
               friendly for human-computer interaction and co-creation. To
               achieve these two goals simultaneously, we designed the
               Transformer Variational AutoEncoder, a hierarchical model that
               unifies the efforts of two recent breakthroughs in deep music
               generation: 1) the Music Transformer and 2) Deep Music Analogy.
               The former learns long-term dependencies using attention
               mechanism, and the latter learns interpretable latent
               representations using a disentangled conditional-VAE. We showed
               that Transformer VAE is essentially capable of learning a
               context-sensitive hierarchical representation, regarding local
               representations as the context and the dependencies among the
               local representations as the global structure. By interacting
               with the model, we can achieve context transfer, realizing the
               imaginary situation of ``what if'' a piece is developed
               following the music flow of another piece.",
  publisher = "ieeexplore.ieee.org",
  pages     = "516--520",
  month     =  may,
  year      =  2020,
  keywords  = "Human computer interaction;Conferences;Signal processing
               algorithms;Signal processing;Acoustics;Speech processing;Context
               modeling;Representation learning;VAE;Transformer;music structure",
  issn      = "2379-190X",
  doi       = "10.1109/ICASSP40776.2020.9054554"
}

@INPROCEEDINGS{Sun2021-fm,
  title     = "Melody Harmonization Using Orderless Nade, Chord Balancing, and
               Blocked Gibbs Sampling",
  booktitle = "{ICASSP} 2021 - 2021 {IEEE} International Conference on
               Acoustics, Speech and Signal Processing ({ICASSP})",
  author    = "Sun, Chung-En and Chen, Yi-Wei and Lee, Hung-Shin and Chen,
               Yen-Hsing and Wang, Hsin-Min",
  abstract  = "Coherence and interestingness are two criteria for evaluating
               the performance of melody harmonization, which aims to generate
               a chord progression from a symbolic melody. In this study, we
               apply the concept of orderless NADE, which takes the melody and
               its partially masked chord sequence as the input of the
               BiLSTM-based networks to learn the masked ground truth, to the
               training process. In addition, the class weights are used to
               compensate for some reasonable chord labels that are rarely seen
               in the training set. Consistent with the stochasticity in
               training, blocked Gibbs sampling with proper numbers of
               masking/generating loops is used in the inference phase to
               progressively trade the coherence of the generated chord
               sequence off against its interestingness. The experiments were
               conducted on a dataset of 18,005 melody/chord pairs. Our
               proposed model outperforms the state-of-the-art system
               MTHarmonizer in five of six different objective metrics based on
               chord/melody harmonicity and chord progression. The subjective
               test results with more than 100 participants also show the
               superiority of our model.",
  publisher = "ieeexplore.ieee.org",
  pages     = "4145--4149",
  month     =  jun,
  year      =  2021,
  keywords  = "Training;Measurement;Conferences;Coherence;Signal
               processing;Acoustics;Speech processing;Melody
               harmonization;orderless NADE;blocked Gibbs sampling;sample
               weighting",
  issn      = "2379-190X",
  doi       = "10.1109/ICASSP39728.2021.9414281"
}

@ARTICLE{Anna_L_C_Wood2018-hj,
  title     = "``Like a Cry from the Heart'': An Insider's View of the Genesis
               of Alan Lomax's Ideas and the Legacy of His Research: Part {I}",
  author    = "{Anna L. C. Wood}",
  abstract  = "[Abstract. This article takes us on a journey into the origins
               of Cantometrics and other interdisciplinary studies of
               expressive style undertaken by Alan Lomax (1915--2002) in
               collaboration with Conrad Arensberg (1910--97), Victor Grauer,
               Forrestine Paulay, Edith Trager, Norman Markel, and others.
               Using archival sources, it traces their theoretical development,
               influences, methodologies, and outcomes as accretions of
               knowledge, observation, and converging streams of thought. It
               documents the trail of Lomax's discourse with a wide range of
               authorities and collaborators. I render a candidly critical
               portrait of Lomax (my father) in relation to his work,
               collaborations, and rhetorical style.]",
  journal   = "Ethnomusicology",
  publisher = "[University of Illinois Press, Society for Ethnomusicology]",
  volume    =  62,
  number    =  2,
  pages     = "230--264",
  year      =  2018,
  issn      = "2156-7417",
  doi       = "10.5406/ethnomusicology.62.2.0230"
}

@ARTICLE{Anna_L_C_Wood2018-pn,
  title     = "``Like a Cry from the Heart'': An Insider's View of the Genesis
               of Alan Lomax's Ideas and the Legacy of His Research: Part {II}",
  author    = "{Anna L. C. Wood}",
  abstract  = "[Part 1 of this article explored the development of Alan Lomax's
               theory of expressive style and culture in terms of his family
               background, temperament, cultural surroundings, influences,
               intellectual growth, and the nature and impact of his field
               experiences, the primary source of his ideas. It described the
               program of research established by Lomax and anthropologist
               Conrad Arensberg, codirector of the project, and set out its
               areas of investigation. Part 2 describes the project's
               hypotheses, methodology, and results; reviews its criticisms;
               and takes a personal, reflexive look at Lomax's personality,
               public persona, and presentational style as factors in the
               reception of his work. Finally, it touches upon the potential of
               a comparativist, cross-cultural approach to the current study of
               expressive culture.]",
  journal   = "Ethnomusicology",
  publisher = "[University of Illinois Press, Society for Ethnomusicology]",
  volume    =  62,
  number    =  3,
  pages     = "403--438",
  year      =  2018,
  issn      = "2156-7417",
  doi       = "10.5406/ethnomusicology.62.3.0403"
}

@ARTICLE{Savage2018-jb,
  title     = "Alan Lomax's Cantometrics Project",
  author    = "Savage, Patrick E",
  abstract  = "Alan Lomax's Cantometrics Project was arguably both the most
               ambitious and the most controversial undertaking in music and
               science that the world has known. Its flagship component,
               Lomax's ``cantometric'' analysis of approximately 1,800 songs
               from 148 worldwide populations using 36 classificatory features,
               sparked extensive debate. While Lomax responded to some
               criticisms, neither his final conclusions nor the evidence on
               which they were based were ever fully made clear. For decades,
               neither cantometrics nor Lomax's related projects involving
               dance, speech, popular music, digital humanities, pedagogy, and
               activism were widely adopted by other researchers, but there has
               been a resurgence of interest since Lomax's death in 2002. Here,
               I provide a comprehensive critical review of the Cantometrics
               Project, focusing on issues regarding the song sample,
               classification scheme, statistical analyses, interpretation, and
               ethnocentrism/reductionism. I identify misunderstandings,
               improvements that were made, and criticisms that remain to be
               addressed, and distil Lomax's sometimes-conflicting claims into
               diagrams summarizing his three primary results: (1) ten regional
               song-style types, (2) nine musical factors representing
               intra-musical correlations, and (3) correlations between these
               musical factors and five factors of social structure. Although
               Lomax's interpretations regarding correlations between song
               style and social structure appear weakly supported, his
               historical interpretations regarding connections ranging from
               colonial diaspora to ancient migrations provide a more promising
               starting point for both research and teaching about the global
               arts. While Lomax's attempts to correlate features of social
               structure such as gender, religion, politics, and economics with
               stylistic features of musical performance largely failed to gain
               acceptance, the Cantometrics Project can still provide both
               inspiration and cautionary lessons for future exploration of
               relationships between music and culture.",
  journal   = "Musicae scientiae: the journal of the European Society for the
               Cognitive Sciences of Music",
  publisher = "SAGE Publications",
  volume    =  1,
  pages     = "205920431878608",
  month     =  jan,
  year      =  2018,
  language  = "en",
  issn      = "1029-8649, 2059-2043",
  doi       = "10.1177/2059204318786084"
}

@ARTICLE{noauthor_undated-ia,
  title = "{OdeonManual.pdf}"
}

@ARTICLE{Benhamou2021-wy,
  title     = "Decoding expectation and surprise in dementia: the paradigm of
               music",
  author    = "Benhamou, Elia and Zhao, Sijia and Sivasathiaseelan, Harri and
               Johnson, Jeremy C S and Requena-Komuro, Ma{\"\i}-Carmen and
               Bond, Rebecca L and van Leeuwen, Janneke E P and Russell, Lucy L
               and Greaves, Caroline V and Nelson, Annabel and Nicholas,
               Jennifer M and Hardy, Chris J D and Rohrer, Jonathan D and
               Warren, Jason D",
  abstract  = "Making predictions about the world and responding appropriately
               to unexpected events are essential functions of the healthy
               brain. In neurodegenerative disorders, such as frontotemporal
               dementia and Alzheimer's disease, impaired processing of
               'surprise' may underpin a diverse array of symptoms,
               particularly abnormalities of social and emotional behaviour,
               but is challenging to characterize. Here, we addressed this
               issue using a novel paradigm: music. We studied 62 patients (24
               female; aged 53-88) representing major syndromes of
               frontotemporal dementia (behavioural variant, semantic variant
               primary progressive aphasia, non-fluent-agrammatic variant
               primary progressive aphasia) and typical amnestic Alzheimer's
               disease, in relation to 33 healthy controls (18 female; aged
               54-78). Participants heard famous melodies containing no
               deviants or one of three types of deviant note-acoustic
               (white-noise burst), syntactic (key-violating pitch change) or
               semantic (key-preserving pitch change). Using a regression model
               that took elementary perceptual, executive and musical
               competence into account, we assessed accuracy detecting melodic
               deviants and simultaneously recorded pupillary responses and
               related these to deviant surprise value (information-content)
               and carrier melody predictability (entropy), calculated using an
               unsupervised machine learning model of music. Neuroanatomical
               associations of deviant detection accuracy and coupling of
               detection to deviant surprise value were assessed using
               voxel-based morphometry of patients' brain MRI. Whereas
               Alzheimer's disease was associated with normal deviant detection
               accuracy, behavioural and semantic variant frontotemporal
               dementia syndromes were associated with strikingly similar
               profiles of impaired syntactic and semantic deviant detection
               accuracy and impaired behavioural and autonomic sensitivity to
               deviant information-content (all P < 0.05). On the other hand,
               non-fluent-agrammatic primary progressive aphasia was associated
               with generalized impairment of deviant discriminability (P <
               0.05) due to excessive false-alarms, despite retained
               behavioural and autonomic sensitivity to deviant
               information-content and melody predictability. Across the
               patient cohort, grey matter correlates of acoustic deviant
               detection accuracy were identified in precuneus, mid and mesial
               temporal regions; correlates of syntactic deviant detection
               accuracy and information-content processing, in inferior frontal
               and anterior temporal cortices, putamen and nucleus accumbens;
               and a common correlate of musical salience coding in
               supplementary motor area (all P < 0.05, corrected for multiple
               comparisons in pre-specified regions of interest). Our findings
               suggest that major dementias have distinct profiles of sensory
               'surprise' processing, as instantiated in music. Music may be a
               useful and informative paradigm for probing the predictive
               decoding of complex sensory environments in neurodegenerative
               proteinopathies, with implications for understanding and
               measuring the core pathophysiology of these diseases.",
  journal   = "Brain communications",
  publisher = "academic.oup.com",
  volume    =  3,
  number    =  3,
  pages     = "fcab173",
  month     =  aug,
  year      =  2021,
  keywords  = "frontotemporal dementia; music; pupillometry; surprise;
               voxel-based morphometry",
  language  = "en",
  issn      = "2632-1297",
  pmid      = "34423301",
  doi       = "10.1093/braincomms/fcab173",
  pmc       = "PMC8376684"
}

@ARTICLE{Di_Liberto2021-ha,
  title     = "Accurate Decoding of Imagined and Heard Melodies",
  author    = "Di Liberto, Giovanni M and Marion, Guilhem and Shamma, Shihab A",
  abstract  = "Music perception requires the human brain to process a variety
               of acoustic and music-related properties. Recent research used
               encoding models to tease apart and study the various cortical
               contributors to music perception. To do so, such approaches
               study temporal response functions that summarise the neural
               activity over several minutes of data. Here we tested the
               possibility of assessing the neural processing of individual
               musical units (bars) with electroencephalography (EEG). We
               devised a decoding methodology based on a maximum correlation
               metric across EEG segments (maxCorr) and used it to decode
               melodies from EEG based on an experiment where professional
               musicians listened and imagined four Bach melodies multiple
               times. We demonstrate here that accurate decoding of melodies in
               single-subjects and at the level of individual musical units is
               possible, both from EEG signals recorded during listening and
               imagination. Furthermore, we find that greater decoding
               accuracies are measured for the maxCorr method than for an
               envelope reconstruction approach based on backward temporal
               response functions (bTRF env ). These results indicate that
               low-frequency neural signals encode information beyond note
               timing, especially with respect to low-frequency cortical
               signals below 1 Hz, which are shown to encode pitch-related
               information. Along with the theoretical implications of these
               results, we discuss the potential applications of this decoding
               methodology in the context of novel brain-computer interface
               solutions.",
  journal   = "Frontiers in neuroscience",
  publisher = "frontiersin.org",
  volume    =  15,
  pages     = "673401",
  month     =  aug,
  year      =  2021,
  keywords  = "EEG; TRF; cortical; decoding; music; neural tracking; pitch;
               signal processing",
  language  = "en",
  issn      = "1662-4548, 1662-453X",
  pmid      = "34421512",
  doi       = "10.3389/fnins.2021.673401",
  pmc       = "PMC8375770"
}

@ARTICLE{Schwitzgebel2021-ml,
  title     = "Effects of chord inversion and bass patterns on harmonic
               expectancy in musicians",
  author    = "Schwitzgebel, Emily and White, Christopher Wm",
  abstract  = "This study tests the respective roles of pitch-class content and
               bass patterns within harmonic expectation using a mix of
               behavioral and computational experiments. In our first two
               experiments, participants heard a paradigmatic chord progression
               derived from music theory textbooks and were asked to rate how
               well different target endings completed that progression. The
               completion included the progression's paradigmatic target,
               different inversions of that chord (i.e., different members of
               the harmony were heard in the lowest voice), and a
               ``mismatched'' target, a triad that shared its lowest pitch with
               the paradigmatic ending but altered other pitch-class content.
               Participants generally rated the paradigmatic target most
               highly, followed by other inversions of that chord, with lowest
               ratings generally elicited by the mismatched target. This
               suggests that listeners' harmonic expectations are sensitive to
               both bass patterns and pitch-class content. However, these
               results did not hold in all cases. A final computational
               experiment was run to determine whether variations in behavioral
               responses could be explained by corpus statistics. To this end,
               n-gram chord-transition models and frequency measurements were
               compiled for each progression. Our findings suggest that
               listeners rate highly and have stronger expectations about chord
               progressions that occur frequently and behave consistently
               within tonal corpora.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  39,
  number    =  1,
  pages     = "41--62",
  month     =  sep,
  year      =  2021,
  keywords  = "To read",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2021.39.1.41"
}

@INPROCEEDINGS{Chang2021-iv,
  title     = "Semi-supervised Many-to-many Music Timbre Transfer",
  booktitle = "Proceedings of the 2021 International Conference on Multimedia
               Retrieval",
  author    = "Chang, Yu-Chen and Chen, Wen-Cheng and Hu, Min-Chun",
  abstract  = "This work presents a music timbre transfer model that aims to
               transfer the style of a music clip while preserving the semantic
               content. Compared to the existing music timbre transfer models,
               our model can achieve many-to-many timbre transfer between
               different instruments. The proposed method is based an
               autoencoder framework, which comprises two pretrained encoders
               trained in a supervised manner and one decoder trained in an
               unsupervised manner. To learn more representative features for
               the encoders, we produced a parallel dataset, called MI-Para,
               which is synthesized from MIDI files and digital audio
               workstations (DAW). Both the objective and the subjective
               evaluation results showed the effectiveness of the proposed
               framework. To scale up the application scenario, we also
               demonstrate that our model can achieve style transfer by
               training in a semi-supervised manner with a smaller parallel
               dataset.",
  publisher = "Association for Computing Machinery",
  pages     = "442--446",
  series    = "ICMR '21",
  month     =  aug,
  year      =  2021,
  address   = "New York, NY, USA",
  keywords  = "music timbre transfer, autoencoder, deep neural networks",
  location  = "Taipei, Taiwan",
  isbn      = "9781450384636",
  doi       = "10.1145/3460426.3463590"
}

@INPROCEEDINGS{Gutierrez_Paez2021-xs,
  title     = "Emotion Annotation of Music: A Citizen Science Approach",
  booktitle = "Collaboration Technologies and Social Computing",
  author    = "Guti{\'e}rrez P{\'a}ez, Nicol{\'a}s Felipe and
               G{\'o}mez-Ca{\~n}{\'o}n, Juan Sebasti{\'a}n and Porcaro, Lorenzo
               and Santos, Patricia and Hern{\'a}ndez-Leo, Davinia and
               G{\'o}mez, Emilia",
  abstract  = "The understanding of the emotions in music has motivated
               research across diverse areas of knowledge for decades. In the
               field of computer science, there is a particular interest in
               developing algorithms to ``predict'' the emotions in music
               perceived by or induced to a listener. However, the gathering of
               reliable ``ground truth'' data for modeling the emotional
               content of music poses challenges, since tasks related with
               annotations of emotions are time consuming, expensive and
               cognitively demanding due to its inherent subjectivity and its
               cross-disciplinary nature. Citizen science projects have proven
               to be a useful approach to solve these types of problems where
               there is a need for recruiting collaborators for massive scale
               tasks. We developed a platform for annotating emotional content
               in musical pieces following a citizen science approach, to
               benefit not only the researchers, who benefit from the generated
               dataset, but also the volunteers, who are engaged to collaborate
               on the research project, not only by providing annotations but
               also through their self and community-awareness about the
               emotional perception of the music. Likewise, gamification
               mechanisms motivate the participants to explore and discover new
               music based on the emotional content. Preliminary user
               evaluations showed that the platform design is in line with the
               motivations of the general public, and that the citizen science
               approach offers an iterative refinement to enhance the quantity
               and quality of contributions by involving volunteers in the
               design process. The usability of the platform was acceptable,
               although some of the features require improvements.",
  publisher = "Springer International Publishing",
  pages     = "51--66",
  year      =  2021,
  doi       = "10.1007/978-3-030-85071-5\_4"
}

@ARTICLE{Bernstein2001-ot,
  title     = "Focusing the ``right'' way in Romance determiner phrases",
  author    = "Bernstein, Judy B",
  abstract  = "This article examines constructions involving DP-final
               demonstratives, possessive adjectives, indefinite quantifiers,
               and demonstrative reinforcers in several Romance languages.
               Across these languages the DP-final position of these elements
               yields a focus interpretation, whereas the prenominal position
               yields a neutral interpretation. Other approaches to these sorts
               of facts have (tacitly) treated the two available word orders as
               equivalent constructions. They have not considered, and so
               cannot easily account for, the distinct interpretation that each
               of the word orders yields. Under the assumption that the
               prenominal position of these elements is basic, the current
               approach develops the idea that the DP-final element is
               ``stranded'' DP finally as a result of the leftward movement of
               a syntactic phrase consisting of an extended NP. The facts
               examined here recall those characterizing the expression of
               focus in the Romance clause, recently analyzed as a case of
               scrambling (Ord{\'o}{\~n}ez 1997, Zubizarreta 1998). If on the
               right track, the current analysis therefore provides further
               evidence for the parallelism between noun phrases and clauses.
               In certain Romance languages, an intermediate (postnominal)
               position is also available for these DP elements , although the
               interpretation associated with this position does not exactly
               match that of either the prenominal or DP-final position. It is
               proposed that the intermediate position is derived by crossing
               the noun over the demonstrative (reinforcer), possessive, or
               indefinite quantifier, whose base positions within DP are
               relatively high. The prediction then is that only those
               languages with robust noun movement (that is, movement to a
               relatively high functional head) will exhibit this word order.",
  publisher = "De Gruyter Mouton",
  volume    =  13,
  number    =  1,
  pages     = "1--29",
  month     =  mar,
  year      =  2001,
  language  = "en",
  issn      = "1613-4079",
  doi       = "10.1515/prbs.13.1.1"
}

@ARTICLE{Sears2021-mk,
  title     = "Intonation discrimination for tonal chord sequences in a priming
               paradigm:Effects of target predictability and musical expertise",
  author    = "Sears, David R W and Verbeten, Jonathan and Percival, Hannah M",
  journal   = "Auditory perception \& cognition",
  publisher = "Informa UK Limited",
  pages     = "1--16",
  month     =  sep,
  year      =  2021,
  keywords  = "To read",
  language  = "en",
  issn      = "2574-2442, 2574-2450",
  doi       = "10.1080/25742442.2021.1972744"
}

@ARTICLE{Morey1940-yn,
  title     = "Upset in Emotions",
  author    = "Morey, Robert",
  journal   = "The Journal of social psychology",
  publisher = "Routledge",
  volume    =  12,
  number    =  2,
  pages     = "333--356",
  month     =  nov,
  year      =  1940,
  keywords  = "To read",
  issn      = "0022-4545",
  doi       = "10.1080/00224545.1940.9921477"
}

@ARTICLE{Duvel2021-fr,
  title     = "Experience of Groove Questionnaire",
  author    = "D{\"u}vel, Nina and Labonde, Philippe and Bechtold, Toni and
               Senn, Olivier and Kopiez, Reinhard",
  abstract  = "In recent empirical research, the experience of groove (i.e.,
               the pleasant sense of wanting to move along with the music) has
               come into focus. By developing the new Experience of Groove
               Questionnaire (EGQ), Senn et al. (2020) have provided a
               standardized and validated research instrument for future
               studies, consisting of the two correlated factors Urge to Move
               and Pleasure. The present study reports the translation of the
               English version into German and a validation with a German
               sample (N = 455). The original version's factor structure was
               confirmed by the German data. Test-retest reliability was found
               to be high (rtt > .85) for both factors. To determine convergent
               validity, two other scales were included: The Drum Pattern
               Quality Scale (Fr{\"u}hauf, Kopiez, \& Platz, 2013) and the
               Aesthetic Emotions Scale (Schindler et al., 2017) showed high
               correlations (.78 < r < .87) with the two factors of the EGQ and
               therefore indicated convergent validity. We conclude that the
               German version shows good psychometric properties and recommend
               its use for future research on the experience of groove.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  39,
  number    =  1,
  pages     = "83--99",
  month     =  sep,
  year      =  2021,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2021.39.1.83"
}

@ARTICLE{Ponsot2018-fl,
  title    = "Cracking the social code of speech prosody using reverse
              correlation",
  author   = "Ponsot, Emmanuel and Burred, Juan Jos{\'e} and Belin, Pascal and
              Aucouturier, Jean-Julien",
  abstract = "Human listeners excel at forming high-level social
              representations about each other, even from the briefest of
              utterances. In particular, pitch is widely recognized as the
              auditory dimension that conveys most of the information about a
              speaker's traits, emotional states, and attitudes. While past
              research has primarily looked at the influence of mean pitch,
              almost nothing is known about how intonation patterns, i.e.,
              finely tuned pitch trajectories around the mean, may determine
              social judgments in speech. Here, we introduce an experimental
              paradigm that combines state-of-the-art voice transformation
              algorithms with psychophysical reverse correlation and show that
              two of the most important dimensions of social judgments, a
              speaker's perceived dominance and trustworthiness, are driven by
              robust and distinguishing pitch trajectories in short utterances
              like the word ``Hello,'' which remained remarkably stable whether
              male or female listeners judged male or female speakers. These
              findings reveal a unique communicative adaptation that enables
              listeners to infer social traits regardless of speakers' physical
              characteristics, such as sex and mean pitch. By characterizing
              how any given individual's mental representations may differ from
              this generic code, the method introduced here opens avenues to
              explore dysprosody and social-cognitive deficits in disorders
              like autism spectrum and schizophrenia. In addition, once derived
              experimentally, these prototypes can be applied to novel
              utterances, thus providing a principled way to modulate
              personality impressions in arbitrary speech signals.",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  115,
  number   =  15,
  pages    = "3972--3977",
  month    =  apr,
  year     =  2018,
  keywords = "prosody; reverse-correlation; social traits; speech; voice",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "29581266",
  doi      = "10.1073/pnas.1716090115",
  pmc      = "PMC5899438"
}

@ARTICLE{Brielmann2021-ij,
  title    = "Beauty, the feeling",
  author   = "Brielmann, Aenne A and Nuzzo, Angelica and Pelli, Denis G",
  abstract = "Many philosophers and psychologists have made claims about what
              is felt in an experience of beauty. Here, we test how well these
              claims match the feelings that people report while looking at an
              image, or listening to music, or recalling a personal experience
              of beauty. We conducted ten experiments (total n = 851) spanning
              three nations (US, UK, and India). Across nations and modalities,
              top-rated beauty experiences are strongly characterized by six
              dimensions: intense pleasure, an impression of universality, the
              wish to continue the experience, exceeding expectation, perceived
              harmony in variety, and meaningfulness. Other frequently proposed
              beauty characteristics - like surprise, desire to understand, and
              mind wandering - are uncorrelated with feeling beauty. A typical
              remembered beautiful experience was active and social like a
              family holiday - hardly ever mentioning beauty - and only rarely
              mentioned art, unlike the academic emphasis, in aesthetics, on
              solitary viewing of art. Our survey aligns well with Kant and the
              psychological theories that emphasize pleasure, and reject
              theories that emphasize information seeking.",
  journal  = "Acta psychologica",
  volume   =  219,
  pages    = "103365",
  month    =  sep,
  year     =  2021,
  keywords = "To read",
  language = "en",
  issn     = "0001-6918, 1873-6297",
  pmid     = "34246875",
  doi      = "10.1016/j.actpsy.2021.103365",
  pmc      = "PMC8514293"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Samiotis2021-ui,
  title        = "Exploring the music perception skills of crowd workers",
  author       = "Samiotis, Ioannis Petros and Qiu, Sihang and Lofi, Christoph
                  and Yang, Jie and Gadiraju, Ujwal and Bozzon, Alessandro",
  abstract     = "Music content annotation campaigns are common on paid
                  crowdsourcing platforms. Crowd workers are expected to
                  annotate complicated music artefacts, which can demand
                  certain skills and expertise. Traditional methods of
                  participant selection are not designed to capture these kind
                  of domainspecific skills and expertise, and often
                  domain-specific questions fall under the general demographics
                  category. Despite the popularity of such tasks, there is a
                  general lack of deeper understanding of the distribution of
                  musical properties-especially …",
  publisher    = "sihang.nl",
  year         =  2021,
  howpublished = "\url{https://sihang.nl/files/publications/hcomp2021.pdf}",
  note         = "Accessed: 2021-9-17",
  keywords     = "To read"
}

@ARTICLE{noauthor_undated-ue,

}

@BOOK{Williamon2021-ld,
  title     = "Performing Music Research: Methods in Music Education,
               Psychology, and Performance Science",
  author    = "Williamon, Aaron and Ginsborg, Jane and Perkins, Rosie and
               Waddell, George",
  abstract  = "What is it that drives people to undertake music research? Such
               interest frequently grows from on-the-ground experiences as
               learners, performers, facilitators, composers, arts
               administrators, and educators. It can emerge, for example, from
               music teachers trying out new teaching methods, performers
               wishing to know more about how to improvise effectively,
               educators pursuing the most effective ways to structure music
               curricula, musicians aiming to explain why their music enhances
               wellbeing among different groups of people, and orchestral
               managers seeking to promote and protect the health of their
               players. At the heart of all of these enquiries lies a question
               of some sort, and it is these research questions that determine
               the direction of the research to be undertaken. Performing Music
               Research is a comprehensive guide to planning, conducting,
               analyzing, and communicating research in music performance. The
               book examines the approaches and strategies that underpin
               research in music education, psychology, and performance
               science. It reviews the knowledge and skills needed to critique
               existing studies in these fields and to design and carry out new
               investigations. Perspectives on qualitative, quantitative, and
               multistrategy methodologies are highlighted across the book in
               ways that help aspiring researchers bring precision to their
               research questions, select methods that are appropriate for
               addressing their questions, and apply those methods
               systematically and rigorously. Each chapter contains a study
               guide, comprising a chapter summary, a list of keywords, and
               suggestions for further discussion, and the book concludes with
               a resources section, including a glossary and supplementary
               material to support advanced statistical analysis. The book''s
               companion website provides information designed to facilitate
               access to original research and to test knowledge and
               understanding.",
  publisher = "Oxford University Press",
  month     =  mar,
  year      =  2021,
  language  = "en",
  isbn      = "9780191023903"
}

@ARTICLE{Warrenburg2020-go,
  title     = "Choosing the right tune",
  author    = "Warrenburg, Lindsay A",
  abstract  = "When designing a new study regarding how music can portray and
               elicit emotion, one of the most crucial design decisions
               involves choosing the best stimuli. Every researcher must find
               musical samples that are able to capture an emotional state, are
               appropriate lengths, and have minimal potential for biasing
               participants. Researchers have often utilized musical excerpts
               that have previously been used by other scholars, but the
               appropriate musical choices depend on the specific goals of the
               study in question and will likely change among various research
               designs. The intention of this paper is to examine how musical
               stimuli have been selected in a sample of 306 research articles
               dating from 1928 through 2018. Analyses are presented regarding
               the designated emotions, how the stimuli were selected, the
               durations of the stimuli, whether the stimuli are excerpts from
               a longer work, and whether the passages have been used in
               studies about perceived or induced emotion. The results suggest
               that the literature relies on nine emotional terms, focuses more
               on perceived emotion than on induced emotion, and contains
               mostly short musical stimuli. I suggest that some of the
               inconclusive results from previous reviews may be due to the
               inconsistent use of emotion terms throughout the music
               community.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  37,
  number    =  3,
  pages     = "240--258",
  month     =  feb,
  year      =  2020,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2020.37.3.240"
}

@ARTICLE{Serrano2009-zu,
  title     = "Extracting the multiscale backbone of complex weighted networks",
  author    = "Serrano, M Angeles and Bogu{\~n}{\'a}, Mari{\'a}n and
               Vespignani, Alessandro",
  abstract  = "A large number of complex systems find a natural abstraction in
               the form of weighted networks whose nodes represent the elements
               of the system and the weighted edges identify the presence of an
               interaction and its relative strength. In recent years, the
               study of an increasing number of large-scale networks has
               highlighted the statistical heterogeneity of their interaction
               pattern, with degree and weight distributions that vary over
               many orders of magnitude. These features, along with the large
               number of elements and links, make the extraction of the truly
               relevant connections forming the network's backbone a very
               challenging problem. More specifically, coarse-graining
               approaches and filtering techniques come into conflict with the
               multiscale nature of large-scale systems. Here, we define a
               filtering method that offers a practical procedure to extract
               the relevant connection backbone in complex multiscale networks,
               preserving the edges that represent statistically significant
               deviations with respect to a null model for the local assignment
               of weights to edges. An important aspect of the method is that
               it does not belittle small-scale interactions and operates at
               all scales defined by the weight distribution. We apply our
               method to real-world network instances and compare the obtained
               results with alternative backbone extraction techniques.",
  journal   = "Proceedings of the National Academy of Sciences of the United
               States of America",
  publisher = "National Acad Sciences",
  volume    =  106,
  number    =  16,
  pages     = "6483--6488",
  month     =  apr,
  year      =  2009,
  language  = "en",
  issn      = "0027-8424, 1091-6490",
  pmid      = "19357301",
  doi       = "10.1073/pnas.0808904106",
  pmc       = "PMC2672499"
}

@ARTICLE{Rosati2021-zi,
  title     = "Modelling song popularity asacontagious process",
  author    = "Rosati, Dora P and Woolhouse, Matthew H and Bolker, Benjamin M
               and Earn, David J D",
  journal   = "Proceedings of the Royal Society A: Mathematical, Physical and
               Engineering Sciences",
  publisher = "Royal Society",
  volume    =  477,
  number    =  2253,
  pages     = "20210457",
  month     =  sep,
  year      =  2021,
  keywords  = "To read",
  doi       = "10.1098/rspa.2021.0457"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Weiss2021-di,
  title     = "Training Deep {Pitch-Class} Representations With a {Multi-Label}
               {CTC} Loss",
  booktitle = "International Society for Music Information Retrieval Conference
               ({ISMIR})",
  author    = "Weiss, Christof and Peeters, Geoffroy",
  abstract  = "Despite the success of end-to-end approaches, chroma (or
               pitch-class) features remain a useful mid-level representation
               of music audio recordings due to their direct interpretability.
               Since traditional chroma variants obtained with signal
               processing suffer from timbral artifacts such as overtones or
               vibrato, they do not directly reflect the pitch classes notated
               in the score. For this reason, training a chroma representation
               using deep learning (`` deep chroma'') has become an interesting
               strategy. Existing approaches involve the use of …",
  publisher = "hal.archives-ouvertes.fr",
  year      =  2021,
  keywords  = "To read"
}

@INPROCEEDINGS{Liang2021-fe,
  title     = "The role of preference consistency, defaults and musical
               expertise in users' exploration behavior in a genre exploration
               recommender",
  booktitle = "Fifteenth {ACM} Conference on Recommender Systems",
  author    = "Liang, Yu and Willemsen, Martijn C",
  abstract  = "Recommender systems are efficient at predicting users' current
               preferences, but how users' preferences develop over time is
               still under-explored. In this work, we study the development of
               users' musical preferences. Exploring musical preference
               consistency between short-term and long-term preferences in data
               from earlier studies, we find that users with higher musical
               expertise have more consistent preferences at their top-listened
               artists and tags than those with lower musical expertise. Users
               typically chose to explore genres that were close to their
               current preferences, and this effect was stronger for expert
               users. Based on these findings we conducted a user study on
               genre exploration to investigate (1) whether it is possible to
               nudge users to explore more distant genres, and (2) how users'
               exploration behaviors within a genre are influenced by default
               recommendation settings that balance personalization with genre
               representativeness in different ways. Our results show that
               users were more likely to select the more distant genres if
               these were presented at the top of the list. However, users with
               high musical expertise were less likely to do so, consistent
               with our earlier findings. When given a representative or mixed
               (balanced) default for exploration within a genre, users
               selected less personalized recommendation settings and explored
               further away from their current preferences, than with a
               personalized default. However, this effect was moderated by
               users' slider usage behaviors. Overall, our results suggest that
               (personalized) defaults can nudge users to explore new, more
               distant genres and songs. However, the effect is smaller for
               those with higher musical expertise levels.",
  publisher = "Association for Computing Machinery",
  pages     = "230--240",
  series    = "RecSys '21",
  month     =  sep,
  year      =  2021,
  address   = "New York, NY, USA",
  keywords  = "Musical expertise, Music genre exploration, Default, Preference
               consistency, Nudge;music preferences;To read",
  location  = "Amsterdam, Netherlands",
  isbn      = "9781450384582",
  doi       = "10.1145/3460231.3474253"
}

@ARTICLE{Cole1974-nk,
  title    = "Toward a theory of speech perception",
  author   = "Cole, R A and Scott, B",
  journal  = "Psychological review",
  volume   =  81,
  number   =  4,
  pages    = "348--374",
  month    =  jul,
  year     =  1974,
  keywords = "To read",
  language = "en",
  issn     = "0033-295X",
  pmid     = "4607301",
  doi      = "10.1037/h0036656"
}

@ARTICLE{Levelt1966-el,
  title     = "Triadic comparisons of musical intervals1",
  author    = "Levelt, W J M and Geer, J P van de and Plomp, R",
  abstract  = "An analysis is made of the perception of musical intervals. Two
               kinds of stimuli were used; intervals consisting of two
               simultaneous simple tones (sinusoids) and intervals consisting
               of two simultaneous complex tones (fundamental plus harmonics).
               Subjects judged the stimuli by the method of triadic comparisons
               in an incomplete balanced design. Multidimensional analysis was
               performed according to Kruskal's MDSCAL program. The following
               results were obtained: (a) In both the space of simple-tone
               intervals (S) and the space of complex-tone intervals (C)
               musical intervals are ordered according to their width
               (frequency difference between fundamental tones). This ordering
               appears to follow a scale which is bowed upwards in the centre;
               extremely narrow and extremely wide intervals are therefore more
               similar than would be expected on the basis of their width
               alone. (b) In addition, the intervals in C are ordered along a
               dimension which is related to the complexity of the frequency
               ratio of the fundamental tones. This is much less true for S.
               (c) In S, on the other hand, intervals are differentiated on a
               dimension which is interpreted as indicating their resemblance
               to certain normative reference intervals. Attention is given to
               a number of methodological issues.",
  journal   = "The British journal of mathematical and statistical psychology",
  publisher = "Wiley",
  volume    =  19,
  number    =  2,
  pages     = "163--179",
  month     =  nov,
  year      =  1966,
  keywords  = "To read",
  language  = "en",
  issn      = "0007-1102, 2044-8317",
  doi       = "10.1111/j.2044-8317.1966.tb00366.x"
}

@ARTICLE{Maher1980-zw,
  title    = "A rigorous test of the proposition that musical intervals have
              different psychological effects",
  author   = "Maher, T F",
  abstract = "Musical intervals, the elementary tonal relations of music, are
              thought to have widely disparate psychological effects. However,
              in previous empirical investigations of this proposition, effects
              due to musical intervals have been routinely confounded with
              those due to the frequencies, frequency differences, and mean
              frequencies of the component tones of the interval. An
              experimental design that can provide an unconfounded
              musical-interval effect was employed in the present study, in
              which ratings for 14 musical intervals formed at two different
              mean frequencies were collected from 16 subjects. Although the
              results indicated that certain musical intervals do indeed differ
              in their psychological effects, 7 of the 14 intervals were never
              discriminated from one another on any of the 11 rating scales,
              and the number of pairwise discriminations observed among
              intervals was considerably less than the maximum number possible.
              Thus, although the present results provide the first rigorous
              demonstration that the musical interval factor can affect verbal
              responding, they provide at the same time only partial support
              for the popular notion that each musical interval has a unique
              psychological effect.",
  journal  = "The American journal of psychology",
  volume   =  93,
  number   =  2,
  pages    = "309--327",
  month    =  jun,
  year     =  1980,
  language = "en",
  issn     = "0002-9556",
  pmid     = "7406071",
  doi      = "10.2307/1422235"
}

@ARTICLE{Frith2003-gw,
  title     = "Models of dyadic social interaction",
  author    = "Frith, C D and Wolpert, D M and Griffin, Dale and Gonzalez,
               Richard",
  journal   = "Philosophical transactions of the Royal Society of London.
               Series B, Biological sciences",
  publisher = "Royal Society",
  volume    =  358,
  number    =  1431,
  pages     = "573--581",
  month     =  mar,
  year      =  2003,
  keywords  = "To read",
  issn      = "0962-8436",
  doi       = "10.1098/rstb.2002.1263"
}

@ARTICLE{Murray-Rust2011-lb,
  title    = "Towards a model of musical interaction and communication",
  author   = "Murray-Rust, Dave and Smaill, Alan",
  abstract = "In this paper we argue there is a need for a formalised
              description of musical interaction, which allows reasoning about
              the musical decisions of human and computational players. To this
              end, we define a simple model of musical transmission which is
              amenable to distribution among several musical agents. On top of
              this, we construct a model of musical perception, based on
              analysis functions from the musical surface to values on
              lattices. These values are then used to construct a musical
              context, allowing for a music-oriented version of concepts such
              as common ground. This context allows for the interpretation of
              individual musical output as a stream of discrete actions, with
              the possibility of constructing sets of performative actions,
              analogous to those used in Speech Act Theory. This allows musical
              agent systems to construct output in terms of a communicative
              dialogue, and should enable more responsive, intelligent
              participation from these virtual musicians. Finally, we discuss a
              prototype system which implements these concepts in order to
              perform piano duets with human performers, and discuss how this
              theory can be seen as a better defined extension of previous
              theories.",
  journal  = "Artificial intelligence",
  volume   =  175,
  number   =  9,
  pages    = "1697--1721",
  month    =  jun,
  year     =  2011,
  keywords = "Multi-agent systems; Musical agents; Communicative acts; Human
              computer interaction;To read",
  issn     = "0004-3702",
  doi      = "10.1016/j.artint.2011.01.002"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Einstein1918-iw,
  title     = "{\"U}ber Gravitationswellen",
  author    = "Einstein, Albert",
  abstract  = "{\"U}ber Gravitationswellen - NASA/ADS … {\"U}ber
               Gravitationswellen …",
  journal   = "Sitzungsberichte der K{\"o}niglich Preu{\ss}ischen Akademie der
               Wissenschaften",
  publisher = "ui.adsabs.harvard.edu",
  pages     = "154--167",
  year      =  1918
}

@ARTICLE{Gustar2020-iy,
  title     = "Fame, obscurity and power laws in music history",
  author    = "Gustar, Andrew",
  abstract  = "This paper investigates the processes leading to musical fame or
               obscurity, whether for composers, performers, or works
               themselves. It starts from the observation that the patterns of
               success, across many historical music datasets, follow a similar
               mathematical relationship known as a power law, often with an
               exponent approximately equal to two. It presents several simple
               models which can produce power law distributions. An examination
               of these models' transience characteristics suggests parallels
               with some historical music examples, giving clues to the ways
               that success and obscurity might emerge in practice and the
               extent to which success might be influenced by inherent musical
               quality. These models can be seen as manifestations of a more
               fundamental process resulting from the law of maximum entropy,
               subject to a constraint on the average value of the logarithm of
               the success measure. This implies that musical success is a
               multiplicative quality, and suggests that musical markets
               operate to strike a balance between familiarity (socio-cultural
               importance) and novelty (individual importance). The common
               power law exponent of two is seen to emerge as a consequence of
               the tendency for musical activity to be spread evenly across the
               log-success bands.",
  journal   = "Empirical musicology review: EMR",
  publisher = "The Ohio State University Libraries",
  volume    =  14,
  number    = "3-4",
  pages     = "186",
  month     =  jul,
  year      =  2020,
  keywords  = "success; obscurity; power law; history; simulation; maximum
               entropy;To read",
  language  = "en",
  issn      = "1559-5749",
  doi       = "10.18061/emr.v14i3-4.7003"
}

@BOOK{Thompson2021-eu,
  title     = "The Science and Psychology of Music: From Beethoven at the
               Office to Beyonc{\'e} at the Gym",
  author    = "Thompson, William Forde and Olsen, Kirk N",
  abstract  = "This book provides a broad introduction to the scientific and
               psychological study of music, exploring how music is processed
               by our brains, affects us emotionally, shapes our personal and
               cultural identities, and can be used in therapeutic and
               educational contexts.Why are some people tone deaf and others
               musical savants? What do our musical preferences say about our
               personality and the culture in which we were raised? Why do
               certain songs remind us so strongly of particular people,
               places, or events? How can music be therapeutically used to help
               those with autism, Parkinson's, and other medical conditions?
               The Science and Psychology of Music: From Beethoven at the
               Office to Beyonc{\'e} at the Gym answers these and other
               questions.This book provides a broad and accessible introduction
               to the fascinating field of music psychology. Despite its name,
               music psychology includes a number of fields, including
               neuroscience, psychology, social psychology, sociology, and
               health. Through a collection of thematically organized chapters,
               readers will discover how our brains recognize elements of
               music, how music can affect us and shape our identities, and the
               many real-world applications for such information.Explores a
               topic that is of great interest to both psychology students and
               the general public through accessible and engaging
               contentProvides a conceptual framework for readers and through a
               multi-part format allows them to focus their attention on their
               particular areas of interestFurthers readers' understanding of
               how music can affect our wellbeing as it includes both our
               physical and psychological healthReflects the subject knowledge
               of contributing experts in a wide variety of academic
               disciplines",
  publisher = "Greenwood Publishing Group Inc",
  year      =  2021,
  address   = "Westwood, CT",
  language  = "en",
  isbn      = "9781440857713"
}

@BOOK{Deutsch2013-xv,
  title     = "Psychology of Music",
  author    = "Deutsch, Diana",
  abstract  = "The Psychology of Music draws together the diverse and scattered
               literature on the psychology of music. It explores the way music
               is processed by the listener and the performer and considers
               several issues that are of importance both to perceptual
               psychology and to contemporary music, such as the way the sound
               of an instrument is identified regardless of its pitch or
               loudness, or the types of information that can be discarded in
               the synthetic replication of a sound without distorting
               perceived timbre. Comprised of 18 chapters, this book begins
               with a review of the classical psychoacoustical literature on
               tone perception, focusing on characteristics of particular
               relevance to music. The attributes of pitch, loudness, and
               timbre are examined, and a summary of research methods in
               psychoacoustics is presented. Subsequent chapters deal with
               timbre perception; the subjective effects of different sound
               fields; temporal aspects of music; abstract structures formed by
               pitch relationships in music; different tests of musical
               ability; and the importance of abstract structural
               representation in understanding how music is performed. The
               final chapter evaluates the relationship between new music and
               psychology. This monograph should be a valuable resource for
               psychologists and musicians.",
  publisher = "Elsevier",
  month     =  oct,
  year      =  2013,
  address   = "London, UK",
  language  = "en",
  isbn      = "9781483292731"
}

@BOOK{Hallam2017-xk,
  title     = "The Oxford Handbook of Music Psychology",
  author    = "Hallam, Susan and Cross, Ian and Thaut, Michael",
  abstract  = "The second edition of The Oxford Handbook of Music Psychology
               updates the original landmark text and provides a comprehensive
               review of the latest developments in this fast-growing area of
               research. Covering both experimental and theoretical
               perspectives, each of the 11 sections is edited byan
               internationally recognised authority in the area. The first ten
               parts present chapters that focus on specific areas of music
               psychology: the origins and functions of music; music
               perception, responses to music; music and the brain; musical
               development; learning musical skills; musical performance;
               composition and improvisation; the role of music ineveryday
               life; and music therapy. In each part authors critically review
               the literature, highlight current issues and explore
               possibilities for the future. The final part examines how, in
               recent years, the study of music psychology has broadened to
               include a range of other disciplines. It considers the way that
               research has developed in relation to technological advances,
               and points the direction for further development in the field.
               With contributionsfrom internationally recognised experts across
               55 chapters, it is an essential resource for students and
               researchers in psychology and musicology.",
  publisher = "Oxford University Press",
  month     =  dec,
  year      =  2017,
  address   = "Oxford, UK",
  language  = "en",
  isbn      = "9780198818830"
}

@ARTICLE{Popescu2021-af,
  title    = "Western listeners detect boundary hierarchy in Indian music: a
              segmentation study",
  author   = "Popescu, Tudor and Widdess, Richard and Rohrmeier, Martin",
  abstract = "How are listeners able to follow and enjoy complex pieces of
              music? Several theoretical frameworks suggest links between the
              process of listening and the formal structure of music, involving
              a division of the musical surface into structural units at
              multiple hierarchical levels. Whether boundaries between
              structural units are perceivable to listeners unfamiliar with the
              style, and are identified congruently between na{\"\i}ve
              listeners and experts, remains unclear. Here, we focused on the
              case of Indian music, and asked 65 Western listeners (of mixed
              levels of musical training; most unfamiliar with Indian music) to
              intuitively segment into phrases a recording of sitar
              {\=a}l{\=a}p of two different r{\=a}ga-modes. Each recording was
              also segmented by two experts, who identified boundary regions at
              section and phrase levels. Participant- and region-wise scores
              were computed on the basis of ``clicks'' inside or outside
              boundary regions (hits/false alarms), inserted earlier or later
              within those regions (high/low ``promptness''). We found
              substantial agreement-expressed as hit rates and click
              densities-among participants, and between participants' and
              experts' segmentations. The agreement and promptness scores
              differed between participants, levels, and recordings. We found
              no effect of musical training, but detected real-time awareness
              of grouping completion and boundary hierarchy. The findings may
              potentially be explained by underlying general bottom-up
              processes, implicit learning of structural relationships,
              cross-cultural musical similarities, or universal cognitive
              capacities.",
  journal  = "Scientific reports",
  volume   =  11,
  number   =  1,
  pages    = "3112",
  month    =  feb,
  year     =  2021,
  keywords = "To read",
  language = "en",
  issn     = "2045-2322",
  pmid     = "33542358",
  doi      = "10.1038/s41598-021-82629-y",
  pmc      = "PMC7862587"
}

@ARTICLE{Von_Berg2021-eq,
  title     = "Assessing room acoustic listening expertise",
  author    = "von Berg, Markus and Steffens, Jochen and Weinzierl, Stefan and
               M{\"u}llensiefen, Daniel",
  abstract  = "Musicians and music professionals are often considered to be
               expert listeners for listening tests on room acoustics. However,
               these tests often target acoustic parameters other than those
               typically relevant in music such as pitch, rhythm, amplitude, or
               timbre. To assess the expertise in perceiving and understanding
               room acoustical phenomena, a listening test battery was
               constructed to measure the perceptual sensitivity and cognitive
               abilities in the identification of rooms with different
               reverberation times and different spectral envelopes.
               Performance in these tests was related to data from the
               Goldsmiths Musical Sophistication Index, self-reported previous
               experience in music recording and acoustics, and academic
               knowledge on acoustics. The data from 102 participants show that
               sensory and cognitive abilities are both correlated
               significantly with musical training, analytic listening skills,
               recording experience, and academic knowledge on acoustics,
               whereas general interest in and engagement with music do not
               show any significant correlations. The regression models, using
               only significantly correlated criteria of musicality and
               professional expertise, explain only small to moderate amounts
               (11\%?28\%) of the variance in the ?room acoustic listening
               expertise? across the different tasks of the battery. Thus, the
               results suggest that the traditional criteria for selecting
               expert listeners in room acoustics are only weak predictors of
               their actual performances.",
  journal   = "The Journal of the Acoustical Society of America",
  publisher = "Acoustical Society of America",
  volume    =  150,
  number    =  4,
  pages     = "2539--2548",
  month     =  oct,
  year      =  2021,
  keywords  = "To read",
  issn      = "0001-4966",
  doi       = "10.1121/10.0006574"
}

@ARTICLE{Gough2021-ko,
  title    = "Acoustic characterisation of string instruments by internal
              cavity measurements",
  author   = "Gough, Colin",
  abstract = "The use of internal cavity sound measurements to characterise the
              acoustic properties of any hollow-bodied string instrument is
              described using the violin family as an example. Measurements are
              described using inexpensive sub-miniature electret microphones as
              sensors for the impact hammer, both internal and radiated sound,
              and bridge admittance. The excited vibrations of the body shell
              are shown to excite a rich spectrum of internal cavity
              resonances, which are strongly correlated with the radiated
              sound, particularly in the signature and transitional frequency
              ranges below around 1.5 kHz for the violin. Examples of how such
              measurements can be used as a working tool in the luthier's
              workshop and for research on the acoustics of string instruments
              of any kind or size are illustrated by measurements on the
              violin, viola, cello, and double bass.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  150,
  number   =  3,
  pages    = "1922",
  month    =  sep,
  year     =  2021,
  keywords = "To read",
  language = "en",
  issn     = "0001-4966, 1520-8524",
  pmid     = "34598639",
  doi      = "10.1121/10.0006205"
}

@ARTICLE{Hassler1988-lv,
  title     = "Handedness, musical abilities, and dichaptic and dichotic
               performance in adolescents: A longitudinal study",
  author    = "Hassler, Marianne and Birbaumer, Niels",
  abstract  = "At five stages of an ongoing longitudinal study with
               adolescents, we compared three groups of male and female
               adolescents having different levels of musical abilities. Once a
               year, participants were tested for musical talent, dichaptic and
               dichotic performance, and spatial and verbal ability. Of 60
               boys, 12 were left?handed; of 60 girls, 7 were left?handed.
               Left?handedness was related to musical talent and to the ability
               to compose/improvise in boys but not in girls. No differences
               were found between left?handers and right?handers on dichaptic
               and dichotic tasks. However, musical talent influenced the
               outcome. Compared with right?handedness, left?handedness in both
               sexes was associated with a significantly higher incidence of
               asthma, allergies, and/or migraine.",
  journal   = "Developmental neuropsychology",
  publisher = "Routledge",
  volume    =  4,
  number    =  2,
  pages     = "129--145",
  month     =  jan,
  year      =  1988,
  issn      = "8756-5641",
  doi       = "10.1080/87565648809540399"
}

@ARTICLE{Hutchins2012-tf,
  title     = "A frog in your throat or in your ear? Searching for the causes
               of poor singing",
  author    = "Hutchins, Sean Michael and Peretz, Isabelle",
  abstract  = "Singing is a cultural universal and an important part of modern
               society, yet many people fail to sing in tune. Many possible
               causes have been posited to explain poor singing abilities;
               foremost among these are poor perceptual ability, poor motor
               control, and sensorimotor mapping errors. To help discriminate
               between these causes of poor singing, we conducted 5 experiments
               testing musicians and nonmusicians in pitch matching and
               judgment tasks. Experiment 1 introduces a new instrument called
               a slider, on which participants can match pitches without using
               their voice. Pitch matching on the slider can be directly
               compared with vocal pitch matching, and results showed that both
               musicians and nonmusicians were more accurate using the slider
               than their voices to match target pitches, arguing against a
               perceptual explanation of singing deficits. Experiment 2 added a
               self-matching condition and showed that nonmusicians were better
               at matching their own voice than a synthesized voice timbre, but
               were still not as accurate as on the slider. This suggests a
               timbral translation type of mapping error. Experiments 3 and 4
               demonstrated that singers do not improve over multiple sung
               responses, or with the aid of a visual representation of pitch.
               Experiment 5 showed that listeners were more accurate at
               perceiving the pitch of the synthesized tones than actual voice
               tones. The pattern of results across experiments demonstrates
               multiple possible causes of poor singing, and attributes most of
               the problem to poor motor control and timbral-translation
               errors, rather than a purely perceptual deficit, as other
               studies have suggested.",
  journal   = "Journal of experimental psychology. General",
  publisher = "psycnet.apa.org",
  volume    =  141,
  number    =  1,
  pages     = "76--97",
  month     =  feb,
  year      =  2012,
  keywords  = "To read",
  language  = "en",
  issn      = "0096-3445",
  pmid      = "21875245",
  doi       = "10.1037/a0025064"
}

@ARTICLE{Temperley2008-ho,
  title     = "Hypermetrical Transitions",
  author    = "Temperley, David",
  abstract  = "Abstract. Most hypermetrical shifts in common-practice music are
               shifts of ``duple phase''--- between ``odd-strong'' hypermeter
               (in which odd-numbered measures are st",
  journal   = "Music Theory Spectrum",
  publisher = "Oxford Academic",
  volume    =  30,
  number    =  2,
  pages     = "305--325",
  month     =  oct,
  year      =  2008,
  keywords  = "To read",
  language  = "en",
  issn      = "0195-6167",
  doi       = "10.1525/mts.2008.30.2.305"
}

@ARTICLE{Dubey2020-cj,
  title     = "Reconciling novelty and complexity through a rational analysis
               of curiosity",
  author    = "Dubey, Rachit and Griffiths, Thomas L",
  abstract  = "Curiosity is considered to be the essence of science and an
               integral component of cognition. What prompts curiosity in a
               learner? Previous theoretical accounts of curiosity remain
               divided-novelty-based theories propose that new and highly
               uncertain stimuli pique curiosity, whereas complexity-based
               theories propose that stimuli with an intermediate degree of
               uncertainty stimulate curiosity. In this article, we present a
               rational analysis of curiosity by considering the computational
               problem underlying curiosity, which allows us to model these
               distinct accounts of curiosity in a common framework. Our
               approach posits that a rational agent should explore stimuli
               that maximally increase the usefulness of its knowledge and that
               curiosity is the mechanism by which humans approximate this
               rational behavior. Critically, our analysis show that the causal
               structure of the environment can determine whether curiosity is
               driven by either highly uncertain or moderately uncertain
               stimuli. This suggests that previous theories need not be in
               contention but are special cases of a more general account of
               curiosity. Experimental results confirm our predictions and
               demonstrate that our theory explains a wide range of findings
               about human curiosity, including its subjectivity and
               malleability. (PsycInfo Database Record (c) 2020 APA, all rights
               reserved).",
  journal   = "Psychological review",
  publisher = "psycnet.apa.org",
  volume    =  127,
  number    =  3,
  pages     = "455--476",
  month     =  apr,
  year      =  2020,
  language  = "en",
  issn      = "0033-295X, 1939-1471",
  pmid      = "31868394",
  doi       = "10.1037/rev0000175"
}

@INCOLLECTION{Cohen1992-if,
  title     = "Things {I} have learned (so far)",
  booktitle = "Methodological issues \& strategies in clinical research , (pp",
  author    = "Cohen, Jacob",
  editor    = "Kazdin, Alan E",
  abstract  = "This reprinted article originally appeared in (American
               Psychologist, 1990, 45[12], 1304-1312). (The following abstract
               of the original article appeared in record 1991-11596-001.) This
               is an account of what I have learned (so far) about the
               application of statistics to psychology and the other
               sociobiomedical sciences. It includes the principles ``less is
               more'' (fewer variables, more highly targeted issues, sharp
               rounding off), ``simple is better'' (graphic representation,
               unit weighting for linear composites), and ``some things you
               learn aren't so.'' I have learned to avoid the many
               misconceptions that surround Fisherian null hypothesis testing.
               I have also learned the importance of power analysis and the
               determination of just how big (rather than how statistically
               significant) are the effects that we study. Finally, I have
               learned that there is no royal road to statistical induction,
               that the informed judgment of the investigator is the crucial
               element in the interpretation of data, and that things take
               time. (PsycInfo Database Record (c) 2020 APA, all rights
               reserved)",
  publisher = "American Psychological Association, xxv",
  volume    =  765,
  pages     = "315--333",
  year      =  1992,
  address   = "Washington, DC, US",
  keywords  = "To read",
  doi       = "10.1037/10109-028"
}

@ARTICLE{Park2019-kb,
  title    = "Global music streaming data reveal diurnal and seasonal patterns
              of affective preference",
  author   = "Park, Minsu and Thom, Jennifer and Mennicken, Sarah and Cramer,
              Henriette and Macy, Michael",
  abstract = "People manage emotions to cope with life's demands1,2. Previous
              research has identified affective patterns using self-reports3
              and text analysis4,5, but these measures track the expression of
              affect, not affective preference for external stimuli such as
              music, which affects mood states and levels of emotional
              arousal1,6,7. We analysed a dataset of 765 million online music
              plays streamed by 1 million individuals in 51 countries to
              measure diurnal and seasonal patterns of affective preference.
              Findings reveal similar diurnal patterns across cultures and
              demographic groups. Individuals listen to more relaxing music
              late at night and more energetic music during normal business
              hours, including mid-afternoon when affective expression is
              lowest. However, there were differences in baselines: younger
              people listen to more intense music; compared with other regions,
              music played in Latin America is more arousing, while music in
              Asia is more relaxing; and compared with other chronotypes,
              'night owls' (people who are habitually active or wakeful at
              night) listen to less-intense music. Seasonal patterns vary with
              distance from the equator and between Northern and Southern
              hemispheres and are more strongly correlated with absolute day
              length than with changes in day length. Taken together with
              previous findings on affective expression in text4, these results
              suggest that musical choice both shapes and reflects mood.",
  journal  = "Nature human behaviour",
  volume   =  3,
  number   =  3,
  pages    = "230--236",
  month    =  mar,
  year     =  2019,
  language = "en",
  issn     = "2397-3374",
  pmid     = "30953008",
  doi      = "10.1038/s41562-018-0508-z"
}

@MISC{Reimer1962-ee,
  title   = "Leonard Meyer' s Theory of Value and Greatness in Music",
  author  = "Reimer, Bennett",
  journal = "Journal of Research in Music Education",
  volume  =  10,
  number  =  2,
  pages   = "87--99",
  year    =  1962,
  doi     = "10.2307/3343992"
}

@MISC{Meyer1959-yf,
  title   = "{SOME} {REMARKS} {ON} {VALUE} {AND} {GREATNESS} {IN} {MUSIC}",
  author  = "Meyer, Leonard B",
  journal = "The Journal of Aesthetics and Art Criticism",
  volume  =  17,
  number  =  4,
  pages   = "486--500",
  year    =  1959,
  doi     = "10.1111/1540\_6245.jaac17.4.0486"
}

@BOOK{MacKay2003-ki,
  title     = "Information Theory, Inference and Learning Algorithms",
  author    = "MacKay, David J C",
  abstract  = "Information theory and inference, often taught separately, are
               here united in one entertaining textbook. These topics lie at
               the heart of many exciting areas of contemporary science and
               engineering - communication, signal processing, data mining,
               machine learning, pattern recognition, computational
               neuroscience, bioinformatics, and cryptography. This textbook
               introduces theory in tandem with applications. Information
               theory is taught alongside practical communication systems, such
               as arithmetic coding for data compression and sparse-graph codes
               for error-correction. A toolbox of inference techniques,
               including message-passing algorithms, Monte Carlo methods, and
               variational approximations, are developed alongside applications
               of these tools to clustering, convolutional codes, independent
               component analysis, and neural networks. The final part of the
               book describes the state of the art in error-correcting codes,
               including low-density parity-check codes, turbo codes, and
               digital fountain codes -- the twenty-first century standards for
               satellite communications, disk drives, and data broadcast.
               Richly illustrated, filled with worked examples and over 400
               exercises, some with detailed solutions, David MacKay's
               groundbreaking book is ideal for self-learning and for
               undergraduate or graduate courses. Interludes on crosswords,
               evolution, and sex provide entertainment along the way. In sum,
               this is a textbook on information, communication, and coding for
               a new generation of students, and an unparalleled entry point
               into these subjects for professionals in areas as diverse as
               computational biology, financial engineering, and machine
               learning.",
  publisher = "Cambridge University Press",
  year      =  2003,
  address   = "Cambridge, UK",
  language  = "en",
  isbn      = "9780521642989"
}

@ARTICLE{Munte2002-tf,
  title    = "The musician's brain as a model of neuroplasticity",
  author   = "M{\"u}nte, Thomas F and Altenm{\"u}ller, Eckart and J{\"a}ncke,
              Lutz",
  abstract = "Studies of experience-driven neuroplasticity at the behavioural,
              ensemble, cellular and molecular levels have shown that the
              structure and significance of the eliciting stimulus can
              determine the neural changes that result. Studying such effects
              in humans is difficult, but professional musicians represent an
              ideal model in which to investigate plastic changes in the human
              brain. There are two advantages to studying plasticity in
              musicians: the complexity of the eliciting stimulus music and the
              extent of their exposure to this stimulus. Here, we focus on the
              functional and anatomical differences that have been detected in
              musicians by modern neuroimaging methods.",
  journal  = "Nature reviews. Neuroscience",
  volume   =  3,
  number   =  6,
  pages    = "473--478",
  month    =  jun,
  year     =  2002,
  language = "en",
  issn     = "1471-003X",
  pmid     = "12042882",
  doi      = "10.1038/nrn843"
}

@ARTICLE{Seither-Preisler2014-wf,
  title    = "Size and synchronization of auditory cortex promotes musical,
              literacy, and attentional skills in children",
  author   = "Seither-Preisler, Annemarie and Parncutt, Richard and Schneider,
              Peter",
  abstract = "Playing a musical instrument is associated with numerous neural
              processes that continuously modify the human brain and may
              facilitate characteristic auditory skills. In a longitudinal
              study, we investigated the auditory and neural plasticity of
              musical learning in 111 young children (aged 7-9 y) as a function
              of the intensity of instrumental practice and musical aptitude.
              Because of the frequent co-occurrence of central auditory
              processing disorders and attentional deficits, we also tested 21
              children with attention deficit (hyperactivity) disorder
              [AD(H)D]. Magnetic resonance imaging and magnetoencephalography
              revealed enlarged Heschl's gyri and enhanced right-left
              hemispheric synchronization of the primary evoked response (P1)
              to harmonic complex sounds in children who spent more time
              practicing a musical instrument. The anatomical characteristics
              were positively correlated with frequency discrimination,
              reading, and spelling skills. Conversely, AD(H)D children showed
              reduced volumes of Heschl's gyri and enhanced volumes of the
              plana temporalia that were associated with a distinct bilateral
              P1 asynchrony. This may indicate a risk for central auditory
              processing disorders that are often associated with attentional
              and literacy problems. The longitudinal comparisons revealed a
              very high stability of auditory cortex morphology and gray matter
              volumes, suggesting that the combined anatomical and functional
              parameters are neural markers of musicality and attention
              deficits. Educational and clinical implications are considered.",
  journal  = "The Journal of neuroscience: the official journal of the Society
              for Neuroscience",
  volume   =  34,
  number   =  33,
  pages    = "10937--10949",
  month    =  aug,
  year     =  2014,
  keywords = "ADHD; auditory cortex; auditory evoked responses;
              magnetencephalography; morphometry; musical aptitude; musical
              learning",
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "25122894",
  doi      = "10.1523/JNEUROSCI.5315-13.2014",
  pmc      = "PMC6705250"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Albert2006-ia,
  title     = "Socioeconomic Status and Instrumental Music: What Does the
               Research Say about the Relationship and Its Implications?",
  author    = "Albert, Daniel J",
  abstract  = "… Phillips acknowledged that although differences in music
               attitude by SES level exist, the differences are quite small and
               inconsistent across grade levels, implying that `` socioeconomic
               status may not be strongly related to music attitudes'' (p.
               106). These studies suggest that …",
  journal   = "Update: Applications of Research in Music Education",
  publisher = "SAGE Publications Inc",
  volume    =  25,
  number    =  1,
  pages     = "39--45",
  month     =  nov,
  year      =  2006,
  issn      = "8755-1233",
  doi       = "10.1177/87551233060250010105"
}

@ARTICLE{Albert2006-ev,
  title     = "Socioeconomic Status and Instrumental Music: What Does the
               Research Say about the Relationship and Its Implications?",
  author    = "Albert, Daniel J",
  journal   = "Update: Applications of Research in Music Education",
  publisher = "SAGE Publications Inc",
  volume    =  25,
  number    =  1,
  pages     = "39--45",
  month     =  nov,
  year      =  2006,
  issn      = "8755-1233",
  doi       = "10.1177/87551233060250010105"
}

@ARTICLE{Dos_Santos-Luiz2016-st,
  title     = "Exploring the long-term associations between adolescents' music
               training and academic achievement",
  author    = "dos Santos-Luiz, Carlos and M{\'o}nico, Lisete S M and Almeida,
               Leandro S and Coimbra, Daniela",
  abstract  = "There is a positive relationship between learning music and
               academic achievement, although doubts remain regarding the
               mechanisms underlying this association. This research analyses
               the academic performance of music and non-music students from
               seventh to ninth grade. The study controls for socioeconomic
               status, intelligence, motivation and prior academic achievement.
               Data were collected from 110 adolescents at two time points,
               once when the students were between 11 and 14 years old in the
               seventh grade, and again 3 years later. Our results show that
               music students perform better academically than non-music
               students in the seventh grade (Cohen's d = 0.88) and in the
               ninth grade (Cohen's d = 1.05). This difference is particularly
               evident in their scores in Portuguese language and natural
               science; the difference is somewhat weaker in history and
               geography scores, and is least pronounced in mathematics and
               English scores ( $\eta$2 p from .09 to .21). A longitudinal
               analysis also revealed better academic performance by music
               students after controlling for prior academic achievement (
               $\eta$2 p = .07). Furthermore, controlling for intelligence,
               socioeconomic status and motivation did not eliminate the
               positive association between music learning from the seventh to
               the ninth grade and students' academic achievement ( $\eta$2 p =
               .06). During the period, music students maintained better and
               more consistent academic standing. We conclude that, after
               controlling for intelligence, socioeconomic status and
               motivation, music training is positively associated with
               academic achievement.",
  journal   = "Musicae scientiae: the journal of the European Society for the
               Cognitive Sciences of Music",
  publisher = "SAGE Publications",
  volume    =  20,
  number    =  4,
  pages     = "512--527",
  month     =  dec,
  year      =  2016,
  language  = "en",
  issn      = "1029-8649, 2045-4147",
  doi       = "10.1177/1029864915623613"
}

@ARTICLE{Glenn_Schellenberg2011-nq,
  title     = "Music lessons, emotional intelligence, and {IQ}",
  author    = "Glenn Schellenberg, E",
  abstract  = "musically trained and untrained participants were administered
               tests of emotional intelligence and IQ. As in previous research,
               trained participants scored higher than untrained participants
               on the IQ Composite score and on its Verbal and Nonverbal
               subtests. The advantage for the trained group on the Composite
               score and on the Nonverbal subtest was evident even when gender,
               parents' education, family income, and first language were held
               constant. The groups performed similarly, however, on the test
               of emotional intelligence, and scores on the IQ test were only
               weakly correlated with scores on the emotional intelligence
               test. The results imply that (1) associations between music
               lessons and nonmusical abilities are limited to intellectual
               abilities, and/or (2) associations between music lessons and
               emotional intelligence are not evident on visual- and/or
               text-based tests of emotional intelligence such as the one used
               here.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  29,
  number    =  2,
  pages     = "185--194",
  month     =  dec,
  year      =  2011,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2011.29.2.185"
}

@INCOLLECTION{Rauscher2002-wg,
  title     = "Mozart and the Mind: Factual and Fictional Effects of Musical
               Enrichment",
  booktitle = "Improving Academic Achievement",
  author    = "Rauscher, Frances H",
  editor    = "Aronson, Joshua",
  abstract  = "Publisher Summary The ``Mozart effect'' refers to the finding
               that college students who listened to the first 10 minutes of a
               Mozart sonata (K.448) scored higher on a spatial-temporal
               reasoning task immediately afterward---an effect that lasted
               approximately 10 minutes. This chapter presents the school
               district of Kettle-Moraine study. Children from four
               kindergarten classrooms at two Wisconsin public elementary
               schools in the school district of Kettle-Moraine participated.
               Some children received piano keyboard instruction (keyboard
               group) and others received no special training (no music group).
               The study began by pretesting all the children using two
               spatial-temporal tasks, a puzzle-solving task, a block-building
               task, and one pictorial memory task. Children were posttested
               twice, once following 4 months of lessons and a second time
               following 8 months. Results showed that young children who were
               provided with music instruction scored higher on
               spatial-temporal tasks compared with children who did not
               receive the instruction. The effect was significant after 4
               months of instruction. No enhancement was found for a nonspatial
               task: pictorial memory. However, when the music instruction was
               terminated the children's scores began to decrease. The children
               who received instruction over the entire 4 years of the study
               continued to score higher on the spatial-temporal tasks. The
               effects of music instruction on spatial-temporal abilities may
               be explained by two types of theories. Neuroscientific theories
               assert that music instruction induces physiological changes in
               brain structure that consequently affect spatial-temporal
               processing. Transfer theories, on the other hand, suggest that
               playing a musical instrument and performing a spatial-temporal
               task require similar cognitive skills, and thus the skills
               involved in making music may transfer to spatial-temporal task
               performance.",
  publisher = "Academic Press",
  pages     = "267--278",
  month     =  jan,
  year      =  2002,
  address   = "San Diego",
  doi       = "10.1016/B978-012064455-1/50016-6"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hetland2000-tr,
  title     = "Learning to Make Music Enhances Spatial Reasoning",
  author    = "Hetland, Lois",
  abstract  = "Does active instruction in music enhance preschool and
               elementary students' performance on spatial tasks? Researchers
               have been interested in this question not only because of the
               importance of spatial abilities, which underlie professions such
               as engineering, archaeology, and surgery, but also because
               spatial abilities are thought to be important in the discipline
               of mathematics.'This meta-analytic review synthesizes the
               results of 15 independent studies that address this
               controversial and highly publicized question. While …",
  journal   = "Journal of Aesthetic Education",
  publisher = "University of Illinois Press",
  volume    =  34,
  number    = "3/4",
  pages     = "179--238",
  year      =  2000,
  issn      = "1543-7809",
  doi       = "10.2307/3333643"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gardiner1996-gh,
  title     = "Learning improved by arts training",
  author    = "Gardiner, M F and Fox, A and Knowles, F and Jeffrey, D",
  abstract  = "SIR-It has been suggested1• 2 that musical experience or
               training can temporarily strengthen visuospatial reasoning. We
               report here further data on the relationship between arts
               training and some broader aspects of learning. In its first
               year, our study included 96 …",
  journal   = "Nature",
  publisher = "researchgate.net",
  volume    =  381,
  number    =  6580,
  pages     = "284",
  month     =  may,
  year      =  1996,
  language  = "en",
  issn      = "0028-0836",
  pmid      = "8692266",
  doi       = "10.1038/381284a0"
}

@ARTICLE{Moreno2014-dx,
  title    = "Examining neural plasticity and cognitive benefit through the
              unique lens of musical training",
  author   = "Moreno, Sylvain and Bidelman, Gavin M",
  abstract = "Training programs aimed to alleviate or improve
              auditory-cognitive abilities have either experienced mixed
              success or remain to be fully validated. The limited benefits of
              such regimens are largely attributable to our weak understanding
              of (i) how (and which) interventions provide the most robust and
              long lasting improvements to cognitive and perceptual abilities
              and (ii) how the neural mechanisms which underlie such abilities
              are positively modified by certain activities and experience.
              Recent studies indicate that music training provides robust,
              long-lasting biological benefits to auditory function.
              Importantly, the behavioral advantages conferred by musical
              experience extend beyond simple enhancements to perceptual
              abilities and even impact non-auditory functions necessary for
              higher-order aspects of cognition (e.g., working memory,
              intelligence). Collectively, preliminary findings indicate that
              alternative forms of arts engagement (e.g., visual arts training)
              may not yield such widespread enhancements, suggesting that music
              expertise uniquely taps and refines a hierarchy of brain networks
              subserving a variety of auditory as well as domain-general
              cognitive mechanisms. We infer that transfer from specific music
              experience to broad cognitive benefit might be mediated by the
              degree to which a listener's musical training tunes lower- (e.g.,
              perceptual) and higher-order executive functions, and the
              coordination between these processes. Ultimately, understanding
              the broad impact of music on the brain will not only provide a
              more holistic picture of auditory processing and plasticity, but
              may help inform and tailor remediation and training programs
              designed to improve perceptual and cognitive benefits in human
              listeners.",
  journal  = "Hearing research",
  volume   =  308,
  pages    = "84--97",
  month    =  feb,
  year     =  2014,
  language = "en",
  issn     = "0378-5955, 1878-5891",
  pmid     = "24079993",
  doi      = "10.1016/j.heares.2013.09.012"
}

@ARTICLE{Sala2020-hw,
  title    = "Cognitive and academic benefits of music training with children:
              A multilevel meta-analysis",
  author   = "Sala, Giovanni and Gobet, Fernand",
  abstract = "Music training has repeatedly been claimed to positively impact
              children's cognitive skills and academic achievement (literacy
              and mathematics). This claim relies on the assumption that
              engaging in intellectually demanding activities fosters
              particular domain-general cognitive skills, or even general
              intelligence. The present meta-analytic review (N = 6,984, k =
              254, m = 54) shows that this belief is incorrect. Once the
              quality of study design is controlled for, the overall effect of
              music training programs is null ([Formula: see text] $\approx$ 0)
              and highly consistent across studies ($\tau$2 $\approx$ 0).
              Results of Bayesian analyses employing distributional assumptions
              (informative priors) derived from previous research in cognitive
              training corroborate these conclusions. Small statistically
              significant overall effects are obtained only in those studies
              implementing no random allocation of participants and employing
              non-active controls ([Formula: see text] $\approx$ 0.200, p <
              .001). Interestingly, music training is ineffective regardless of
              the type of outcome measure (e.g., verbal, non-verbal,
              speed-related, etc.), participants' age, and duration of
              training. Furthermore, we note that, beyond meta-analysis of
              experimental studies, a considerable amount of cross-sectional
              evidence indicates that engagement in music has no impact on
              people's non-music cognitive skills or academic achievement. We
              conclude that researchers' optimism about the benefits of music
              training is empirically unjustified and stems from
              misinterpretation of the empirical data and, possibly,
              confirmation bias.",
  journal  = "Memory \& cognition",
  volume   =  48,
  number   =  8,
  pages    = "1429--1441",
  month    =  nov,
  year     =  2020,
  keywords = "Academic achievement; Cognitive ability; Cognitive training;
              Music; Transfer",
  language = "en",
  issn     = "0090-502X, 1532-5946",
  pmid     = "32728850",
  doi      = "10.3758/s13421-020-01060-2",
  pmc      = "PMC7683441"
}

@ARTICLE{De_Gregorio2021-dh,
  title    = "Categorical rhythms in a singing primate",
  author   = "De Gregorio, Chiara and Valente, Daria and Raimondi, Teresa and
              Torti, Valeria and Miaretsoa, Longondraza and Friard, Olivier and
              Giacoma, Cristina and Ravignani, Andrea and Gamba, Marco",
  abstract = "What are the origins of musical rhythm? One approach to the
              biology and evolution of music consists in finding common musical
              traits across species. These similarities allow biomusicologists
              to infer when and how musical traits appeared in our species1. A
              parallel approach to the biology and evolution of music focuses
              on finding statistical universals in human music2. These include
              rhythmic features that appear above chance across musical
              cultures. One such universal is the production of categorical
              rhythms3, defined as those where temporal intervals between note
              onsets are distributed categorically rather than uniformly2,4,5.
              Prominent rhythm categories include those with intervals related
              by small integer ratios, such as 1:1 (isochrony) and 1:2, which
              translates as some notes being twice as long as their adjacent
              ones. In humans, universals are often defined in relation to the
              beat, a top-down cognitive process of inferring a temporal
              regularity from a complex musical scene1. Without assuming the
              presence of the beat in other animals, one can still investigate
              its downstream products, namely rhythmic categories with small
              integer ratios detected in recorded signals. Here we combine the
              comparative and statistical universals approaches, testing the
              hypothesis that rhythmic categories and small integer ratios
              should appear in species showing coordinated group singing3. We
              find that a lemur species displays, in its coordinated songs, the
              isochronous and 1:2 rhythm categories seen in human music,
              showing that such categories are not, among mammals, unique to
              humans3.",
  journal  = "Current biology: CB",
  volume   =  31,
  number   =  20,
  pages    = "R1379--R1380",
  month    =  oct,
  year     =  2021,
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "34699799",
  doi      = "10.1016/j.cub.2021.09.032"
}

@ARTICLE{Rad2018-ih,
  title    = "Toward a psychology of Homo sapiens: Making psychological science
              more representative of the human population",
  author   = "Rad, Mostafa Salari and Martingano, Alison Jane and Ginges,
              Jeremy",
  abstract = "Two primary goals of psychological science should be to
              understand what aspects of human psychology are universal and the
              way that context and culture produce variability. This requires
              that we take into account the importance of culture and context
              in the way that we write our papers and in the types of
              populations that we sample. However, most research published in
              our leading journals has relied on sampling WEIRD (Western,
              educated, industrialized, rich, and democratic) populations. One
              might expect that our scholarly work and editorial choices would
              by now reflect the knowledge that Western populations may not be
              representative of humans generally with respect to any given
              psychological phenomenon. However, as we show here, almost all
              research published by one of our leading journals, Psychological
              Science, relies on Western samples and uses these data in an
              unreflective way to make inferences about humans in general. To
              take us forward, we offer a set of concrete proposals for
              authors, journal editors, and reviewers that may lead to a
              psychological science that is more representative of the human
              condition.",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  115,
  number   =  45,
  pages    = "11401--11405",
  month    =  nov,
  year     =  2018,
  keywords = "cognition; culture; diversity; methodology; psychological science",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "30397114",
  doi      = "10.1073/pnas.1721165115",
  pmc      = "PMC6233089"
}

@ARTICLE{De_Cheveigne2021-wy,
  title    = "Harmonic {Cancellation-A} Fundamental of Auditory Scene Analysis",
  author   = "de Cheveign{\'e}, Alain",
  abstract = "This paper reviews the hypothesis of harmonic cancellation
              according to which an interfering sound is suppressed or canceled
              on the basis of its harmonicity (or periodicity in the time
              domain) for the purpose of Auditory Scene Analysis. It defines
              the concept, discusses theoretical arguments in its favor, and
              reviews experimental results that support it, or not. If correct,
              the hypothesis may draw on time-domain processing of temporally
              accurate neural representations within the brainstem, as required
              also by the classic equalization-cancellation model of binaural
              unmasking. The hypothesis predicts that a target sound corrupted
              by interference will be easier to hear if the interference is
              harmonic than inharmonic, all else being equal. This prediction
              is borne out in a number of behavioral studies, but not all. The
              paper reviews those results, with the aim to understand the
              inconsistencies and come up with a reliable conclusion for, or
              against, the hypothesis of harmonic cancellation within the
              auditory system.",
  journal  = "Trends in hearing",
  volume   =  25,
  pages    = "23312165211041422",
  month    =  jan,
  year     =  2021,
  keywords = "auditory scene analysis; harmonic cancellation; harmonicity;
              pitch perception; segregation;To read",
  language = "en",
  issn     = "2331-2165",
  pmid     = "34698574",
  doi      = "10.1177/23312165211041422",
  pmc      = "PMC8552394"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Akinbo2021-rr,
  title    = "The Language of G{\'a}ngan, A Yor{\`u}b{\'a} Talking Drum",
  author   = "Akinbo, Samuel Kayode",
  abstract = "It is widely known that Yorùb{\'a} drummers communicate through
              their native drums. This paper investigates the grammar of
              g{\'a}ngan, which belongs to a family of Yoruba drums called
              d{\`u}nd{\'u}n. The results of this study show that Yorùb{\'a}
              drummers represent the phonetic realisation of lexical and
              grammatical tones of their language with the drum. Statistically,
              the speech tones and the acoustic correlate of the corresponding
              drum representations have a significant positive relationship. In
              both spoken and drum communication, vowel (V) and consonant-vowel
              (CV) prosodic units have different statuses. To conclude,
              Yor{\`u}b{\'a} drummers communicate via the g{\'a}ngan drum by
              transposing certain phonemic features and maybe phonological
              conditions of their language to musical forms.",
  journal  = "Frontiers in Communication",
  volume   =  6,
  pages    = "180",
  year     =  2021,
  keywords = "To read",
  issn     = "2297-900X",
  doi      = "10.3389/fcomm.2021.650382"
}

@ARTICLE{Berlyne1966-va,
  title    = "Curiosity and exploration",
  author   = "Berlyne, D E",
  journal  = "Science",
  volume   =  153,
  number   =  3731,
  pages    = "25--33",
  month    =  jul,
  year     =  1966,
  keywords = "To read",
  language = "en",
  issn     = "0036-8075",
  pmid     = "5328120",
  doi      = "10.1126/science.153.3731.25"
}

@ARTICLE{Miguel2020-ph,
  title    = "From beat tracking to beat expectation: Cognitive-based beat
              tracking for capturing pulse clarity through time",
  author   = "Miguel, Martin Alejandro and Sigman, Mariano and Fernandez
              Slezak, Diego",
  abstract = "Pulse is the base timing to which western music is commonly
              notated, generally expressed by a listener by performing periodic
              taps with their hand or foot. This cognitive construction helps
              organize the perception of timed events in music and is the most
              basic expectation in rhythms. The analysis of expectations, and
              more specifically the strength with which the beat is felt-the
              pulse clarity-has been used to analyze affect in music. Most
              computational models of pulse clarity, and rhythmic expectation
              in general, analyze the input as a whole, without exhibiting
              changes through a rhythmic passage. We present Tactus Hypothesis
              Tracker (THT), a model of pulse clarity over time intended for
              symbolic rhythmic stimuli. The model was developed based on ideas
              of beat tracking models that extract beat times from musical
              stimuli. Our model also produces possible beat interpretations
              for the rhythm, a fitness score for each interpretation and how
              these evolve in time. We evaluated the model's pulse clarity by
              contrasting against tapping variability of human annotators
              achieving results comparable to a state-of-the-art pulse clarity
              model. We also analyzed the clarity metric dynamics on synthetic
              data that introduced changes in the beat, showing that our model
              presented doubt in the pulse estimation process and adapted
              accordingly to beat changes. Finally, we assessed if the beat
              tracking generated by the model was correct regarding listeners
              tapping data. We compared our beat tracking results with previous
              beat tracking models. The THT model beat tracking output showed
              generally correct estimations in phase but exhibits a bias
              towards a musically correct subdivision of the beat.",
  journal  = "PloS one",
  volume   =  15,
  number   =  11,
  pages    = "e0242207",
  month    =  nov,
  year     =  2020,
  keywords = "To read",
  language = "en",
  issn     = "1932-6203",
  pmid     = "33206697",
  doi      = "10.1371/journal.pone.0242207",
  pmc      = "PMC7673539"
}

@ARTICLE{Patynen2010-py,
  title     = "Directivities of Symphony Orchestra Instruments",
  author    = "P{\"a}tynen, Jukka and Lokki, Tapio",
  abstract  = "The sound radiation patterns of musical instruments represent a
               considerable part of the perceived room acoustics. The
               directivities of fourteen common symphony orchestra instruments
               and a soprano singer during performance are investigated. For
               this purpose, each instrument was recorded with the musician in
               an anechoic room with 22 microphones distributed around the
               player. As the result, directivities of the strings and woodwind
               instruments are noticed to change with the played tone while the
               brass instruments radiate constantly in the direction of the
               bell. Playing dynamics was not found to affect the directivity
               although the spectrum of the sound changes considerably in
               particular with the brass instruments. The results can be
               utilized with source modeling in room acoustics simulation and
               in research on musical acoustics.",
  journal   = "Acta Acustica united with Acustica",
  publisher = "ingentaconnect.com",
  volume    =  96,
  number    =  1,
  pages     = "138--167",
  year      =  2010,
  issn      = "1610-1928",
  doi       = "10.3813/AAA.918265"
}

@ARTICLE{Van_Lieshout2021-ju,
  title    = "Curiosity or savouring? Information seeking is modulated by both
              uncertainty and valence",
  author   = "van Lieshout, Lieke L F and Traast, Iris J and de Lange, Floris P
              and Cools, Roshan",
  abstract = "Curiosity is pervasive in our everyday lives, but we know little
              about the factors that contribute to this drive. In the current
              study, we assessed whether curiosity about uncertain outcomes is
              modulated by the valence of the information, i.e. whether the
              information is good or bad news. Using a lottery task in which
              outcome uncertainty, expected value and outcome valence (gain
              versus loss) were manipulated independently, we found that
              curiosity is overall higher for gains compared with losses and
              that curiosity increased with increasing outcome uncertainty for
              both gains and losses. These effects of uncertainty and valence
              did not interact, indicating that the motivation to reduce
              uncertainty and the motivation to maximize positive information
              represent separate, independent drives.",
  journal  = "PloS one",
  volume   =  16,
  number   =  9,
  pages    = "e0257011",
  month    =  sep,
  year     =  2021,
  keywords = "To read",
  language = "en",
  issn     = "1932-6203",
  pmid     = "34559816",
  doi      = "10.1371/journal.pone.0257011",
  pmc      = "PMC8462690"
}

@ARTICLE{Rohrmeier2020-lq,
  title    = "The Syntax of Jazz Harmony: Diatonic Tonality, Phrase Structure,
              and Form",
  author   = "Rohrmeier, Martin",
  abstract = "The regularities underlying the structure building of chord
              sequences, harmonic phrases, and combinations of phrases
              constitute a central research problem in music theory. This
              article proposes a formalization of Jazz harmony with a
              generative framework based on formal grammars, in which syntactic
              structure tightly corresponds with the functional interpretation
              of the sequence. It assumes that chords establish nested
              hierarchical dependencies that are characterized by two core
              types: preparation and prolongation. The approach expresses
              diatonic harmony, embedded modulation, borrowing, and
              substitution within a single grammatical framework. It is argued
              in the second part that the proposed framework models not only
              core phrase structure, but also relations between phrases and the
              syntactic structures underlying the main forms of Jazz standards.
              As a special case, the Blues form relies heavily on the plagal
              derivation from the tonic and is analyzed in comparison with
              other analytical approaches to the Blues. The proposed theory is
              specified to a sufficient level of detail that it lends itself to
              computational implementation and empirical exploration, and this
              way it makes a step towards music theory building that embraces
              the close links between formal, mathematical, and computational
              methods.",
  journal  = "Journal of Mathematics \& Music. Mathematical and Computational
              Approaches to Music Theory, Analysis, Composition and Performance",
  volume   =  7,
  number   =  1,
  pages    = "1--63",
  year     =  2020,
  keywords = "MUSIC, SYNTAX THEORY, HARMONY, JAZZ, GENERATIVE MODELING, MUSIC
              THEORY",
  issn     = "1745-9737, 2295-5917",
  doi      = "10.11116/MTA.7.1.1"
}

@UNPUBLISHED{Van_de_Cruys2021-ju,
  title    = "Preferences need inferences: Learning, valuation, and curiosity
              in aesthetic experience",
  author   = "Van de Cruys, Sander and Bervoets, Jo and Moors, Agnes",
  abstract = "More than 40 years ago, pioneering social psychologist Robert
              Zajonc (1980) published his seminal work titled ``Preferences
              need no inferences'' in which he argued for the primacy of affect
              over cognition. Affective evaluation (the preference) comes
              first, he claimed, and only then do cognitive processes (the
              inferences) kick in. The view is untenable in light of recent
              predictive processing accounts of the mind, which hold that all
              mental functioning is built from (approximate) Bayesian
              inference. It casts perception, action, and learning as inference
              but, perhaps counterintuitively, valuation too. We discuss how
              valuation ---understood as the process of how we come to value,
              prefer or like things--- emerges as a function of learning and
              inference, and how this conception may help us resolve
              traditional conundrums in the science of aesthetic experience,
              such as the nature of the ``beholder's share'', the link between
              curiosity and appreciation, Keats' ``negative capability'' and
              the tension between the mere exposure principle and the
              goldilocks (optimal level) principle.",
  month    =  nov,
  year     =  2021,
  keywords = "active inference; aesthetic appreciation; aesthetic experience;
              affect; art perception; Bayesian Brain; Bayesian inference;
              curiosity; learning; mere exposure; neuroaesthetics; predictive
              processing; preference; psychoaesthetics; valuation;My
              publications",
  doi      = "10.31234/osf.io/zh6nt"
}

@MISC{Mc_Leod_undated-om,
  title        = "A modular system for the harmonic analysis of musical scores
                  using a large vocabulary",
  author       = "Mc Leod, Andrew and Rohrmeier, Martin",
  howpublished = "\url{https://archives.ismir.net/ismir2021/paper/000054.pdf}",
  note         = "Accessed: 2021-11-10"
}

@ARTICLE{Cross2008-ph,
  title     = "Musicality and the human capacity for culture",
  author    = "Cross, Ian",
  abstract  = "This paper proposes that the human capacity for musicality is
               integral to the human capacity for culture, and that the key
               feature of music that motivates its efficacy is its
               indeterminacy of meaning, or floating intentionality. It
               suggests that, from an evolutionary perspective, a focus on
               music's commonalities of function (rather than of structure)
               across cultures provides an appropriate framework for theorising
               the roles and the operational features of music's indeterminacy
               of meaning. A three-dimension account of meaning in music is
               presented in which biologically generic, humanly specific, and
               culturally enactive dimensions of the experience of music are
               delineated, with summary examples of the application of the
               theory to musical usages in different cultures. It is noted that
               the dimensions outlined in the theory may be operational at
               different semiotic levels, and it is concluded that music became
               part of the repertoire of modern human behaviour as an exaptive
               consequence of processes of progressive altricialisation in the
               hominin lineage.",
  journal   = "Musicae scientiae: the journal of the European Society for the
               Cognitive Sciences of Music",
  publisher = "SAGE Publications Ltd",
  volume    =  12,
  number    = "1\_suppl",
  pages     = "147--167",
  month     =  mar,
  year      =  2008,
  issn      = "1029-8649",
  doi       = "10.1177/1029864908012001071"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Rahn1991-hj,
  title    = "Coordination of Interval Sizes in {Seven-Tone} Collections",
  author   = "Rahn, Jay",
  abstract = "In the Appendix to his book on The Structure of Atonal M Allen
              Forte lists 38 seven-pc subsets of the twelve-semitone set and
              cf. 1964). These 38 seven-tone sets are listed in Figure 1. In
              present study, each of these 38 7-pc subsets of the twelve-semit
              aggregate is referred to as a`` seven-tone collection.'' In
              recent years, much attention has been paid to seven-tone c
              lections in general and in particular to the so-called`` diatonic
              co tion.''(The diatonic collection is 7-35 in Forte's numbering,
              whic followed in Figure 1.) Authors who …",
  journal  = " Journal of Music Theory",
  volume   =  35,
  number   = "1/2",
  pages    = "33--60",
  year     =  1991,
  doi      = "10.2307/843809"
}

@ARTICLE{Von_Hippel2000-yo,
  title     = "Why do skips precede reversals? The effect of tessitura on
               melodic structure",
  author    = "Von Hippel, Paul and Huron, David",
  abstract  = "In melodies from a wide variety of cultures, a large pitch
               interval tends to be followed by a change of direction. Although
               this tendency is often attributed to listeners' expectations, it
               might arise more simply from constraints on melodic ranginess or
               tessitura. Skips tend toward the extremes of a melody's
               tessitura, and from those extremes a melody has little choice
               but to retreat by changing direction. Statistical analyses of
               vocal melodies from four different continents are consistent
               with this simple explanation. The results suggest that, in the
               sampled repertoires, patterns such as ``gap-fill,'' ``registral
               direction,'' and ``registral return'' (L. Meyer, 1956, 1973; E.
               Narmour, 1990) are mere side effects of constraints on melodic
               tessitura.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  18,
  number    =  1,
  pages     = "59--85",
  month     =  oct,
  year      =  2000,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.2307/40285901"
}

@ARTICLE{Lee2021-gv,
  title    = "Cross-cultural mood perception in pop songs and its alignment
              with mood detection algorithms",
  author   = "Lee, H and Hoeger, F and Schoenwiesner, M and Park, M and Jacoby,
              N",
  journal  = "ArXiv",
  year     =  2021,
  language = "en",
  arxivid  = "2108.00768"
}

@ARTICLE{McDermott2013-hh,
  title    = "Summary statistics in auditory perception",
  author   = "McDermott, Josh H and Schemitsch, Michael and Simoncelli, Eero P",
  abstract = "Sensory signals are transduced at high resolution, but their
              structure must be stored in a more compact format. Here we
              provide evidence that the auditory system summarizes the temporal
              details of sounds using time-averaged statistics. We measured
              discrimination of 'sound textures' that were characterized by
              particular statistical properties, as normally result from the
              superposition of many acoustic features in auditory scenes. When
              listeners discriminated examples of different textures,
              performance improved with excerpt duration. In contrast, when
              listeners discriminated different examples of the same texture,
              performance declined with duration, a paradoxical result given
              that the information available for discrimination grows with
              duration. These results indicate that once these sounds are of
              moderate length, the brain's representation is limited to
              time-averaged statistics, which, for different examples of the
              same texture, converge to the same values with increasing
              duration. Such statistical representations produce good
              categorical discrimination, but limit the ability to discern
              temporal detail.",
  journal  = "Nature neuroscience",
  volume   =  16,
  number   =  4,
  pages    = "493--498",
  month    =  apr,
  year     =  2013,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "23434915",
  doi      = "10.1038/nn.3347",
  pmc      = "PMC4143328"
}

@ARTICLE{Jimenez2021-ld,
  title     = "Relative salience of chord-type and chord-voicing changes: A
               two-oddball paradigm",
  author    = "Jimenez, Ivan and Kuusi, Tuire and Ojala, Juha",
  abstract  = "Our research project investigated the effect of background and
               stimuli factors on the relative salience of chord-type and
               chord-voicing changes. Earlier studies have shown that surface
               features tend to be easier to perceive than deeper features and
               that musical training attenuates this general tendency. For
               further studying how deeper-level and surface-level musical
               features are perceived, we used a two-oddball paradigm. Each
               item consisted of a succession of five same-root chords: one
               chord-type oddball (deeper feature), one voicing oddball
               (surface feature), and three standards. Participants chose the
               chord that sounded most different to them. All chord-type
               pairings formed of major, minor, dominant seventh, major
               seventh, and minor seventh chords were tested. Chord-type
               oddball and voicing oddball were chosen equally often, together
               forming the majority of the responses. Musical training and
               conceptual knowledge of chords affected the chord-type oddball
               responses, but not the voicing-oddball responses. However,
               chord-type oddballs were chosen regardless of the musical
               training. Chord-type responses were easiest for pairs consisting
               of a major-based and a minor-based chord and for pairs involving
               two pitch-class changes. Our results suggest that musical
               training and conceptual knowledge about chords is not the only
               factor influencing the relative salience of chord-type changes
               over voicing changes.",
  journal   = "Psychology of Music",
  publisher = "SAGE Publications Ltd",
  pages     = "03057356211055214",
  month     =  nov,
  year      =  2021,
  keywords  = "To read",
  issn      = "0305-7356",
  doi       = "10.1177/03057356211055214"
}

@ARTICLE{Palmer1986-sd,
  title     = "Phase-locking in the cochlear nerve of the guinea-pig and its
               relation to the receptor potential of inner hair-cells",
  author    = "Palmer, A R and Russell, I J",
  abstract  = "The high-frequency limit of phase-locking has been measured in
               fibres of the auditory nerve in the guinea-pig. It is shown that
               phase-locking begins to decline at about 600 Hz and is no longer
               detectable above 3.5 kHz which is about 1 octave lower than in
               the cat, squirrel monkey and some birds. Direct measurements of
               the cochlear afferent fibre synaptic delay are consistent with
               indirect estimates from phase-locking, both giving values of
               0.7-0.8 ms. Measurements of the receptor potentials of inner
               hair-cells in the guinea pig cochlea indicate that as the
               stimulus frequency is increased there is a progressive decrease
               in the a.c. component compared to the steady depolarization. The
               cause of this decline is the low-pass filtering of the a.c.
               component by the hair-cell membrane. The cut-off and slope of
               the decline in the a.c. component is consistent with the
               suggestion that this process is the limiting factor in cochlear
               nerve fibre phase-locking. The implications of these findings
               for interspecies variation in phase-locking cut-off, for
               cochlear mechanisms and for the encoding of complex sounds are
               discussed.",
  journal   = "Hearing research",
  publisher = "Elsevier",
  volume    =  24,
  number    =  1,
  pages     = "1--15",
  year      =  1986,
  language  = "en",
  issn      = "0378-5955",
  pmid      = "3759671",
  doi       = "10.1016/0378-5955(86)90002-x"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Graves2021-yo,
  title     = "Consonance perception in congenital amusia: behavioral and brain
               responses to harmonicity and beating cues",
  author    = "Graves, J E and Pralus, A and Fornoni, L and Oxenham, A J and
               Tillmann, B and Caclin, A",
  abstract  = "Congenital amusia is a neurodevelopmental disorder characterized
               by difficulties in the perception and production of music,
               including the perception of consonance and dissonance, or the
               judgment of certain combinations of pitches as more pleasant
               than others. Two perceptual cues for dissonance are
               inharmonicity (the lack of a common fundamental frequency
               between components) and beating (amplitude fluctuations produced
               by close, interacting frequency components). In the presence of
               inharmonicities or beats …",
  publisher = "europepmc.org",
  year      =  2021,
  keywords  = "To read"
}

@ARTICLE{Siugzdaite2020-mh,
  title     = "Transdiagnostic Brain Mapping in Developmental Disorders",
  author    = "Siugzdaite, Roma and Bathelt, Joe and Holmes, Joni and Astle,
               Duncan E",
  abstract  = "Childhood learning difficulties and developmental disorders are
               common, but progress toward understanding their underlying brain
               mechanisms has been slow. Structural neuroimaging, cognitive,
               and learning data were collected from 479 children (299 boys,
               ranging in age from 62 to 223 months), 337 of whom had been
               referred to the study on the basis of learning-related cognitive
               problems. Machine learning identified different cognitive
               profiles within the sample, and hold-out cross-validation showed
               that these profiles were significantly associated with
               children's learning ability. The same machine learning approach
               was applied to cortical morphology data to identify different
               brain profiles. Hold-out cross-validation demonstrated that
               these were significantly associated with children's cognitive
               profiles. Crucially, these mappings were not one-to-one. The
               same neural profile could be associated with different cognitive
               impairments across different children. One possibility is that
               the organization of some children's brains is less susceptible
               to local deficits. This was tested by using diffusion-weighted
               imaging (DWI) to construct whole-brain white-matter connectomes.
               A simulated attack on each child's connectome revealed that some
               brain networks were strongly organized around highly connected
               hubs. Children with these networks had only selective cognitive
               impairments or no cognitive impairments at all. By contrast, the
               same attacks had a significantly different impact on some
               children's networks, because their brain efficiency was less
               critically dependent on hubs. These children had the most
               widespread and severe cognitive impairments. On this basis, we
               propose a new framework in which the nature and mechanisms of
               brain-to-cognition relationships are moderated by the
               organizational context of the overall network.",
  journal   = "Current biology: CB",
  publisher = "Elsevier",
  volume    =  30,
  number    =  7,
  pages     = "1245--1257.e4",
  month     =  apr,
  year      =  2020,
  keywords  = "cognitive skills; connectomics; cortical morphology;
               developmental disorders; diffusion weighted imaging; graph
               theory; learning difficulties; machine learning;To read",
  language  = "en",
  issn      = "0960-9822, 1879-0445",
  pmid      = "32109389",
  doi       = "10.1016/j.cub.2020.01.078",
  pmc       = "PMC7139199"
}

@BOOK{Fux1725-nr,
  title     = "Gradus ad Parnassum",
  author    = "Fux, Johann Joseph",
  publisher = "Johann Peter van Ghelen",
  year      =  1725,
  address   = "Vienna"
}

@INPROCEEDINGS{Sanna_Passino2021-vb,
  title     = "Where To Next? A Dynamic Model of User Preferences",
  booktitle = "Proceedings of the Web Conference 2021",
  author    = "Sanna Passino, Francesco and Maystre, Lucas and Moor, Dmitrii
               and Anderson, Ashton and Lalmas, Mounia",
  abstract  = "We consider the problem of predicting users' preferences on
               online platforms. We build on recent findings suggesting that
               users' preferences change over time, and that helping users
               expand their horizons is important in ensuring that they stay
               engaged. Most existing models of user preferences attempt to
               capture simultaneous preferences: ``Users who like A tend to
               like B as well''. In this paper, we argue that these models fail
               to anticipate changing preferences. To overcome this issue, we
               seek to understand the structure that underlies the evolution of
               user preferences. To this end, we propose the Preference
               Transition Model (PTM), a dynamic model for user preferences
               towards classes of items. The model enables the estimation of
               transition probabilities between classes of items over time,
               which can be used to estimate how users' tastes are expected to
               evolve based on their past history. We test our model's
               predictive performance on a number of different prediction tasks
               on data from three different domains: music streaming,
               restaurant recommendations and movie recommendations, and find
               that it outperforms competing approaches. We then focus on a
               music application, and inspect the structure learned by our
               model. We find that the PTM uncovers remarkable regularities in
               users' preference trajectories over time. We believe that these
               findings could inform a new generation of dynamic,
               diversity-enhancing recommender systems.",
  publisher = "Association for Computing Machinery",
  pages     = "3210--3220",
  series    = "WWW '21",
  month     =  apr,
  year      =  2021,
  address   = "New York, NY, USA",
  keywords  = "time series, diversity, user modelling., Recommender systems;To
               read",
  location  = "Ljubljana, Slovenia",
  isbn      = "9781450383127",
  doi       = "10.1145/3442381.3450028"
}

@INCOLLECTION{noauthor_2022-eg,
  title     = "Towards a {Cognitively-Based} Quantification of Metrical
               Dissonance",
  booktitle = "The Oxford Handbook of Time in Music",
  year      =  2022,
  keywords  = "To read"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Patel2021-rx,
  title     = "Musicality and gene-culture coevolution: ten concepts to guide
               productive exploration",
  author    = "Patel, Aniruddh D",
  abstract  = "A growing number of researchers across the sciences and
               humanities theorize that human musicality arose via an interplay
               of cultural invention and biological evolution, or ``gene-
               culture coevolution.'' This chapter offers ten concepts to help
               guide productive cross- disciplinary discussions on this topic.
               Such interactions across traditional disciplinary boundaries are
               needed to propel deep explorations of human musicality. These
               explorations are important for the study of human origins
               because musicality may prove to …",
  publisher = "PsyArXiv",
  year      =  2021,
  keywords  = "To read"
}

@ARTICLE{Mikkola2021-vc,
  title         = "Prior knowledge elicitation: The past, present, and future",
  author        = "Mikkola, Petrus and Martin, Osvaldo A and Chandramouli,
                   Suyog and Hartmann, Marcelo and Pla, Oriol Abril and Thomas,
                   Owen and Pesonen, Henri and Corander, Jukka and Vehtari, Aki
                   and Kaski, Samuel and B{\"u}rkner, Paul-Christian and Klami,
                   Arto",
  abstract      = "Specification of the prior distribution for a Bayesian model
                   is a central part of the Bayesian workflow for data
                   analysis, but it is often difficult even for statistical
                   experts. Prior elicitation transforms domain knowledge of
                   various kinds into well-defined prior distributions, and
                   offers a solution to the prior specification problem, in
                   principle. In practice, however, we are still fairly far
                   from having usable prior elicitation tools that could
                   significantly influence the way we build probabilistic
                   models in academia and industry. We lack elicitation methods
                   that integrate well into the Bayesian workflow and perform
                   elicitation efficiently in terms of costs of time and
                   effort. We even lack a comprehensive theoretical framework
                   for understanding different facets of the prior elicitation
                   problem. Why are we not widely using prior elicitation? We
                   analyze the state of the art by identifying a range of key
                   aspects of prior knowledge elicitation, from properties of
                   the modelling task and the nature of the priors to the form
                   of interaction with the expert. The existing prior
                   elicitation literature is reviewed and categorized in these
                   terms. This allows recognizing under-studied directions in
                   prior elicitation research, finally leading to a proposal of
                   several new avenues to improve prior elicitation
                   methodology.",
  month         =  dec,
  year          =  2021,
  keywords      = "To read",
  archivePrefix = "arXiv",
  eprint        = "2112.01380",
  primaryClass  = "stat.ME",
  arxivid       = "2112.01380"
}

@BOOK{Spiro2022-nt,
  title     = "Collaborative insights: Interdisciplinary perspectives on
               musical care throughout the life course",
  editor    = "Spiro, Neta and Sanfilippo, Katie Rose M",
  publisher = "Oxford University Press",
  year      =  2022,
  address   = "Oxford, UK",
  isbn      = "9780197535028"
}

@ARTICLE{Sievers2013-pg,
  title    = "Music and movement share a dynamic structure that supports
              universal expressions of emotion",
  author   = "Sievers, Beau and Polansky, Larry and Casey, Michael and
              Wheatley, Thalia",
  abstract = "Music moves us. Its kinetic power is the foundation of human
              behaviors as diverse as dance, romance, lullabies, and the
              military march. Despite its significance, the music-movement
              relationship is poorly understood. We present an empirical method
              for testing whether music and movement share a common structure
              that affords equivalent and universal emotional expressions. Our
              method uses a computer program that can generate matching
              examples of music and movement from a single set of features:
              rate, jitter (regularity of rate), direction, step size, and
              dissonance/visual spikiness. We applied our method in two
              experiments, one in the United States and another in an isolated
              tribal village in Cambodia. These experiments revealed three
              things: (i) each emotion was represented by a unique combination
              of features, (ii) each combination expressed the same emotion in
              both music and movement, and (iii) this common structure between
              music and movement was evident within and across cultures.",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  110,
  number   =  1,
  pages    = "70--75",
  month    =  jan,
  year     =  2013,
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "23248314",
  doi      = "10.1073/pnas.1209023110",
  pmc      = "PMC3538264"
}

@BOOK{Thagard2005-rj,
  title     = "Mind, second edition: Introduction to Cognitive Science",
  author    = "Thagard, Paul",
  abstract  = "Cognitive science approaches the study of mind and intelligence
               from an interdisciplinary perspective, working at the
               intersection of philosophy, psychology, artificial intelligence,
               neuroscience, linguistics, and anthropology. With Mind, Paul
               Thagard offers an introduction to this interdisciplinary field
               for readers who come to the subject with very different
               backgrounds. It is suitable for classroom use by students with
               interests ranging from computer science and engineering to
               psychology and philosophy.Thagard's systematic descriptions and
               evaluations of the main theories of mental representation
               advanced by cognitive scientists allow students to see that
               there are many complementary approaches to the investigation of
               mind. The fundamental theoretical perspectives he describes
               include logic, rules, concepts, analogies, images, and
               connections (artificial neural networks). The discussion of
               these theories provides an integrated view of the different
               achievements of the various fields of cognitive science.This
               second edition includes substantial revision and new material.
               Part I, which presents the different theoretical approaches, has
               been updated in light of recent work the field. Part II, which
               treats extensions to cognitive science, has been thoroughly
               revised, with new chapters added on brains, emotions, and
               consciousness. Other additions include a list of relevant Web
               sites at the end of each chapter and a glossary at the end of
               the book. As in the first edition, each chapter concludes with a
               summary and suggestions for further reading.",
  publisher = "MIT Press",
  month     =  feb,
  year      =  2005,
  language  = "en",
  isbn      = "9780262701099"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INBOOK{Thagard2008-fk,
  title     = "Cognitive science",
  booktitle = "The Routledge Companion to Philosophy of Science",
  author    = "Thagard, Paul",
  abstract  = "Cognitive science is the interdisciplinary investigation of mind
               and intelligence, embracing psychology, neuroscience,
               anthropology, artificial intelligence, and philosophy. There are
               many important philosophical questions related to this
               investigation, but this short essay focuses …",
  publisher = "Routledge",
  year      =  2008
}

@ARTICLE{Herculano-Houzel2009-mu,
  title    = "The human brain in numbers: a linearly scaled-up primate brain",
  author   = "Herculano-Houzel, Suzana",
  abstract = "The human brain has often been viewed as outstanding among
              mammalian brains: the most cognitively able, the
              largest-than-expected from body size, endowed with an
              overdeveloped cerebral cortex that represents over 80\% of brain
              mass, and purportedly containing 100 billion neurons and 10x more
              glial cells. Such uniqueness was seemingly necessary to justify
              the superior cognitive abilities of humans over larger-brained
              mammals such as elephants and whales. However, our recent studies
              using a novel method to determine the cellular composition of the
              brain of humans and other primates as well as of rodents and
              insectivores show that, since different cellular scaling rules
              apply to the brains within these orders, brain size can no longer
              be considered a proxy for the number of neurons in the brain.
              These studies also showed that the human brain is not exceptional
              in its cellular composition, as it was found to contain as many
              neuronal and non-neuronal cells as would be expected of a primate
              brain of its size. Additionally, the so-called overdeveloped
              human cerebral cortex holds only 19\% of all brain neurons, a
              fraction that is similar to that found in other mammals. In what
              regards absolute numbers of neurons, however, the human brain
              does have two advantages compared to other mammalian brains:
              compared to rodents, and probably to whales and elephants as
              well, it is built according to the very economical, space-saving
              scaling rules that apply to other primates; and, among
              economically built primate brains, it is the largest, hence
              containing the most neurons. These findings argue in favor of a
              view of cognitive abilities that is centered on absolute numbers
              of neurons, rather than on body size or encephalization, and call
              for a re-examination of several concepts related to the
              exceptionality of the human brain.",
  journal  = "Frontiers in human neuroscience",
  volume   =  3,
  pages    = "31",
  month    =  nov,
  year     =  2009,
  keywords = "brain scaling; encephalization; human; number of neurons",
  language = "en",
  issn     = "1662-5161",
  pmid     = "19915731",
  doi      = "10.3389/neuro.09.031.2009",
  pmc      = "PMC2776484"
}

@BOOK{Marr1982-di,
  title     = "Vision: A Computational Investigation into the Human
               Representation and Processing of Visual Information",
  author    = "Marr, D",
  publisher = "W. H. Freeman",
  year      =  1982
}

@ARTICLE{Miller2003-ku,
  title     = "The cognitive revolution: a historical perspective",
  author    = "Miller, George A",
  abstract  = "Cognitive science is a child of the 1950s, the product of a time
               when psychology, anthropology and linguistics were redefining
               themselves and computer science and neuroscience as disciplines
               were coming into existence. Psychology could not participate in
               the cognitive revolution until it had freed itself from
               behaviorism, thus restoring cognition to scientific
               respectability. By then, it was becoming clear in several
               disciplines that the solution to some of their problems depended
               crucially on solving problems traditionally allocated to other
               disciplines. Collaboration was called for: this is a personal
               account of how it came about.",
  journal   = "Trends in cognitive sciences",
  publisher = "Elsevier",
  volume    =  7,
  number    =  3,
  pages     = "141--144",
  month     =  mar,
  year      =  2003,
  language  = "en",
  issn      = "1364-6613, 1879-307X",
  pmid      = "12639696",
  doi       = "10.1016/s1364-6613(03)00029-9"
}

@ARTICLE{Omigie2021-lm,
  title     = "Accounting for expressions of curiosity and enjoyment during
               music listening",
  author    = "Omigie, Diana and Ricci, Jessica",
  abstract  = "Music induces surprise and uncertainty in listeners as it
               unfolds. However, it remains unexamined whether it is also able
               to induce waxing and waning feelings of curiosity, how such
               feelings relate to the enjoyment of music, and what role music's
               information theoretic structure and listeners' expertise and
               trait curiosity may play. Here, we characterized melodies using
               a computational model and required participants to report on
               their experience of them as they unfolded. In a first
               experiment, listeners indicated, when cued, how curious they
               were as to how the melodies would continue. In a second, a
               further set of participants indicated, when cued, how much they
               were enjoying the melodies, before completing a multidimensional
               assessment of curiosity. We found a positive association between
               curiosity and note information content (IC, surprisingness) that
               was more pronounced in low entropy (highly predictable)
               contexts. However, we found that curiosity ratings of listeners
               with no music-theory training (and little/ no experience playing
               music) were less influenced by musical structure and more driven
               by judgments of stimulus valence. Finally, we showed that two
               subgroups of curious people, revealed using cluster analyses,
               did not differ in how well their curiosity ratings were
               explained by IC and entropy, but differed in the extent to which
               their unfolding enjoyment of music changed as a function of IC.
               Taken together, our results demonstrate that musical structure
               interacts with musical background to influence the emergence of
               felt curiosity during music listening, while trait curiosity
               further influences how listening enjoyment emerges.",
  journal   = "Psychology of Aesthetics, Creativity and the Arts",
  publisher = "American Psychological Association",
  month     =  nov,
  year      =  2021,
  keywords  = "music, curiosity, emotion, expertise, epistemic emotion,
               information seeking;To read",
  language  = "en",
  issn      = "1931-3896"
}

@ARTICLE{Fuentes-Sanchez2021-jg,
  title     = "Individual differences in music reward sensitivity influence the
               perception of emotions represented by music",
  author    = "Fuentes-S{\'a}nchez, Nieves and Pastor, M Carmen and Eerola,
               Tuomas and Pastor, Ra{\'u}l",
  abstract  = "Although music is one of the most important sources of pleasure
               for many people, there are considerable individual differences
               in music reward sensitivity. Behavioral and neurobiological
               characterizations of music reward variability have been topics
               of increasing scientific interest over the last two decades.
               However, it is not clear how differences in music reward
               sensitivity might influence the perception of emotions
               represented by music and, specifically, how music reward
               sensitivity could influence subjective music evaluation when the
               affective valence of music is considered. In the present study,
               we investigated the relationship between music reward
               sensitivity and the perception of emotions in music, taking into
               account the emotional category of stimuli (pleasant, neutral, or
               unpleasant music clips). Music reward and emotion perception
               were also explored as a function of gender, musicianship, and
               music discrimination skills. We used the Barcelona Music Reward
               Questionnaire and the previously validated Film Music Stimulus
               Set (FMSS); participants rated FMSS excerpts for affective
               dimensions (valence, energy, and tension arousal) and discrete
               emotions (happiness, anger, fear, tenderness, and sadness). Our
               results showed that music reward was the main factor influencing
               FMSS evaluation, particularly for excerpts associated with
               positive affect. Gender had an important influence on
               evaluations linked to the negative pole of emotions, and music
               discrimination skills seemed to be associated with cognitive
               aspects of music analysis, rather than with the emotional
               architecture of pleasant music excerpts. Our findings highlight
               the need to consider music reward sensitivity and gender in
               studies of music and emotion, and open the possibility of using
               the FMSS in studies exploring the neurobiological and
               psychosocial bases of music emotion.",
  journal   = "Musicae scientiae: the journal of the European Society for the
               Cognitive Sciences of Music",
  publisher = "SAGE Publications Ltd",
  pages     = "10298649211060028",
  month     =  dec,
  year      =  2021,
  keywords  = "To read",
  issn      = "1029-8649",
  doi       = "10.1177/10298649211060028"
}

@ARTICLE{Butler1989-ck,
  title     = "Describing the perception of tonality in music: A critique of
               the tonal hierarchy theory and a proposal for a theory of
               intervallic rivalry",
  author    = "Butler, David",
  abstract  = "Strengths and limitations of the tonal hierarchy theory, and of
               the probetone testing procedure used to substantiate that
               theory, are discussed. The tonal hierarchy theory is
               characterized as an important contribution in that it begins to
               describe hierarchical relationships of tones in the diatonic
               set. The tonal hierarchy theory is, however, criticized because
               it does not describe the mental process or processes by which
               the tonal center of a piece of tonal music is recognized, nor
               does it account for the dynamic perception of tonality as it
               unfolds during actual musical listening. The probe-tone testing
               procedure most often used to substantiate the tonal hierarchy
               theory is criticized for the ambiguity of its response task, so
               that test results could be an artifact of effects of short-term
               memory. An alternative perceptual theory is proposed to describe
               the timedependent nature of pitch relationships in music. In
               this description, listeners are assumed to recognize the tonal
               center in tonal music on a bestevidence basis, and it is
               asserted that the clearest evidence is carried in the
               rarest-occurring intervals in the diatonic set. Evidence,
               gathered in a series of experiments, is cited to demonstrate
               that listeners both with and without extensive formal training
               in music form strong (and usually tacit) mental representations
               of unambiguous tonality when tones are arranged across time so
               as to form meaningful tonal referents.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  6,
  number    =  3,
  pages     = "219--241",
  month     =  apr,
  year      =  1989,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.2307/40285588"
}

@ARTICLE{Butler1998-yw,
  title     = "Tonal bootstrapping: Re-thinking the intervallic rivalry model",
  author    = "Butler, David",
  journal   = "Music, Mind, and Science",
  publisher = "Seoul University Press Seoul",
  pages     = "7--12",
  year      =  1998
}

@ARTICLE{Butler1988-br,
  title     = "Effacing the memory of musical pitch",
  author    = "Butler, David and Ward, W Dixon",
  abstract  = "Researchers who design tests involving judgments of pitch face
               the persistent problem that test subjects may remember a pitch
               associated with one test item and carry that memory over to the
               next item. This immediate memory does weaken with time, but it
               weakens quite slowly. Although a number of studies report
               attempts to ``erase'' subjects' impressions by inserting
               distracting sounds--- white noise bursts, electronically
               generated tone glides, excerpts from Schoenberg's Piano
               Concerto--- between trials, no systematic study of the efficacy
               of pitch eraser patterns has yet been undertaken. An initial
               attempt was made to identify and measure a reasonably short list
               of variable attributes of distractor tones that might undo a
               listener's memory for the pitch of a test tone. Those variables
               were the length of the series of distractor tones, the rate at
               which distractor tones were presented, and the temperament
               system---or lack of it---used to tune distractor tones. Test
               results indicate that tuning variables have little effect on
               listeners' accuracy at identifying test tones. Series length and
               presentation rate, however, both have a strong effect on
               accuracy levels for pitch memory.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  5,
  number    =  3,
  pages     = "251--259",
  month     =  apr,
  year      =  1988,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.2307/40285399"
}

@MISC{Matsunaga2005-bb,
  title   = "Cues for Key Perception of a Melody",
  author  = "Matsunaga, Rie and Abe, Jun-Ichi",
  journal = "Music Perception",
  volume  =  23,
  number  =  2,
  pages   = "153--164",
  year    =  2005,
  doi     = "10.1525/mp.2005.23.2.153"
}

@ARTICLE{Faraldo_undated-ew,
  title  = "Key Estimation in Electronic Dance Music",
  author = "Faraldo, {\'A}ngel and G{\'o}mez, Emilia and Jord{\`a}, Sergi and
            Herrera, Perfecto"
}

@ARTICLE{Moore1986-ru,
  title     = "Parallels between frequency selectivity measured
               psychophysically and in cochlear mechanics",
  author    = "Moore, B C",
  abstract  = "One of the most important features of the auditory system is its
               action as a frequency analyser. The frequency analysis appears
               to have its basis in the mechanical patterns of vibration on the
               basilar membrane (BM). Its properties can be measured
               psychophysically using masking experiments and the results
               explained using the concept of the auditory filter (critical
               bandwidth). A method of measuring the auditory filter shape at a
               particular centre frequency is described. This method is based
               upon the power-spectrum model of masking which assumes: 1) when
               detecting a signal in a masker the observer uses the single
               filter giving the highest signal-to-masker ratio; 2) threshold
               corresponds to a fixed signal-to-masker ratio at the output of
               that filter. The variation of the auditory filter bandwidth with
               centre frequency is described and related to measurements of the
               frequency-position map on the BM in man. The equivalent
               rectangular bandwidth (ERB) of the auditory filter corresponds
               approximately to a constant distance of 0.9 mm on the BM.
               Changes in the auditory filter shape with level are described
               and are shown to correspond, at least qualitatively, to
               input-output functions measured on the BM and in single neurones
               of the auditory nerve. Finally, a method is described for
               deriving the excitation pattern of a sound from its power
               spectrum, using the results of auditory-filter measurements. The
               excitation pattern derived in this way probably corresponds to
               the distribution of excitation along the BM.",
  journal   = "Scandinavian audiology. Supplementum",
  publisher = "europepmc.org",
  volume    =  25,
  pages     = "139--152",
  year      =  1986,
  language  = "en",
  issn      = "0107-8593",
  pmid      = "3472318"
}

@ARTICLE{Gockel2021-ew,
  title    = "On musical interval perception for complex tones at very high
              frequencies",
  author   = "Gockel, Hedwig E and Carlyon, Robert P",
  abstract = "Listeners appear able to extract a residue pitch from
              high-frequency harmonics for which phase locking to the temporal
              fine structure is weak or absent. The present study investigated
              musical interval perception for high-frequency harmonic complex
              tones using the same stimuli as Lau, Mehta, and Oxenham [J.
              Neurosci. 37, 9013-9021 (2017)]. Nine young musically trained
              listeners with especially good high-frequency hearing adjusted
              various musical intervals using harmonic complex tones containing
              harmonics 6-10. The reference notes had fundamental frequencies
              (F0s) of 280 or 1400 Hz. Interval matches were possible, albeit
              markedly worse, even when all harmonic frequencies were above the
              presumed limit of phase locking. Matches showed significantly
              larger systematic errors and higher variability, and subjects
              required more trials to finish a match for the high than for the
              low F0. Additional absolute pitch judgments from one subject with
              absolute pitch, for complex tones containing harmonics 1-5 or
              6-10 with a wide range of F0s, were perfect when the lowest
              frequency component was below about 7 kHz, but at least 50\% of
              responses were incorrect when it was 8 kHz or higher. The results
              are discussed in terms of the possible effects of phase-locking
              information and familiarity with high-frequency stimuli on pitch.",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  149,
  number   =  4,
  pages    = "2644",
  month    =  apr,
  year     =  2021,
  language = "en",
  issn     = "0001-4966, 1520-8524",
  pmid     = "33940917",
  doi      = "10.1121/10.0004222",
  pmc      = "PMC7612123"
}

@ARTICLE{Mori2022-fl,
  title    = "Decoding peak emotional responses to music from computational
              acoustic and lyrical features",
  author   = "Mori, Kazuma",
  abstract = "Music can evoke strong emotions. Research has suggested that
              pleasurable chills (shivering) and tears (weeping) are peak
              emotional responses to music. The present study examines whether
              computational acoustic and lyrical features can decode chills and
              tears. The experiment comprises 186 pieces of self-selected music
              to evoke emotional responses from 54 Japanese participants.
              Machine learning analysis with L2-norm-regularization regression
              revealed the decoding accuracy and specified well-defined
              features. In Study 1, time-series acoustic features significantly
              decoded emotional chills, tears, and the absence of chills or
              tears by using information within a few seconds before and after
              the onset of the three responses. The classification results
              showed three significant periods, indicating that complex
              anticipation-resolution mechanisms lead to chills and tears.
              Evoking chills was particularly associated with rhythm
              uncertainty, while evoking tears was related to harmony.
              Violating rhythm expectancy may have been a trigger for chills,
              while the harmonious overlapping of acoustic spectra may have
              played a role in evoking tears. In Study 2, acoustic and lyrical
              features from the entire piece decoded tears but not chill
              frequency. Mixed emotions stemming from happiness were associated
              with major chords, while lyric content related to sad farewells
              can contribute to the prediction of emotional tears, indicating
              that distinctive emotions in music may evoke a tear response.
              When considered in tandem with theoretical studies, the violation
              of rhythm may biologically boost both the pleasure- and
              fight-related physiological response of chills, whereas tears may
              be evolutionarily embedded in the social bonding effect of
              musical harmony and play a unique role in emotional regulation.",
  journal  = "Cognition",
  volume   =  222,
  pages    = "105010",
  month    =  jan,
  year     =  2022,
  keywords = "Audio; Lyric; Machine learning; Music information retrieval;
              Natural language processing; Peak emotion;To read",
  language = "en",
  issn     = "0010-0277, 1873-7838",
  pmid     = "34998244",
  doi      = "10.1016/j.cognition.2021.105010"
}

@ARTICLE{Parncutt2021-pr,
  title     = "The missing fundamentals of harmonic theory: Chord roots and
               their ambiguity in arrangements of jazz standards",
  author    = "Parncutt, Richard and Radovanovic, Lazar",
  abstract  = "Since Lippius and Rameau, chords have roots that are often
               voiced in the bass, doubled, and used as labels. Psychological
               experiments and analyses of databases of Western classical music
               have not produced clear evidence for the psychological reality
               of chord roots. We analyzed a symbolic database of 100
               arrangements of jazz standards (musical instrument digital
               interface [MIDI] files from midkar.com and thejazzpage.de).
               Selection criteria were representativeness and quality.The
               original songs had been composed in the 1930s and 1950s, and
               each file had a beat track. Files were converted to chord
               progressions by identifying tone onsets near beat locations
               ($\pm$10\% of beat duration). Chords were classified as triads
               (major, minor, diminished, suspended) or seventh chords
               (major?minor, minor, major, half-diminished, diminished, and
               suspended) plus extra tones. Roots that were theoretically less
               ambiguous were more often in the bass or (to a lesser extent)
               doubled. The root of the minor triad was ambiguous, as predicted
               (conventional root or third). Of the sevenths, the major?minor
               had the clearest root. The diminished triad was often part of a
               major?minor seventh chord; the half-diminished seventh, of a
               dominant ninth. Added notes (?tensions?) tended to minimize
               dissonance (roughness or inharmonicity). In arrangements of
               songs from the 1950s, diminished triads and sevenths were less
               common, and suspended triads more common, relative to the 1930s.
               Results confirm the psychological reality of chord roots and
               their specific ambiguities. Results are consistent with
               Terhardt?s virtual pitch theory and the idea that musical chords
               emerge gradually from cultural and historic processes. The
               approach can enrich music theory (including pitch-class set
               analysis) and jazz pedagogy.",
  journal   = "Musicae scientiae: the journal of the European Society for the
               Cognitive Sciences of Music",
  publisher = "SAGE Publications Ltd",
  pages     = "10298649211062934",
  month     =  dec,
  year      =  2021,
  keywords  = "To read",
  issn      = "1029-8649",
  doi       = "10.1177/10298649211062934"
}

@ARTICLE{Brown2013-lz,
  title     = "Universals in the world's musics",
  author    = "Brown, Steven and Jordania, Joseph",
  abstract  = "Many decades of skepticism have prevented the field of
               musicology from embracing the importance of musical universals.
               When universals have been discussed, it has generally been in
               the form of meta-critiques about the concept of universals,
               rather than in positive proposals about actual universals. We
               present here a typology of four categories of musical universals
               and a listing of 70 putative universals in musics
               cross-culturally. These universals span a wide variety of
               features, including pitch, rhythm, melodic structure, form,
               vocal style, expressive devices, instruments, performance
               contexts, contents, and behaviors.",
  journal   = "Psychology of music",
  publisher = "SAGE Publications",
  volume    =  41,
  number    =  2,
  pages     = "229--248",
  month     =  mar,
  year      =  2013,
  language  = "en",
  issn      = "0305-7356, 1741-3087",
  doi       = "10.1177/0305735611425896"
}

@ARTICLE{Smit2021-va,
  title     = "The need for composite models of music perception: Consonance in
               tuning systems (familiar or unfamiliar) cannot be explained by a
               single predictor",
  author    = "Smit, Eline A and Milne, Andrew J",
  journal   = "Music Perception",
  publisher = "University of California Press",
  volume    =  38,
  number    =  3,
  pages     = "335--336",
  year      =  2021,
  doi       = "10.1525/mp.2021.38.3.335"
}

@UNPUBLISHED{Chiba2019-kk,
  title    = "Small-integer ratios predominate throughout the world's musical
              scales",
  author   = "Chiba, Gakuto and Ho, Meng-Jou and Sato, Shoichiro and
              Kuroyanagi, Jiei and Six, Joren and Pfordresher, Peter and
              Tierney, Adam and Fujii, Shinya and Savage, Patrick E",
  abstract = "The structure of musical scales has been proposed to reflect
              universal bioacoustic principles based on simple integer ratios.
              However, some researchers who have studied tuning in small
              samples of non-Western cultures have argued that such ratios are
              instead specific to Western music. To address this debate, we
              algorithmically analyzed and cross-culturally compared scale
              tunings within a global sample of 124 music recordings, including
              both instrumental and vocal music. Although we found great
              cross-cultural diversity in most scale degrees, we also found a
              strong cross-cultural tendency to include the simplest possible
              integer ratios within the octave (3:2 ratio [perfect 5th] and 4:3
              ratio [perfect 4th]). This suggests that cultural diversity in
              musical scales is not without limit, but is constrained by
              general bioacoustic principles, such as harmonic consonance in
              group performance, that may shed light on the evolution of human
              music.",
  month    =  jun,
  year     =  2019,
  doi      = "10.31234/osf.io/5bghm"
}

@BOOK{Schnupp2011-ux,
  title     = "Audio neuroscience: Making sense of sound",
  author    = "Schnupp, Jan and Nelken, Israel and King, Andrew",
  publisher = "MIT Press",
  year      =  2011,
  address   = "Cambridge, MA"
}

@ARTICLE{Jadoul2018-ee,
  title     = "Introducing Parselmouth: A Python interface to Praat",
  author    = "Jadoul, Yannick and Thompson, Bill and de Boer, Bart",
  abstract  = "This paper introduces Parselmouth, an open-source Python library
               that facilitates access to core functionality of Praat in
               Python, in an efficient and programmer-friendly way. We
               introduce and motivate the package, and present simple usage
               examples. Specifically, we focus on applications in data
               visualisation, file manipulation, audio manipulation,
               statistical analysis, and integration of Parselmouth into a
               Python-based experimental design for automated, in-the-loop
               manipulation of acoustic data. Parselmouth is available at
               https://github.com/YannickJadoul/Parselmouth.",
  journal   = "Journal of phonetics",
  publisher = "Elsevier",
  volume    =  71,
  pages     = "1--15",
  month     =  nov,
  year      =  2018,
  keywords  = "Praat; Python; Data analysis; Acoustics; Phonetics; Software",
  issn      = "0095-4470",
  doi       = "10.1016/j.wocn.2018.07.001"
}

@ARTICLE{Tymoczko2022-eq,
  title     = "Hierarchical set theory",
  author    = "Tymoczko, Dmitri",
  journal   = "Journal of Mathematics \& Music. Mathematical and Computational
               Approaches to Music Theory, Analysis, Composition and
               Performance",
  publisher = "Informa UK Limited",
  pages     = "1--9",
  month     =  jan,
  year      =  2022,
  keywords  = "To read",
  language  = "en",
  issn      = "1745-9737, 1745-9745",
  doi       = "10.1080/17459737.2021.2008035"
}

@ARTICLE{Rule2020-wb,
  title    = "The Child as Hacker",
  author   = "Rule, Joshua S and Tenenbaum, Joshua B and Piantadosi, Steven T",
  abstract = "The scope of human learning and development poses a radical
              challenge for cognitive science. We propose that developmental
              theories can address this challenge by adopting perspectives from
              computer science. Many of our best models treat learning as
              analogous to computer programming because symbolic programs
              provide the most compelling account of sophisticated mental
              representations. We specifically propose that children's learning
              is analogous to a particular style of programming called hacking,
              making code better along many dimensions through an open-ended
              set of goals and activities. By contrast to existing theories,
              which depend primarily on local search and simple metrics, this
              view highlights the many features of good mental representations
              and the multiple complementary processes children use to create
              them.",
  journal  = "Trends in cognitive sciences",
  volume   =  24,
  number   =  11,
  pages    = "900--915",
  month    =  nov,
  year     =  2020,
  keywords = "Computational modeling; Hacking; Language of thought; Learning
              and cognitive development; Program induction;To read",
  language = "en",
  issn     = "1364-6613, 1879-307X",
  pmid     = "33012688",
  doi      = "10.1016/j.tics.2020.07.005",
  pmc      = "PMC7673661"
}

@ARTICLE{Zentner2008-mv,
  title    = "Emotions evoked by the sound of music: characterization,
              classification, and measurement",
  author   = "Zentner, Marcel and Grandjean, Didier and Scherer, Klaus R",
  abstract = "One reason for the universal appeal of music lies in the
              emotional rewards that music offers to its listeners. But what
              makes these rewards so special? The authors addressed this
              question by progressively characterizing music-induced emotions
              in 4 interrelated studies. Studies 1 and 2 (n=354) were conducted
              to compile a list of music-relevant emotion terms and to study
              the frequency of both felt and perceived emotions across 5 groups
              of listeners with distinct music preferences. Emotional responses
              varied greatly according to musical genre and type of response
              (felt vs. perceived). Study 3 (n=801)--a field study carried out
              during a music festival--examined the structure of music-induced
              emotions via confirmatory factor analysis of emotion ratings,
              resulting in a 9-factorial model of music-induced emotions. Study
              4 (n=238) replicated this model and found that it accounted for
              music-elicited emotions better than the basic emotion and
              dimensional emotion models. A domain-specific device to measure
              musically induced emotions is introduced--the Geneva Emotional
              Music Scale.",
  journal  = "Emotion",
  volume   =  8,
  number   =  4,
  pages    = "494--521",
  month    =  aug,
  year     =  2008,
  language = "en",
  issn     = "1528-3542",
  pmid     = "18729581",
  doi      = "10.1037/1528-3542.8.4.494"
}

@ARTICLE{Russell1980-xv,
  title     = "A circumplex model of affect",
  author    = "Russell, James A",
  journal   = "Journal of personality and social psychology",
  publisher = "American Psychological Association",
  volume    =  39,
  number    =  6,
  pages     = "1161",
  year      =  1980,
  issn      = "0022-3514"
}

@ARTICLE{Savage2022-xg,
  title    = "Sequence alignment of folk song melodies reveals cross-cultural
              regularities of musical evolution",
  author   = "Savage, Patrick E and Passmore, Sam and Chiba, Gakuto and Currie,
              Thomas E and Suzuki, Haruo and Atkinson, Quentin D",
  abstract = "Culture evolves,1-5 but the existence of cross-culturally general
              regularities of cultural evolution is debated.6-8 As a diverse
              but universal cultural phenomenon, music provides a novel domain
              to test for the existence of such regularities.9-12 Folk song
              melodies can be thought of as culturally transmitted sequences of
              notes that change over time under the influence of cognitive and
              acoustic/physical constraints.9-15 Modeling melodies as evolving
              sequences constructed from an ``alphabet'' of 12 scale degrees16
              allows us to quantitatively test for the presence of
              cross-cultural regularities using a sample of 10,062 melodies
              from musically divergent Japanese and English (British/American)
              folk song traditions.17,18 Our analysis identifies 328 pairs of
              highly related melodies, finding that note changes are more
              likely when they have smaller impacts on a song's melody.
              Specifically, (1) notes with stronger rhythmic functions are less
              likely to change, and (2) note substitutions are most likely
              between neighboring notes. We also find that note
              insertions/deletions (``indels'') are more common than note
              substitutions, unlike genetic evolution where the reverse is
              true. Our results are consistent across English and Japanese
              samples despite major differences in their scales and tonal
              systems. These findings demonstrate that even a creative art form
              such as music is subject to evolutionary constraints analogous to
              those governing the evolution of genes, languages, and other
              domains of culture.",
  journal  = "Current biology: CB",
  month    =  feb,
  year     =  2022,
  keywords = "cross-cultural; cultural evolution; music; sequence alignment;To
              read",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "35120658",
  doi      = "10.1016/j.cub.2022.01.039"
}

@ARTICLE{Kidd2013-rr,
  title    = "Reading literary fiction improves theory of mind",
  author   = "Kidd, David Comer and Castano, Emanuele",
  abstract = "Understanding others' mental states is a crucial skill that
              enables the complex social relationships that characterize human
              societies. Yet little research has investigated what fosters this
              skill, which is known as Theory of Mind (ToM), in adults. We
              present five experiments showing that reading literary fiction
              led to better performance on tests of affective ToM (experiments
              1 to 5) and cognitive ToM (experiments 4 and 5) compared with
              reading nonfiction (experiments 1), popular fiction (experiments
              2 to 5), or nothing at all (experiments 2 and 5). Specifically,
              these results show that reading literary fiction temporarily
              enhances ToM. More broadly, they suggest that ToM may be
              influenced by engagement with works of art.",
  journal  = "Science",
  volume   =  342,
  number   =  6156,
  pages    = "377--380",
  month    =  oct,
  year     =  2013,
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "24091705",
  doi      = "10.1126/science.1239918"
}

@ARTICLE{Mar2008-vw,
  title    = "The Function of Fiction is the Abstraction and Simulation of
              Social Experience",
  author   = "Mar, Raymond A and Oatley, Keith",
  abstract = "Fiction literature has largely been ignored by psychology
              researchers because its only function seems to be entertainment,
              with no connection to empirical validity. We argue that literary
              narratives have a more important purpose. They offer models or
              simulations of the social world via abstraction, simplification,
              and compression. Narrative fiction also creates a deep and
              immersive simulative experience of social interactions for
              readers. This simulation facilitates the communication and
              understanding of social information and makes it more compelling,
              achieving a form of learning through experience. Engaging in the
              simulative experiences of fiction literature can facilitate the
              understanding of others who are different from ourselves and can
              augment our capacity for empathy and social inference.",
  journal  = "Perspectives on psychological science: a journal of the
              Association for Psychological Science",
  volume   =  3,
  number   =  3,
  pages    = "173--192",
  month    =  may,
  year     =  2008,
  language = "en",
  issn     = "1745-6916",
  pmid     = "26158934",
  doi      = "10.1111/j.1745-6924.2008.00073.x"
}

@ARTICLE{Huron2020-wm,
  title    = "On the Enjoyment of Sad Music: Pleasurable Compassion Theory and
              the Role of Trait Empathy",
  author   = "Huron, David and Vuoskoski, Jonna K",
  abstract = "Drawing on recent empirical studies on the enjoyment of nominally
              sad music, a general theory of the pleasure of tragic or sad
              portrayals is presented. Not all listeners enjoy sad music.
              Multiple studies indicate that those individuals who enjoy sad
              music exhibit a particular pattern of empathic traits. These
              individuals score high on empathic concern (compassion) and high
              on imaginative absorption (fantasy), with only nominal personal
              distress (commiseration). Empirical studies are reviewed
              implicating compassion as a positively valenced affect.
              Accordingly, individuals who most enjoy sad musical portrayals
              experience a pleasurable prosocial affect (compassion), amplified
              by empathetic engagement (fantasy), while experiencing only
              nominal levels of unpleasant emotional contagion (commiseration).
              It is suggested that this pattern of trait empathy may apply more
              broadly, accounting for many other situations where spectators
              experience pleasure when exposed to tragic representations or
              portrayals.",
  journal  = "Frontiers in psychology",
  volume   =  11,
  pages    = "1060",
  month    =  may,
  year     =  2020,
  keywords = "compassion; fiction; music and emotion; sadness; trait empathy",
  language = "en",
  issn     = "1664-1078",
  pmid     = "32547455",
  doi      = "10.3389/fpsyg.2020.01060",
  pmc      = "PMC7270397"
}

@ARTICLE{Lee2013-cn,
  title     = "Interpersonal Relationships and Preferences for
               {Mood-Congruency} in Aesthetic Experiences",
  author    = "Lee, Chan Jean and Andrade, Eduardo B and Palmer, Stephen E",
  abstract  = "Abstract. Prior research examining how negative feelings
               influence aesthetic preferences (e.g., liking of different kinds
               of music, movies, or stories) has repo",
  journal   = "The Journal of consumer research",
  publisher = "Oxford Academic",
  volume    =  40,
  number    =  2,
  pages     = "382--391",
  month     =  aug,
  year      =  2013,
  issn      = "0093-5301",
  doi       = "10.1086/670609"
}

@ARTICLE{Huron2011-pi,
  title     = "Why is sad music pleasurable? A possible role for prolactin",
  author    = "Huron, David",
  abstract  = "A hedonic theory of music and sadness is proposed. Some
               listeners report that nominally sad music genuinely makes them
               feel sad. It is suggested that, for these listeners, sad affect
               is evoked through a combination of empathetic responses to sad
               acoustic features, learned associations, and cognitive
               rumination. Among those listeners who report sad feelings, some
               report an accompanying positive affect, whereas others report
               the experience to be solely negative. Levels of the hormone
               prolactin increase when sad ? producing a consoling
               psychological effect suggestive of a homeostatic function. It is
               proposed that variations in prolactin levels might account for
               the variability in individual hedonic responses. Specifically,
               it is conjectured that high prolactin concentrations are
               associated with pleasurable music-induced sadness, whereas low
               prolactin concentrations are associated with unpleasant
               music-induced sadness.",
  journal   = "Musicae scientiae: the journal of the European Society for the
               Cognitive Sciences of Music",
  publisher = "SAGE Publications Ltd",
  volume    =  15,
  number    =  2,
  pages     = "146--158",
  month     =  jul,
  year      =  2011,
  issn      = "1029-8649",
  doi       = "10.1177/1029864911401171"
}

@ARTICLE{Drake2012-gw,
  title    = "Confronting sadness through art-making: Distraction is more
              beneficial than venting",
  author   = "Drake, Jennifer E and Winner, Ellen",
  abstract = "We examined two ways in which art-making may function to elevate
              mood---venting (expressing negative feelings) and distraction
              (expressing something unrelated to the negative feelings). In
              Study 1 we induced a negative mood in participants by showing
              them a sad film clip and then assigned them to one of two
              conditions. In the venting condition they were asked to draw
              something related to the film; in the distraction condition they
              were asked to draw an image unrelated to the film (a house). In
              Study 2 we induced a negative mood by asking participants to
              think of the saddest event they had experienced and then assigned
              them to one of three conditions: venting, distraction, and
              sitting - a new condition in which participants just sat quietly.
              This latter condition allowed us to assess the effect of passage
              of time. In both studies, positive and negative affect were
              measured before and after the assigned activity. In both studies,
              mood improved significantly more in the distraction than in the
              venting or sitting condition. We argue that the mood elevating
              effects of art-making are stronger when art is used to distract
              than when used to vent. (PsycINFO Database Record (c) 2017 APA,
              all rights reserved)",
  journal  = "Psychology of Aesthetics, Creativity, and the Arts",
  volume   =  6,
  number   =  3,
  pages    = "255--261",
  month    =  aug,
  year     =  2012,
  doi      = "10.1037/a0026909"
}

@ARTICLE{Savage2020-mb,
  title    = "Music as a coevolved system for social bonding",
  author   = "Savage, Patrick E and Loui, Psyche and Tarr, Bronwyn and
              Schachner, Adena and Glowacki, Luke and Mithen, Steven and Fitch,
              W Tecumseh",
  abstract = "Why do humans make music? Theories of the evolution of musicality
              have focused mainly on the value of music for specific adaptive
              contexts such as mate selection, parental care, coalition
              signaling, and group cohesion. Synthesizing and extending
              previous proposals, we argue that social bonding is an
              overarching function that unifies all of these theories, and that
              musicality enabled social bonding at larger scales than grooming
              and other bonding mechanisms available in ancestral primate
              societies. We combine cross-disciplinary evidence from
              archeology, anthropology, biology, musicology, psychology, and
              neuroscience into a unified framework that accounts for the
              biological and cultural evolution of music. We argue that the
              evolution of musicality involves gene-culture coevolution,
              through which proto-musical behaviors that initially arose and
              spread as cultural inventions had feedback effects on biological
              evolution because of their impact on social bonding. We emphasize
              the deep links between production, perception, prediction, and
              social reward arising from repetition, synchronization, and
              harmonization of rhythms and pitches, and summarize empirical
              evidence for these links at the levels of brain networks,
              physiological mechanisms, and behaviors across cultures and
              across species. Finally, we address potential criticisms and make
              testable predictions for future research, including
              neurobiological bases of musicality and relationships between
              human music, language, animal song, and other domains. The music
              and social bonding hypothesis provides the most comprehensive
              theory to date of the biological and cultural evolution of music.",
  journal  = "Behavioral and brain sciences",
  volume   =  44,
  pages    = "e59",
  month    =  aug,
  year     =  2020,
  keywords = "comparative; cooperation; cultural evolution; harmony; language;
              music; prediction; reward; synchrony; vocal learning",
  language = "en",
  issn     = "0140-525X, 1469-1825",
  pmid     = "32814608",
  doi      = "10.1017/S0140525X20000333"
}

@ARTICLE{Mehr2020-zk,
  title    = "Origins of music in credible signaling",
  author   = "Mehr, Samuel A and Krasnow, Max M and Bryant, Gregory A and
              Hagen, Edward H",
  abstract = "Music comprises a diverse category of cognitive phenomena that
              likely represent both the effects of psychological adaptations
              that are specific to music (e.g., rhythmic entrainment) and the
              effects of adaptations for non-musical functions (e.g., auditory
              scene analysis). How did music evolve? Here, we show that
              prevailing views on the evolution of music - that music is a
              byproduct of other evolved faculties, evolved for social bonding,
              or evolved to signal mate quality - are incomplete or wrong. We
              argue instead that music evolved as a credible signal in at least
              two contexts: coalitional interactions and infant care.
              Specifically, we propose that (1) the production and reception of
              coordinated, entrained rhythmic displays is a co-evolved system
              for credibly signaling coalition strength, size, and coordination
              ability; and (2) the production and reception of infant-directed
              song is a co-evolved system for credibly signaling parental
              attention to secondarily altricial infants. These proposals,
              supported by interdisciplinary evidence, suggest that basic
              features of music, such as melody and rhythm, result from
              adaptations in the proper domain of human music. The adaptations
              provide a foundation for the cultural evolution of music in its
              actual domain, yielding the diversity of musical forms and
              musical behaviors found worldwide.",
  journal  = "Behavioral and brain sciences",
  volume   =  44,
  pages    = "e60",
  month    =  aug,
  year     =  2020,
  keywords = "coalitions; credible signaling; cultural evolution; infancy;
              music; natural selection; parent--offspring conflict;
              territoriality",
  language = "en",
  issn     = "0140-525X, 1469-1825",
  pmid     = "32843107",
  doi      = "10.1017/S0140525X20000345",
  pmc      = "PMC7907251"
}

@BOOK{Blacking1995-es,
  title     = "Music, culture and experience",
  author    = "Blacking, J",
  publisher = "University of Chicago Press",
  year      =  1995,
  address   = "London",
  language  = "en"
}

@ARTICLE{Margulis2005-sd,
  title    = "A model of melodic expectation",
  author   = "Margulis, E H",
  journal  = "Music perception",
  volume   =  22,
  number   =  4,
  pages    = "663--714",
  year     =  2005,
  language = "en",
  issn     = "0730-7829"
}

@PHDTHESIS{McAuley1995-dd,
  title    = "Perception of time as phase: Toward an adaptive-oscillator model
              of rhythmic pattern processing",
  author   = "McAuley, J D",
  year     =  1995,
  school   = "Indiana University",
  language = "en"
}

@PHDTHESIS{Hearne2020-hk,
  title    = "The cognition of harmonic tonality in microtonal scales",
  author   = "Hearne, L M",
  year     =  2020,
  school   = "Western Sydney University",
  language = "en"
}

@ARTICLE{Huron1996-lv,
  title    = "The melodic arch in Western folksongs",
  author   = "Huron, D",
  journal  = "Computing in Musicology",
  volume   =  10,
  pages    = "3--23",
  year     =  1996,
  language = "en"
}

@ARTICLE{McDermott2016-xz,
  title     = "Indifference to dissonance in native Amazonians reveals cultural
               variation in music perception",
  author    = "McDermott, Josh H and Schultz, Alan F and Undurraga, Eduardo A
               and Godoy, Ricardo A",
  abstract  = "by biology remains debated. One widely discussed phenomenon is
               that some combinations of notes are perceived by Westerners as
               pleasant, or consonant, whereas others are perceived as
               unpleasant,or dissonant. The contrast between consonance and
               dissonance is central to Western music and its origins have
               fascinated scholars since the ancient Greeks. Aesthetic
               responses to consonance are commonly assumed by scientists to
               have biological roots, and thus to be universally present in
               humans. Ethnomusicologists and composers, in contrast, have
               argued that consonance is a creation of Western musical culture.
               The issue has remained unresolved, partly because little is
               known about the extent of cross-cultural variation in consonance
               preferences. Here we report experiments with the Tsimane'--a
               native Amazonian society with minimal exposure to Western
               culture--and comparison populations in Bolivia and the United
               States that varied in exposure to Western music. Participants
               rated the pleasantness of sounds. Despite exhibiting
               Western-like discrimination abilities and Western-like aesthetic
               responses to familiar sounds and acoustic roughness, the
               Tsimane' rated consonant and dissonant chords and vocal
               harmonies as equally pleasant. By contrast, Bolivian city- and
               town-dwellers exhibited significant preferences for
               consonance,albeit to a lesser degree than US residents. The
               results indicate that consonance preferences can be absent in
               cultures sufficiently isolated from Western music, and are thus
               unlikely to reflect innate biases or exposure to harmonic
               natural sounds. The observed variation in preferences is
               presumably determined by exposure to musical harmony, suggesting
               that culture has a dominant role in shaping aesthetic responses
               to music.",
  journal   = "Nature",
  publisher = "Springer Science and Business Media LLC",
  volume    =  535,
  number    =  7613,
  pages     = "547--550",
  month     =  jul,
  year      =  2016,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "27409816",
  doi       = "10.1038/nature18635"
}

@ARTICLE{McDermott2011-km,
  title    = "Recovering sound sources from embedded repetition",
  author   = "McDermott, J H and Wrobleski, D and Oxenham, A J",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  108,
  number   =  3,
  pages    = "1188--1193",
  year     =  2011,
  language = "en"
}

@ARTICLE{McGowan2011-sv,
  title    = "A comparison of rhythm in English dialects and music",
  author   = "McGowan, R W and Levitt, A G",
  journal  = "Music perception",
  volume   =  28,
  number   =  3,
  pages    = "307--314",
  year     =  2011,
  language = "en",
  issn     = "0730-7829"
}

@INCOLLECTION{Juslin2001-zk,
  title     = "Communicating emotion in music performance: A review and a
               theoretical framework",
  booktitle = "Music and Emotion: Theory and Research",
  author    = "Juslin, P N",
  editor    = "Juslin, P N and Sloboda, J A",
  publisher = "Oxford University Press",
  pages     = "309--337",
  year      =  2001,
  language  = "en"
}

@ARTICLE{Juslin2013-fk,
  title    = "From everyday emotions to aesthetic emotions: Towards a unified
              theory of musical emotions",
  author   = "Juslin, P N",
  journal  = "Physics of life reviews",
  volume   =  10,
  number   =  3,
  pages    = "235--266",
  year     =  2013,
  language = "en",
  issn     = "1571-0645"
}

@ARTICLE{Juslin2003-tf,
  title    = "Communication of emotions in vocal expression and music
              performance: Different channels, same code?",
  author   = "Juslin, P N and Laukka, P",
  journal  = "Psychological bulletin",
  volume   =  129,
  number   =  5,
  pages    = "770--814",
  year     =  2003,
  language = "fr",
  issn     = "0033-2909"
}

@INCOLLECTION{Koelsch2009-yd,
  title     = "Neural substrates of processing syntax and semantics in music",
  booktitle = "Music that works",
  author    = "Koelsch, S",
  publisher = "Springer-Verlag",
  pages     = "143--153",
  year      =  2009,
  address   = "Vienna, Austria",
  language  = "nl"
}

@ARTICLE{Large2015-yr,
  title    = "Neural Networks for Beat Perception in Musical Rhythm",
  author   = "Large, Edward W and Herrera, Jorge A and Velasco, Marc J",
  abstract = "Entrainment of cortical rhythms to acoustic rhythms has been
              hypothesized to be the neural correlate of pulse and meter
              perception in music. Dynamic attending theory first proposed
              synchronization of endogenous perceptual rhythms nearly 40 years
              ago, but only recently has the pivotal role of neural synchrony
              been demonstrated. Significant progress has since been made in
              understanding the role of neural oscillations and the neural
              structures that support synchronized responses to musical rhythm.
              Synchronized neural activity has been observed in auditory and
              motor networks, and has been linked with attentional allocation
              and movement coordination. Here we describe a neurodynamic model
              that shows how self-organization of oscillations in interacting
              sensory and motor networks could be responsible for the formation
              of the pulse percept in complex rhythms. In a pulse
              synchronization study, we test the model's key prediction that
              pulse can be perceived at a frequency for which no spectral
              energy is present in the amplitude envelope of the acoustic
              rhythm. The result shows that participants perceive the pulse at
              the theoretically predicted frequency. This model is one of the
              few consistent with neurophysiological evidence on the role of
              neural oscillation, and it explains a phenomenon that other
              computational models fail to explain. Because it is based on a
              canonical model, the predictions hold for an entire family of
              dynamical systems, not only a specific one. Thus, this model
              provides a theoretical link between oscillatory neurodynamics and
              the induction of pulse and meter in musical rhythm.",
  journal  = "Frontiers in systems neuroscience",
  volume   =  9,
  pages    = "159",
  month    =  nov,
  year     =  2015,
  keywords = "beat perception; dynamical systems; musical rhythm; neural
              networks; neural resonance",
  language = "en",
  issn     = "1662-5137",
  pmid     = "26635549",
  doi      = "10.3389/fnsys.2015.00159",
  pmc      = "PMC4658578"
}

@ARTICLE{Koelsch2000-el,
  title    = "Brain indices of music processing: ``Non-musicians'' are musical",
  author   = "Koelsch, S and Gunter, T C and Friederici, A D and Schr{\"o}ger,
              E",
  journal  = "Journal of cognitive neuroscience",
  volume   =  12,
  pages    = "520--541",
  year     =  2000,
  language = "en",
  issn     = "0898-929X"
}

@ARTICLE{Krumhansl1995-ix,
  title    = "Effects of musical context on similarity and expectancy",
  author   = "Krumhansl, C L",
  journal  = "Systematische Musikwissenschaft",
  volume   =  3,
  number   =  2,
  pages    = "211--250",
  year     =  1995,
  language = "de"
}

@ARTICLE{Lerdahl1988-hi,
  title     = "Tonal pitch space",
  author    = "Lerdahl, Fred",
  abstract  = "Models of pitch space have been developed in music psychology to
               account for perceived proximity among pitches, chords, or
               regions. This article introduces a different model that (1)
               treats pitches, chords, and regions within one framework, (2)
               correlates with the experimental data, and (3) connects in
               interesting ways with a variety of music theories.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  5,
  number    =  3,
  pages     = "315--349",
  month     =  apr,
  year      =  1988,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.2307/40285402"
}

@ARTICLE{Leman2000-ky,
  title    = "An auditory model of the role of short-term memory in probe-tone
              ratings",
  author   = "Leman, M",
  journal  = "Music perception",
  volume   =  17,
  number   =  4,
  pages    = "481--509",
  year     =  2000,
  language = "en",
  issn     = "0730-7829"
}

@ARTICLE{Juslin2008-rc,
  title    = "Emotional responses to music: the need to consider underlying
              mechanisms",
  author   = "Juslin, Patrik N and V{\"a}stfj{\"a}ll, Daniel",
  abstract = "Research indicates that people value music primarily because of
              the emotions it evokes. Yet, the notion of musical emotions
              remains controversial, and researchers have so far been unable to
              offer a satisfactory account of such emotions. We argue that the
              study of musical emotions has suffered from a neglect of
              underlying mechanisms. Specifically, researchers have studied
              musical emotions without regard to how they were evoked, or have
              assumed that the emotions must be based on the ``default''
              mechanism for emotion induction, a cognitive appraisal. Here, we
              present a novel theoretical framework featuring six additional
              mechanisms through which music listening may induce emotions: (1)
              brain stem reflexes, (2) evaluative conditioning, (3) emotional
              contagion, (4) visual imagery, (5) episodic memory, and (6)
              musical expectancy. We propose that these mechanisms differ
              regarding such characteristics as their information focus,
              ontogenetic development, key brain regions, cultural impact,
              induction speed, degree of volitional influence, modularity, and
              dependence on musical structure. By synthesizing theory and
              findings from different domains, we are able to provide the first
              set of hypotheses that can help researchers to distinguish among
              the mechanisms. We show that failure to control for the
              underlying mechanism may lead to inconsistent or
              non-interpretable findings. Thus, we argue that the new framework
              may guide future research and help to resolve previous
              disagreements in the field. We conclude that music evokes
              emotions through mechanisms that are not unique to music, and
              that the study of musical emotions could benefit the emotion
              field as a whole by providing novel paradigms for emotion
              induction.",
  journal  = "The Behavioral and brain sciences",
  volume   =  31,
  number   =  5,
  pages    = "559--75; discussion 575--621",
  month    =  oct,
  year     =  2008,
  language = "en",
  issn     = "0140-525X, 1469-1825",
  pmid     = "18826699",
  doi      = "10.1017/S0140525X08005293"
}

@ARTICLE{Jacoby2019-ew,
  title    = "Universal and Non-universal Features of Musical Pitch Perception
              Revealed by Singing",
  author   = "Jacoby, Nori and Undurraga, Eduardo A and McPherson, Malinda J
              and Vald{\'e}s, Joaqu{\'\i}n and Ossand{\'o}n, Tom{\'a}s and
              McDermott, Josh H",
  abstract = "Musical pitch perception is argued to result from nonmusical
              biological constraints and thus to have similar characteristics
              across cultures, but its universality remains unclear. We probed
              pitch representations in residents of the Bolivian Amazon-the
              Tsimane', who live in relative isolation from Western culture-as
              well as US musicians and non-musicians. Participants sang back
              tone sequences presented in different frequency ranges. Sung
              responses of Amazonian and US participants approximately
              replicated heard intervals on a logarithmic scale, even for tones
              outside the singing range. Moreover, Amazonian and US
              reproductions both deteriorated for high-frequency tones even
              though they were fully audible. But whereas US participants
              tended to reproduce notes an integer number of octaves above or
              below the heard tones, Amazonians did not, ignoring the note
              ``chroma'' (C, D, etc.). Chroma matching in US participants was
              more pronounced in US musicians than non-musicians, was not
              affected by feedback, and was correlated with similarity-based
              measures of octave equivalence as well as the ability to match
              the absolute f0 of a stimulus in the singing range. The results
              suggest the cross-cultural presence of logarithmic scales for
              pitch, and biological constraints on the limits of pitch, but
              indicate that octave equivalence may be culturally contingent,
              plausibly dependent on pitch representations that develop from
              experience with particular musical systems. VIDEO ABSTRACT.",
  journal  = "Current biology: CB",
  volume   =  29,
  number   =  19,
  pages    = "3229--3243.e12",
  month    =  oct,
  year     =  2019,
  keywords = "Tsimane'; absolute pitch; bio-musicology; cross-cultural
              psychology; mental scales; music cognition; octave equivalence;
              pitch; relative pitch; singing",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "31543451",
  doi      = "10.1016/j.cub.2019.08.020"
}

@ARTICLE{Huron2001-zz,
  title     = "Tone and voice: A derivation of the rules of voice-leading from
               perceptual principles",
  author    = "Huron, David",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  19,
  number    =  1,
  pages     = "1--64",
  month     =  sep,
  year      =  2001,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2001.19.1.1"
}

@ARTICLE{Harrison2020-lp,
  title    = "Simultaneous consonance in music perception and composition",
  author   = "Harrison, P M C and Pearce, M T",
  journal  = "Psychological review",
  volume   =  127,
  number   =  2,
  pages    = "216--244",
  year     =  2020,
  language = "en",
  issn     = "0033-295X"
}

@BOOK{Huron2016-vp,
  title     = "Voice leading: The science behind a musical art",
  author    = "Huron, D",
  publisher = "MIT Press",
  year      =  2016,
  address   = "Cambridge, MA",
  language  = "en"
}

@ARTICLE{Longuet-Higgins1982-mg,
  title    = "The perception of musical rhythms",
  author   = "Longuet-Higgins, H C and Lee, C S",
  journal  = "Perception",
  volume   =  11,
  number   =  2,
  pages    = "115--128",
  year     =  1982,
  language = "en",
  issn     = "0301-0066",
  pmid     = "7155765",
  doi      = "10.1068/p110115"
}

@ARTICLE{Hutchinson1978-mx,
  title    = "The acoustic component of Western consonance",
  author   = "Hutchinson, W and Knopoff, L",
  journal  = "The Journal of New Music Research",
  volume   =  7,
  number   =  1,
  pages    = "1--29",
  year     =  1978,
  language = "en"
}

@BOOK{Jackendoff1987-xl,
  title     = "Consciousness and the computational mind",
  author    = "Jackendoff, R",
  publisher = "MIT Press",
  year      =  1987,
  address   = "Cambridge, MA",
  language  = "en"
}

@ARTICLE{Jacoby2017-fy,
  title    = "Integer ratio priors on musical rhythm revealed cross-culturally
              by iterated reproduction",
  author   = "Jacoby, N and McDermott, J H",
  journal  = "Current biology: CB",
  volume   =  27,
  number   =  3,
  pages    = "359--370",
  year     =  2017,
  language = "en",
  issn     = "0960-9822"
}

@ARTICLE{Cross2001-nt,
  title    = "Music, cognition, culture, and evolution",
  author   = "Cross, I",
  abstract = "We seem able to define the biological foundations for our
              musicality within a clear and unitary framework, yet music itself
              does not appear so clearly definable. Music is different things
              and does different things in different cultures; the bundles of
              elements and functions that are music for any given culture may
              overlap minimally with those of another culture, even for those
              cultures where ``music'' constitutes a discrete and identifiable
              category of human activity in its own right. The dynamics of
              culture, of music as cultural praxis, are neither necessarily
              reducible, nor easily relatable, to the dynamics of our
              biologies. Yet music appears to be a universal human competence.
              Recent evolutionary theory, however, affords a means for
              exploring things biological and cultural within a framework in
              which they are at least commensurable. The adoption of this
              perspective shifts the focus of the search for the foundations of
              music away from the mature and particular expression of music
              within a specific culture or situation and on to the human
              capacity for musicality. This paper will survey recent research
              that examines that capacity and its evolutionary origins in the
              light of a definition of music that embraces music's
              multifariousness. It will be suggested that music, like speech,
              is a product of both our biologies and our social interactions;
              that music is a necessary and integral dimension of human
              development; and that music may have played a central role in the
              evolution of the modern human mind.",
  journal  = "Annals of the New York Academy of Sciences",
  volume   =  930,
  pages    = "28--42",
  month    =  jun,
  year     =  2001,
  language = "en",
  issn     = "0077-8923",
  pmid     = "11458835",
  doi      = "10.1111/j.1749-6632.2001.tb05723.x"
}

@ARTICLE{Bregman1978-ej,
  title    = "Auditory streaming and the building of timbre",
  author   = "Bregman, A S and Pinker, S",
  journal  = "Canadian Journal of Psychology/Revue canadienne de psychologie",
  volume   =  32,
  number   =  1,
  pages    = "20--31",
  year     =  1978,
  language = "en"
}

@ARTICLE{Cross1995-ar,
  title    = "Review of `The analysis and cognition of melodic complexity: The
              implication-realization model'",
  author   = "Cross, I",
  journal  = "Narmour",
  volume   =  12,
  number   =  4,
  pages    = "486--509",
  year     =  1995,
  language = "en"
}

@ARTICLE{Krumhansl2000-nj,
  title     = "Cross-cultural music cognition: cognitive methodology applied to
               North Sami yoiks",
  author    = "Krumhansl, C L and Toivanen, P and Eerola, T and Toiviainen, P
               and J{\"a}rvinen, T and Louhivuori, J",
  abstract  = "This article is a study of melodic expectancy in North Sami
               yoiks, a style of music quite distinct from Western tonal music.
               Three different approaches were taken. The first approach was a
               statistical style analysis of tones in a representative corpus
               of 18 yoiks. The analysis determined the relative frequencies of
               tone onsets and two- and three-tone transitions. It also
               identified style characteristics, such as pentatonic
               orientation, the presence of two reference pitches, the
               frequency of large consonant intervals, and a relatively large
               set of possible melodic continuations. The second approach was a
               behavioral experiment in which listeners made judgments about
               melodic continuations. Three groups of listeners participated.
               One group was from the Sami culture, the second group consisted
               of Finnish music students who had learned some yoiks, and the
               third group consisted of Western musicians unfamiliar with
               yoiks. Expertise was associated with stronger veridical
               expectations (for the correct next tone) than schematic
               expectations (based on general style characteristics).
               Familiarity with the particular yoiks was found to compensate
               for lack of experience with the musical culture. The third
               approach simulated melodic expectancy with neural network models
               of the self-organizing map (SOM) type (Kohonen, T. (1997).
               Self-organizing maps (2nd ed.). Berlin: Springer). One model was
               trained on the excerpts of yoiks used in the behavioral
               experiment including the correct continuation tone, while
               another was trained with a set of Finnish folk songs and
               Lutheran hymns. The convergence of the three approaches showed
               that both listeners and the SOM model are influenced by the
               statistical distributions of tones and tone sequences. The
               listeners and SOM models also provided evidence supporting a
               core set of psychological principles underlying melody formation
               whose relative weights appear to differ across musical styles.",
  journal   = "Cognition",
  publisher = "Elsevier BV",
  volume    =  76,
  number    =  1,
  pages     = "13--58",
  month     =  jul,
  year      =  2000,
  language  = "en",
  issn      = "0010-0277, 1873-7838",
  pmid      = "10822042",
  doi       = "10.1016/s0010-0277(00)00068-8"
}

@ARTICLE{McDermott2010-ad,
  title    = "Individual differences reveal the basis of consonance",
  author   = "McDermott, Josh H and Lehr, Andriana J and Oxenham, Andrew J",
  abstract = "Some combinations of musical notes are consonant (pleasant),
              whereas others are dissonant (unpleasant), a distinction central
              to music. Explanations of consonance in terms of acoustics,
              auditory neuroscience, and enculturation have been debated for
              centuries. We utilized individual differences to distinguish the
              candidate theories. We measured preferences for musical chords as
              well as nonmusical sounds that isolated particular acoustic
              factors--specifically, the beating and the harmonic relationships
              between frequency components, two factors that have long been
              thought to potentially underlie consonance. Listeners preferred
              stimuli without beats and with harmonic spectra, but across more
              than 250 subjects, only the preference for harmonic spectra was
              consistently correlated with preferences for consonant over
              dissonant chords. Harmonicity preferences were also correlated
              with the number of years subjects had spent playing a musical
              instrument, suggesting that exposure to music amplifies
              preferences for harmonic frequencies because of their musical
              importance. Harmonic spectra are prominent features of natural
              sounds, and our results indicate that they also underlie the
              perception of consonance.",
  journal  = "Current biology",
  volume   =  20,
  number   =  11,
  pages    = "1035--1041",
  month    =  jun,
  year     =  2010,
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "20493704",
  doi      = "10.1016/j.cub.2010.04.019",
  pmc      = "PMC2885564"
}

@BOOK{Lerdahl1983-rv,
  title     = "A generative theory of tonal music",
  author    = "Lerdahl, F and Jackendoff, R",
  publisher = "MIT Press",
  year      =  1983,
  address   = "Cambridge, MA",
  language  = "en"
}

@INPROCEEDINGS{McAuley1994-mf,
  title     = "Finding metrical structure in time",
  booktitle = "Proceedings of the 1993 Connectionist Models Summer School",
  author    = "McAuley, J D",
  editor    = "Mozer, M C and Touretzky, D S and Smolensky, P",
  pages     = "219--227",
  year      =  1994,
  language  = "en"
}

@BOOK{Sachs1962-lw,
  title     = "The Wellsprings of Music",
  author    = "Sachs, C",
  publisher = "Martinus Nijhoff",
  year      =  1962,
  language  = "de"
}

@BOOK{Chomsky1957-om,
  title     = "Syntactic structures",
  author    = "Chomsky, N",
  publisher = "Mouton Publishers",
  year      =  1957,
  language  = "en"
}

@ARTICLE{Desain2003-tc,
  title     = "The formation of rhythmic categories and metric priming",
  author    = "Desain, Peter and Honing, Henkjan",
  abstract  = "Two experiments on categorical rhythm perception are reported,
               the object of which was to investigate how listeners perceive
               discrete rhythmic categories while listening to rhythms
               performed on a continuous time scale. This is studied by
               considering the space of all temporal patterns (all possible
               rhythms made up of three intervals) and how they, in perception,
               are partitioned into categories, ie where the boundaries of
               these categories are located. This process of categorisation is
               formalised as the mapping from the continuous space of a series
               of time intervals to a discrete, symbolic domain of
               integer-ratio sequences. The methodological framework uses
               concepts from mathematics and psychology (eg convexity and
               entropy) that allow precise characterisations of the empirical
               results. In the first experiment, twenty-nine participants
               performed an identification task with 66 rhythmic stimuli (a
               systematic sampling of the performance space). The results show
               that listeners do not just perceive the time intervals between
               onsets of sounds as placed in a homogeneous continuum. Instead,
               they can reliably identify rhythmic categories, as a chronotopic
               time clumping map reveals. In a second experiment, the effect of
               metric priming was studied by presenting the same stimuli but
               preceded with a duple or triple metre subdivision. It is shown
               that presenting patterns in the context of a metre has a large
               effect on rhythmic categorisation: the presence of a specific
               musical metre primes the perception of specific rhythmic
               patterns.",
  journal   = "Perception",
  publisher = "SAGE Publications",
  volume    =  32,
  number    =  3,
  pages     = "341--365",
  year      =  2003,
  language  = "en",
  issn      = "0301-0066, 1468-4233",
  pmid      = "12729384",
  doi       = "10.1068/p3370"
}

@ARTICLE{Eerola2009-ug,
  title    = "Expectancy in Sami Yoiks revisited: The role of data-driven and
              schema-driven knowledge in the formation of melodic expectations",
  author   = "Eerola, T and Louhivuori, J and Lebaka, E",
  journal  = "Musicae scientiae: the journal of the European Society for the
              Cognitive Sciences of Music",
  volume   =  13,
  number   =  2,
  pages    = "231--272",
  year     =  2009,
  language = "en",
  issn     = "1029-8649"
}

@INCOLLECTION{Ekman1999-xr,
  title     = "Basic emotions",
  booktitle = "The Handbook of Cognition and Emotion",
  author    = "Ekman, P",
  editor    = "Dalgleish, T and Power, T",
  publisher = "John Wiley \& Sons, Ltd",
  pages     = "45--60",
  year      =  1999,
  language  = "en"
}

@ARTICLE{Hannon2005-li,
  title    = "Tuning in to musical rhythms: infants learn more readily than
              adults",
  author   = "Hannon, Erin E and Trehub, Sandra E",
  abstract = "Domain-general tuning processes may guide the acquisition of
              perceptual knowledge in infancy. Here, we demonstrate that
              12-month-old infants show an adult-like, culture-specific pattern
              of responding to musical rhythms, in contrast to the
              culture-general responding that is evident at 6 months of age.
              Nevertheless, brief exposure to foreign music enables
              12-month-olds, but not adults, to perceive rhythmic distinctions
              in foreign musical contexts. These findings may indicate a
              sensitive period early in life for acquiring rhythm in particular
              or socially and biologically important structures more generally.",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  102,
  number   =  35,
  pages    = "12639--12643",
  month    =  aug,
  year     =  2005,
  language = "en",
  issn     = "0027-8424",
  pmid     = "16105946",
  doi      = "10.1073/pnas.0504254102",
  pmc      = "PMC1194930"
}

@INCOLLECTION{Fastl2007-dc,
  title     = "Just-noticeable sound changes",
  booktitle = "Psychoacoustics",
  author    = "Fastl, H and Zwicker, E",
  publisher = "Springer",
  pages     = "175--202",
  year      =  2007,
  address   = "Berlin, Germany",
  language  = "en"
}

@PHDTHESIS{Harrison2020-si,
  title    = "Modelling the perception and composition of Western musical
              harmony",
  author   = "Harrison, P M C",
  year     =  2020,
  school   = "Queen Mary University of London",
  language = "en"
}

@ARTICLE{Hakizimana2021-wt,
  title    = "Inner hair cell stereocilia are embedded in the tectorial
              membrane",
  author   = "Hakizimana, Pierre and Fridberger, Anders",
  abstract = "Mammalian hearing depends on sound-evoked displacements of the
              stereocilia of inner hair cells (IHCs), which cause the
              endogenous mechanoelectrical transducer channels to conduct
              inward currents of cations including Ca2+. Due to their presumed
              lack of contacts with the overlaying tectorial membrane (TM), the
              putative stimulation mechanism for these stereocilia is by means
              of the viscous drag of the surrounding endolymph. However,
              despite numerous efforts to characterize the TM by electron
              microscopy and other techniques, the exact IHC stereocilia-TM
              relationship remains elusive. Here we show that Ca2+-rich
              filamentous structures, that we call Ca2+ ducts, connect the TM
              to the IHC stereocilia to enable mechanical stimulation by the TM
              while also ensuring the stereocilia access to TM Ca2+. Our
              results call for a reassessment of the stimulation mechanism for
              the IHC stereocilia and the TM role in hearing.",
  journal  = "Nature communications",
  volume   =  12,
  number   =  1,
  pages    = "2604",
  month    =  may,
  year     =  2021,
  language = "en",
  issn     = "2041-1723",
  pmid     = "33972539",
  doi      = "10.1038/s41467-021-22870-1",
  pmc      = "PMC8110531"
}

@ARTICLE{Thurlow2022-ao,
  title     = "Mechanisms of absolute pitch: {II}. Pitch shift and perfect
               touch",
  author    = "Thurlow, Alan and Baggaley, Jon",
  abstract  = "The previous article in this series reviewed the historical and
               modern academic literature concerning the distinctive
               characteristics of individual musical notes and keys. It
               stressed Bachem?s definition of tone chroma (TC) as the quality
               that allows notes/keys to be identified instantly and accurately
               by musicians possessing the type of absolute pitch (AP) that
               Bachem described as genuine. TC qualities were shown to vary in
               the same systematic manner as the second-order acoustical beats
               predicted to accumulate during the tuning of instruments to
               equal temperament. This article offers further evidence for the
               connection between TC and acoustical sensitivity, as indicated
               by an examination of paracusis musicalis (PM), the shifting of
               the pitch sense with age to a level sharper or flatter than its
               original level. It is also noted that AP judgments have been
               shown to be based on kinaesthetic and tactile sensations, which
               perform the same cueing functions as auditory TC, and that types
               of AP judgment may, therefore, exist not typically identified as
               absolute: for example, an absolute or perfect touch capacity
               observed in keyboard players. Evidence of this capacity supports
               the theory of instrument-specific AP.",
  journal   = "Musicae scientiae: the journal of the European Society for the
               Cognitive Sciences of Music",
  publisher = "SAGE Publications Ltd",
  pages     = "10298649211072505",
  month     =  feb,
  year      =  2022,
  issn      = "1029-8649",
  doi       = "10.1177/10298649211072505"
}

@ARTICLE{Schellenberg1996-hz,
  title    = "Expectancy in melody: tests of the implication-realization model",
  author   = "Schellenberg, E G",
  abstract = "The implication-realization model's description of tone-to-tone
              expectancies for continuations of melodies was examined. The
              model's predictions for expectancies are described with a small
              number of principles specified precisely in terms of interval
              size and direction of pitch. These principles were quantified and
              used to predict the data from three experiments in which
              listeners were required to judge how well individual test tones
              continued melodic fragments. The model successfully predicted
              listeners' judgments across different musical styles (British and
              Chinese folk songs and Webern Lieder), regardless of the extent
              of listeners' musical training (Experiments 1 and 2) or whether
              they were born and raised in China or the U.S.A. (Experiment 3).
              For each experiment, however, the collinearity of the model's
              predictors indicated that a simplified version of the model might
              predict the data equally well. Indeed, a revised and simplified
              model did not result in a loss of predictive power for any of the
              three experiments. Convergent evidence was provided in a
              reanalysis of data reported by Carlsen (1981) and Unyk and
              Carlsen (1987), whose listeners were required to sing
              continuations to two-tone stimuli. Thus, these findings indicate
              that the implication-realization model is over-specified. The
              consistency that was found across experimental tasks, musical
              styles, and listeners raises the possibility, however, that the
              revised version of the model may withstand the original model's
              claims of universality.",
  journal  = "Cognition",
  volume   =  58,
  number   =  1,
  pages    = "75--125",
  month    =  jan,
  year     =  1996,
  language = "en",
  issn     = "0010-0277",
  pmid     = "8808327",
  doi      = "10.1016/0010-0277(95)00665-6"
}

@ARTICLE{Patel2014-fq,
  title    = "The evolutionary neuroscience of musical beat perception: the
              Action Simulation for Auditory Prediction ({ASAP}) hypothesis",
  author   = "Patel, A D and Iversen, J R",
  journal  = "Frontiers in systems neuroscience",
  volume   =  8,
  year     =  2014,
  language = "en",
  doi      = "10.3389/fnsys.2014.00057"
}

@ARTICLE{Terhardt1982-fx,
  title    = "Pitch of complex signals according to virtual-pitch theory:
              Tests, examples, and predictions",
  author   = "Terhardt, E and Stoll, G and Seewann, M",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  71,
  number   =  3,
  pages    = "671--678",
  year     =  1982,
  language = "en",
  issn     = "0001-4966"
}

@ARTICLE{Terhardt1982-mk,
  title    = "Algorithm for extraction of pitch and pitch salience from complex
              tonal signals",
  author   = "Terhardt, E and Stoll, G and Seewann, M",
  journal  = "The Journal of the Acoustical Society of America",
  volume   =  71,
  number   =  3,
  pages    = "679--688",
  year     =  1982,
  language = "en",
  issn     = "0001-4966"
}

@ARTICLE{Hart1973-mz,
  title    = "Intonation by rule: a perceptual quest",
  author   = "Hart, J and Cohen, A",
  journal  = "Journal of phonetics",
  volume   =  1,
  number   =  4,
  pages    = "309--327",
  year     =  1973,
  language = "fr",
  issn     = "0095-4470"
}

@ARTICLE{Skov2020-rm,
  title    = "There are no aesthetic emotions: Comment on Menninghaus et al",
  author   = "Skov, M and Nadal, M",
  journal  = "Psychological review",
  volume   =  127,
  number   =  4,
  pages    = "640--649",
  year     =  2020,
  language = "en",
  issn     = "0033-295X"
}

@BOOK{Sethares2005-lo,
  title     = "Tuning, timbre, spectrum, scale",
  author    = "Sethares, W A",
  publisher = "Springer",
  year      =  2005,
  language  = "da"
}

@ARTICLE{Shanahan2011-km,
  title    = "Interval size and phrase position: a comparison between German
              and Chinese folksongs",
  author   = "Shanahan, D and Huron, D",
  journal  = "Empirical musicology review: EMR",
  volume   =  6,
  number   =  4,
  pages    = "187--197",
  year     =  2011,
  language = "en"
}

@INCOLLECTION{Vaissiere1983-lo,
  title     = "{Language-Independent} Prosodic Features",
  booktitle = "Springer Series in Language and Communication",
  author    = "Vaissi{\`e}re, Jacqueline",
  publisher = "Springer Berlin Heidelberg",
  pages     = "53--66",
  year      =  1983,
  address   = "Berlin, Heidelberg",
  issn      = "0172-620X",
  isbn      = "9783642691058, 9783642691034",
  doi       = "10.1007/978-3-642-69103-4\_5"
}

@ARTICLE{Thompson1996-pk,
  title    = "Eugene Narmour: The analysis and cognition of basic musical
              structures (1990) and The analysis and cognition of melodic
              complexity (1992): A review and empirical assessment",
  author   = "Thompson, W F",
  journal  = "Journal of the American Musicological Society",
  volume   =  49,
  number   =  1,
  pages    = "127--145",
  year     =  1996,
  language = "en"
}

@ARTICLE{Tierney2013-or,
  title    = "Speech versus song: multiple pitch-sensitive areas revealed by a
              naturally occurring musical illusion",
  author   = "Tierney, A and Dick, F and Deutsch, D and Sereno, M",
  journal  = "Cerebral cortex",
  volume   =  23,
  number   =  2,
  pages    = "249--254",
  year     =  2013,
  language = "en",
  issn     = "1047-3211"
}

@PHDTHESIS{Weij2020-tr,
  title    = "Experienced listeners: Modeling the influence of long-term
              musical exposure on rhythm perception",
  author   = "Weij, B",
  year     =  2020,
  school   = "University of Amsterdam",
  language = "en"
}

@INPROCEEDINGS{Velasco2011-zw,
  title     = "Pulse detection in syncopated rhythms using neural oscillators",
  booktitle = "Proceedings of the 12th International Society for Music
               Information Retrieval",
  author    = "Velasco, M J and Large, E W",
  pages     = "185--190",
  year      =  2011,
  language  = "en"
}

@ARTICLE{Watt1924-xc,
  title    = "Functions of the size of interval in the songs of Schubert and of
              the Chippewa and Teton Sioux Indians",
  author   = "Watt, H J",
  journal  = "British journal of psychology",
  volume   =  14,
  number   =  4,
  pages    = "370--421",
  year     =  1924,
  language = "en",
  issn     = "0007-1269"
}

@ARTICLE{Temperley1999-af,
  title     = "Modeling meter and Harmony: A preference-rule approach",
  author    = "Temperley, David and Sleator, Daniel",
  journal   = "Computer music journal",
  publisher = "MIT Press - Journals",
  volume    =  23,
  number    =  1,
  pages     = "10--27",
  month     =  mar,
  year      =  1999,
  language  = "en",
  issn      = "0148-9267, 1531-5169",
  doi       = "10.1162/014892699559616"
}

@ARTICLE{Shanahan2019-ia,
  title     = "Examining the effect of oral transmission on folksongs",
  author    = "Shanahan, Daniel and Albrecht, Joshua",
  abstract  = "Sociolinguists frequently examine the nature of gradual,
               internal shifts in languages and dialects over time, arguing for
               both cognitive and cultural factors, as well as those that might
               be somehow internal to the language itself. Similarly,
               musicologists have often argued that musical genres and even
               specific songs can be examined through gradual diachronic
               shifts, which seem to be especially accelerated in traditions
               that rely on oral transmission. For example, Spitzer (1994)
               examined the stemma of ``Oh! Susanna'' and noticed that it
               tended to become more pentatonicized at cadence points by
               dropping scale degree seven, and suggested that this might be
               true with folk songs in general. To test this, we employed both
               experimental and corpus-based paradigms. The experimental
               approach attempted to simulate oral transmission in a compressed
               timeframe by involving singers who heard and replicated short
               musical excerpts, and then would teach a colleague, who in turn
               passed it on to another participant. Similarly, we conducted a
               corpus analysis that examined the prevalence of descending
               stepwise endings in styles of music primarily transmitted orally
               compared with those transmitted primarily through notation. The
               experimental results suggest that cadence points in Western folk
               music are more likely to lose scale degree seven through the act
               of oral transmission, and the corpus study suggests that,
               although stylistic constraints play a large role in folk music,
               there might also be a relationship between transmission and
               physical affordances.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  36,
  number    =  3,
  pages     = "273--288",
  month     =  feb,
  year      =  2019,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2019.36.3.273"
}

@ARTICLE{Tichko2019-qd,
  title    = "Modeling infants' perceptual narrowing to musical rhythms: neural
              oscillation and Hebbian plasticity",
  author   = "Tichko, P and Large, E W",
  journal  = "Annals of the New York Academy of Sciences",
  volume   =  1453,
  number   =  1,
  pages    = "125--139",
  year     =  2019,
  language = "en",
  issn     = "0077-8923"
}

@INPROCEEDINGS{Hippel2002-nx,
  title     = "Melodic-expectation rules as learned heuristics",
  booktitle = "Proceedings of the 7th International Conference on Music
               Perception and Cognition",
  author    = "Hippel, P",
  year      =  2002,
  language  = "en"
}

@ARTICLE{Hippel2000-el,
  title    = "Why do skips precede reversals? The effect of tessitura on
              melodic structure",
  author   = "Hippel, P and Huron, D",
  journal  = "Music perception",
  volume   =  18,
  number   =  1,
  pages    = "59--85",
  year     =  2000,
  language = "en",
  issn     = "0730-7829"
}

@ARTICLE{Zentner2008-bj,
  title    = "Emotions evoked by the sound of music: characterization,
              classification, and measurement",
  author   = "Zentner, Marcel and Grandjean, Didier and Scherer, Klaus R",
  abstract = "One reason for the universal appeal of music lies in the
              emotional rewards that music offers to its listeners. But what
              makes these rewards so special? The authors addressed this
              question by progressively characterizing music-induced emotions
              in 4 interrelated studies. Studies 1 and 2 (n=354) were conducted
              to compile a list of music-relevant emotion terms and to study
              the frequency of both felt and perceived emotions across 5 groups
              of listeners with distinct music preferences. Emotional responses
              varied greatly according to musical genre and type of response
              (felt vs. perceived). Study 3 (n=801)--a field study carried out
              during a music festival--examined the structure of music-induced
              emotions via confirmatory factor analysis of emotion ratings,
              resulting in a 9-factorial model of music-induced emotions. Study
              4 (n=238) replicated this model and found that it accounted for
              music-elicited emotions better than the basic emotion and
              dimensional emotion models. A domain-specific device to measure
              musically induced emotions is introduced--the Geneva Emotional
              Music Scale.",
  journal  = "Emotion",
  volume   =  8,
  number   =  4,
  pages    = "494--521",
  month    =  aug,
  year     =  2008,
  language = "en",
  issn     = "1528-3542",
  pmid     = "18729581",
  doi      = "10.1037/1528-3542.8.4.494"
}

@BOOK{Darwin1871-rg,
  title     = "The descent of man and selection in relation to sex",
  author    = "Darwin, Charles",
  publisher = "John Murray",
  year      =  1871,
  address   = "England"
}

@BOOK{Ladd2008-gu,
  title     = "Intonational Phonology",
  author    = "Ladd, D R",
  publisher = "Cambridge University Press",
  edition   = "2nd",
  year      =  2008,
  language  = "en"
}

@BOOK{Pinker1997-gh,
  title     = "How the mind works",
  author    = "Pinker, S",
  publisher = "W. W. Norton",
  year      =  1997,
  address   = "New York, NY",
  language  = "en"
}

@ARTICLE{Ammirante2015-mn,
  title     = "Low-skip bias: The distribution of skips across the pitch ranges
               of vocal and instrumental melodies is vocally constrained",
  author    = "Ammirante, Paolo and Russo, Frank A",
  journal   = "Music Perception: An Interdisciplinary Journal",
  publisher = "University of California Press",
  volume    =  32,
  number    =  4,
  pages     = "355--363",
  year      =  2015
}

@ARTICLE{Mehr2019-xu,
  title    = "Universality and diversity in human song",
  author   = "Mehr, Samuel A and Singh, Manvir and Knox, Dean and Ketter,
              Daniel M and Pickens-Jones, Daniel and Atwood, S and Lucas,
              Christopher and Jacoby, Nori and Egner, Alena A and Hopkins, Erin
              J and Howard, Rhea M and Hartshorne, Joshua K and Jennings,
              Mariela V and Simson, Jan and Bainbridge, Constance M and Pinker,
              Steven and O'Donnell, Timothy J and Krasnow, Max M and Glowacki,
              Luke",
  abstract = "What is universal about music, and what varies? We built a corpus
              of ethnographic text on musical behavior from a representative
              sample of the world's societies, as well as a discography of
              audio recordings. The ethnographic corpus reveals that music
              (including songs with words) appears in every society observed;
              that music varies along three dimensions (formality, arousal,
              religiosity), more within societies than across them; and that
              music is associated with certain behavioral contexts such as
              infant care, healing, dance, and love. The discography-analyzed
              through machine summaries, amateur and expert listener ratings,
              and manual transcriptions-reveals that acoustic features of songs
              predict their primary behavioral context; that tonality is
              widespread, perhaps universal; that music varies in rhythmic and
              melodic complexity; and that elements of melodies and rhythms
              found worldwide follow power laws.",
  journal  = "Science",
  volume   =  366,
  number   =  6468,
  month    =  nov,
  year     =  2019,
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "31753969",
  doi      = "10.1126/science.aax0868",
  pmc      = "PMC7001657"
}

@BOOK{Mehrabian1974-rb,
  title     = "An approach to environmental psychology",
  author    = "Mehrabian, A and Russell, J A",
  publisher = "MIT Press",
  year      =  1974,
  language  = "pt"
}

@ARTICLE{Menninghaus2019-lz,
  title    = "What are aesthetic emotions?",
  author   = "Menninghaus, W and Wagner, V and Wassiliwizky, E and Schindler, I
              and Hanich, J and Jacobsen, T and Koelsch, S",
  journal  = "Psychological review",
  volume   =  126,
  number   =  2,
  pages    = "171--195",
  year     =  2019,
  language = "en",
  issn     = "0033-295X"
}

@BOOK{Meyer1956-em,
  title     = "Emotion and meaning in music",
  author    = "Meyer, L",
  publisher = "University of Chicago Press",
  year      =  1956,
  language  = "en"
}

@ARTICLE{Milne2011-rm,
  title    = "Modelling the similarity of pitch collections with expectation
              tensors",
  author   = "Milne, A J and Sethares, W A and Laney, R and Sharp, D B",
  journal  = "Journal of Mathematics \& Music. Mathematical and Computational
              Approaches to Music Theory, Analysis, Composition and Performance",
  volume   =  5,
  number   =  1,
  pages    = "1--20",
  year     =  2011,
  language = "en",
  issn     = "1745-9737"
}

@BOOK{Narmour1992-ka,
  title     = "The analysis and cognition of melodic complexity: The
               implication-realization model",
  author    = "Narmour, E",
  publisher = "University of Chicago Press",
  year      =  1992,
  language  = "en"
}

@ARTICLE{Palmer1990-ak,
  title    = "Mental representations for musical meter",
  author   = "Palmer, C and Krumhansl, C L",
  journal  = "Journal of experimental psychology. Human perception and
              performance",
  volume   =  16,
  number   =  4,
  pages    = "728--741",
  year     =  1990,
  language = "en",
  issn     = "0096-1523"
}

@ARTICLE{Palmer1986-gm,
  title    = "Phase-locking in the cochlear nerve of the guinea-pig and its
              relation to the receptor potential of inner hair-cells",
  author   = "Palmer, A R and Russell, I J",
  journal  = "Hearing research",
  volume   =  24,
  number   =  1,
  pages    = "1--15",
  year     =  1986,
  language = "en",
  issn     = "0378-5955"
}

@BOOK{Parncutt1989-ut,
  title     = "Harmony: A psychoacoustical approach",
  author    = "Parncutt, R",
  publisher = "Springer-Verlag",
  year      =  1989,
  language  = "nl"
}

@ARTICLE{Patel2003-em,
  title    = "An empirical comparison of rhythm in language and music",
  author   = "Patel, A D and Daniele, J R",
  journal  = "Cognition",
  volume   =  87,
  number   =  1,
  pages    = "35-- 45",
  year     =  2003,
  language = "en",
  issn     = "0010-0277"
}

@ARTICLE{Patel2009-jz,
  title    = "Experimental evidence for synchronization to a musical beat in a
              nonhuman animal",
  author   = "Patel, A D and Iversen, J R and Bregman, M R and Schulz, I",
  journal  = "Current biology: CB",
  volume   =  19,
  number   =  10,
  pages    = "827--830",
  year     =  2009,
  language = "it",
  issn     = "0960-9822"
}

@PHDTHESIS{Pearce2005-ug,
  title    = "The construction and evaluation of statistical models of melodic
              structure in music perception and composition",
  author   = "Pearce, M T",
  year     =  2005,
  school   = "City University London",
  language = "en"
}

@ARTICLE{Pearce2018-pw,
  title    = "Statistical learning and probabilistic prediction in music
              cognition: mechanisms of stylistic enculturation",
  author   = "Pearce, M T",
  journal  = "Annals of the New York Academy of Sciences",
  volume   =  1423,
  number   =  1,
  pages    = "378--395",
  year     =  2018,
  language = "en",
  issn     = "0077-8923"
}

@ARTICLE{Pearce2006-hk,
  title     = "Expectation in melody: The influence of context and learning",
  author    = "Pearce, Marcus T and Wiggins, Geraint A",
  abstract  = "The Implication-Realization (IR) theory (Narmour, 1990) posits
               two cognitive systems involved in the generation of melodic
               expectations: The first consists of a limited number of symbolic
               rules that are held to be innate and universal; the second
               reflects the top-down influences of acquired stylistic
               knowledge. Aspects of both systems have been implemented as
               quantitative models in research which has yielded empirical
               support for both components of the theory (Cuddy \& Lunny, 1995;
               Krumhansl, 1995a, 1995b; Schellenberg, 1996, 1997). However,
               there is also evidence that the implemented bottom-up rules
               constitute too inflexible a model to account for the influence
               of the musical experience of the listener and the melodic
               context in which expectations are elicited. A theory is
               presented, according to which both bottom-up and top-down
               descriptions of observed patterns of melodic expectation may be
               accounted for in terms of the induction of statistical
               regularities in existing musical repertoires. A computational
               model that embodies this theory is developed and used to
               reanalyze existing experimental data on melodic expectancy. The
               results of three experiments with increasingly complex melodic
               stimuli demonstrate that this model is capable of accounting for
               listeners' expectations as well as or better than the two-factor
               model of Schellenberg (1997).",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  23,
  number    =  5,
  pages     = "377--405",
  month     =  jul,
  year      =  2006,
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2006.23.5.377"
}

@ARTICLE{Polak2018-io,
  title    = "Rhythmic prototypes across cultures: A comparative study of
              tapping synchronization",
  author   = "Polak, R and Jacoby, N and Fischinger, T and Goldberg, D and
              Holzapfel, A and London, J",
  journal  = "Music perception",
  volume   =  36,
  number   =  1,
  pages    = "1--23",
  year     =  2018,
  language = "en",
  issn     = "0730-7829"
}

@ARTICLE{Ravignani2016-yc,
  title    = "Musical evolution in the lab exhibits rhythmic universals",
  author   = "Ravignani, A and Delgado, T and Kirby, S",
  journal  = "Nature Human Behaviour",
  volume   =  1,
  number   =  1,
  year     =  2016,
  language = "fr"
}

@ARTICLE{Rohrmeier2011-ds,
  title    = "Towards a generative syntax of tonal harmony",
  author   = "Rohrmeier, M",
  journal  = "Journal of Mathematics \& Music. Mathematical and Computational
              Approaches to Music Theory, Analysis, Composition and Performance",
  volume   =  5,
  number   =  1,
  pages    = "35--53",
  year     =  2011,
  language = "en",
  issn     = "1745-9737"
}

@ARTICLE{Russell1980-cg,
  title    = "A circumplex model of affect",
  author   = "Russell, J A",
  journal  = "Journal of personality and social psychology",
  volume   =  39,
  number   =  6,
  pages    = "1161--1178",
  year     =  1980,
  language = "en",
  issn     = "0022-3514"
}

@INPROCEEDINGS{Von_Hippel2002-wa,
  title     = "{Melodic-Expectation} Rules as Learned Heuristics",
  booktitle = "Proceedings of the 7th International Conference on Music
               Perception and Cognition",
  author    = "von Hippel, Paul",
  abstract  = "Evidence is presented that certain rules of melodic expectation
               are learned rather than innate. In an experiment, 28 trained
               musicians and 12 non-musicians were asked to predict the
               direction of controlled experimental melodies. Whereas the
               musicians' expectations fit two well-known rules, the rules were
               not evident in the expectancies of non-musicians. Moreover, the
               rules corresponded only approximately to melodic structure, not
               unlike the heuristics that people use to make predictions in
               other cognitive domains. In sum, the results suggest that
               musicians have learned imperfect but serviceable heuristics for
               making predictions in their area of expertise.",
  month     =  may,
  year      =  2002,
  keywords  = "music, expectation, cognition, learning"
}

@ARTICLE{Serra-Peralta2022-cm,
  title    = "Lognormals, power laws and double power laws in the distribution
              of frequencies of harmonic codewords from classical music",
  author   = "Serra-Peralta, Marc and Serr{\`a}, Joan and Corral, {\'A}lvaro",
  abstract = "Zipf's law is a paradigm describing the importance of different
              elements in communication systems, especially in linguistics.
              Despite the complexity of the hierarchical structure of language,
              music has in some sense an even more complex structure, due to
              its multidimensional character (melody, harmony, rhythm, timbre,
              etc.). Thus, the relevance of Zipf's law in music is still an
              open question. Using discrete codewords representing harmonic
              content obtained from a large-scale analysis of classical
              composers, we show that a nearly universal Zipf-like law holds at
              a qualitative level. However, in an in-depth quantitative
              analysis, where we introduce the double power-law distribution as
              a new player in the classical debate between the superiority of
              Zipf's (power) law and that of the lognormal distribution, we
              conclude not only that universality does not hold, but also that
              there is not a unique probability distribution that best
              describes the usage of the different codewords by each composer.",
  journal  = "Scientific reports",
  volume   =  12,
  number   =  1,
  pages    = "2615",
  month    =  feb,
  year     =  2022,
  keywords = "To read",
  language = "en",
  issn     = "2045-2322",
  pmid     = "35173194",
  doi      = "10.1038/s41598-022-06137-3",
  pmc      = "PMC8850585"
}

@ARTICLE{Box-Steffensmeier2022-em,
  title    = "The future of human behaviour research",
  author   = "Box-Steffensmeier, Janet M and Burgess, Jean and Corbetta,
              Maurizio and Crawford, Kate and Duflo, Esther and Fogarty, Laurel
              and Gopnik, Alison and Hanafi, Sari and Herrero, Mario and Hong,
              Ying-Yi and Kameyama, Yasuko and Lee, Tatia M C and Leung,
              Gabriel M and Nagin, Daniel S and Nobre, Anna C and Nordentoft,
              Merete and Okbay, Aysu and Perfors, Andrew and Rival, Laura M and
              Sugimoto, Cassidy R and Tungodden, Bertil and Wagner, Claudia",
  journal  = "Nature human behaviour",
  volume   =  6,
  number   =  1,
  pages    = "15--24",
  month    =  jan,
  year     =  2022,
  language = "en",
  issn     = "2397-3374",
  pmid     = "35087189",
  doi      = "10.1038/s41562-021-01275-6"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gabriel1978-ve,
  title     = "An Experimental Study of Deryck Cooke's Theory of Music and
               Meaning",
  author    = "Gabriel, Clive",
  abstract  = "… Discussion The results of the first section of this paper are
               clear cut: Cooke's hypothesis is not supported by the empirical
               test to which it was subjected. It remains a possibility that …",
  journal   = "Psychology of Music",
  publisher = "SAGE Publications Ltd",
  volume    =  6,
  number    =  1,
  pages     = "13--20",
  month     =  apr,
  year      =  1978,
  keywords  = "To read",
  issn      = "0305-7356",
  doi       = "10.1177/030573567861002"
}

@ARTICLE{Rohrmeier2022-to,
  title     = "On creativity, music's {AI} completeness, and four challenges
               for artificial musical creativity",
  author    = "Rohrmeier, Martin",
  journal   = "Transactions of the International Society for Music Information
               Retrieval",
  publisher = "Ubiquity Press, Ltd.",
  volume    =  5,
  number    =  1,
  pages     = "50--66",
  month     =  mar,
  year      =  2022,
  keywords  = "To read",
  language  = "en",
  issn      = "2514-3298",
  doi       = "10.5334/tismir.104"
}

@MISC{noauthor_undated-tk,
  title        = "[No title]",
  howpublished = "\url{https://www.researchgate.net/profile/Anna-Fiveash/publication/359468252_You_got_rhythm_or_more_The_multidimensionality_of_rhythmic_abilities/links/623de0ae7931cc7ccff681a0/You-got-rhythm-or-more-The-multidimensionality-of-rhythmic-abilities.pdf}",
  note         = "Accessed: 2022-4-7",
  keywords     = "To read"
}

@ARTICLE{Vuust2022-na,
  title     = "Music in the brain",
  author    = "Vuust, Peter and Heggli, Ole A and Friston, Karl J and
               Kringelbach, Morten L",
  abstract  = "Music is ubiquitous across human cultures - as a source of
               affective and pleasurable experience, moving us both physically
               and emotionally - and learning to play music shapes both brain
               structure and brain function. Music processing in the brain -
               namely, the perception of melody, harmony and rhythm - has
               traditionally been studied as an auditory phenomenon using
               passive listening paradigms. However, when listening to music,
               we actively generate predictions about what is likely to happen
               next. This enactive aspect has led to a more comprehensive
               understanding of music processing involving brain structures
               implicated in action, emotion and learning. Here we review the
               cognitive neuroscience literature of music perception. We show
               that music perception, action, emotion and learning all rest on
               the human brain's fundamental capacity for prediction - as
               formulated by the predictive coding of music model. This Review
               elucidates how this formulation of music perception and
               expertise in individuals can be extended to account for the
               dynamics and underlying brain mechanisms of collective music
               making. This in turn has important implications for human
               creativity as evinced by music improvisation. These recent
               advances shed new light on what makes music meaningful from a
               neuroscientific perspective.",
  journal   = "Nature reviews. Neuroscience",
  publisher = "nature.com",
  month     =  mar,
  year      =  2022,
  keywords  = "To read",
  language  = "en",
  issn      = "1471-003X, 1471-0048",
  pmid      = "35352057",
  doi       = "10.1038/s41583-022-00578-5"
}

@BOOK{Hastie2001-yr,
  title     = "The elements of statistical learning: Data mining, inference,
               and prediction",
  author    = "Hastie, Trevor and Friedman, Jerome and Tibshirani, Robert",
  publisher = "Springer",
  year      =  2001,
  address   = "New York, NY",
  isbn      = "9780387952840, 9780387216065",
  doi       = "10.1007/978-0-387-21606-5"
}

@INPROCEEDINGS{Kenny2009-sk,
  title       = "The factor structure of the revised Kenny music performance
                 anxiety inventory",
  booktitle   = "International Symposium on performance science",
  author      = "Kenny, Dianna T",
  pages       = "37--41",
  institution = "Association Europ{\'e}enne des Conservatoires Utrecht, The
                 Netherlands",
  year        =  2009
}

@ARTICLE{Caspi2018-ze,
  title    = "All for One and One for All: Mental Disorders in One Dimension",
  author   = "Caspi, Avshalom and Moffitt, Terrie E",
  abstract = "In both child and adult psychiatry, empirical evidence has now
              accrued to suggest that a single dimension is able to measure a
              person's liability to mental disorder, comorbidity among
              disorders, persistence of disorders over time, and severity of
              symptoms. This single dimension of general psychopathology has
              been termed ``p,'' because it conceptually parallels a dimension
              already familiar to behavioral scientists and clinicians: the
              ``g'' factor of general intelligence. As the g dimension reflects
              low to high mental ability, the p dimension represents low to
              high psychopathology severity, with thought disorder at the
              extreme. The dimension of p unites all disorders. It influences
              present/absent status on hundreds of psychiatric symptoms, which
              modern nosological systems typically aggregate into dozens of
              distinct diagnoses, which in turn aggregate into three
              overarching domains, namely, the externalizing, internalizing,
              and psychotic experience domains, which finally aggregate into
              one dimension of psychopathology from low to high: p. Studies
              show that the higher a person scores on p, the worse that person
              fares on measures of family history of psychiatric illness, brain
              function, childhood developmental history, and adult life
              impairment. A dimension of p may help account for ubiquitous
              nonspecificity in psychiatry: multiple disorders share the same
              risk factors and biomarkers and often respond to the same
              therapies. Here, the authors summarize the history of the
              unidimensional idea, review modern research into p, demystify
              statistical models, articulate some implications of p for
              prevention and clinical practice, and outline a transdiagnostic
              research agenda. [AJP AT 175: Remembering Our Past As We Envision
              Our Future October 1910: A Study of Association in Insanity Grace
              Helen Kent and A.J. Rosanoff: ``No sharp distinction can be drawn
              between mental health and mental disease; a large collection of
              material shows a gradual and not an abrupt transition from the
              normal state to pathological states.''(Am J Psychiatry 1910;
              67(2):317-390 )].",
  journal  = "The American journal of psychiatry",
  volume   =  175,
  number   =  9,
  pages    = "831--844",
  month    =  sep,
  year     =  2018,
  keywords = "Development; Diagnosis And Classification; Etiology;
              Transdiagnostic; p Factor",
  language = "en",
  issn     = "0002-953X, 1535-7228",
  pmid     = "29621902",
  doi      = "10.1176/appi.ajp.2018.17121383",
  pmc      = "PMC6120790"
}

@ARTICLE{Smit2019-wh,
  title    = "Perception of affect in unfamiliar musical chords",
  author   = "Smit, Eline Adrianne and Milne, Andrew J and Dean, Roger T and
              Weidemann, Gabrielle",
  abstract = "This study investigates the role of extrinsic and intrinsic
              predictors in the perception of affect in mostly unfamiliar
              musical chords from the Bohlen-Pierce microtonal tuning system.
              Extrinsic predictors are derived, in part, from long-term
              statistical regularities in music; for example, the prevalence of
              a chord in a corpus of music that is relevant to a participant.
              Conversely, intrinsic predictors make no use of long-term
              statistical regularities in music; for example, psychoacoustic
              features inherent in the music, such as roughness. Two types of
              affect were measured for each chord: pleasantness/unpleasantness
              and happiness/sadness. We modelled the data with a number of
              novel and well-established intrinsic predictors, namely
              roughness, harmonicity, spectral entropy and average pitch
              height; and a single extrinsic predictor, 12-TET Dissimilarity,
              which was estimated by the chord's smallest distance to any
              12-tone equally tempered chord. Musical sophistication was
              modelled as a potential moderator of the above predictors. Two
              experiments were conducted, each using slightly different tunings
              of the Bohlen-Pierce musical system: a just intonation version
              and an equal-tempered version. It was found that, across both
              tunings and across both affective responses, all the tested
              intrinsic features and 12-TET Dissimilarity have consistent
              influences in the expected direction. These results contrast with
              much current music perception research, which tends to assume the
              dominance of extrinsic over intrinsic predictors. This study
              highlights the importance of both intrinsic characteristics of
              the acoustic signal itself, as well as extrinsic factors, such as
              12-TET Dissimilarity, on perception of affect in music.",
  journal  = "PloS one",
  volume   =  14,
  number   =  6,
  pages    = "e0218570",
  month    =  jun,
  year     =  2019,
  language = "en",
  issn     = "1932-6203",
  pmid     = "31226170",
  doi      = "10.1371/journal.pone.0218570",
  pmc      = "PMC6588276"
}

@ARTICLE{Parncutt2021-wy,
  title     = "Octave-generalized analysis of chord progressions:
               Diatonic/fifth relations, missing fundamentals, completion tones",
  author    = "Parncutt, Richard and Reisinger, Daniel",
  abstract  = "In a representative historical database of musical scores, a
               sonority was defined at every onset in any voice. For eight
               trichords?major (047), minor (037), suspended (027), diminished
               (036), 015, 045, 025, 035?immediately preceding and following
               sonorities were analysed. Chroma prevalence profiles depended
               surprisingly little on century or temporal position?especially
               for major/minor trichords (cf. Krumhansl?s key profiles).
               Profiles for nine non-chord chromas per trichord were influenced
               more strongly by diatonic scales and 5th relationships than
               missing fundamentals (roots) or completion tones (tones that
               complete familiar tetrachords) according to predictions of
               simple models.",
  journal   = "Journal of New Music Research",
  publisher = "Routledge",
  volume    =  50,
  number    =  1,
  pages     = "52--73",
  month     =  jan,
  year      =  2021,
  issn      = "0929-8215",
  doi       = "10.1080/09298215.2020.1840596"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Li2006-vu,
  title     = "The effect of inharmonic and harmonic spectra in Javanese
               Gamelan tuning (1): A theory of the Sl{\'e}ndro",
  booktitle = "Proceedings of the 7th {WSEAS} International Conference on
               Acoustics \& Music: Theory \& Applications",
  author    = "Li, G",
  abstract  = "Sl{\'e}ndro is a distinctive Javanese pentatonic scalar system
               about which no established musical theory has thus far been able
               to offer a valid explanation regarding its acoustic foundation.
               Since the mid-1980s, scholars began to realize that the
               intervallic features of the sl{\'e}ndro can be developed as an
               effect of inharmonic spectra of the metal instruments that
               constitute the basis of the tradition (Li 1986, Sethares 1998,
               Schneider 2001). Furthering previous theories, it is concluded
               in this essay that the inharmonic spectrum of the bonang …",
  publisher = "Citeseer",
  pages     = "65--71",
  year      =  2006,
  address   = "Cavtat, Croatia"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Schneider2001-ux,
  title    = "Sound, pitch, and scale: From ``tone measurements'' to
              sonological analysis in ethnomusicology",
  author   = "Schneider, Albrecht",
  abstract = "Since the seminal studies of Ellis and Hipkins (Ellis 1884 and
              1885) and of Stumpf (1901), investigations of non-Western musical
              scales have frequently been carried out, and with a variety of
              goals. Whereas some scholars wanted to demonstrate the relativity
              of Western tone systems by point-ing to the variety of scales,
              others sought to prove culture contacts over vast distances by
              measuring and comparing tunings of panpipes and xylophones, and
              other instruments. Further, tonometrical research was undertaken
              either to confirm or to …",
  journal  = "Ethnomusicology",
  volume   =  45,
  number   =  3,
  pages    = "489--519",
  year     =  2001,
  doi      = "10.2307/852868"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Rahn1996-vi,
  title     = "Perceptual aspects of tuning in a Balinese gamelan angklung for
               North American students",
  author    = "Rahn, Jay",
  abstract  = "A detailed analysis of the spectra and frequencies of tones
               produced on metallophones in a Balinese orchestra clarifies a
               number of issues that arise in studying timbre and tuning. Among
               these are the relative importance of accuracy and completeness
               of measurements, the relevance of acoustical description to
               musical perception and style, the appropriateness of statistical
               generalizations and numerical formulations to musical practice
               and theory, and the possibility of bi-musical responses to
               divergent tuning systems. Byproducts of the …",
  journal   = "Canadian University Music Review/Revue de musique des
               universit{\'e}s canadiennes",
  publisher = "Canadian University Music Society/Soci{\'e}t{\'e} de musique des
               universit{\'e}s canadiennes",
  volume    =  16,
  number    =  2,
  pages     = "1--43",
  year      =  1996
}

@ARTICLE{Young1952-ku,
  title     = "Inharmonicity of plain wire piano strings",
  author    = "Young, Robert W",
  abstract  = "The inharmonicity of plain wire strings in situ has been
               measured in six pianos of various styles and makes. By
               inharmonicity is meant the departure in frequency from the
               harmonic modes of vibration expected of an ideal flexible
               string. It is shown from the theory of stiff strings that the
               basic inharmonicity cents (hundredths of a semitone) is given by
               3.4?1013n2d2/v02l4, where n is the mode number, d is the
               diameter of the wire in cm, l is the vibrating length in cm, and
               v0 is the fundamental frequency. A value of
               Q/??=?25.5???1010?(cm/sec)2 was assumed for the steel wire,
               where Q is Young's modulus and ? is the density. The
               observations are entirely compatible with the relationship
               given. In general terms the inharmonicity of the plain steel
               strings is about the same in all the pianos tested, being about
               1.2 cents for the second mode of vibration of the middle C
               string. Above this point every eight semitones it is doubled.
               Below middle C the inharmonicity is consistently less in large
               pianos than in small ones.",
  journal   = "The Journal of the Acoustical Society of America",
  publisher = "Acoustical Society of America",
  volume    =  24,
  number    =  3,
  pages     = "267--273",
  month     =  may,
  year      =  1952,
  issn      = "0001-4966",
  doi       = "10.1121/1.1906888"
}

@ARTICLE{Cazden1962-fd,
  title     = "Sensory theories of musical consonance",
  author    = "Cazden, Norman",
  journal   = "Journal of Aesthetics and Art Criticism",
  publisher = "Oxford University Press (OUP)",
  volume    =  20,
  number    =  3,
  pages     = "301--320",
  month     =  mar,
  year      =  1962,
  keywords  = "To read",
  copyright = "https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model",
  language  = "en",
  issn      = "0021-8529, 1540-6245",
  doi       = "10.1111/1540\_6245.jaac20.3.0301"
}

@UNPUBLISHED{Kern2022-hd,
  title    = "Cortical activity during naturalistic music listening reflects
              short-range predictions based on long-term experience",
  author   = "Kern, Pius and Heilbron, Micha and de Lange, Floris P and Spaak,
              Eelke",
  abstract = "Expectations shape our experience of music. However, the internal
              model upon which listeners form melodic expectations is still
              debated. Do expectations stem from Gestalt-like principles or
              statistical learning? If the latter, does long-term experience
              play an important role, or are short-term regularities
              sufficient? And finally, what length of context informs
              contextual expectations? To answer these questions, we presented
              human listeners with diverse naturalistic compositions from
              Western classical music, while recording neural activity using
              MEG. We quantified note-level melodic surprise and uncertainty
              using various computational models of music, including a
              state-of-the-art transformer neural network. A time-resolved
              regression analysis revealed that neural activity over
              fronto-temporal areas tracked melodic surprise particularly
              around 200 ms and 300--500 ms after note onset. This neural
              surprise response was dissociated from sensory-acoustic and
              adaptation effects. Neural surprise was best predicted by
              computational models that incorporated long-term statistical
              learning -- rather than by simple, Gestalt-like principles. Yet,
              intriguingly, the surprise reflected primarily short-range
              musical contexts of less than ten notes. We present a full
              replication of our novel MEG results in an openly available EEG
              dataset. Together, these results elucidate the internal model
              that shapes melodic predictions during naturalistic music
              listening. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.06.08.495241",
  month    =  jun,
  year     =  2022,
  keywords = "To read",
  language = "en",
  doi      = "10.1101/2022.06.08.495241"
}

@ARTICLE{Zhao2022-ic,
  title    = "Robust and Efficient Online Auditory Psychophysics",
  author   = "Zhao, Sijia and Brown, Christopher A and Holt, Lori L and Dick,
              Frederic",
  abstract = "Most human auditory psychophysics research has historically been
              conducted in carefully controlled environments with calibrated
              audio equipment, and over potentially hours of repetitive testing
              with expert listeners. Here, we operationally define such
              conditions as having high 'auditory hygiene'. From this
              perspective, conducting auditory psychophysical paradigms online
              presents a serious challenge, in that results may hinge on
              absolute sound presentation level, reliably estimated perceptual
              thresholds, low and controlled background noise levels, and
              sustained motivation and attention. We introduce a set of
              procedures that address these challenges and facilitate auditory
              hygiene for online auditory psychophysics. First, we establish a
              simple means of setting sound presentation levels. Across a set
              of four level-setting conditions conducted in person, we
              demonstrate the stability and robustness of this level setting
              procedure in open air and controlled settings. Second, we test
              participants' tone-in-noise thresholds using widely adopted
              online experiment platforms and demonstrate that reliable
              threshold estimates can be derived online in approximately one
              minute of testing. Third, using these level and threshold setting
              procedures to establish participant-specific stimulus conditions,
              we show that an online implementation of the classic probe-signal
              paradigm can be used to demonstrate frequency-selective attention
              on an individual-participant basis, using a third of the trials
              used in recent in-lab experiments. Finally, we show how threshold
              and attentional measures relate to well-validated assays of
              online participants' in-task motivation, fatigue, and confidence.
              This demonstrates the promise of online auditory psychophysics
              for addressing new auditory perception and neuroscience questions
              quickly, efficiently, and with more diverse samples. Code for the
              tests is publicly available through Pavlovia and Gorilla.",
  journal  = "Trends in hearing",
  volume   =  26,
  pages    = "23312165221118792",
  month    =  jan,
  year     =  2022,
  keywords = "auditory thresholds; motivation; online testing; probe-signal;
              psychophysics;To read",
  language = "en",
  issn     = "2331-2165",
  pmid     = "36131515",
  doi      = "10.1177/23312165221118792",
  pmc      = "PMC9500270"
}

@ARTICLE{Wysocki2022-lu,
  title     = "Statistical Control Requires Causal Justification",
  author    = "Wysocki, Anna C and Lawson, Katherine M and Rhemtulla, Mijke",
  abstract  = "It is common practice in correlational or quasiexperimental
               studies to use statistical control to remove confounding effects
               from a regression coefficient. Controlling for relevant
               confounders can debias the estimated causal effect of a
               predictor on an outcome; that is, it can bring the estimated
               regression coefficient closer to the value of the true causal
               effect. But statistical control works only under ideal
               circumstances. When the selected control variables are
               inappropriate, controlling can result in estimates that are more
               biased than uncontrolled estimates. Despite the ubiquity of
               statistical control in published regression analyses and the
               consequences of controlling for inappropriate third variables,
               the selection of control variables is rarely explicitly
               justified in print. We argue that to carefully select
               appropriate control variables, researchers must propose and
               defend a causal structure that includes the outcome, predictors,
               and plausible confounders. We underscore the importance of
               causality when selecting control variables by demonstrating how
               regression coefficients are affected by controlling for
               appropriate and inappropriate variables. Finally, we provide
               practical recommendations for applied researchers who wish to
               use statistical control.",
  journal   = "Advances in Methods and Practices in Psychological Science",
  publisher = "SAGE Publications Inc",
  volume    =  5,
  number    =  2,
  pages     = "25152459221095823",
  month     =  apr,
  year      =  2022,
  issn      = "2515-2459",
  doi       = "10.1177/25152459221095823"
}

@ARTICLE{Costa2004-uh,
  title     = "Interval distributions, mode, and tonal strength of melodies as
               predictors of perceived emotion",
  author    = "Costa, Marco and Fine, Philip and Ricci Bitti, Pio Enrico",
  abstract  = "Fifty-one tonal and atonal classical melodies were evaluated by
               29 students on 10 bipolar adjective scales that focused on
               emotional evaluation along four factors: valence, aesthetic
               judgment, activity, and potency. Significant predictors for each
               factor were obtained through ridge regression analyses.
               Predictors were quantified characteristics of each melody: the
               distribution of intervals according to interval size, the mode,
               and tonal strength (C. L. Krumhansl, 1990). Valence was best
               predicted by mode. Aesthetic judgment was predicted by the
               interval distribution and by tonal strength. Melodies judged
               pleasant contained more perfect fourths and minor sevenths and
               fewer augmented fourths; they were also high in tonal strength.
               Activity and potency were best predicted by the interval
               distribution. Activity, a sense of instability and motion, was
               conveyed by a greater occurrence of minor seconds, augmented
               fourths, and intervals larger than the octave. Potency, an
               expression of vigor and power, was marked by a greater
               occurrence of unisons and octaves. Thus the emotional expression
               of a melody appears to be related to the distributions of its
               interval categories, its mode, and its tonal strength.",
  journal   = "Music perception",
  publisher = "University of California Press",
  volume    =  22,
  number    =  1,
  pages     = "1--14",
  month     =  sep,
  year      =  2004,
  keywords  = "To read",
  language  = "en",
  issn      = "0730-7829, 1533-8312",
  doi       = "10.1525/mp.2004.22.1.1"
}

@ARTICLE{Roberts1986-nn,
  title    = "Consonance judgements of musical chords by musicians and
              untrained listeners",
  author   = "Roberts, L A",
  abstract = "Musically-trained and untrained subjects rated both the degree of
              consonance and pleasantness of major, minor, diminished and
              augmented chords. These chords were computer generated and varied
              in their overtone structure, temperament, and chordal position.
              In every situation tested, major chords were judged as most
              consonant, followed by minor, diminished, then augmented chords.
              In the first two experiments, subjects judged three- and
              four-note isolated chords. Chords in root position were judged as
              more consonant than first or second inversions and chords in
              equal temperament were judged as more consonant than chords in
              just or Pythagorean tuning. In the third experiment, subjects
              rated the consonance of the third or fourth chord of a four-chord
              sequence. In general, chords were judged as being more consonant
              when they were heard in a traditional than in an untraditional
              musical context. Several differences depending on musical
              training were observed and for all three experiments, very high
              correlations were observed for consonance and pleasantness
              judgements. Results of these experiments do not refute either
              relativistic or psychoacoustic theories of consonance.
              Zusammenfassung Musikalisch ge{\"u}bte und unge{\"u}bte
              Versuchspersonen beurteilten die Konsonanz und die Annehmlichkeit
              von Dur-, Moll-, verminderten und {\"u}berm{\"a}{\ss} Akkorden.
              Die Akkorde wurden vom Computer erzeugt und unterscheiden sich
              bez{\"u}glich der Obertonstruktur, der Stimmung und des
              Grundtons. In jedem H{\"o}rversuch wurden Dur-Akkorde als am
              konsonantesten beurteilt, gefolgt von Moll-, verminderten und
              {\"u}berm{\"a}{\ss} Akkorden. In den beiden ersten
              H{\"o}rversuchen wurden isolierte Akkorde aus drei und vier
              Einzelnoten beurteilt. Akkorde in Grundposition wurden als
              konsonanter beurteilt als Akkorde in erster und zweiter
              Inversion. Auch gleichschwebende Akkorde wurden als konsonanter
              empfunden als Akkorde in nat{\"u}rlicher oder Pythagor{\"a}ischer
              Stimmung. In einem dritten H{\"o}rversuch wurde die Konsonanz der
              dritten und vierten Akkorde einer Folge von vier Akkorden
              beurteilt. Dabei erschienen Akkorde dann als konsonanter, wenn
              sie in einem ,,traditionellen musikalischen Zusammenhang
              dargeboten wurden. Es wurden verschiedene Abh{\"a}ngigkeiten vom
              Grad der musikalischen Vorbildung sowie eine sehr hohe
              Korrelation zwischen ,,Konsonanz und ,,Annehmlichkeit
              festgestellt. Die Ergebnisse Sommaire Des sujets avec ou sans
              formation musicale ont \textbackslash'et\textbackslash'e
              charg\textbackslash'es de classer, selon leur
              degr\textbackslash'e de consonance et leur
              caract\textbackslash`ere d'agr\textbackslash'ement, divers
              accords musicaux majeurs, mineurs, diminu\textbackslash'es ou
              augment\textbackslash'es. Ces accords \textbackslash'etaient
              engendr\textbackslash'es par un ordinateur qui permettait d'en
              varier la structure harmonique, le temp\textbackslash'erament et
              la position. Dans tous les \textbackslash'echantillons
              pr\textbackslash'esent\textbackslash'es, les accords majeurs
              furent jug\textbackslash'es les plus consonants, suivis dans
              l'ordre par les accords mineurs, les diminu\textbackslash'es et
              les augment\textbackslash'es. Au cours des deux
              premi\textbackslash`eres experiences, les sujets devaient juger
              des accords isol\textbackslash'es \textbackslash`a 3 ou 4 notes.
              Les accords en position fondamentale furent jug\textbackslash'es
              plus consonants que ceux en premier ou second renversement et, de
              m{\^e}me, les accords \textbackslash`a temp\textbackslash'erament
              \textbackslash'egal plus consonants que ceux \textbackslash`a
              temp\textbackslash'e\}rament pythagoricien ou juste. Lors d'une
              troisi\{\textbackslash`e\}me exp\{\textbackslash'e\}rience, les
              sujets devaient classer le degr\{\textbackslash'e\} de consonance
              du troisi\{\textbackslash`e\}me ou du
              quatri\{\textbackslash`e\}me accord d'une
              s\{\textbackslash'e\}quence de quatre accords. En
              g\{\textbackslash'e\}n\{\textbackslash'e\}ral les accords furent
              jug\{\textbackslash'e\}s plus consonants lorsqu'ils
              \{\textbackslash'e\}taient
              \{\textbackslash'e\}cout\{\textbackslash'e\}s dans un contexte
              musical plus traditionnel. Quelques
              diff\{\textbackslash'e\}rences de jugement dues
              \{\textbackslash`a\} la formation musicale furent
              observ\{\textbackslash'e\}es. Cependant toutes les trois
              exp\{\textbackslash'e\}riences firent
              appara\{\textbackslash^{\i}\}tre une forte
              corr\{\textbackslash'e\}lation entre les jugements de consonance
              et ceux d'agr\{\textbackslash'e\}ment. Les
              r\{\textbackslash'e\}sultats de ces
              exp\{\textbackslash'e\}riences ne r\{\textbackslash'e\}futent ni
              les th\{\textbackslash'e\}ories relativistes ni les
              th\{\textbackslash'e\}ories psycho-acoustiques de la consonance.",
  journal  = "Acta Acustica united with Acustica",
  volume   =  62,
  number   =  2,
  pages    = "163--171",
  year     =  1986,
  issn     = "1610-1928"
}

@ARTICLE{Lahdelma2015-dv,
  title     = "Theoretical proposals on how vertical Harmony may convey
               nostalgia and longing in music",
  author    = "Lahdelma, Imre and Eerola, Tuomas",
  abstract  = "Music is often associated with the emotions of nostalgia and
               longing. According to previous survey studies both nostalgia and
               longing are among the most commonly evoked emotions by music
               (Juslin, 2011). Despite nostalgia's significance as a musical
               emotion, research on the specific properties of music that might
               contribute to this particular emotion has been scarce. A recent
               empirical experiment by Lahdelma and Eerola (2014) sought to
               explore whether single chords could be effective at conveying
               musical emotions to listeners, which spanned complex emotions
               such as nostalgia. According to the results single chords such
               as the minor triad, the minor seventh and the major seventh
               communicate the emotion of nostalgia effectively. The aim of the
               current paper is to raise several possible explanations that
               might account for single chords' ability to convey the emotion
               of nostalgia. In these explanations we consider cultural,
               music-theoretical and psychoacoustic issues, as well as their
               possible interactions. The three proposed candidate explanations
               are (1) learning, (2) intrinsic emotional connotations arising
               from tonal relations, and (3) clashing conventions arising from
               concurrent yet separate affective associations, stemming from
               certain triad and interval combinations. Finally, we propose
               experimental designs for future research to empirically test
               these explanations.",
  journal   = "Empirical musicology review: EMR",
  publisher = "The Ohio State University Libraries",
  volume    =  10,
  number    =  3,
  pages     = "245",
  month     =  sep,
  year      =  2015,
  issn      = "1559-5749",
  doi       = "10.18061/emr.v10i3.4534"
}

@ARTICLE{Bell2004-wo,
  title    = "Hearing: travelling wave or resonance?",
  author   = "Bell, Andrew",
  abstract = "A fresh look at classic work of Thomas Gold on how the inner ear
              processes sound",
  journal  = "PLoS biology",
  volume   =  2,
  number   =  10,
  pages    = "e337",
  month    =  oct,
  year     =  2004,
  language = "en",
  issn     = "1544-9173, 1545-7885",
  pmid     = "15486577",
  doi      = "10.1371/journal.pbio.0020337",
  pmc      = "PMC521729"
}

@ARTICLE{Dallos2008-lk,
  title    = "Cochlear amplification, outer hair cells and prestin",
  author   = "Dallos, Peter",
  abstract = "Mechanical amplification of acoustic signals is apparently a
              common feature of vertebrate auditory organs. In non-mammalian
              vertebrates amplification is produced by stereociliary processes,
              related to the mechanotransducer channel complex and probably to
              the phenomenon of fast adaptation. The extended frequency range
              of the mammalian cochlea has probably co-evolved with a novel
              hair cell type, the outer hair cell and its constituent membrane
              protein, prestin. Cylindrical outer hair cells are motile and
              their somatic length changes are voltage driven and powered by
              prestin. One of the central outstanding problems in mammalian
              cochlear neurobiology is the relation between the two
              amplification processes.",
  journal  = "Current opinion in neurobiology",
  volume   =  18,
  number   =  4,
  pages    = "370--376",
  month    =  aug,
  year     =  2008,
  language = "en",
  issn     = "0959-4388",
  pmid     = "18809494",
  doi      = "10.1016/j.conb.2008.08.016",
  pmc      = "PMC2630119"
}

@BOOK{Von_Bekesy1960-oh,
  title     = "Experiments in hearing",
  author    = "von B{\'e}k{\'e}sy, G",
  publisher = "McGraw-Hill",
  year      =  1960,
  address   = "New York, NY"
}
