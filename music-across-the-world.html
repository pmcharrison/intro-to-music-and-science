<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 14 Music across the world | Music and Science</title>
<meta name="author" content="Peter M. C. Harrison">
<meta name="description" content="It has long been understood that music can be found in diverse cultures across the world. A recent ethnographic survey of 315 societies across the world found music to be present in every case...">
<meta name="generator" content="bookdown 0.37 with bs4_book()">
<meta property="og:title" content="Chapter 14 Music across the world | Music and Science">
<meta property="og:type" content="book">
<meta property="og:description" content="It has long been understood that music can be found in diverse cultures across the world. A recent ethnographic survey of 315 societies across the world found music to be present in every case...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 14 Music across the world | Music and Science">
<meta name="twitter:description" content="It has long been understood that music can be found in diverse cultures across the world. A recent ethnographic survey of 315 societies across the world found music to be present in every case...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script><link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="libs/datatables-binding-0.31/datatables.js"></script><link href="libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script><link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script><!-- It makes little sense to put CSS in an HTML file instead of a 
  CSS file, but this seems to be the only way I could get BS4 book to
  recognise it !--><style>
    .csl-entry {
      margin-bottom: 15px;
      padding-left: 30px;
      text-indent: -30px;
    }
  </style>
<script src="https://hypothes.is/embed.js" async></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Music and Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Overview</a></li>
<li><a class="" href="undergraduate-courses.html"><span class="header-section-number">2</span> Undergraduate courses</a></li>
<li><a class="" href="how-to-approach-the-courses.html"><span class="header-section-number">3</span> How to approach the courses</a></li>
<li><a class="" href="advice-on-essay-writing.html"><span class="header-section-number">4</span> Advice on essay writing</a></li>
<li><a class="" href="copyright.html"><span class="header-section-number">5</span> Copyright</a></li>
<li class="book-part">What is science?</li>
<li><a class="" href="science.html"><span class="header-section-number">6</span> Science</a></li>
<li><a class="" href="science-and-music.html"><span class="header-section-number">7</span> Science and music</a></li>
<li class="book-part">The science of music</li>
<li><a class="" href="foundations-of-acoustics.html"><span class="header-section-number">8</span> Foundations of acoustics</a></li>
<li><a class="" href="timbre.html"><span class="header-section-number">9</span> Timbre</a></li>
<li><a class="" href="pitch.html"><span class="header-section-number">10</span> Pitch</a></li>
<li><a class="" href="consonance.html"><span class="header-section-number">11</span> Consonance</a></li>
<li><a class="" href="expectation.html"><span class="header-section-number">12</span> Expectation</a></li>
<li><a class="" href="evolution.html"><span class="header-section-number">13</span> Evolution</a></li>
<li><a class="active" href="music-across-the-world.html"><span class="header-section-number">14</span> Music across the world</a></li>
<li><a class="" href="emotion.html"><span class="header-section-number">15</span> Emotion</a></li>
<li class="book-part">Scientific methods</li>
<li><a class="" href="introduction-1.html"><span class="header-section-number">16</span> Introduction</a></li>
<li><a class="" href="research-topics.html"><span class="header-section-number">17</span> Research topics</a></li>
<li><a class="" href="research-questions.html"><span class="header-section-number">18</span> Research questions</a></li>
<li><a class="" href="quantitativequalitative.html"><span class="header-section-number">19</span> Quantitative/qualitative</a></li>
<li><a class="" href="ethics.html"><span class="header-section-number">20</span> Ethics</a></li>
<li class="book-part">Quantitative methods</li>
<li><a class="" href="variables.html"><span class="header-section-number">21</span> Variables</a></li>
<li><a class="" href="causality.html"><span class="header-section-number">22</span> Causality</a></li>
<li><a class="" href="generalisability.html"><span class="header-section-number">23</span> Generalisability</a></li>
<li><a class="" href="data-visualisation.html"><span class="header-section-number">24</span> Data visualisation</a></li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">25</span> Descriptive statistics</a></li>
<li><a class="" href="inferential-statistics.html"><span class="header-section-number">26</span> Inferential statistics</a></li>
<li><a class="" href="appraising-limitations.html"><span class="header-section-number">27</span> Appraising limitations</a></li>
<li class="book-part">Computational approaches</li>
<li><a class="" href="computational-music-psychology.html"><span class="header-section-number">28</span> Computational music psychology</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/pmcharrison/intro-to-music-and-science">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="music-across-the-world" class="section level1">
<h1>
<span class="header-section-number">14</span> Music across the world<a class="anchor" aria-label="anchor" href="#music-across-the-world"><i class="fas fa-link"></i></a>
</h1>
<!-- How to define music? From Savage et al. (2015): -->
<!-- " It should be noted that the editors of the Encyclopedia did not adopt a formal definition of music in choosing their selections. We thus assume that they followed the common practice in ethnomusicology of defining music as “humanly organized sound” (48) other than speech, with the distinction between speech and music being left to each culture’s emic (insider, subjective) conceptions, rather than being defined objectively by outsiders. Thus, our analyses suggest that there is no absolutely universal and objective definition of music, but that Lomax and Grauer’s definition may offer a useful working def- inition to distinguish music from speech." -->
<p>It has long been understood that music can be found in diverse cultures across the world. A recent ethnographic survey of 315 societies across the world found music to be present in every case <span class="citation">(Mehr et al., <a href="#ref-Mehr2019-xu" role="doc-biblioref">2019</a>)</span>. This widespread prevalence of music speaks already to its notional evolutionary function: if music is indeed an indispensable part of human society, this suggests that it has some important utility across human cultures that may have a long evolutionary history.</p>
<p>An important question then arises: how does this music-making vary across the world? One way of studying this question is to ‘zoom in’ on individual societies and study them using ethnomusicological methods. Traditionally an ethnomusicologist will spend years embedding themselves within a given musical culture to learn about it as an insider, paying attention both to the structural features of the music and the cultural and social roles it plays within the society. The result is typically a highly detailed understanding of a particular musical culture, developed primarily ‘on its own terms’, without necessarily referring to other musical cultures around the world.</p>
<p>An alternative approach that has ebbed and flowed in popularity over the decades is <em>comparative musicology</em>. Comparative musicology seeks to establish a <em>comparative</em> understanding of different musical cultures, looking both at the sense in which they are similar and the sense in which they are different. It is a more scientifically oriented approach, in that it seeks to represent musical pieces and cultures as data points that can be compared quantitatively to one another.</p>
<p>Comparative musicology saw initial popularity from the late 1800s, with foundational work by researchers such as Erich von Hornbostel (1877-1935). Relevant studies included investigations of scale systems and instrument usage across the world. Unfortunately, this early work ended up manifesting certain problematic characteristics, for example an ‘evolutionist’ way of thinking that considered Western art music to be the ultimate end-goal of musical style development, and that considered other musical styles to be ‘primitive’ in various ways. These philosophical and interpretative issues are part of the reason why ethnomusicology largely displaced comparative musicology for most of the 20th century.</p>
<p>Recent years have seen something of a resurgence of interest in comparative approaches. <span class="citation">Brown &amp; Jordania (<a href="#ref-Brown2013-lz" role="doc-biblioref">2013</a>)</span> present a strong argument for setting cross-cultural comparisons at the heart of musicology and music psychology, placing particular emphasis on the importance of studying <em>musical universals</em>, features of music which reliably occur across many musical cultures. <span class="citation">Savage et al. (<a href="#ref-Savage2015-rp" role="doc-biblioref">2015</a>)</span> present a systematic quantitative analysis of the occurrence of different musical features across a set of globally sampled music recordings. <span class="citation">Mehr et al. (<a href="#ref-Mehr2019-xu" role="doc-biblioref">2019</a>)</span> present a systematic quantitative analysis of ethnographic accounts of music performance from all over the world, focusing in particular on the social contexts in which music manifests in these cultures. Psychological studies have investigated the cross-cultural perception of diverse musical dimensions including pitch <span class="citation">(Jacoby et al., <a href="#ref-Jacoby2019-ew" role="doc-biblioref">2019</a>)</span>, consonance <span class="citation">(McDermott et al., <a href="#ref-McDermott2016-sf" role="doc-biblioref">2016</a>)</span>, and rhythm <span class="citation">(Jacoby et al., <a href="#ref-Jacoby2021-xp" role="doc-biblioref">2021</a>)</span>. Together, this work is giving us an increasingly complete picture of the diverse ways in which music manifests across the world, allowing us to explore interesting questions about the genetic and cultural processes underlying music’s evolution. In the next few sections we will explore different parts of this field.</p>
<div id="cultural-contexts-of-music-making" class="section level2">
<h2>
<span class="header-section-number">14.1</span> Cultural contexts of music-making<a class="anchor" aria-label="anchor" href="#cultural-contexts-of-music-making"><i class="fas fa-link"></i></a>
</h2>
<p>An important principle in ethnomusicology is that we should pay serious attention to the social and cultural contexts within which music is produced. These sociocultural elements have most commonly been studied from qualitative perspectives such as ethnography, where the researcher spends a significant amount of time immersed in the relevant culture documenting events that they observe. This approach delivers very rich data with many personal insights. However, by itself it does not contribute directly to a comparative understanding of the world’s musics, because no single researcher would have enough time to immerse themselves in a sufficient number of cultures to produce a proper global perspective.</p>
<p>The paper by <span class="citation">Mehr et al. (<a href="#ref-Mehr2019-xu" role="doc-biblioref">2019</a>)</span> addresses this problem by taking a large amount of ethnographic writings indexed in the <a href="https://ehrafworldcultures.yale.edu/ehrafe/"><em>eHRAF World Cultures Database</em></a>, identifying passages related to vocal music, and constructing a large set of variables summarising key features of the writings, including both variables concerning the music itself (e.g. the sex of the singer, the presence of instruments) and variables concerning its behavioural context (e.g. the song appears to be part of a ceremony, or the song is associated with war). They christen the resulting dataset the <em>NHS Ethnography</em>, where ‘NHS’ stands for ‘Natural History of Song’. The authors then construct various quantitative analyses that compare these variables across different musical cultures.</p>
<p>Quantitative analyses can quickly becoming overwhelming if they report many different variables at the same time. There are various strategies available for coping with this issue. One popular family of approaches is <em>dimensionality reduction</em>, where we try to summarise the collection of variables in terms of a small number of learned <em>dimensions</em>, where each dimension is shorthand for a collection of variables that tend to go together. There are several statistical approaches to dimensionality reduction out there, of which the most popular are <em>principal component analysis</em> and <em>factor analysis</em>. <span class="citation">Mehr et al. (<a href="#ref-Mehr2019-xu" role="doc-biblioref">2019</a>)</span> use a particular approach called Bayesian principal component analysis, a version of principal component analysis which is able to cope with the fact that the ethnographic dataset has missing data in certain places.</p>
<p>The Bayesian principal component analysis returns three main dimensions that together summarise much of the variation in behavioural context for the different songs in the NHS Ethnography. The authors describe these three dimensions as follows:</p>
<blockquote>
<ul>
<li>
<strong>Formality</strong>: “Excerpts high along this dimension describe ceremonial events involving adults, large audiences, and instruments; excerpts low on it describe informal events with small audiences and children.”</li>
<li>
<strong>Arousal</strong>: “Excerpts high along this dimension describe lively events with many singers, large audiences, and dancing; excerpts low on it describe calmer events involving fewer people and less overt affect, such as people singing to themselves.”</li>
<li>
<strong>Religiosity</strong>: “Passages high along this dimension describe shamanic ceremonies, possession, and funerary songs; passages low on it describe communal events without spiritual content, such as community celebrations.”</li>
</ul>
</blockquote>
<p>One might hypothesise that music plays different roles in different cultures: for example, one culture might predominantly use music in a formal religious context, whereas other cultures might predominantly use music in an informal nonreligious context. The quantitative analyses show that there is indeed some cross-cultural variation along these lines. However, the takeaway message from the analyses is actually that there tends to be much more variation within a given culture than between different cultures. In other words, most cultures tend to exhibit multiple modes of music-making that explore different levels of formality, arousal, and religiosity; if we average over these different modes, we find that most cultures actually sit in a middleground for these three different variables.</p>
<p>The authors provide a <a href="https://www.themusiclab.org/nhs_explorer/ethnography/index.html">web app</a> that allows you to explore how different extracts from the NHS Ethnography sit on these three dimensions:</p>
<iframe src="https://www.themusiclab.org/nhs_explorer/ethnography/index.html" width="100%" height="700px" data-external="1">
</iframe>
<p>In a subsequent analysis, the authors take a more granular approach to understanding music’s behavioural contexts. They look in particular at a collection of keywords chosen to reflect hypotheses generated from published literature in anthropology, ethnomusicology, and cognitive science. They then look to see how often these keywords occur in the context of the musical parts of the ethnographies, as compared to non-musical parts.</p>
<p>They find indeed that, across different cultures, music tends to be associated in certain contexts above others. Many such contexts are listed in their Table 1, though some are more statistically prevalent than others. There seem to be particularly strong effects for the following contexts:</p>
<ul>
<li>Dance</li>
<li>Healing</li>
<li>Religious activity, rituals</li>
<li>Mourning, death, funerals</li>
<li>Processions, spectacles, nuptials</li>
<li>Play, games, childhood activities</li>
<li>Love</li>
</ul>
<p>It is interesting to speculate about why these contexts crop up repeatedly across different cultures. Is it because music has particular evolutionary functions that are mediated by its usage in these contexts? Or is it simply that, once you’ve evolved a musical capacity, these are natural arenas in which to express it?</p>
<p>The second part of the paper focuses on a secondary dataset of cross-cultural music recordings sampled to represent four different song categories chosen in previous work: dance songs, healing songs, love songs, and lullabies. This dataset is termed the <em>NHS Discography</em>.</p>
<p>In an initial experiment, the authors demonstrate that Western (or at least Westernised) listeners are capable of categorising cross-cultural song recordings into these four different categories (dance, healing, love, lullaby) at a reasonable success rate, even though in most cases the listeners will have been totally unfamiliar with the source musical culture. Classification performance was largely independent of the listener’s musical training, or indeed their self-reported familiarity with traditional music. This suggests that these song types tend to exhibit certain consistent musical features across different cultures that are associated with their particular functions, and that listeners are sensitive to the implications of these features even in the absence of formal musical experience.</p>
<p>In a series of follow-up analyses, the authors explore what musical features might be responsible for distinguishing these different song functions. They find a variety of patterns here, including the following:</p>
<ul>
<li>Dance and healing songs tend to have more differentiated accents than lullabies;</li>
<li>Dance songs tend to have fast tempos;</li>
<li>Love songs tend to have high variability in interval sizes;</li>
<li>Healing songs tend to have lots of stepwise motion.</li>
</ul>
<p>Again, it is interesting to speculate as to why these song functions might be consistently associated with these musical features across different cultures.</p>
<p>The final part of the paper corresponds to candidate musical universals that are independent of particular behavioural contexts. We will discuss these in the next section.</p>
</div>
<div id="structural-features-of-music" class="section level2">
<h2>
<span class="header-section-number">14.2</span> Structural features of music<a class="anchor" aria-label="anchor" href="#structural-features-of-music"><i class="fas fa-link"></i></a>
</h2>
<p>Music researchers have written for many decades about cross-cultural differences in musical styles, and have theorised in particular about the idea of <em>musical universals</em>, musical features which might reliably occur across many musical cultures. However, little progress was made on this question in the 20th century, with ethnomusicologists tending to avoid this topic and the baggage it brought from comparative musicology. In this section we will discuss a couple of recent articles that revisit this question of musical universals, bringing a quantitative perspective that simultaneously compares many cultures across the world.</p>
<div id="savage-et-al.-2015" class="section level3">
<h3>
<span class="header-section-number">14.2.1</span> Savage et al. (2015)<a class="anchor" aria-label="anchor" href="#savage-et-al.-2015"><i class="fas fa-link"></i></a>
</h3>
<p><span class="citation">Savage et al. (<a href="#ref-Savage2015-rp" role="doc-biblioref">2015</a>)</span> analysed a collection of 304 recordings from the <em>Garland Encyclopedia of World Music</em>, a dataset comprising recordings from a variety of sources from all over the world, including both field recordings of traditional indigenous music and studio recordings of nontraditional music. The researchers listened to each recording and coded them in terms of 32 musical features covering various aspects of pitch, rhythm, form, instrumentation, performance style, and social context. These features are strongly inspired by the arguments of <span class="citation">Brown &amp; Jordania (<a href="#ref-Brown2013-lz" role="doc-biblioref">2013</a>)</span>.</p>
<p>When examining the recurrence of particular features across different cultures, it’s important to account for the notion of cultural relatedness. If we see the same musical feature recur many times in cultures that are completely unrelated to each other, this implies that there is some kind of latent evolutionary pressure that encourages the development of that feature. However, if the same musical feature recurs many times in cultures that are close neighbours, the evidential strength is weaker: it could simply be that the feature developed once by chance in a historical parent culture, and the child cultures just inherited it. <span class="citation">Savage et al. (<a href="#ref-Savage2015-rp" role="doc-biblioref">2015</a>)</span> therefore use so-called <em>phylogenetic comparative methods</em> to adjust for cultural relatedness in their analyses. Their primary analyses operationalise cultural relatedness using data on the historical relatedness of different languages (<em>language phylogenies</em>), but they also present supplementary analyses that instead operationalise cultural relatedness using geographic information.</p>
<p>An important question in the the interpretation of the results concerns the definition of ‘musical universal’. A strict definition of musical universal would mean that the feature is found in every piece of music, no matter its origin. <span class="citation">Savage et al. (<a href="#ref-Savage2015-rp" role="doc-biblioref">2015</a>)</span> take a weaker definition of musical universal, defining it as a feature that occurs at least 50% of the time. Such features can be termed <em>statistical universals</em>.</p>
<p>The paper identifies a collection of statistical universals spanning different musical domains. The authors summarise them as follows:</p>
<blockquote>
<ul>
<li>
<strong>Pitch</strong>: Music tends to use discrete pitches (1) to form nonequidistant scales (2) containing seven or fewer scale degrees per octave (3). Music also tends to use descending or arched melodic contours (4) composed of small intervals (5) of less than 750 cents (i.e., a perfect fifth or smaller).</li>
<li>
<strong>Rhythm</strong>: Music tends to use an isochronous beat (6) organized according to metrical hierarchies (7) based on multiples of two or three beats (8)—especially multiples of two beats (9). This beat tends to be used to construct motivic patterns (10) based on fewer than five durational values (11).</li>
<li>
<strong>Form</strong>: Music tends to consist of short phrases (12) less than 9 s long.</li>
<li>
<strong>Instrumentation</strong>: Music tends to use both the voice (13) and (nonvocal) instruments (14), often together in the form of accompanied vocal song.</li>
<li>
<strong>Performance style</strong>: Music tends to use the chest voice (i.e., modal register) (15) to sing words (16), rather than vocables (nonlexical syllables).</li>
<li>
<strong>Social context</strong>: Music tends to be performed predominantly in groups (17) and by males (18). The bias toward male performance is true of singing, but even more so of instrumental performance.</li>
</ul>
</blockquote>
<p>Further to this analysis of individual features, <span class="citation">Savage et al. (<a href="#ref-Savage2015-rp" role="doc-biblioref">2015</a>)</span> also studied the sense in which certain features tend to occur together. In particular, they find a collection of statistically associated features that seem to recur in the context of group performance and dance:</p>
<blockquote>
<ul>
<li>Isochronous beat</li>
<li>Motivic patterns</li>
<li>Few durational values</li>
<li>Phrase repetition</li>
<li>Percussion instruments</li>
<li>Syllabic singing</li>
</ul>
</blockquote>
<p>It is not hard to understand why the above features might be promoted in the context of dancing and group performance: each feature looks like it should be useful for encouraging inter-individual rhythmic entrainment. However, it is less obvious why some of the other musical features might become universal, for example discrete pitches or nonequidistant scales. We will revisit these questions in Section <a href="music-across-the-world.html#potential-origins-of-musical-structures">14.3</a>.</p>
</div>
<div id="mehr-et-al.-2019" class="section level3">
<h3>
<span class="header-section-number">14.2.2</span> Mehr et al. (2019)<a class="anchor" aria-label="anchor" href="#mehr-et-al.-2019"><i class="fas fa-link"></i></a>
</h3>
<p>The previously discussed paper by <span class="citation">Mehr et al. (<a href="#ref-Mehr2019-xu" role="doc-biblioref">2019</a>)</span> includes a significant section on candidate musical universals. This follows a detailed analysis of the behavioural contexts of music around the world. This behavioural context part of the paper is very impressive in its scope and quantitative execution; in contrast, unfortunately, the subsequent musical universals section feels a little disappointing, both for its lack of detail and for the Western-centric nature of its methods.</p>
<p>One proposed universal is tonality, specifically the notion that songs tend to be built around a particular tonal centre. This hypothesis is reasonable, but the analysis involves (a) having Western music theorists annotate tonal centres for the melodies, and (b) running the Krumhansl-Kessler keyfinding algorithm on the melodies, an algorithm which is trained on behavioural data from Western listeners. In both cases, one might expect the derived keys to be shaped significantly by the cultural expectations of Western listeners. A better approach to this question would define tonality in a much more culturally neutral way.</p>
<p>A second proposed universal is that melodies vary along two dimensions of complexity: one of which is melodic complexity, and the other of which is rhythmic complexity. These two dimensions are extracted through principal component analysis. Again, the hypothesis seems reasonable, but the support from the data is relatively weak: the two components only explain 13.1% and 10.8% of the variance respectively. In other words, these two dimensions are only explaining a small part of the way in which melodic structure varies across the world.</p>
<p>A third proposed universal is that the prevalence of different melodic and rhythmic bigrams is distributed according to a so-called <em>power law</em>. Traditionally speaking, a bigram is a pair of elements from a given alphabet, for example ‘AB’ or ‘CA’. The authors actually do not analyse bigrams in the conventional sense, which confuses things a little bit. Instead, they just look at frequency distributions for (a) melodic pitch intervals and (b) rhythmic ratios between successive notes. Curiously, the authors do not tabulate separate distributions for different cultures, but instead calculate an overall distribution of intervals and ratios across all the musical cultures in their sample. They find that certain intervals are particularly common cross-culturally (unison, major second, and minor third), and likewise certain rhythmic ratios (1:1, 2:1, and 3:1) are particularly common cross-culturally. Moreover, they show that, when ranking the full set of observed intervals/ratios, the distribution of their relative frequencies is well-approximated by a curve of a particular shape corresponding to a <em>power law</em>. Power-law shapes have previously been observed in many contexts, including music, language, and painting, but it would be interesting to see that this phenomenon replicates in different musical cultures. Unfortunately, the present analysis does not quite show this, because it doesn’t compute separate distributions for individual cultures. However, it is arguably interesting nonetheless to know that we get a power-law distribution if we look at all the cultures jointly. It should be noted though that these distributions are filtered through the transcriptions of expert Western musicians, and may inherit some biases from them. In particular, the process of representing melodies on the Western 12-tone scale arguably forces the musicians to impose Western biases on their transcriptions; likewise, the rhythmic notation forces the musicians to express rhythms in terms of the integer-ratio rhythmic categories used in Western music theory. Future work ought to find ways to reduce these biases, perhaps by representing pitch and rhythm in a culturally neutral continuous space.</p>
<p>The authors provide a nice <a href="https://www.themusiclab.org/nhs_explorer/discography/index.html">web app</a> that allows you to explore different songs in the NHS Discography organised according to the principal components described above. Different songs are represented as different points; click on a point to learn more about the song, and to play an audio recording.</p>
<iframe src="https://www.themusiclab.org/nhs_explorer/discography/index.html" width="100%" height="700px" data-external="1">
</iframe>
</div>
<div id="controversies" class="section level3">
<h3>
<span class="header-section-number">14.2.3</span> Controversies<a class="anchor" aria-label="anchor" href="#controversies"><i class="fas fa-link"></i></a>
</h3>
<p>It should be noted that the concept of musical universals remain controversial. <span class="citation">Mehr et al. (<a href="#ref-Mehr2019-xu" role="doc-biblioref">2019</a>)</span> conducted a survey of 940 music scholars examining their perspective on this topic. Self-identified ethnomusicologists were particularly sceptical of the concept, with their free-text responses including the following:</p>
<blockquote>
<p>“I’m not sure precisely what the angle is here, but the question of musical universals has largely been settled by ethnomusicology–in short, there are very, very few of them. …”</p>
</blockquote>
<blockquote>
<p>“You cannot be serious. Universals? I understand and appreciate your project (really, human musicking is my intellectual jam). But you cannot suggest that scales are universal. You cannot suggest that tonality is universal. And why pitch organization? Because that’s how European music culture thinks. …”</p>
</blockquote>
<blockquote>
<p>“The idea that music is universally understood is a long discounted theory. This line of questioning is condescending to ‘people around the world’.”</p>
</blockquote>
<blockquote>
<p>“A study of universals would negate the rich diversity of the world’s cultures. We are different, no matter how many similarities we may share. The value we must find lives in the in between spaces.”</p>
</blockquote>
<blockquote>
<p>“I fear that this undertaking, spearheaded by the paragon of colonialist expeditions (harvard grad students) risks recapitulating the efforts of comparative musicologists a century ago. Why identify universalities if not to compare and categorize? …”</p>
</blockquote>
<blockquote>
<p>“The idea that there is such a thing as musical universals (let alone that it should be studied) is deeply ethnocentric and Eurocentric. This idea reinforces 19th century European colonial ideology. There is no place for this type of antiquated and prejudiced thinking in a global 21st century education system marked by international and cultural diversity.”</p>
</blockquote>
<blockquote>
<p>“I prefer not to approach music in a universal way. Every culture perceives facts and music in a different way depending on their cultural background. Thus, I think that only people with similar cultural backgrounds could - or may - understand the music as well as the musical and non- musical behaviors of the people under research.”</p>
</blockquote>
<blockquote>
<p>“The problem with the questions about whether this or that use of music is universal or not is that human societies are so many and so various! …”</p>
</blockquote>
<blockquote>
<p>“You are using the term ‘music’ in a very biased Western way. Frankly, I don’t know what you mean by the term. You are treating it as a natural, objective thing that exists. …”</p>
</blockquote>
<p>They make important points, especially concerning the dangers of imposing an overly Western perspective on music studies. Nonetheless, there are many modern musicologists who now think that these statements go too far, and that we should not give up on the goal of developing a comparative understanding of the world’s musics. It seems worthwhile to work towards a comparative musicology that acknowledges and rectifies the problematic cultural imperialism found in early work.</p>
</div>
</div>
<div id="potential-origins-of-musical-structures" class="section level2">
<h2>
<span class="header-section-number">14.3</span> Potential origins of musical structures<a class="anchor" aria-label="anchor" href="#potential-origins-of-musical-structures"><i class="fas fa-link"></i></a>
</h2>
<p>The work of researchers like <span class="citation">Mehr et al. (<a href="#ref-Mehr2019-xu" role="doc-biblioref">2019</a>)</span> and <span class="citation">Savage et al. (<a href="#ref-Savage2015-rp" role="doc-biblioref">2015</a>)</span> constitutes important progress towards understanding what musical universals might be out there. A follow-up question, once we have established the existence of such universals, concerns the mechanisms by which such universals arise. Such work is necessarily speculative, but it gets at the root of an essential musicological question: why musical styles developed the way that they did.</p>
<p>In this section we will consider various influences that may shape the development of particular musical styles. This will include both influences that are relatively fixed between different musical cultures (e.g. the nature of the human voice) and influences which change between different cultures (e.g. local languages, local musical instruments).</p>
<div id="vocal-constraints" class="section level3">
<h3>
<span class="header-section-number">14.3.1</span> Vocal constraints<a class="anchor" aria-label="anchor" href="#vocal-constraints"><i class="fas fa-link"></i></a>
</h3>
<div id="small-pitch-intervals" class="section level4">
<h4>
<span class="header-section-number">14.3.1.1</span> Small pitch intervals<a class="anchor" aria-label="anchor" href="#small-pitch-intervals"><i class="fas fa-link"></i></a>
</h4>
<p>One of the most obvious features cross-culturally is that melodies tend to contain <strong>small pitch intervals</strong>. A plausible explanation of this is simply that small pitch intervals are easier (or more natural) to sing. As we discussed in a previous section, this phenomenon has a consequence in auditory scene analysis, where we find that notes with similar pitches tend to be grouped together into a single auditory stream, reflecting the fact that notes with similar pitches are likely to come from the same speaker or singer.</p>
<p>Of course, there are always counter-examples to these kinds of rules. Yodelling is an example, where we see big pitch leaps as the singer jumps rapidly between chest voice and falsetto. Experienced yodellers can create impressive pseudo-polyphonic lines as a result.</p>
<div class="figure">
<img src="images/1x1.png" alt=""><p class="caption"><iframe width="560" height="315" src="https://www.youtube.com/embed/8_UnANdDqJc?start=0" style="display: block; margin-bottom: 25px" title="Yodelling." frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <strong>Yodelling.</strong> ‘Auf und auf voll lebenslust’, sung by Franzl Lang.</p>
</div>
<p><br></p>

</div>
<div id="declination" class="section level4">
<h4>
<span class="header-section-number">14.3.1.2</span> Declination<a class="anchor" aria-label="anchor" href="#declination"><i class="fas fa-link"></i></a>
</h4>
<p>In speech, <strong>declination</strong> refers to the way in which speech utterances tend on average to have downwards pitch trajectories <span class="citation">(e.g. Hart &amp; Cohen, <a href="#ref-Hart1973-mz" role="doc-biblioref">1973</a>; Vaissière, <a href="#ref-Vaissiere1983-lo" role="doc-biblioref">1983</a>)</span>. A plausible explanation for this is that the speaker’s lungs gradually run out of air over the course of the utterance, which makes it increasingly hard to maintain a given pitch height. </p>
<p>Several researchers have noted that melodies also seem to exhibit pitch declination: in other words, melodies tend to drop in pitch towards the end of phrases <span class="citation">(Huron, <a href="#ref-Huron1996-lv" role="doc-biblioref">1996</a>; Sachs, <a href="#ref-Sachs1962-lw" role="doc-biblioref">1962</a>)</span>. <span class="citation">Huron (<a href="#ref-Huron1996-lv" role="doc-biblioref">1996</a>)</span> identified such an effect in a corpus analysis of European folksongs. However, the effect seems to be quite weak in music compared to speech. This might be because singing typically involves more breath support than speech, so the pitch is less likely to drop towards the end of a phrase. It might also be because melodies tend to be drawn from discrete scale systems, which should provide a ‘centring’ force to act against unintended gradual pitch drops.</p>
</div>
<div id="late-phrase-compression" class="section level4">
<h4>
<span class="header-section-number">14.3.1.3</span> Late-phrase compression<a class="anchor" aria-label="anchor" href="#late-phrase-compression"><i class="fas fa-link"></i></a>
</h4>
<p>A related phenomenon is something called ‘<strong>late-phrase compression</strong>’. In speech, late-phrase compression refers to the way in which pitch range tends to decrease towards the end of an utterance <span class="citation">(Ladd, <a href="#ref-Ladd2008-gu" role="doc-biblioref">2008</a>)</span>. At the beginning of a sentence, I have lots of air in my lungs. This makes it easy for me to send my voice up and down with little effort. In contrast, if I wait all the way until the end of a sentence, then I’ll end up having less air in my lungs, and this makes it harder to jump up and down between pitches.</p>
<p>In a corpus analysis, <span class="citation">Shanahan &amp; Huron (<a href="#ref-Shanahan2011-km" role="doc-biblioref">2011</a>)</span> investigated whether melodies also exhibit late-phrase compression. It seemed plausible that they would, because melodies are subject to the same kinds of vocal constraints as speech utterances. Indeed, they found evidence for late-phrase compression in Germanic folksongs. However, when they replicated the same analysis with Chinese folksongs, they found the opposite effect: pitch range tended to increase towards the end of musical phrases. This suggests that late-phrase compression effects are likely to correspond to idiosyncrasies of particular musical styles, rather than universal vocal constraints.</p>
</div>
<div id="low-skip-bias" class="section level4">
<h4>
<span class="header-section-number">14.3.1.4</span> Low-skip bias<a class="anchor" aria-label="anchor" href="#low-skip-bias"><i class="fas fa-link"></i></a>
</h4>
<p>This idea of <strong>low-skip bias</strong> is based on two observations. The first is that pitch skips (or pitch leaps) are vocally demanding, as we’ve discussed previously. The second observation is that singers generally find it easier to sing towards the lower part of their register than towards the upper part.</p>
<p>On this basis, <span class="citation">Ammirante &amp; Russo (<a href="#ref-Ammirante2015-mn" role="doc-biblioref">2015</a>)</span> concluded that composers should prefer placing pitch skips in lower registers, because the lower register can help to compensate for the vocally demanding nature of the pitch skip. They describe a corpus analysis that supports their claim. Importantly, they show that this so-called ‘low-skip bias’ is strongest in vocal music, and occurs less commonly in instrumental music, where there is no longer such a consistent association between register and difficulty.</p>
</div>
</div>
<div id="memory-constraints" class="section level3">
<h3>
<span class="header-section-number">14.3.2</span> Memory constraints<a class="anchor" aria-label="anchor" href="#memory-constraints"><i class="fas fa-link"></i></a>
</h3>
<p>Musical structure manifests as patterns of sound that spread over a variety of time intervals, including both small-scale patterns (e.g. the fluctuation of pitch in a violin’s vibrato), mid-scale patterns (e.g. the organisation of notes into melodic phrases), and large-scale patterns (e.g. the arrangement of movements in a symphony). Understanding these different aspects of musical structure requires the ability to hold the relevant musical materials in memory, so that they can make the relevant comparisons and inferences to identify the underlying patterns and structures. To the extent that musicians want their music to be appreciated by the listener, they therefore must operate within the listener’s memory constraints. These memory constraints are also important at the point of music production, especially in music traditions that rely heavily on oral transmission; if a melody is too complex to memorise, then it is unlikely to be reproduced effectively by the next performer.</p>
<p>Scientists are still working out how musical memory works and how it may relate to the development of musical styles. We’ll outline several possible effects now.</p>
<div id="categorical-memory-representations" class="section level4">
<h4>
<span class="header-section-number">14.3.2.1</span> Categorical memory representations<a class="anchor" aria-label="anchor" href="#categorical-memory-representations"><i class="fas fa-link"></i></a>
</h4>
<p>Many psychological percepts are derived from essentially continuous physical spaces. For example, pitch is derived from frequency, and frequency is a continuous numeric quantity; likewise, vowel sounds can be expressed in terms of formant frequencies, which again correspond to continuous numeric quantities. However, humans have a strong tendency to remember these percepts not as continuous values, but rather as categorical values. For example, when we hear a melody, we might remember it as a series of scale degrees; likewise, when we hear a spoken sentence, we might remember the words that are spoken rather than the exact acoustic parameters of the utterance. This is not to say that the more continuous parameters are completely absent from memory; we know that people do develop detailed memory representations for such phenomena, especially on repeated listenings. Nonetheless, it does seem that categorical representations have a very important role in melody.</p>
<p>In musical styles across the world, we do seem to see that musical elements are used in a manner that supports categorical memory representations, with these musical elements being drawn from finite vocabularies of pitches (e.g. the scale degrees within a melody) or rhythms (e.g. simple integer duration ratios). It seems plausible that this strategy helps people to remember musical stimuli, which is important both for their ability to appreciate the music as a listener, and for the ability of performers to recreate the music from memory.</p>
</div>
<div id="repetition" class="section level4">
<h4>
<span class="header-section-number">14.3.2.2</span> Repetition<a class="anchor" aria-label="anchor" href="#repetition"><i class="fas fa-link"></i></a>
</h4>
<p>Humans have an excellent capacity to detect repeated patterns, even if the underlying elements are themselves unfamiliar. For example, if we hear a sequence of sounds, we might remember them as ‘Three times Sound A, then Sound B, then two more repetitions of Sound A’. Following this logic, we can expect music to be easier to remember if it regularly reuses its own constituent elements. This reuse can take place at various levels of structure; it might mean reusing different notes within a scale, or reusing the same motif multiple times, or repeating whole sections spanning multiple bars. This phenomenon could explain why music across the world tends to manifest various kinds of repetitive structure.</p>
</div>
<div id="contour-perception" class="section level4">
<h4>
<span class="header-section-number">14.3.2.3</span> Contour perception<a class="anchor" aria-label="anchor" href="#contour-perception"><i class="fas fa-link"></i></a>
</h4>
<p>The <em>contour</em> of a melody may be defined as its overall shape, paying particular attention to the general direction of travel (e.g. upwards versus downwards) and the location of direction changes, and paying less attention to the melody’s precise pitch content. Behavioural research has shown that contour has a privileged role in melodic memory, particularly in contexts where the listener must remember a novel melody over a short time period <span class="citation">(Dowling, <a href="#ref-Dowling1978-ga" role="doc-biblioref">1978</a><a href="#ref-Dowling1978-ga" role="doc-biblioref">b</a>)</span>. Correspondingly, to maximise a musical extract’s memorability, it’s important that the music’s motivic repetitions should preserve contour, but not necessarily exact pitch intervals. This is something we see very clearly in common-practice Western music, where motives often recur with their shape preserved but their precise intervallic structure altered.</p>
</div>
<div id="nonequidistant-scales" class="section level4">
<h4>
<span class="header-section-number">14.3.2.4</span> Nonequidistant scales<a class="anchor" aria-label="anchor" href="#nonequidistant-scales"><i class="fas fa-link"></i></a>
</h4>
<p>An equidistant scale is a scale where every adjacent note is separated by the same interval. Examples of equidistant scales include the 12-tone chromatic scale and the whole-tone scale. Conversely, nonequidistant scales are scales where the intervals between adjacent notes vary. Nonequidistant scales have been noted several times as a candidate musical universal, including in the recent paper by <span class="citation">Savage et al. (<a href="#ref-Savage2015-rp" role="doc-biblioref">2015</a>)</span>.</p>
<p>Why might musical styles across the world tend to converge on nonequidistant scales, when equidistant scales are conceptually simpler? One possibility is that nonequidistant scales make music easier to remember. In particular, it has been noted that nonequidistant scales allow different notes to have distinct, individualised relationships with the other notes in the scale, in contrast to equidistant scales, where the scale is fully symmetric and hence every note is conceptually identical <span class="citation">(Balzano, <a href="#ref-Balzano1982-za" role="doc-biblioref">1982</a>)</span>. This individualisation may make pitch sequences easier to remember.</p>
<p>To my knowledge, there is no research yet that directly tests whether nonequidistant scales make melodies easier to remember. However, a recent study by <span class="citation">Pelofi &amp; Farbood (<a href="#ref-Pelofi2021-jf" role="doc-biblioref">2021</a>)</span> demonstrates something related: that listeners are better able to learn musical ‘grammars’ (i.e. artificial musical styles) if these grammars are drawn from nonequidistant rather than equidistant scales.</p>
</div>
</div>
<div id="bounded-tessituras" class="section level3">
<h3>
<span class="header-section-number">14.3.3</span> Bounded tessituras<a class="anchor" aria-label="anchor" href="#bounded-tessituras"><i class="fas fa-link"></i></a>
</h3>
<p>Various music theorists have noted that the direction of a melody tends to reverse after a large skip. This phenomenon was perhaps most famously expressed as the <strong>registral direction</strong> principle of Eugene Narmour’s ‘Implication-Realization Model’ of melodic expectation <span class="citation">(Narmour, <a href="#ref-Narmour1990-gv" role="doc-biblioref">1990</a>, <a href="#ref-Narmour1992-ka" role="doc-biblioref">1992</a>)</span></p>
<p>Music theorists have advanced various explanations for this phenomenon. <span class="citation">Meyer (<a href="#ref-Meyer1956-em" role="doc-biblioref">1956</a>)</span> proposed that skips create ‘structural gaps’ that listeners expect to be filled. <span class="citation">Narmour (<a href="#ref-Narmour1990-gv" role="doc-biblioref">1990</a>)</span> proposed that the dissimilarity between the first two notes in the pattern makes the listener expect further dissimilarity, which comes in the form of reversed interval direction. These explanations are arguably rather <em>ad hoc</em>, though…</p>
<p><span class="citation">Watt (<a href="#ref-Watt1924-xc" role="doc-biblioref">1924</a>)</span> proposed a much simpler explanation: on average, skips are likely to take the instrument towards the edge of its tessitura, after which point a direction reversal becomes necessary in order to return towards the centre of the tessitura. </p>
<p><span class="citation">Von Hippel &amp; Huron (<a href="#ref-Von_Hippel2000-yo" role="doc-biblioref">2000</a>)</span> tested Watt’s hypothesis using a corpus analysis. Their conclusion was positive: post-skip reversals were no more common than would be expected by chance given tessitura constraints. In other words, composers weren’t actively trying to write post-skip reversals; they were just trying to stay within the instrument’s tessitura.</p>
<p>In a follow-up study, <span class="citation">Hippel (<a href="#ref-Von_Hippel2002-wa" role="doc-biblioref">2002</a>)</span> tested listener expectations for post-skip reversals. Interestingly, the results contrasted with the corpus analysis; unlike the composers, the listeners actively expected post-skip reversals, independently of any tessitura constraints. The implication is quite interesting. Originally, post-skip reversals just arise as a byproduct of the composer’s requirement to stay within the instrument’s tessitura. However, listeners learn to expect post-skip reversals through musical exposure. As a result, they end up expecting reversals whenever they see a pitch skip, even if there are no tessitura constraints currently at play.</p>
</div>
<div id="speech-patterns" class="section level3">
<h3>
<span class="header-section-number">14.3.4</span> Speech patterns<a class="anchor" aria-label="anchor" href="#speech-patterns"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s now consider how speech patterns might shape the development of musical styles. This possibility has been addressed most systematically from the perspective of rhythm. The idea is that the rhythmic properties of a given language or dialect might end up being manifested in the musical rhythms produced by that culture. A few papers have explored this idea, for example <span class="citation">Patel &amp; Daniele (<a href="#ref-Patel2003-em" role="doc-biblioref">2003</a>)</span>, and <span class="citation">McGowan &amp; Levitt (<a href="#ref-McGowan2011-sv" role="doc-biblioref">2011</a>)</span>. We’re going to focus today on the latter paper.</p>
<p><span class="citation">McGowan &amp; Levitt (<a href="#ref-McGowan2011-sv" role="doc-biblioref">2011</a>)</span> consider three different geographical locations: Donegal, Kentucky, and Shetland. They analyse the speech rhythms of these three different places, and compare them to the rhythms manifested in traditional fiddle playing from these places.</p>
<p>For illustration, here’s a clip of someone speaking with a Kentucky accent. We hear how the rhythms of the syllables tend to be rather swung, almost like dotted rhythms in Western musical notation.</p>
<div class="figure">
<img src="images/1x1.png" alt=""><p class="caption"><iframe width="560" height="315" src="https://www.youtube.com/embed/nAE-5IG0RrU?start=0" style="display: block; margin-bottom: 25px" title="An example of a Kentucky accent." frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <strong>An example of a Kentucky accent.</strong></p>
</div>
<p><br></p>

<p>We can contrast this to someone speaking with a Shetland accent. Here the syllables seem much more even.</p>
<div class="figure">
<img src="images/1x1.png" alt=""><p class="caption"><iframe width="560" height="315" src="https://www.youtube.com/embed/v37bgydws0E?start=0" style="display: block; margin-bottom: 25px" title="An example of a Shetland accent." frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <strong>An example of a Shetland accent.</strong></p>
</div>
<p><br></p>

<p>Let’s compare these speech rhythms now to the fiddle music rhythms. Here’s an excerpt of some Kentucky fiddle music. We can hear how the basic rhythm is very much swung, analogous to the speech rhythms we heard earlier.</p>
<div class="figure">
<img src="images/1x1.png" alt=""><p class="caption"><iframe width="560" height="315" src="https://www.youtube.com/embed/Dx49-WxSTnM?start=0" style="display: block; margin-bottom: 25px" title="An example of Kentucky fiddle music." frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <strong>An example of Kentucky fiddle music.</strong></p>
</div>
<p><br></p>

<p>We can compare this to an excerpt of some Shetland fiddle music. Here, similar to the Shetland speaker we heard earlier, the rhythm is much more even.</p>
<div class="figure">
<img src="images/1x1.png" alt=""><p class="caption"><iframe width="560" height="315" src="https://www.youtube.com/embed/caFrGTt-drg?start=0" style="display: block; margin-bottom: 25px" title="An example of Shetland fiddle music." frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <strong>An example of Shetland fiddle music.</strong></p>
</div>
<p><br></p>

<p><span class="citation">McGowan &amp; Levitt (<a href="#ref-McGowan2011-sv" role="doc-biblioref">2011</a>)</span> performed a quantitative analysis along these lines, and found that the trends in rhythmic variability across languages were mirrored by the rhythmic variability across musical styles. Specifically, Donegal and Shetland had relatively even rhythms in both speech and music, whereas Kentucky had relatively uneven rhythms in both speech and music. Now, this is just a sample of three different cultures, so we can’t read that much into the results. Nonetheless, they are suggestive of some kind of stylistic interaction between speech and music rhythms.</p>
</div>
<div id="instrument-acoustics" class="section level3">
<h3>
<span class="header-section-number">14.3.5</span> Instrument acoustics<a class="anchor" aria-label="anchor" href="#instrument-acoustics"><i class="fas fa-link"></i></a>
</h3>
<p>We know from earlier in the course that the spectral content of a sound has important implications for the listener. Of course, spectral content is crucial for determining a sound’s timbre. It’s also important in other ways, though. It determines how the partials interact to create consonance or dissonance, and it determines the spectral similarity of successive sonorities, which is potentially important in determining expectation.</p>
<p>We’ve mostly been thinking so far about harmonic tone spectra, because these are the kind of spectra produced by the voice as well as by many other musical instruments. If we put harmonic tones into consonance models, we see that consonance and spectral similarity are both maximised when we draw our notes from musical scales containing lots of harmonic intervals, such as the perfect fifth, perfect fourth, and major third. Many musical cultures across the world use scales like this; the Western diatonic scale is just one example.</p>
<p>An interesting question is then, what kinds of scale systems will we see in musical styles that use inharmonic tone spectra? We can’t expect that the same harmonic scales will maximise consonance or spectral similarity.</p>
<p>The Balinese gamelan is an interesting example of a musical tradition that makes heavy use of inharmonic instruments. The following video shows an example performance:</p>
<div class="figure">
<img src="images/1x1.png" alt=""><p class="caption"><iframe width="560" height="315" src="https://www.youtube.com/embed/qIq8LNbYKT8?start=0" style="display: block; margin-bottom: 25px" title="Balinese gamelan performance" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <strong>Balinese gamelan performance</strong> Ubud Palace, Ubud, Bali, Indonesia, January 2012</p>
</div>
<p><br></p>

<p>The Balinese gamelan is built on two primary scales: the slendro and the pelog. The slendro scale splits the octave into five more-or-less equally sized intervals; in other words, it approximates a five-tone equal-tempered scale. The pelog scale, meanwhile, varies quite a lot in tuning between orchestras.</p>
<div class="inline-figure"><img src="images/slendro-scale.png" style="width:100.0%"></div>
<div class="inline-figure"><img src="images/pelog-scale.png" style="width:100.0%"></div>
<p><span class="citation">Sethares (<a href="#ref-Sethares2005-ko" role="doc-biblioref">2005</a>)</span> has argued that these scale systems developed in order to maximise consonance. His argument begins with the bonang, one of the key instruments in the gamelan orchestra. The bonang is a collection of small gongs, typically hit with padded sticks.</p>
<div class="figure">
<img src="images/1x1.png" alt=""><p class="caption"><video controls width="100%"><source src="videos/bonang.mp4" type="video/mp4"></source></video><strong>Demonstration of the bonang</strong> Credit: Feureau, <a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en">CC BY-SA 3.0</a></p>
</div>
<p><br></p>

<p>Gamelan music often combines inharmonic instruments like the bonang with harmonic instruments such as the voice and the flute. So, let’s look at the dissonance profile produced when we combine a bonang with a harmonic sound. Low points in this plot correspond to points with low dissonance, or equivalently high consonance. These consonant points fall outside the harmonic scale. We can see though that they align quite nicely to five-tone equal temperament, as manifested in the slendro scale.</p>
<div class="figure">
<img src="images/sethares-bonang-model" style="width:100.0%" alt=""><p class="caption">Dissonance model for the bonang, excerpted from <span class="citation">Sethares (<a href="#ref-Sethares2005-ko" role="doc-biblioref">2005</a>)</span>.</p>
</div>
<p>Let’s consider now the saron, a second inharmonic instrument within the gamelan orchestra.</p>
<div class="figure">
<img src="images/1x1.png" alt=""><p class="caption"><iframe width="560" height="315" src="https://www.youtube.com/embed/W1xdd8LpHR4?start=0" style="display: block; margin-bottom: 25px" title="Demonstration of the saron." frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <strong>Demonstration of the saron.</strong> Credit: UK Gamelan Network</p>
</div>
<p><br></p>

<p>If we go through the same exercise for the saron, we find that the consonance profile fits remarkably nicely to the scale degrees of the pelog scale. You can see this by comparing the bottom two lines of numbers in this figure: the bottom line gives the tunings of the pelog scale in cents, whereas the middle line gives the consonance peaks in cents. The two sets of numbers are aligned rather closely, meaning that the pelog scale fits closely to the consonance peaks.</p>
<div class="figure">
<img src="images/sethares-bonang-model" style="width:100.0%" alt=""><p class="caption">Dissonance model for the saron, excerpted from <span class="citation">Sethares (<a href="#ref-Sethares2005-ko" role="doc-biblioref">2005</a>)</span>.</p>
</div>
<p>These demonstrations are provocative, but they come with some caveats. One issue in particular is that gamelan tuning (in particular that of the pelog) varies substantially between gamelans. The figure above plots the pelog scale from the Swastigitha gamelan against a dissonance curve computed for the spectrum of the Swastigitha saron, as measured by <span class="citation">Sethares (<a href="#ref-Sethares2005-ko" role="doc-biblioref">2005</a>)</span>. There is a need to replicate these analyses with a broader range of gamelan instruments and tuning systems to verify that the relationship is indeed a reliable one.</p>
</div>
</div>
<div id="conclusions-and-further-thoughts" class="section level2">
<h2>
<span class="header-section-number">14.4</span> Conclusions and further thoughts<a class="anchor" aria-label="anchor" href="#conclusions-and-further-thoughts"><i class="fas fa-link"></i></a>
</h2>
<p>This section introduced several phenomena that might shape melodic structures in musical styles. In the context of vocal constraints, we focused particularly on the way in which the lungs run out of breath during an utterance, and the implications that this might have for musical pitch <span class="citation">(Huron, <a href="#ref-Huron1996-lv" role="doc-biblioref">1996</a>)</span>. We also considered the way in which lower registers are generally easier to sing in than higher registers, meaning that composers are more likely to place pitch skips in the former rather than the latter <span class="citation">(Ammirante &amp; Russo, <a href="#ref-Ammirante2015-mn" role="doc-biblioref">2015</a>)</span>. Following <span class="citation">Watt (<a href="#ref-Watt1924-xc" role="doc-biblioref">1924</a>)</span>, we discussed how bounded tessituras might provide an explanation for Narmour’s registral direction principle. In the context of speech patterns, we focused particularly on the relationship between speech rhythms and musical rhythms, and discussed a study that addresses this relationship from the perspective of fiddle music and different English dialects <span class="citation">(McGowan &amp; Levitt, <a href="#ref-McGowan2011-sv" role="doc-biblioref">2011</a>)</span>. Lastly, we discussed how the inharmonic scales of the Balinese gamelan might be explained in terms of the tone spectra of its instruments <span class="citation">(Sethares, <a href="#ref-Sethares2005-ko" role="doc-biblioref">2005</a>)</span>.</p>
<p>In many of these cases, the stylistic bias comes originally not from the mind of the listener, but from some kind of physical constraint, for example the nature of sound production in the human voice, the bounded tessitura of a musical instrument, or the spectral content of a musical tone. Once composers start producing music that reflects this bias, though, listeners will become familiar with this kind of music, and internalise its patterns through statistical learning. These internalised patterns can then shape phenomena such as musical expectation, even in contexts where the original physical biases have been removed. So, the biases begin as something physical and external to the listener’s mind, but eventually they end up being psychological and internal to the mind.</p>
<p>An interesting trend in recent work is to explore these questions of stylistic evolution in laboratory experiments <span class="citation">(e.g. Ravignani &amp; Delgado, <a href="#ref-Ravignani2016-om" role="doc-biblioref">2016</a>; Shanahan &amp; Albrecht, <a href="#ref-Shanahan2019-ia" role="doc-biblioref">2019</a>)</span>. Many of these studies rely on the transmission chain method, where a participant learns to perform a particular musical extract, and then plays it for the next participant, who then learns it off them and performs for the next participant, and so on. This method can be used to simulate the effects of oral transmission on musical styles. It’s quite difficult to get these kinds of studies right, but they offer a nice contrasting perspective to corpus analyses of pre-existing music.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Ammirante2015-mn">
<p>Ammirante, P., &amp; Russo, F. A. (2015). Low-skip bias: The distribution of skips across the pitch ranges of vocal and instrumental melodies is vocally constrained. <em>Music Perception: An Interdisciplinary Journal</em>, <em>32</em>(4), 355–363.</p>
</div>
<div id="ref-Balzano1982-za">
<p>Balzano, G. J. (1982). The pitch set as a level of description for studying musical pitch perception. In M. Clynes (Ed.), <em>Music, mind, and brain: The neuropsychology of music</em> (pp. 321–351). Springer US. <a href="https://doi.org/10.1007/978-1-4684-8917-0%5C_17">https://doi.org/10.1007/978-1-4684-8917-0\_17</a></p>
</div>
<div id="ref-Brown2013-lz">
<p>Brown, S., &amp; Jordania, J. (2013). Universals in the world’s musics. <em>Psychology of Music</em>, <em>41</em>(2), 229–248. <a href="https://doi.org/10.1177/0305735611425896">https://doi.org/10.1177/0305735611425896</a></p>
</div>
<div id="ref-Dowling1978-ga">
<p>Dowling, W. J. (1978b). Scale and contour: Two components of a theory of memory for melodies. <em>Psychological Review</em>, <em>85</em>(4), 341–354.</p>
</div>
<div id="ref-Hart1973-mz">
<p>Hart, J., &amp; Cohen, A. (1973). Intonation by rule: A perceptual quest. <em>Journal of Phonetics</em>, <em>1</em>(4), 309–327.</p>
</div>
<div id="ref-Von_Hippel2002-wa">
<p>Hippel, P. von. (2002, May). Melodic-Expectation rules as learned heuristics. <em>Proceedings of the 7th International Conference on Music Perception and Cognition</em>.</p>
</div>
<div id="ref-Huron1996-lv">
<p>Huron, D. (1996). The melodic arch in western folksongs. <em>Computing in Musicology</em>, <em>10</em>, 3–23.</p>
</div>
<div id="ref-Jacoby2021-xp">
<p>Jacoby, N., Polak, R., Grahn, J., Cameron, D. J., Lee, K. M., Godoy, R., Undurraga, E. A., Huanca, T., Thalwitzer, T., Doumbia, N., &amp; al., E. (2021). <em>Universality and cross-cultural variation in mental representations of music revealed by global comparison of rhythm priors</em>. <a href="https://doi.org/10.31234/osf.io/b879v">https://doi.org/10.31234/osf.io/b879v</a></p>
</div>
<div id="ref-Jacoby2019-ew">
<p>Jacoby, N., Undurraga, E. A., McPherson, M. J., Valdés, J., Ossandón, T., &amp; McDermott, J. H. (2019). Universal and non-universal features of musical pitch perception revealed by singing. <em>Current Biology: CB</em>, <em>29</em>(19), 3229–3243.e12. <a href="https://doi.org/10.1016/j.cub.2019.08.020">https://doi.org/10.1016/j.cub.2019.08.020</a></p>
</div>
<div id="ref-Ladd2008-gu">
<p>Ladd, D. R. (2008). <em>Intonational phonology</em> (2nd ed.). Cambridge University Press.</p>
</div>
<div id="ref-McDermott2016-sf">
<p>McDermott, J. H., Schultz, A. F., Undurraga, E. A., &amp; Godoy, R. A. (2016). Indifference to dissonance in native amazonians reveals cultural variation in music perception. <em>Nature</em>, <em>535</em>(7613), 547–550. <a href="https://doi.org/10.1038/nature18635">https://doi.org/10.1038/nature18635</a></p>
</div>
<div id="ref-McGowan2011-sv">
<p>McGowan, R. W., &amp; Levitt, A. G. (2011). A comparison of rhythm in english dialects and music. <em>Music Perception</em>, <em>28</em>(3), 307–314.</p>
</div>
<div id="ref-Mehr2019-xu">
<p>Mehr, S. A., Singh, M., Knox, D., Ketter, D. M., Pickens-Jones, D., Atwood, S., Lucas, C., Jacoby, N., Egner, A. A., Hopkins, E. J., Howard, R. M., Hartshorne, J. K., Jennings, M. V., Simson, J., Bainbridge, C. M., Pinker, S., O’Donnell, T. J., Krasnow, M. M., &amp; Glowacki, L. (2019). Universality and diversity in human song. <em>Science</em>, <em>366</em>(6468). <a href="https://doi.org/10.1126/science.aax0868">https://doi.org/10.1126/science.aax0868</a></p>
</div>
<div id="ref-Meyer1956-em">
<p>Meyer, L. (1956). <em>Emotion and meaning in music</em>. University of Chicago Press.</p>
</div>
<div id="ref-Narmour1990-gv">
<p>Narmour, E. (1990). <em>The analysis and cognition of basic melodic structures: The implication-realization model</em>. University of Chicago Press.</p>
</div>
<div id="ref-Narmour1992-ka">
<p>Narmour, E. (1992). <em>The analysis and cognition of melodic complexity: The implication-realization model</em>. University of Chicago Press.</p>
</div>
<div id="ref-Patel2003-em">
<p>Patel, A. D., &amp; Daniele, J. R. (2003). An empirical comparison of rhythm in language and music. <em>Cognition</em>, <em>87</em>(1), 35–45.</p>
</div>
<div id="ref-Pelofi2021-jf">
<p>Pelofi, C., &amp; Farbood, M. M. (2021). Asymmetry in scales enhances learning of new musical structures. <em>Proceedings of the National Academy of Sciences of the United States of America</em>, <em>118</em>(31). <a href="https://doi.org/10.1073/pnas.2014725118">https://doi.org/10.1073/pnas.2014725118</a></p>
</div>
<div id="ref-Ravignani2016-om">
<p>Ravignani, A., &amp; Delgado, T. (2016). Musical evolution in the lab exhibits rhythmic universals. <em>Nature Publishing Group</em>, <em>1</em>(december), 1–7. <a href="https://doi.org/10.1038/s41562-016-0007">https://doi.org/10.1038/s41562-016-0007</a></p>
</div>
<div id="ref-Sachs1962-lw">
<p>Sachs, C. (1962). <em>The wellsprings of music</em>. Martinus Nijhoff.</p>
</div>
<div id="ref-Savage2015-rp">
<p>Savage, P. E., Brown, S., Sakai, E., &amp; Currie, T. E. (2015). Statistical universals reveal the structures and functions of human music. <em>Proceedings of the National Academy of Sciences</em>, <em>112</em>(29), 8987–8992. <a href="https://doi.org/10.1073/pnas.1414495112">https://doi.org/10.1073/pnas.1414495112</a></p>
</div>
<div id="ref-Sethares2005-ko">
<p>Sethares, W. A. (2005). <em>Tuning, timbre, spectrum, scale</em>. Springer.</p>
</div>
<div id="ref-Shanahan2019-ia">
<p>Shanahan, D., &amp; Albrecht, J. (2019). Examining the effect of oral transmission on folksongs. <em>Music Perception</em>, <em>36</em>(3), 273–288. <a href="https://doi.org/10.1525/mp.2019.36.3.273">https://doi.org/10.1525/mp.2019.36.3.273</a></p>
</div>
<div id="ref-Shanahan2011-km">
<p>Shanahan, D., &amp; Huron, D. (2011). Interval size and phrase position: A comparison between german and chinese folksongs. <em>Empirical Musicology Review: EMR</em>, <em>6</em>(4), 187–197.</p>
</div>
<div id="ref-Vaissiere1983-lo">
<p>Vaissière, J. (1983). Language-Independent prosodic features. In <em>Springer series in language and communication</em> (pp. 53–66). Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-642-69103-4%5C_5">https://doi.org/10.1007/978-3-642-69103-4\_5</a></p>
</div>
<div id="ref-Von_Hippel2000-yo">
<p>Von Hippel, P., &amp; Huron, D. (2000). Why do skips precede reversals? The effect of tessitura on melodic structure. <em>Music Perception</em>, <em>18</em>(1), 59–85. <a href="https://doi.org/10.2307/40285901">https://doi.org/10.2307/40285901</a></p>
</div>
<div id="ref-Watt1924-xc">
<p>Watt, H. J. (1924). Functions of the size of interval in the songs of schubert and of the chippewa and teton sioux indians. <em>British Journal of Psychology</em>, <em>14</em>(4), 370–421.</p>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="evolution.html"><span class="header-section-number">13</span> Evolution</a></div>
<div class="next"><a href="emotion.html"><span class="header-section-number">15</span> Emotion</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#music-across-the-world"><span class="header-section-number">14</span> Music across the world</a></li>
<li><a class="nav-link" href="#cultural-contexts-of-music-making"><span class="header-section-number">14.1</span> Cultural contexts of music-making</a></li>
<li>
<a class="nav-link" href="#structural-features-of-music"><span class="header-section-number">14.2</span> Structural features of music</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#savage-et-al.-2015"><span class="header-section-number">14.2.1</span> Savage et al. (2015)</a></li>
<li><a class="nav-link" href="#mehr-et-al.-2019"><span class="header-section-number">14.2.2</span> Mehr et al. (2019)</a></li>
<li><a class="nav-link" href="#controversies"><span class="header-section-number">14.2.3</span> Controversies</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#potential-origins-of-musical-structures"><span class="header-section-number">14.3</span> Potential origins of musical structures</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#vocal-constraints"><span class="header-section-number">14.3.1</span> Vocal constraints</a></li>
<li><a class="nav-link" href="#memory-constraints"><span class="header-section-number">14.3.2</span> Memory constraints</a></li>
<li><a class="nav-link" href="#bounded-tessituras"><span class="header-section-number">14.3.3</span> Bounded tessituras</a></li>
<li><a class="nav-link" href="#speech-patterns"><span class="header-section-number">14.3.4</span> Speech patterns</a></li>
<li><a class="nav-link" href="#instrument-acoustics"><span class="header-section-number">14.3.5</span> Instrument acoustics</a></li>
</ul>
</li>
<li><a class="nav-link" href="#conclusions-and-further-thoughts"><span class="header-section-number">14.4</span> Conclusions and further thoughts</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/pmcharrison/intro-to-music-and-science/blob/main/055-music-across-the-world.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/pmcharrison/intro-to-music-and-science/edit/main/055-music-across-the-world.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Music and Science</strong>" was written by Peter M. C. Harrison. It was last built on 2024-05-15.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
