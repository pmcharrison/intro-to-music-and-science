<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 10 Consonance | Music and Science</title>
<meta name="author" content="Peter M. C. Harrison">
<meta name="description" content="Consonance is a fundamental principle in Western music that describes how ‘harmonious’ a collection of notes sound when played together. It is particularly important in polyphonic music...">
<meta name="generator" content="bookdown 0.37 with bs4_book()">
<meta property="og:title" content="Chapter 10 Consonance | Music and Science">
<meta property="og:type" content="book">
<meta property="og:description" content="Consonance is a fundamental principle in Western music that describes how ‘harmonious’ a collection of notes sound when played together. It is particularly important in polyphonic music...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 10 Consonance | Music and Science">
<meta name="twitter:description" content="Consonance is a fundamental principle in Western music that describes how ‘harmonious’ a collection of notes sound when played together. It is particularly important in polyphonic music...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script><link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="libs/datatables-binding-0.31/datatables.js"></script><link href="libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script><link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script><!-- It makes little sense to put CSS in an HTML file instead of a 
  CSS file, but this seems to be the only way I could get BS4 book to
  recognise it !--><style>
    .csl-entry {
      margin-bottom: 15px;
      padding-left: 30px;
      text-indent: -30px;
    }
  </style>
<script src="https://hypothes.is/embed.js" async></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Music and Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Overview</a></li>
<li><a class="" href="how-to-approach-the-courses.html"><span class="header-section-number">2</span> How to approach the courses</a></li>
<li><a class="" href="advice-on-essay-writing.html"><span class="header-section-number">3</span> Advice on essay writing</a></li>
<li><a class="" href="copyright.html"><span class="header-section-number">4</span> Copyright</a></li>
<li class="book-part">What is science?</li>
<li><a class="" href="science.html"><span class="header-section-number">5</span> Science</a></li>
<li><a class="" href="science-and-music.html"><span class="header-section-number">6</span> Science and music</a></li>
<li class="book-part">The science of music</li>
<li><a class="" href="foundations-of-acoustics.html"><span class="header-section-number">7</span> Foundations of acoustics</a></li>
<li><a class="" href="timbre.html"><span class="header-section-number">8</span> Timbre</a></li>
<li><a class="" href="pitch.html"><span class="header-section-number">9</span> Pitch</a></li>
<li><a class="active" href="consonance.html"><span class="header-section-number">10</span> Consonance</a></li>
<li><a class="" href="expectation.html"><span class="header-section-number">11</span> Expectation</a></li>
<li><a class="" href="evolution.html"><span class="header-section-number">12</span> Evolution</a></li>
<li><a class="" href="music-across-the-world.html"><span class="header-section-number">13</span> Music across the world</a></li>
<li><a class="" href="emotion.html"><span class="header-section-number">14</span> Emotion</a></li>
<li class="book-part">Scientific methods</li>
<li><a class="" href="introduction-1.html"><span class="header-section-number">15</span> Introduction</a></li>
<li><a class="" href="research-topics.html"><span class="header-section-number">16</span> Research topics</a></li>
<li><a class="" href="research-questions.html"><span class="header-section-number">17</span> Research questions</a></li>
<li><a class="" href="quantitativequalitative.html"><span class="header-section-number">18</span> Quantitative/qualitative</a></li>
<li><a class="" href="ethics.html"><span class="header-section-number">19</span> Ethics</a></li>
<li class="book-part">Quantitative methods</li>
<li><a class="" href="variables.html"><span class="header-section-number">20</span> Variables</a></li>
<li><a class="" href="causality.html"><span class="header-section-number">21</span> Causality</a></li>
<li><a class="" href="generalisability.html"><span class="header-section-number">22</span> Generalisability</a></li>
<li><a class="" href="data-visualisation.html"><span class="header-section-number">23</span> Data visualisation</a></li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">24</span> Descriptive statistics</a></li>
<li><a class="" href="inferential-statistics.html"><span class="header-section-number">25</span> Inferential statistics</a></li>
<li><a class="" href="appraising-limitations.html"><span class="header-section-number">26</span> Appraising limitations</a></li>
<li class="book-part">Computational approaches</li>
<li><a class="" href="computational-music-psychology.html"><span class="header-section-number">27</span> Computational music psychology</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/pmcharrison/intro-to-music-and-science">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="consonance" class="section level1">
<h1>
<span class="header-section-number">10</span> Consonance<a class="anchor" aria-label="anchor" href="#consonance"><i class="fas fa-link"></i></a>
</h1>
<p>Consonance is a fundamental principle in Western music that describes how ‘harmonious’ a collection of notes sound when played together. It is particularly important in polyphonic music composition, where many different musical parts play at the same time. In particular, it is used to determine which kinds of musical sonorities are treated as stable and which are treated as unstable, something which helps drive the temporal dynamics of lots of Western tonal music.</p>
<p>When we study consonance from a psychological perspective, we typically distil it down to a very basic question: what makes some chords sound consonant, and others sound dissonant? Is it just a cultural convention, or does it come down to deeper acoustic or psychological processes?</p>
<p>In order to study consonance in psychological experiments, we need to have an operational definition of consonance. In this psychological context, we typically consider consonance to be a perceptual quality of a chord: something subjective in the mind of the listener, like pitch or loudness. The question is then, how do we access that perceptual quality?</p>
<p>One approach is simply to ask the participant, “how consonant is this chord”? However, consonance is arguably specialist musical terminology, and it does not always translate well across languages.</p>
<p>In practice, psychologists therefore often use an alternative question, “how pleasant is this chord?”. The assumption here is that consonance is essentially equivalent to subjective pleasantness, at least when a chord is presented in isolation. This approach seems to work well, and has successfully been applied cross-culturally. However, it should be noted that some researchers dispute this operationalisation, and say that the word ‘consonance’ cannot be replaced in this context. Whether this makes any meaningful difference in practice is still a matter for debate…</p>
<p>Having operationalised consonance as perceived pleasantness, we can then do experiments to quantify how consonant particular chords are perceived to be in practice. In a given trial of the experiment, we might for example play the participant a particular musical chord, and ask them to rate the pleasantness of this chord on a multiple choice scale. Now, we can’t read all that much into an individual trial, because subjective judgments like pleasantness are typically variable on an individual basis, and often differ between participants. So, in practice we would play the same sound to many participants, get ratings from each of them, and then average these ratings to get an overall ‘consonance rating for the chord’. We can repeat this process for many different chords, systematically characterising the perceived pleasantness for each one.</p>
<p>If we do this for all dyads between 0 and 15 semitones, we get a graph like the following:</p>
<div class="figure">
<img src="images/consonance-profile.png" style="width:100.0%" alt=""><p class="caption">Data from Marjieh, Harrison, Lee, Deligiannaki, &amp; Jacoby. (in preparation), collected from behavioural experiments with US participants. Shaded regions correspond to +/- 1 standard error, computed over trials after normalising within participants.</p>
</div>
<p>Here we have intervals in semitones plotted on the horizontal axis, and aggregated consonance ratings plotted on the vertical axis. We see lots of peaks at integer values of semitones, showing us that dyads are most consonant (to Westerners) when they correspond to intervals from the Western 12-tone scale. Within this 12-tone scale, we still see lots of variation, though. For example, we see a big peak at 7 semitones, corresponding to the perfect fifth, in contrast to a minimal peak at 6 semitones (the tritone). Our challenge is then to explain these peaks and valleys, both in the context of simple dyads and in the context of more complex three- and four-note chords.</p>
<div id="theories-of-consonance" class="section level2">
<h2>
<span class="header-section-number">10.1</span> Theories of consonance<a class="anchor" aria-label="anchor" href="#theories-of-consonance"><i class="fas fa-link"></i></a>
</h2>
<p>Many different theories of consonance have been presented over the centuries, and some have proved to be more effective than others. Here we are going to focus on three theories that have survived the most criticism, and that seem to provide the best candidates for explaining the data that we get from consonance experiments:</p>
<ol style="list-style-type: decimal">
<li><p>Periodicity/harmonicity</p></li>
<li><p>Interference between partials</p></li>
<li><p>Cultural familiarity</p></li>
</ol>
<div id="periodicity-and-harmonicity" class="section level3">
<h3>
<span class="header-section-number">10.1.1</span> Periodicity and harmonicity<a class="anchor" aria-label="anchor" href="#periodicity-and-harmonicity"><i class="fas fa-link"></i></a>
</h3>
<p>In Chapter <a href="foundations-of-acoustics.html#foundations-of-acoustics">7</a> we introduced the notion of a harmonic complex tone, an idealised kind of tone built only out of frequency components that are integer multiples of a common fundamental frequency. When a sound has this property of frequency components largely corresponding to integer multiples of a common fundamental frequency, we say that the spectrum has high harmonicity.</p>
<div class="figure">
<img src="images/consonance-harmonic-spectrum.png" style="width:100.0%" alt=""><p class="caption">Idealised harmonic spectrum with a fundamental frequency of 100 Hz.</p>
</div>
<p>Harmonicity is something that we observe by looking at the sound’s frequency-domain representation. If we then look at the waveform in its temporal representation, we see the consequence of this harmonicity: a highly periodic waveform, that repeats itself at a set time period. It turns out that periodicity and harmonicity are deeply linked from a mathematical perspective, and typically go hand-in-hand.</p>
<div class="figure">
<img src="images/consonance-harmonicity-and-periodicity.png" style="width:100.0%" alt=""><p class="caption">A harmonic complex tone with a fundamental frequency of 100 Hz expressed in both the spectral (top) and temporal (bottom) domains.</p>
</div>
<p>Certain musical chords share these properties of harmonicity and periodicity. Take the perfect fifth, for example. The perfect fifth is built from approximately a 3:2 frequency ratio, and hence several of the harmonics in each tone overlap with one another. Moreover, it turns out that the partials in the resulting spectrum all end up being multiples of a common fundamental frequency, corresponding to one octave below the lowest tone. So, we can say that the perfect fifth exhibits high harmonicity. The claim is then that the high harmonicity and periodicity of the perfect fifth is what makes it pleasant, or consonant.</p>
<div class="figure">
<img src="images/consonance-perfect-fifth.png" style="width:100.0%" alt=""><p class="caption"><strong>The harmonicity and periodicity of the perfect fifth.</strong> <audio controls controlslist="nodownload" style="display: block; margin-top: 10px"><source src="audio/perfect-fifth.wav" type="audio/mpeg"></source></audio></p>
</div>
<p><br></p>

<p>In contrast, the tritone behaves in an opposite way to the perfect fifth. Its spectrum does not relate clearly to any harmonic template, and its waveform is not periodic in any clear way.</p>
<div class="figure">
<img src="images/consonance-tritone.png" style="width:100.0%" alt=""><p class="caption"><strong>The low harmonicity and limited periodicity of the tritone.</strong> <audio controls controlslist="nodownload" style="display: block; margin-top: 10px"><source src="audio/tritone.wav" type="audio/mpeg"></source></audio></p>
</div>
<p><br></p>

<p>There are various suggestions as to why humans might consider harmonicity and periodicity to be pleasant. One is that humans like harmonicity because harmonic sounds correspond to a simpler, easier to process auditory environment. Another suggestion is that humans like harmonicity because harmonicity is associated with vocalisations, and vocalisations are important features of the environment to pay attention to. A third suggestion is that humans don’t have any innate preferences for harmonicity, but learn such preferences through cultural exposure.</p>
</div>
<div id="interference-between-partials" class="section level3">
<h3>
<span class="header-section-number">10.1.2</span> Interference between partials<a class="anchor" aria-label="anchor" href="#interference-between-partials"><i class="fas fa-link"></i></a>
</h3>
<p>We already know that musical chords can be expressed in a spectral form, where we plot the frequency and amplitude of every notional pure tone component in the chord. A spectrum for a diminished triad might look like this.</p>
<div class="inline-figure"><img src="images/consonance-interference-spectrum.png" style="width:100.0%"></div>
<p>Interference theories of consonance claim that consonance comes from the absence of unpleasant interactions between neighbouring partials in this spectrum. The nature of these interactions has been studied in psychoacoustic experiments where researchers play participants pairs of pure tones separated by a variable distance, and ask them to rate the pleasantness of the combination. It turns out that the combination sounds quite pleasant when the two tones are almost overlapping, or when they are far apart, but when they are a small distance apart (approximately a semitone apart) they elicit an unpleasant interference effect. There are two main suggestions for why pairs of partials interact negatively in this way: beating and masking. Let’s discuss both in turn.</p>
<p><strong>Beating.</strong> When you add two sine waves together, both of similar frequencies, it turns out that the resulting waveform ends up oscillating in amplitude in what is called a ‘beating’ effect. The frequency of this amplitude oscillation corresponds to the difference in frequency between the two sine waves. At certain frequencies, typically between about 20 and 30 Hz, this beating tends to feel unpleasant, causing a perceptual sensation that we term ‘roughness’.</p>
<div class="figure">
<img src="images/consonance-beating.png" style="width:100.0%" alt=""><p class="caption"><strong>Beating resulting from combining pure tones of 400 Hz and 430 Hz.</strong> <audio controls controlslist="nodownload" style="display: block; margin-top: 10px"><source src="audio/beating-400-430.wav" type="audio/mpeg"></source></audio></p>
</div>
<p><br></p>

<p><strong>Masking.</strong> Masking concerns the auditory system’s ability to resolve, or ‘hear out’, different partials in the acoustic spectrum. When partials are well-separated, they are easy to distinguish, because they stimulate distinct parts of the basilar membrane. However, when partials are close together, they end up stimulating overlapping regions, which makes them hard to distinguish, and causes what is known as ‘masking’. It is thought that this masking effect might feel unpleasant, because it reflects an auditory environment that is hard to process accurately.</p>
<div class="figure">
<img src="images/consonance-masking.png" style="width:100.0%" alt=""><p class="caption">Schematic illustration, not to scale</p>
</div>
<p>It is thought that both beating and masking depend closely on the notion of <em>auditory filters</em>, discussed in Chapter <a href="pitch.html#pitch">9</a> in the context of pitch perception. As a reminder, each location on the basilar membrane can be modelled as a kind of auditory filter centred on that location’s characteristic frequency, with this filter selectively retaining frequency components in the neighbourhood of that characteristic frequency. In particular, two partials are thought to interfere with each other only if they are both resolved within the <em>same</em> auditory filter. When partials are localised to different auditory filters, they do not end up being superposed, and hence do not produce beating effects. Furthermore, if the partials are localised to different auditory filters, this makes it easy for the brain to distinguish them from one another, hence reducing masking.</p>
<p>According to interference theories of consonance, these unpleasant pairwise interactions (stemming potentially from beating and masking) accumulate across all the different pairs of partials within a chord. The consonance of a chord therefore depends on the extent to which it manages to avoid these kinds of negative interactions.</p>
<p>Here are two illustrative spectra for visualising the contribution of interference to consonance and dissonance. The first corresponds to a C major triad; the nature of its pitch intervals means that many of its tones’ harmonics overlap neatly with each other, or else give each other a wide berth. As a result, the partials only experience a minimal amount of interference, which here is marked in red. In contrast, the second spectrum corresponds to a three-semitone cluster chord, C C# D. Here the harmonics do not overlap neatly with each other, but instead sit in prime locations for eliciting interference. The interference theories therefore correctly predict that this chord will be perceived as unpleasant, or dissonant.</p>
<div class="inline-figure"><img src="images/consonance-interference-model.png" style="width:100.0%"></div>
<p>It’s worth pointing out now that periodicity, harmonicity, and interference theories all predict that intervals based on simple integer frequency ratios should be consonant. Simple frequency ratios produce harmonic chords by definition, because their fundamental frequencies are all integer multiples of a common frequency. This has the mathematical consequence of the chords being also periodic. It turns out that this integer-ratio property tends also to minimise interference, because it means that the harmonics in the chord tones tend to overlap neatly with each other.</p>
<div class="inline-table"><table class="table table-sm">
<caption>Integer-ratio approximations for musical intervals, from Ptolemy’s intense diatonic scale.</caption>
<thead><tr class="header">
<th>Interval</th>
<th>Frequency ratio</th>
<th>Classification</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Unison</td>
<td>1:1</td>
<td>Consonant</td>
</tr>
<tr class="even">
<td>Major second</td>
<td>9:8</td>
<td>Dissonant</td>
</tr>
<tr class="odd">
<td>Major third</td>
<td>5:4</td>
<td>Consonant</td>
</tr>
<tr class="even">
<td>Perfect fourth</td>
<td>4:3</td>
<td>Consonant</td>
</tr>
<tr class="odd">
<td>Perfect fifth</td>
<td>3:2</td>
<td>Consonant</td>
</tr>
<tr class="even">
<td>Major sixth</td>
<td>5:3</td>
<td>Consonant</td>
</tr>
<tr class="odd">
<td>Major seventh</td>
<td>15:8</td>
<td>Dissonant</td>
</tr>
<tr class="even">
<td>Octave</td>
<td>2:1</td>
<td>Consonant</td>
</tr>
</tbody>
</table></div>
<p>We can visualise this common property of the theories by operationalising each theory as a computational model, and plotting its predictions for different dyadic intervals. Here I’ve plotted the Hutchinson-Knopoff interference model in red <span class="citation">(Hutchinson &amp; Knopoff, <a href="#ref-hutchinson1978" role="doc-biblioref">1978</a>)</span> and a periodicity model in blue (derived from the Praat sound analysis toolbox), for comparison against empirical pleasantness ratings from participants. In addition, I’ve placed yellow lines corresponding to the simplest integer frequency ratios: 5:4, which is the major third, 4:3, which is the perfect fourth, 3:2, which is the perfect fifth, and 2:1, which is the octave. We can see that both models successfully predict the consonance of these intervals. See Section <a href="computational-music-psychology.html#the-hutchinson-knopoff-dissonance-algorithm">27.3.3</a> for a more in-depth exposition of the Hutchinson-Knopoff algorithm.</p>
<div class="figure">
<img src="images/consonance-modelling.png" style="width:100.0%" alt=""><p class="caption">Data from Marjieh, Harrison, Lee, Deligiannaki, &amp; Jacoby. (in preparation)</p>
</div>
</div>
<div id="cultural-familiarity" class="section level3">
<h3>
<span class="header-section-number">10.1.3</span> Cultural familiarity<a class="anchor" aria-label="anchor" href="#cultural-familiarity"><i class="fas fa-link"></i></a>
</h3>
<p>The cultural familiarity theory is perhaps the simplest of the three. It states that humans do not have any innate predisposition to perceive certain chords as consonant and others as dissonant. Rather, it claims that these preferences are learnt through exposure: in particular, chords that the individual experiences many times in their lifetime begin to be experienced as pleasant, in what is known as the ‘mere exposure effect’. This mere exposure effect is a well-established phenomenon in many psychological domains.</p>
<p>In the context of Western listeners, we can model the cultural familiarity of chords through corpus analyses of popular music, studying how often different chord types appear. This figure illustrates the results of such an analysis, conducted on the McGill Billboard Corpus of popular music. As we might expect, the four most prevalent chords in this corpus correspond to major and minor chords in triad and seventh form. Each of these chords is generally perceived as very consonant by Western listeners, consistent with the theory.</p>
<p>However, we have a chicken and egg problem here, concerning the different possible causal directions between pleasantness and familiarity. On the one hand, on the level of an individual listener, it is quite plausible that musical prevalence comes first (since lots of music was composed before the listeners’ birth), and that this musical prevalence engenders familiarity, and therefore pleasantness. On the other hand, the prevalence of simple integer frequency ratios in the music has to come from somewhere – it would be a strange coincidence for this phenomenon to arise without there being some kind of human predisposition to be sensitive to these ratios, as mediated through periodicity, harmonicity, or interference between partials.</p>
<p>One possibility is that cultural learning provides a feedback loop that amplifies the perceptual effects of periodicity, harmonicity, and interference on pleasantness. Perhaps initially the effects of these features are slight, and not salient to most listeners. However, this slight effect has a slight effect on music composition, causing listeners to become more familiar with integer-based frequency ratios, and hence to perceive these frequency ratios as more pleasant than before. This effect then feeds back into music composition, and so on and so on, producing a self-reinforcing feedback loop.</p>
<div class="inline-figure"><img src="images/consonance-feedback-loop.png" width="550"></div>
</div>
</div>
<div id="disentangling-consonance-theories" class="section level2">
<h2>
<span class="header-section-number">10.2</span> Disentangling consonance theories<a class="anchor" aria-label="anchor" href="#disentangling-consonance-theories"><i class="fas fa-link"></i></a>
</h2>
<p>Disentangling these different theories is hard because, on the face of it, all the theories make similar predictions. Chords that exhibit low interference tend also to exhibit high periodicity and high cultural familiarity. This makes it hard to design experiments that can support one theory while discrediting another.</p>
<p>Four different approaches have proved particularly useful for tackling this entanglement problem in recent years:</p>
<ol style="list-style-type: decimal">
<li><p>Studying different cultural groups;</p></li>
<li><p>Studying individual differences in consonance perception;</p></li>
<li><p>Studying consonance perception using different tone spectra;</p></li>
<li><p>Regression modelling.</p></li>
</ol>
<p>Let’s consider each in turn.</p>
<div id="cultural-groups" class="section level3">
<h3>
<span class="header-section-number">10.2.1</span> Cultural groups<a class="anchor" aria-label="anchor" href="#cultural-groups"><i class="fas fa-link"></i></a>
</h3>
<p>In the last few years a research group from MIT has performed a series of studies with the Tsimane’ people, an indigenous group from Bolivia with very little exposure to Western culture <span class="citation">(J. H. McDermott et al., <a href="#ref-mcdermott2016a" role="doc-biblioref">2016</a>)</span>. It turns out that participants from this group exhibit no preferences for Western consonance: for example, they do not prefer major triads to diminished triads. This is consistent with the idea that culture plays an important role in shaping consonance perception.</p>
<p>Moreover, one can find several musical cultures across the world that seem to actively promote the kinds of pitch intervals that Westerners would consider to be dissonant. It doesn’t seem like these musicians are insensitive to the particular aesthetic effect of these intervals, like it seemed for the Tsimane’ people; instead, it seems like the particular acoustic effects of these intervals are being intrinsically valued in these musical styles. There are not many formal psychological studies of people from these cultures, but music recordings from these cultures are very suggestive. Here’s one such recording of a group of Bosnian Ganga singers:</p>
<div class="figure">
<img src="images/1x1.png" alt=""><p class="caption"><video controls width="100%"><source src="images/GangaLive.mp4" type="video/mp4"></source></video><strong>A performance by a group of Bosnian Ganga singers.</strong> Credit: Pantelis N. Vassilakis, <a href="http://acousticslab.org/RECA220/" class="uri">http://acousticslab.org/RECA220/</a></p>
</div>
<p><br></p>

</div>
<div id="individual-differences-in-consonance-perception" class="section level3">
<h3>
<span class="header-section-number">10.2.2</span> Individual differences in consonance perception<a class="anchor" aria-label="anchor" href="#individual-differences-in-consonance-perception"><i class="fas fa-link"></i></a>
</h3>
<p>The second strategy is the <em>individual differences</em> approach. This approach relies on the observation that preferences for certain auditory features tend to vary between participants. For example, some people have particularly strong preferences for consonant chords, whereas others are quite happy to hear dissonant chords. Likewise, people might differ in the extent to which they prefer harmonicity, or the extent to which they dislike interference between partials.</p>
<p>There is one main study in the literature that pursues this approach <span class="citation">(McDermott et al., <a href="#ref-mcdermott2010" role="doc-biblioref">2010</a>)</span>. After a series of experiments with Western listeners, they concluded that consonance preferences correlated with preferences for harmonicity, but not with aversion to interference<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Example stimuli from this study can be found &lt;a href="http://mcdermottlab.mit.edu/consonance_examples/index.html"&gt;here&lt;/a&gt;.&lt;/p&gt;'><sup>5</sup></a>. On the face of it, this provides strong support for harmonicity theories of consonance perception, and against interference theories. However, there is still a little scepticism in the field about the generalisability of the results. Operationalising preference in a clean way is always difficult, and it’s important to be sure that the experimental methods are really measuring consonance, harmonicity, and interference preferences in the way that is claimed.</p>
</div>
<div id="tone-spectra" class="section level3">
<h3>
<span class="header-section-number">10.2.3</span> Tone spectra<a class="anchor" aria-label="anchor" href="#tone-spectra"><i class="fas fa-link"></i></a>
</h3>
<p>A third strategy is to explore consonance with different tone spectra. The idea is that, if we replace the harmonic spectrum with some other cleverly chosen tone spectrum, then the different theories such as harmonicity and interference theories will start making different predictions from each other, helping us to explain what’s really underlying consonance perception. </p>
<p>One simple yet powerful manipulation is to stretch the harmonics in a tone. The following image illustrates a harmonic spectrum that has been stretched such that the octave corresponds to a 2.1:1 frequency ratio:</p>
<p>Below we have a normal harmonic spectrum, where the octave corresponds to a 2.1 ratio:</p>
<div class="inline-figure"><img src="images/consonance-stretched-spectrum.png" style="width:100.0%"></div>
<p>It turns out that, when we stretch the tone spectra in this way, the consonance profiles also stretch. In the below figure, we see that the peaks in the pleasantness ratings (top) no longer correspond to the simple integer ratios, but rather correspond to stretched versions of these integer ratios. This phenomenon is predicted by the interference model (in red), but is not predicted by the periodicity/harmonicity model (blue). This provides strong evidence that interference between partials does contribute in some way to consonance.</p>
<div class="figure">
<img src="images/consonance-stretched-consonance-profiles.png" style="width:100.0%" alt=""><p class="caption">Data from Marjieh, Harrison, Lee, Deligiannaki, &amp; Jacoby. (in preparation)</p>
</div>
<p>Bill Sethares has produced a compelling musical illustration of this phenomenon. First, we hear a simple musical extract played with harmonic complex tones in the conventional 12-tone scale. It sounds consonant, as we might expect (<a href="https://s3-eu-west-1.amazonaws.com/media.pmcharrison.com/music/sethares/simptun1.mp3">listen here</a>). Next, we play the same extract but on a stretched scale, where the octave corresponds to a 2.1 frequency ratio (<a href="https://s3-eu-west-1.amazonaws.com/media.pmcharrison.com/music/sethares/simptun2.mp3">listen here</a>). The extract now sounds very dissonant, because the harmonics don’t align with the musical scale. Finally, we stretch the tone spectra to match the stretched scale (<a href="https://s3-eu-west-1.amazonaws.com/media.pmcharrison.com/music/sethares/simptun3.mp3">listen here</a>). As predicted by the interference theories, the music becomes consonant again.</p>
</div>
<div id="regression-modelling" class="section level3">
<h3>
<span class="header-section-number">10.2.4</span> Regression modelling<a class="anchor" aria-label="anchor" href="#regression-modelling"><i class="fas fa-link"></i></a>
</h3>
<p>These previous strategies are useful for demonstrating whether or not a particular mechanism contributes to consonance perception. However, they’re not so good for telling us how much these different mechanisms contribute to consonance perception in practice. Regression modelling is a statistical technique for doing just that: we take consonance ratings for many different chords, aggregated over many participants, and we build a statistical model that predicts these consonance ratings on the basis of computational models operationalising the main different theories of consonance. We discuss regression modelling more in Section <a href="inferential-statistics.html#linear-regression">25.7</a>.</p>
<p>If we go through this process, the resulting models tend to point to distinct contributions of interference between partials, periodicity/harmonicity, and cultural familiarity. Here on this bar chart we have one bar for each computational model, where bar length corresponds to the extent to which the predictor contributes to the model. We see similar bar lengths for all three of the primary computational models, supporting the idea that these different mechanisms contribute jointly to consonance perception.</p>
<div class="figure">
<img src="images/consonance-regression.png" width="400" alt=""><p class="caption">Reproduced from <span class="citation">Harrison &amp; Pearce (<a href="#ref-Harrison2020-gx" role="doc-biblioref">2020</a>)</span> (<a href="https://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>).</p>
</div>
<p>These results are compatible with the hypothetical causal diagram from earlier in this section. In general, the results of empirical studies are consistent with the idea that consonance derives from multiple chord features, including a potential feedback loop that amplifies certain effects through cultural learning.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Harrison2020-gx">
<p>Harrison, P. M. C., &amp; Pearce, M. T. (2020). Simultaneous consonance in music perception and composition. <em>Psychological Review</em>, <em>127</em>(2), 216–244. <a href="https://doi.org/10.1037/rev0000169">https://doi.org/10.1037/rev0000169</a></p>
</div>
<div id="ref-hutchinson1978">
<p>Hutchinson, W., &amp; Knopoff, L. (1978). The acoustic component of western consonance. <em>Interface</em>, <em>7</em>(1), 1–29. <a href="https://doi.org/10.1080/09298217808570246">https://doi.org/10.1080/09298217808570246</a></p>
</div>
<div id="ref-mcdermott2010">
<p>McDermott, J. H., Lehr, A. J., &amp; Oxenham, A. J. (2010). Individual differences reveal the basis of consonance. <em>Current Biology</em>, <em>20</em>(11), 1035–1041. <a href="https://doi.org/10.1016/j.cub.2010.04.019">https://doi.org/10.1016/j.cub.2010.04.019</a></p>
</div>
<div id="ref-mcdermott2016a">
<p>McDermott, J. H., Schultz, A. F., Undurraga, E. A., &amp; Godoy, R. A. (2016). Indifference to dissonance in native amazonians reveals cultural variation in music perception. <em>Nature</em>, <em>535</em>(7613), 547–550. <a href="https://doi.org/10.1038/nature18635">https://doi.org/10.1038/nature18635</a></p>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="pitch.html"><span class="header-section-number">9</span> Pitch</a></div>
<div class="next"><a href="expectation.html"><span class="header-section-number">11</span> Expectation</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#consonance"><span class="header-section-number">10</span> Consonance</a></li>
<li>
<a class="nav-link" href="#theories-of-consonance"><span class="header-section-number">10.1</span> Theories of consonance</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#periodicity-and-harmonicity"><span class="header-section-number">10.1.1</span> Periodicity and harmonicity</a></li>
<li><a class="nav-link" href="#interference-between-partials"><span class="header-section-number">10.1.2</span> Interference between partials</a></li>
<li><a class="nav-link" href="#cultural-familiarity"><span class="header-section-number">10.1.3</span> Cultural familiarity</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#disentangling-consonance-theories"><span class="header-section-number">10.2</span> Disentangling consonance theories</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#cultural-groups"><span class="header-section-number">10.2.1</span> Cultural groups</a></li>
<li><a class="nav-link" href="#individual-differences-in-consonance-perception"><span class="header-section-number">10.2.2</span> Individual differences in consonance perception</a></li>
<li><a class="nav-link" href="#tone-spectra"><span class="header-section-number">10.2.3</span> Tone spectra</a></li>
<li><a class="nav-link" href="#regression-modelling"><span class="header-section-number">10.2.4</span> Regression modelling</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/pmcharrison/intro-to-music-and-science/blob/main/040-consonance.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/pmcharrison/intro-to-music-and-science/edit/main/040-consonance.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Music and Science</strong>" was written by Peter M. C. Harrison. It was last built on 2025-01-02.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
