<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>References | Introduction to Music and Science</title>
<meta name="author" content="Peter M. C. Harrison">
<meta name="description" content="Albrecht, J., &amp; Shanahan, D. (2013). The use of large corpora to train a new type of key-finding algorithm. Music Perception, 31(1), 59–67. https://doi.org/10.1525/mp.2013.31.1.59  Ammirante, P.,...">
<meta name="generator" content="bookdown 0.37 with bs4_book()">
<meta property="og:title" content="References | Introduction to Music and Science">
<meta property="og:type" content="book">
<meta property="og:description" content="Albrecht, J., &amp; Shanahan, D. (2013). The use of large corpora to train a new type of key-finding algorithm. Music Perception, 31(1), 59–67. https://doi.org/10.1525/mp.2013.31.1.59  Ammirante, P.,...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="References | Introduction to Music and Science">
<meta name="twitter:description" content="Albrecht, J., &amp; Shanahan, D. (2013). The use of large corpora to train a new type of key-finding algorithm. Music Perception, 31(1), 59–67. https://doi.org/10.1525/mp.2013.31.1.59  Ammirante, P.,...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script><link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="libs/datatables-binding-0.31/datatables.js"></script><link href="libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script><link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script><!-- It makes little sense to put CSS in an HTML file instead of a 
  CSS file, but this seems to be the only way I could get BS4 book to
  recognise it !--><style>
    .csl-entry {
      margin-bottom: 15px;
      padding-left: 30px;
      text-indent: -30px;
    }
  </style>
<script src="https://hypothes.is/embed.js" async></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Introduction to Music and Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Overview</a></li>
<li><a class="" href="how-to-approach-the-courses.html"><span class="header-section-number">2</span> How to approach the courses</a></li>
<li><a class="" href="advice-on-essay-writing.html"><span class="header-section-number">3</span> Advice on essay writing</a></li>
<li><a class="" href="copyright.html"><span class="header-section-number">4</span> Copyright</a></li>
<li class="book-part">What is science?</li>
<li><a class="" href="science.html"><span class="header-section-number">5</span> Science</a></li>
<li><a class="" href="science-and-music.html"><span class="header-section-number">6</span> Science and music</a></li>
<li class="book-part">The science of music</li>
<li><a class="" href="foundations-of-acoustics.html"><span class="header-section-number">7</span> Foundations of acoustics</a></li>
<li><a class="" href="timbre.html"><span class="header-section-number">8</span> Timbre</a></li>
<li><a class="" href="pitch.html"><span class="header-section-number">9</span> Pitch</a></li>
<li><a class="" href="consonance.html"><span class="header-section-number">10</span> Consonance</a></li>
<li><a class="" href="expectation.html"><span class="header-section-number">11</span> Expectation</a></li>
<li><a class="" href="evolution.html"><span class="header-section-number">12</span> Evolution</a></li>
<li><a class="" href="music-across-the-world.html"><span class="header-section-number">13</span> Music across the world</a></li>
<li><a class="" href="emotion.html"><span class="header-section-number">14</span> Emotion</a></li>
<li class="book-part">Scientific methods</li>
<li><a class="" href="introduction-1.html"><span class="header-section-number">15</span> Introduction</a></li>
<li><a class="" href="research-topics.html"><span class="header-section-number">16</span> Research topics</a></li>
<li><a class="" href="research-questions.html"><span class="header-section-number">17</span> Research questions</a></li>
<li><a class="" href="quantitativequalitative.html"><span class="header-section-number">18</span> Quantitative/qualitative</a></li>
<li><a class="" href="ethics.html"><span class="header-section-number">19</span> Ethics</a></li>
<li class="book-part">Quantitative methods</li>
<li><a class="" href="variables.html"><span class="header-section-number">20</span> Variables</a></li>
<li><a class="" href="causality.html"><span class="header-section-number">21</span> Causality</a></li>
<li><a class="" href="generalisability.html"><span class="header-section-number">22</span> Generalisability</a></li>
<li><a class="" href="data-visualisation.html"><span class="header-section-number">23</span> Data visualisation</a></li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">24</span> Descriptive statistics</a></li>
<li><a class="" href="inferential-statistics.html"><span class="header-section-number">25</span> Inferential statistics</a></li>
<li><a class="" href="appraising-limitations.html"><span class="header-section-number">26</span> Appraising limitations</a></li>
<li class="book-part">Computational approaches</li>
<li><a class="" href="computational-music-psychology.html"><span class="header-section-number">27</span> Computational music psychology</a></li>
<li><a class="active" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/pmcharrison/intro-to-music-and-science">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="references" class="section level1 unnumbered">
<h1>References<a class="anchor" aria-label="anchor" href="#references"><i class="fas fa-link"></i></a>
</h1>

<div id="refs" class="references">
<div>
<p>Albrecht, J., &amp; Shanahan, D. (2013). The use of large corpora to train a new type of key-finding algorithm. <em>Music Perception</em>, <em>31</em>(1), 59–67. <a href="https://doi.org/10.1525/mp.2013.31.1.59">https://doi.org/10.1525/mp.2013.31.1.59</a></p>
</div>
<div>
<p>Ammirante, P., &amp; Russo, F. A. (2015). Low-skip bias: The distribution of skips across the pitch ranges of vocal and instrumental melodies is vocally constrained. <em>Music Perception: An Interdisciplinary Journal</em>, <em>32</em>(4), 355–363.</p>
</div>
<div>
<p>Babbs, C. F. (2011). Quantitative reappraisal of the helmholtz-guyton resonance theory of frequency tuning in the cochlea. <em>Journal of Biophysics</em>, <em>2011</em>, 435135. <a href="https://doi.org/10.1155/2011/435135">https://doi.org/10.1155/2011/435135</a></p>
</div>
<div>
<p>Bachem, A. (1950). Tone height and tone chroma as two different pitch qualities. <em>Acta Psychologica</em>, <em>7</em>, 80–88. <a href="https://doi.org/10.1016/0001-6918(50)90004-7">https://doi.org/10.1016/0001-6918(50)90004-7</a></p>
</div>
<div>
<p>Balzano, G. J. (1982). The pitch set as a level of description for studying musical pitch perception. In M. Clynes (Ed.), <em>Music, mind, and brain: The neuropsychology of music</em> (pp. 321–351). Springer US. <a href="https://doi.org/10.1007/978-1-4684-8917-0%5C_17">https://doi.org/10.1007/978-1-4684-8917-0\_17</a></p>
</div>
<div>
<p>Bell, A. (2004). Hearing: Travelling wave or resonance? <em>PLoS Biology</em>, <em>2</em>(10), e337. <a href="https://doi.org/10.1371/journal.pbio.0020337">https://doi.org/10.1371/journal.pbio.0020337</a></p>
</div>
<div>
<p>Bellmann, H. (2005). About the determination of key of a musical excerpt. In R. Kronland-Martinet, T. Voinier, &amp; S. Ystad (Eds.), <em>Proceedings of the Third International Symposium of Computer Music Modeling and Retrieval</em> (pp. 76–91). Springer.</p>
</div>
<div>
<p>Békésy, G. von. (1960). <em>Experiments in hearing</em>. McGraw-Hill.</p>
</div>
<div>
<p>Bigand, E., Parncutt, R., &amp; Lerdahl, F. (1996). Perception of musical tension in short chord sequences: The influence of harmonic function, sensory dissonance, horizontal motion, and musical training. <em>Perception &amp; Psychophysics</em>, <em>58</em>(1), 124–141. <a href="https://doi.org/10.3758/BF03205482">https://doi.org/10.3758/BF03205482</a></p>
</div>
<div>
<p>Bigand, E., &amp; Poulin-Charronnat, B. (2006). Are we “experienced listeners”? A review of the musical capacities that do not depend on formal musical training. <em>Cognition</em>, <em>100</em>(1), 100–130. <a href="https://doi.org/10.1016/j.cognition.2005.11.007">https://doi.org/10.1016/j.cognition.2005.11.007</a></p>
</div>
<div>
<p>Brown, H. (1988). The interplay of set content and temporal context in a functional theory of tonality perception. <em>Music Perception</em>, <em>5</em>(3), 219–249. <a href="https://doi.org/10.2307/40285398">https://doi.org/10.2307/40285398</a></p>
</div>
<div>
<p>Brown, S., &amp; Jordania, J. (2013). Universals in the world’s musics. <em>Psychology of Music</em>, <em>41</em>(2), 229–248. <a href="https://doi.org/10.1177/0305735611425896">https://doi.org/10.1177/0305735611425896</a></p>
</div>
<div>
<p>Broze, Y., &amp; Shanahan, D. (2013). Diachronic changes in jazz harmony: A cognitive perspective. <em>Music Perception</em>, <em>31</em>(1), 32–45. <a href="https://doi.org/10.1525/rep.2008.104.1.92">https://doi.org/10.1525/rep.2008.104.1.92</a></p>
</div>
<div>
<p>Chomsky, N. (1957). <em>Syntactic structures</em>. Mouton Publishers.</p>
</div>
<div>
<p>Coutinho, E., &amp; Scherer, K. R. (2017). Introducing the GEneva music-induced affect checklist (GEMIAC) a brief instrument for the rapid assessment of musically induced emotions. <em>Music Perception: An Interdisciplinary</em>.</p>
</div>
<div>
<p>Cowen, A. S., Fang, X., Sauter, D., &amp; Keltner, D. (2020). What music makes us feel: At least 13 dimensions organize subjective experiences associated with music across different cultures. <em>Proceedings of the National Academy of Sciences of the United States of America</em>, <em>117</em>(4), 1924–1934. <a href="https://doi.org/10.1073/pnas.1910704117">https://doi.org/10.1073/pnas.1910704117</a></p>
</div>
<div>
<p>Cronbach, L. J., &amp; Meehl, P. E. (1955). Construct validity in psychological tests. <em>Psychol. Bull.</em>, <em>52</em>(4), 281–302.</p>
</div>
<div>
<p>Cross, I. (1995). Review of “the analysis and cognition of melodic complexity: The implication-realization model”. <em>Narmour</em>, <em>12</em>(4), 486–509.</p>
</div>
<div>
<p>Cross, I. (2001). Music, cognition, culture, and evolution. <em>Annals of the New York Academy of Sciences</em>, <em>930</em>, 28–42. <a href="https://doi.org/10.1111/j.1749-6632.2001.tb05723.x">https://doi.org/10.1111/j.1749-6632.2001.tb05723.x</a></p>
</div>
<div>
<p>Dallos, P. (2008). Cochlear amplification, outer hair cells and prestin. <em>Current Opinion in Neurobiology</em>, <em>18</em>(4), 370–376. <a href="https://doi.org/10.1016/j.conb.2008.08.016">https://doi.org/10.1016/j.conb.2008.08.016</a></p>
</div>
<div>
<p>Daniel, P., &amp; Weber, R. (1997). Psychoacoustical roughness: Implementation of an optimized model. <em>Acta Acustica United with Acustica</em>, <em>83</em>(1), 113–123.</p>
</div>
<div>
<p>Darwin, C. (1871). <em>The descent of man and selection in relation to sex</em>. John Murray.</p>
</div>
<div>
<p>Deutsch, D. (2013). <em>Psychology of music</em>. Elsevier.</p>
</div>
<div>
<p>Dowling, W. J. (1978a). Scale and contour: Two components of a theory of memory for melodies. <em>Psychological Review</em>, <em>85</em>(4), 341–354. <a href="https://doi.org/10.1037/0033-295x.85.4.341">https://doi.org/10.1037/0033-295x.85.4.341</a></p>
</div>
<div>
<p>Dowling, W. J. (1978b). Scale and contour: Two components of a theory of memory for melodies. <em>Psychological Review</em>, <em>85</em>(4), 341–354.</p>
</div>
<div>
<p>Drake, J. E., &amp; Winner, E. (2012). Confronting sadness through art-making: Distraction is more beneficial than venting. <em>Psychology of Aesthetics, Creativity, and the Arts</em>, <em>6</em>(3), 255–261. <a href="https://doi.org/10.1037/a0026909">https://doi.org/10.1037/a0026909</a></p>
</div>
<div>
<p>Eerola, T., Louhivuori, J., &amp; Lebaka, E. (2009). Expectancy in sami yoiks revisited: The role of data-driven and schema-driven knowledge in the formation of melodic expectations. <em>Musicae Scientiae: The Journal of the European Society for the Cognitive Sciences of Music</em>, <em>13</em>(2), 231–272.</p>
</div>
<div>
<p>Eerola, T., Vuoskoski, J. K., Peltola, H.-R., Putkinen, V., &amp; Schäfer, K. (2018). An integrative review of the enjoyment of sadness associated with music. <em>Physics of Life Reviews</em>, <em>25</em>, 100–121. <a href="https://doi.org/10.1016/j.plrev.2017.11.016">https://doi.org/10.1016/j.plrev.2017.11.016</a></p>
</div>
<div>
<p>Einstein, A. (1918). Über gravitationswellen. <em>Sitzungsberichte Der Königlich Preußischen Akademie Der Wissenschaften</em>, 154–167.</p>
</div>
<div>
<p>Ekman, P. (1999). Basic emotions. In T. Dalgleish &amp; T. Power (Eds.), <em>The handbook of cognition and emotion</em> (pp. 45–60). John Wiley &amp; Sons, Ltd.</p>
</div>
<div>
<p>Fogel, A. R., Rosenberg, J. C., Lehman, F. M., Kuperberg, G. R., &amp; Patel, A. D. (2015). Studying musical and linguistic prediction in comparable ways: The melodic cloze probability method. <em>Frontiers in Psychology</em>, <em>6</em>, 1718. <a href="https://doi.org/10.3389/fpsyg.2015.01718">https://doi.org/10.3389/fpsyg.2015.01718</a></p>
</div>
<div>
<p>Gardiner, M. F., Fox, A., Knowles, F., &amp; Jeffrey, D. (1996). Learning improved by arts training. <em>Nature</em>, <em>381</em>(6580), 284. <a href="https://doi.org/10.1038/381284a0">https://doi.org/10.1038/381284a0</a></p>
</div>
<div>
<p>Gosling, S. D., Rentfrow, P. J., &amp; Swann, W. B. (2003). A very brief measure of the Big-Five personality domains. <em>J. Res. Pers.</em>, <em>37</em>(6), 504–528.</p>
</div>
<div>
<p>Hakizimana, P., &amp; Fridberger, A. (2021). Inner hair cell stereocilia are embedded in the tectorial membrane. <em>Nature Communications</em>, <em>12</em>(1), 2604. <a href="https://doi.org/10.1038/s41467-021-22870-1">https://doi.org/10.1038/s41467-021-22870-1</a></p>
</div>
<div>
<p>Hallam, S., Cross, I., &amp; Thaut, M. (2017). <em>The oxford handbook of music psychology</em>. Oxford University Press.</p>
</div>
<div>
<p>Harrison, P. M. C. (2020). <em>Modelling the perception and composition of western musical harmony</em> [PhD thesis]. Queen Mary University of London.</p>
</div>
<div>
<p>Harrison, P. M. C., &amp; Pearce, M. T. (2020). Simultaneous consonance in music perception and composition. <em>Psychological Review</em>, <em>127</em>(2), 216–244. <a href="https://doi.org/10.1037/rev0000169">https://doi.org/10.1037/rev0000169</a></p>
</div>
<div>
<p>Harrison, P., &amp; Pearce, M. (2020). A computational cognitive model for the analysis and generation of voice leadings. <em>Music Perception: An Interdisciplinary Journal</em>, <em>37</em>(3), 208–224. <a href="https://doi.org/10.1525/mp.2020.37.3.208">https://doi.org/10.1525/mp.2020.37.3.208</a></p>
</div>
<div>
<p>Hart, J., &amp; Cohen, A. (1973). Intonation by rule: A perceptual quest. <em>Journal of Phonetics</em>, <em>1</em>(4), 309–327.</p>
</div>
<div>
<p>Hearne, L. M. (2020). <em>The cognition of harmonic tonality in microtonal scales</em> [PhD thesis]. Western Sydney University.</p>
</div>
<div>
<p>Helmholtz, H. L. F. (1875). <em>On the sensations of tone as a physiological basis for the theory of music</em>. Longmans, Green; Co.</p>
</div>
<div>
<p>Henrich, J., Heine, S. J., &amp; Norenzayan, A. (2010). Most people are not WEIRD. <em>Nature</em>, <em>466</em>(7302), 29–29. <a href="https://doi.org/10.1038/466029a">https://doi.org/10.1038/466029a</a></p>
</div>
<div>
<p>Hetland, L. (2000). Learning to make music enhances spatial reasoning. <em>Journal of Aesthetic Education</em>, <em>34</em>(3/4), 179–238. <a href="https://doi.org/10.2307/3333643">https://doi.org/10.2307/3333643</a></p>
</div>
<div>
<p>Hippel, P. von. (2002, May). Melodic-expectation rules as learned heuristics. <em>Proceedings of the 7th International Conference on Music Perception and Cognition</em>.</p>
</div>
<div>
<p>Hu, D. J., &amp; Saul, L. K. (2009). A probabilistic topic model for unsupervised learning of musical key-profiles. In K. Hirata, G. Tzanetakis, &amp; K. Yoshii (Eds.), <em>Proceedings of the 10th International Society for Music Information Retrieval Conference</em>.</p>
</div>
<div>
<p>Huron, D. (1996). The melodic arch in western folksongs. <em>Computing in Musicology</em>, <em>10</em>, 3–23.</p>
</div>
<div>
<p>Huron, D. (2001). Tone and voice: A derivation of the rules of voice-leading from perceptual principles. <em>Music Perception</em>, <em>19</em>(1), 1–64. <a href="https://doi.org/10.1525/mp.2001.19.1.1">https://doi.org/10.1525/mp.2001.19.1.1</a></p>
</div>
<div>
<p>Huron, D., &amp; Sellmer, P. (1992). Critical bands and the spelling of vertical sonorities. <em>Music Perception</em>, <em>10</em>(2), 129–149. <a href="https://doi.org/10.2307/40285604">https://doi.org/10.2307/40285604</a></p>
</div>
<div>
<p>Huron, D., &amp; Vuoskoski, J. K. (2020). On the enjoyment of sad music: Pleasurable compassion theory and the role of trait empathy. <em>Frontiers in Psychology</em>, <em>11</em>, 1060. <a href="https://doi.org/10.3389/fpsyg.2020.01060">https://doi.org/10.3389/fpsyg.2020.01060</a></p>
</div>
<div>
<p>Hutchinson, W., &amp; Knopoff, L. (1978). The acoustic component of western consonance. <em>Interface</em>, <em>7</em>(1), 1–29. <a href="https://doi.org/10.1080/09298217808570246">https://doi.org/10.1080/09298217808570246</a></p>
</div>
<div>
<p>Jacoby, N., Polak, R., Grahn, J., Cameron, D. J., Lee, K. M., Godoy, R., Undurraga, E. A., Huanca, T., Thalwitzer, T., Doumbia, N., &amp; al., E. (2021). <em>Universality and cross-cultural variation in mental representations of music revealed by global comparison of rhythm priors</em>. <a href="https://doi.org/10.31234/osf.io/b879v">https://doi.org/10.31234/osf.io/b879v</a></p>
</div>
<div>
<p>Jacoby, N., Undurraga, E. A., McPherson, M. J., Valdés, J., Ossandón, T., &amp; McDermott, J. H. (2019). Universal and non-universal features of musical pitch perception revealed by singing. <em>Current Biology: CB</em>, <em>29</em>(19), 3229–3243.e12. <a href="https://doi.org/10.1016/j.cub.2019.08.020">https://doi.org/10.1016/j.cub.2019.08.020</a></p>
</div>
<div>
<p>Juslin, P. N. (2013). From everyday emotions to aesthetic emotions: Towards a unified theory of musical emotions. <em>Physics of Life Reviews</em>, <em>10</em>(3), 235–266. <a href="https://doi.org/10.1016/j.plrev.2013.05.008">https://doi.org/10.1016/j.plrev.2013.05.008</a></p>
</div>
<div>
<p>Juslin, P. N., Juslin, P. N., &amp; Sloboda, J. A. (2001). Communicating emotion in music performance: A review and a theoretical framework. <em>Music and Emotion: Theory and Research</em>, 309–337.</p>
</div>
<div>
<p>Juslin, P. N., &amp; Laukka, P. (2003). Communication of emotions in vocal expression and music performance: Different channels, same code? <em>Psychological Bulletin</em>, <em>129</em>(5), 770–814.</p>
</div>
<div>
<p>Juslin, P. N., &amp; Västfjäll, D. (2008). Emotional responses to music: The need to consider underlying mechanisms. <em>Behavioral and Brain Sciences</em>, <em>31</em>(6), 751–751. <a href="https://doi.org/10.1017/s0140525x08006079">https://doi.org/10.1017/s0140525x08006079</a></p>
</div>
<div>
<p>Kidd, D. C., &amp; Castano, E. (2013). Reading literary fiction improves theory of mind. <em>Science</em>, <em>342</em>(6156), 377–380. <a href="https://doi.org/10.1126/science.1239918">https://doi.org/10.1126/science.1239918</a></p>
</div>
<div>
<p>Koelsch, S. (2009). Neural substrates of processing syntax and semantics in music. In <em>Music that works</em> (pp. 143–153). Springer-Verlag.</p>
</div>
<div>
<p>Koelsch, S., Gunter, T., Friederici, A. D., &amp; Schröger, E. (2000). Brain indices of music processing: “Nonmusicians” are musical. <em>Journal of Cognitive Neuroscience</em>, <em>12</em>(3), 520–541.</p>
</div>
<div>
<p>Krumhansl, C., &amp; Kessler, E. (1982). Tracing the dynamic changes in perceived tonal organization in a spatial representation of musical keys. <em>Psychological Review</em>, <em>89</em>(4), 334–368. <a href="https://doi.org/10.1037/0033-295x.89.4.334">https://doi.org/10.1037/0033-295x.89.4.334</a></p>
</div>
<div>
<p>Krumhansl, C. L. (1990). Cognitive foundations of musical pitch. <em>Oxford Psychology Series</em>.</p>
</div>
<div>
<p>Krumhansl, C. L. (1995). Music psychology and music theory: Problems and prospects. <em>Music Theory Spectrum</em>, <em>17</em>(1), 53–80.</p>
</div>
<div>
<p>Krumhansl, C. L., Toivanen, P., Eerola, T., Toiviainen, P., Järvinen, T., &amp; Louhivuori, J. (2000). Cross-cultural music cognition: Cognitive methodology applied to north sami yoiks. <em>Cognition</em>, <em>76</em>(1), 13–58. <a href="https://doi.org/10.1016/s0010-0277(00)00068-8">https://doi.org/10.1016/s0010-0277(00)00068-8</a></p>
</div>
<div>
<p>Ladd, D. R. (2008). <em>Intonational phonology</em> (2nd ed.). Cambridge University Press.</p>
</div>
<div>
<p>Lee, C. J., Andrade, E. B., &amp; Palmer, S. E. (2013). Interpersonal relationships and preferences for mood-congruency in aesthetic experiences. <em>The Journal of Consumer Research</em>, <em>40</em>(2), 382–391. <a href="https://doi.org/10.1086/670609">https://doi.org/10.1086/670609</a></p>
</div>
<div>
<p>Leman, M. (2000). An auditory model of the role of short-term memory in probe-tone ratings. <em>Music Perception</em>, <em>17</em>(4), 481–509.</p>
</div>
<div>
<p>Lerdahl, F. (1988). Tonal pitch space. <em>Music Perception</em>, <em>5</em>(3), 315–349. <a href="https://doi.org/10.2307/40285402">https://doi.org/10.2307/40285402</a></p>
</div>
<div>
<p>London, J. (2013). Building a representative corpus of classical music. <em>Music Perception</em>, <em>31</em>(1), 68–90.</p>
</div>
<div>
<p>MacKay, D. J. C. (2003). <em>Information theory, inference and learning algorithms</em>. Cambridge University Press.</p>
</div>
<div>
<p>Madsen, S. T., &amp; Widmer, G. (2007). Key-finding with interval profiles. <em>Proceedings of the International Computer Music Conference (ICMC)</em>.</p>
</div>
<div>
<p>Mar, R. A., &amp; Oatley, K. (2008). The function of fiction is the abstraction and simulation of social experience. <em>Perspectives on Psychological Science: A Journal of the Association for Psychological Science</em>, <em>3</em>(3), 173–192. <a href="https://doi.org/10.1111/j.1745-6924.2008.00073.x">https://doi.org/10.1111/j.1745-6924.2008.00073.x</a></p>
</div>
<div>
<p>Margulis, E. H. (2005). A model of melodic expectation. <em>Music Perception</em>, <em>22</em>(4), 663–714.</p>
</div>
<div>
<p>Mathes, R. C., &amp; Miller, R. L. (1947). Phase effects in monaural perception. <em>The Journal of the Acoustical Society of America</em>, <em>19</em>(5), 780–797. <a href="https://doi.org/10.1121/1.1916623">https://doi.org/10.1121/1.1916623</a></p>
</div>
<div>
<p>Matsunaga, R., &amp; Abe, J. (2005). Cues for key perception of a melody. <em>Music Perception</em>, <em>23</em>(2), 153–164. <a href="https://doi.org/10.1525/mp.2005.23.2.153">https://doi.org/10.1525/mp.2005.23.2.153</a></p>
</div>
<div>
<p>McAdams, S., &amp; Giordano, B. L. (2009). The perception of musical timbre. In S. Hallam, I. Cross, &amp; M. Thaut (Eds.), <em>The Oxford handbook of music psychology</em> (pp. 72–80). Oxford University Press.</p>
</div>
<div>
<p>McDermott, J. H., Lehr, A. J., &amp; Oxenham, A. J. (2010). Individual differences reveal the basis of consonance. <em>Current Biology</em>, <em>20</em>(11), 1035–1041. <a href="https://doi.org/10.1016/j.cub.2010.04.019">https://doi.org/10.1016/j.cub.2010.04.019</a></p>
</div>
<div>
<p>McDermott, J. H., Schultz, A. F., Undurraga, E. A., &amp; Godoy, R. A. (2016). Indifference to dissonance in native amazonians reveals cultural variation in music perception. <em>Nature</em>, <em>535</em>(7613), 547–550. <a href="https://doi.org/10.1038/nature18635">https://doi.org/10.1038/nature18635</a></p>
</div>
<div>
<p>McDermott, J. H., Schultz, A. F., Undurraga, E. A., &amp; Godoy, R. A. (2016). Indifference to dissonance in native amazonians reveals cultural variation in music perception. <em>Nature</em>, <em>535</em>(7613), 547–550. <a href="https://doi.org/10.1038/nature18635">https://doi.org/10.1038/nature18635</a></p>
</div>
<div>
<p>McGowan, R. W., &amp; Levitt, A. G. (2011). A comparison of rhythm in english dialects and music. <em>Music Perception</em>, <em>28</em>(3), 307–314.</p>
</div>
<div>
<p>Mehr, S. A., Krasnow, M. M., Bryant, G. A., &amp; Hagen, E. H. (2020). Origins of music in credible signaling. <em>Behavioral and Brain Sciences</em>, <em>44</em>, e60. <a href="https://doi.org/10.1017/S0140525X20000345">https://doi.org/10.1017/S0140525X20000345</a></p>
</div>
<div>
<p>Mehr, S. A., Singh, M., Knox, D., Ketter, D. M., Pickens-Jones, D., Atwood, S., Lucas, C., Jacoby, N., Egner, A. A., Hopkins, E. J., Howard, R. M., Hartshorne, J. K., Jennings, M. V., Simson, J., Bainbridge, C. M., Pinker, S., O’Donnell, T. J., Krasnow, M. M., &amp; Glowacki, L. (2019). Universality and diversity in human song. <em>Science</em>, <em>366</em>(6468). <a href="https://doi.org/10.1126/science.aax0868">https://doi.org/10.1126/science.aax0868</a></p>
</div>
<div>
<p>Mehrabian, A., &amp; Russell, J. A. (1974). <em>An approach to environmental psychology.</em> MIT Press.</p>
</div>
<div>
<p>Menninghaus, W., Wagner, V., Wassiliwizky, E., Schindler, I., Hanich, J., Jacobsen, T., &amp; Koelsch, S. (2019). What are aesthetic emotions? <em>Psychological Review</em>, <em>126</em>(2), 171–195. <a href="https://doi.org/10.1037/rev0000135">https://doi.org/10.1037/rev0000135</a></p>
</div>
<div>
<p>Meyer, L. (1956). <em>Emotion and meaning in music</em>. University of Chicago Press.</p>
</div>
<div>
<p>Milne, A. J., Laney, R., &amp; Sharp, D. (2015). A spectral pitch class model of the probe tone data and scalic tonality. <em>Music Perception</em>, <em>32</em>(4), 364–393. <a href="https://doi.org/10.1525/MP.2015.32.4.364">https://doi.org/10.1525/MP.2015.32.4.364</a></p>
</div>
<div>
<p>Milne, A. J., Sethares, W. A., Laney, R., &amp; Sharp, D. B. (2011). Modelling the similarity of pitch collections with expectation tensors. <em>Journal of Mathematics &amp; Music. Mathematical and Computational Approaches to Music Theory, Analysis, Composition and Performance</em>, <em>5</em>(1), 1–20. <a href="https://doi.org/10.1080/17459737.2011.573678">https://doi.org/10.1080/17459737.2011.573678</a></p>
</div>
<div>
<p>Moreno, S., &amp; Bidelman, G. M. (2014). Examining neural plasticity and cognitive benefit through the unique lens of musical training. <em>Hearing Research</em>, <em>308</em>, 84–97. <a href="https://doi.org/10.1016/j.heares.2013.09.012">https://doi.org/10.1016/j.heares.2013.09.012</a></p>
</div>
<div>
<p>Morgan, E., Fogel, A., Nair, A., &amp; Patel, A. D. (2019). Statistical learning and gestalt-like principles predict melodic expectations. <em>Cognition</em>, <em>189</em>, 23–34. <a href="https://doi.org/10.1016/j.cognition.2018.12.015">https://doi.org/10.1016/j.cognition.2018.12.015</a></p>
</div>
<div>
<p>Moss, F., &amp; Rohrmeier, M. (2021). Discovering tonal profiles with latent dirichlet allocation. <em>Music &amp; Science</em>, <em>4</em>, 205920432110488. <a href="https://doi.org/10.1177/20592043211048827">https://doi.org/10.1177/20592043211048827</a></p>
</div>
<div>
<p>Narmour, E. (1990). <em>The analysis and cognition of basic melodic structures: The implication-realization model</em>. University of Chicago Press.</p>
</div>
<div>
<p>Narmour, E. (1992). <em>The analysis and cognition of melodic complexity: The implication-realization model</em>. University of Chicago Press.</p>
</div>
<div>
<p>Palmer, A. R., &amp; Russell, I. J. (1986). Phase-locking in the cochlear nerve of the guinea-pig and its relation to the receptor potential of inner hair-cells. <em>Hearing Research</em>, <em>24</em>(1), 1–15. <a href="https://doi.org/10.1016/0378-5955(86)90002-x">https://doi.org/10.1016/0378-5955(86)90002-x</a></p>
</div>
<div>
<p>Park, M., Thom, J., Mennicken, S., Cramer, H., &amp; Macy, M. (2019). Global music streaming data reveal diurnal and seasonal patterns of affective preference. <em>Nat Hum Behav</em>, <em>3</em>(3), 230–236.</p>
</div>
<div>
<p>Parncutt, R. (1989). <em>Harmony: A psychoacoustical approach</em>. Springer-Verlag.</p>
</div>
<div>
<p>Patel, A. D. (2021). Vocal learning as a preadaptation for the evolution of human beat perception and synchronization. <em>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</em>, <em>376</em>(1835), 20200326. <a href="https://doi.org/10.1098/rstb.2020.0326">https://doi.org/10.1098/rstb.2020.0326</a></p>
</div>
<div>
<p>Patel, A. D., &amp; Daniele, J. R. (2003). An empirical comparison of rhythm in language and music. <em>Cognition</em>, <em>87</em>(1), 35–45.</p>
</div>
<div>
<p>Patel, A. D., &amp; Iversen, J. R. (2014). The evolutionary neuroscience of musical beat perception: The action simulation for auditory prediction (asap) hypothesis. <em>Frontiers in Systems Neuroscience</em>, <em>8</em>. <a href="https://doi.org/10.3389/fnsys.2014.00057">https://doi.org/10.3389/fnsys.2014.00057</a></p>
</div>
<div>
<p>Patel, A. D., Iversen, J. R., Bregman, M. R., &amp; Schulz, I. (2009). Experimental evidence for synchronization to a musical beat in a nonhuman animal. <em>Current Biology</em>, <em>19</em>(10), 880. <a href="https://doi.org/10.1016/j.cub.2009.05.023">https://doi.org/10.1016/j.cub.2009.05.023</a></p>
</div>
<div>
<p>Pearce, M. T. (2005). <em>The construction and evaluation of statistical models of melodic structure in music perception and composition</em> [PhD thesis]. City University, London.</p>
</div>
<div>
<p>Pearce, M. T. (2018). Statistical learning and probabilistic prediction in music cognition: Mechanisms of stylistic enculturation. <em>Annals of the New York Academy of Sciences</em>, <em>1423</em>(1), 378–395.</p>
</div>
<div>
<p>Pearce, M. T., &amp; Wiggins, G. A. (2006). Expectation in melody: The influence of context and learning. <em>Music Perception</em>, <em>23</em>(5), 377–405. <a href="https://doi.org/10.1525/mp.2006.23.5.377">https://doi.org/10.1525/mp.2006.23.5.377</a></p>
</div>
<div>
<p>Pelofi, C., &amp; Farbood, M. M. (2021). Asymmetry in scales enhances learning of new musical structures. <em>Proceedings of the National Academy of Sciences of the United States of America</em>, <em>118</em>(31). <a href="https://doi.org/10.1073/pnas.2014725118">https://doi.org/10.1073/pnas.2014725118</a></p>
</div>
<div>
<p>Pinker, S. (1997). <em>How the mind works</em>. W. W. Norton.</p>
</div>
<div>
<p>Rad, M. S., Martingano, A. J., &amp; Ginges, J. (2018). Toward a psychology of homo sapiens: Making psychological science more representative of the human population. <em>Proceedings of the National Academy of Sciences of the United States of America</em>, <em>115</em>(45), 11401–11405. <a href="https://doi.org/10.1073/pnas.1721165115">https://doi.org/10.1073/pnas.1721165115</a></p>
</div>
<div>
<p>Rauscher, F. H. (2002). Mozart and the mind: Factual and fictional effects of musical enrichment. In J. Aronson (Ed.), <em>Improving academic achievement</em> (pp. 267–278). Academic Press. <a href="https://doi.org/10.1016/B978-012064455-1/50016-6">https://doi.org/10.1016/B978-012064455-1/50016-6</a></p>
</div>
<div>
<p>Ravignani, A., &amp; Delgado, T. (2016). Musical evolution in the lab exhibits rhythmic universals. <em>Nature Publishing Group</em>, <em>1</em>(december), 1–7. <a href="https://doi.org/10.1038/s41562-016-0007">https://doi.org/10.1038/s41562-016-0007</a></p>
</div>
<div>
<p>Rohrmeier, M. (2011). Towards a generative syntax of tonal harmony. <em>Journal of Mathematics &amp; Music. Mathematical and Computational Approaches to Music Theory, Analysis, Composition and Performance</em>, <em>5</em>(1), 35–53.</p>
</div>
<div>
<p>Russell, J. A. (1980). A circumplex model of affect. <em>Journal of Personality and Social Psychology</em>, <em>39</em>(6), 1161–1178. <a href="https://doi.org/10.1037/h0077714">https://doi.org/10.1037/h0077714</a></p>
</div>
<div>
<p>Sachs, C. (1962). <em>The wellsprings of music</em>. Martinus Nijhoff.</p>
</div>
<div>
<p>Sala, G., &amp; Gobet, F. (2020). Cognitive and academic benefits of music training with children: A multilevel meta-analysis. <em>Memory &amp; Cognition</em>, <em>48</em>(8), 1429–1441. <a href="https://doi.org/10.3758/s13421-020-01060-2">https://doi.org/10.3758/s13421-020-01060-2</a></p>
</div>
<div>
<p>Santos-Luiz, C. dos, Mónico, L. S. M., Almeida, L. S., &amp; Coimbra, D. (2016). Exploring the long-term associations between adolescents’ music training and academic achievement. <em>Music Scientiae</em>, <em>20</em>(4), 512–527.</p>
</div>
<div>
<p>Sapp, C. S. (2011). <em>Computational methods for the analysis of musical structure</em> [PhD thesis]. Stanford University.</p>
</div>
<div>
<p>Savage, P. E., Brown, S., Sakai, E., &amp; Currie, T. E. (2015). Statistical universals reveal the structures and functions of human music. <em>Proceedings of the National Academy of Sciences</em>, <em>112</em>(29), 8987–8992. <a href="https://doi.org/10.1073/pnas.1414495112">https://doi.org/10.1073/pnas.1414495112</a></p>
</div>
<div>
<p>Savage, P. E., Loui, P., Tarr, B., Schachner, A., Glowacki, L., Mithen, S., &amp; Fitch, W. T. (2020). Music as a coevolved system for social bonding. <em>Behavioral and Brain Sciences</em>, <em>44</em>, e59. <a href="https://doi.org/10.1017/S0140525X20000333">https://doi.org/10.1017/S0140525X20000333</a></p>
</div>
<div>
<p>Schellenberg, E. G. (2004). Music lessons enhance IQ. <em>Psychological Science</em>, <em>15</em>(8), 511–514. <a href="https://doi.org/10.1111/j.0956-7976.2004.00711.x">https://doi.org/10.1111/j.0956-7976.2004.00711.x</a></p>
</div>
<div>
<p>Schellenberg, E. G. (2011a). Examining the association between music lessons and intelligence. <em>British Journal of Psychology</em>, <em>102</em>(3), 283–302. <a href="https://doi.org/10.1111/j.2044-8295.2010.02000.x">https://doi.org/10.1111/j.2044-8295.2010.02000.x</a></p>
</div>
<div>
<p>Schellenberg, E. G. (1996). Expectancy in melody: Tests of the implication-realization model. <em>Cognition</em>, <em>58</em>(1), 75–125. <a href="https://doi.org/10.1016/0010-0277(95)00665-6">https://doi.org/10.1016/0010-0277(95)00665-6</a></p>
</div>
<div>
<p>Schellenberg, E. G. (2011b). Music lessons, emotional intelligence, and IQ. <em>Music Perception</em>, <em>29</em>(2), 185–194. <a href="https://doi.org/10.1525/mp.2011.29.2.185">https://doi.org/10.1525/mp.2011.29.2.185</a></p>
</div>
<div>
<p>Sethares, W. A. (2005). <em>Tuning, timbre, spectrum, scale</em>. Springer.</p>
</div>
<div>
<p>Shanahan, D., &amp; Albrecht, J. (2019). Examining the effect of oral transmission on folksongs. <em>Music Perception</em>, <em>36</em>(3), 273–288. <a href="https://doi.org/10.1525/mp.2019.36.3.273">https://doi.org/10.1525/mp.2019.36.3.273</a></p>
</div>
<div>
<p>Shanahan, D., &amp; Huron, D. (2011). Interval size and phrase position: A comparison between german and chinese folksongs. <em>Empirical Musicology Review: EMR</em>, <em>6</em>(4), 187–197.</p>
</div>
<div>
<p>Skov, M., &amp; Nadal, M. (2020). There are no aesthetic emotions: Comment on menninghaus et al. (2019). <em>Psychological Review</em>, <em>127</em>(4), 640–649. <a href="https://doi.org/10.1037/rev0000187">https://doi.org/10.1037/rev0000187</a></p>
</div>
<div>
<p>Temperley, D. (1999). What’s key for key? The Krumhansl-Schmuckler key-finding algorithm reconsidered. <em>Music Perception</em>, <em>17</em>, 65–100.</p>
</div>
<div>
<p>Temperley, D. (2008). A probabilistic model of melody perception. <em>Cogn. Sci.</em>, <em>32</em>(2), 418–444.</p>
</div>
<div>
<p>Temperley, D. (2013). Computational models of music cognition. In D. Deutsch (Ed.), <em>The psychology of music</em> (pp. 327–368). Elsevier Academic Press. <a href="https://doi.org/10.1016/B978-0-12-381460-9.00008-0">https://doi.org/10.1016/B978-0-12-381460-9.00008-0</a></p>
</div>
<div>
<p>Thompson, W. F. (1996). Eugene narmour: The analysis and cognition of basic musical structures (1990) and the analysis and cognition of melodic complexity (1992): A review and empirical assessment. <em>Journal of the American Musicological Society</em>, <em>49</em>(1), 127–145.</p>
</div>
<div>
<p>Thompson, W. F., &amp; Olsen, K. N. (2021). <em>The science and psychology of music: From beethoven at the office to beyoncé at the gym</em>. Greenwood Publishing Group Inc.</p>
</div>
<div>
<p>Tillmann, B., Koelsch, S., Escoffier, N., Bigand, E., Lalitte, P., Friederici, A. D., &amp; Cramon, D. Y. von. (2006). Cognitive priming in sung and instrumental music: Activation of inferior frontal cortex. <em>Neuroimage</em>, <em>31</em>(4), 1771–1782. <a href="https://doi.org/10.1016/j.neuroimage.2006.02.028">https://doi.org/10.1016/j.neuroimage.2006.02.028</a></p>
</div>
<div>
<p>Toiviainen, P., &amp; Krumhansl, C. L. (2003). Measuring and modeling real-time responses to music: The dynamics of tonality induction. <em>Perception</em>, <em>32</em>, 741–766. <a href="https://doi.org/10.1068/p3312">https://doi.org/10.1068/p3312</a></p>
</div>
<div>
<p>Vaissière, J. (1983). Language-independent prosodic features. In <em>Springer series in language and communication</em> (pp. 53–66). Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-642-69103-4%5C_5">https://doi.org/10.1007/978-3-642-69103-4\_5</a></p>
</div>
<div>
<p>Vassilakis, P. N. (2001). <em>Perceptual and physical properties of amplitude fluctuation and their musical significance</em> [PhD thesis]. UCLA.</p>
</div>
<div>
<p>Von Hippel, P., &amp; Huron, D. (2000). Why do skips precede reversals? The effect of tessitura on melodic structure. <em>Music Perception</em>, <em>18</em>(1), 59–85. <a href="https://doi.org/10.2307/40285901">https://doi.org/10.2307/40285901</a></p>
</div>
<div>
<p>Wang, Y. S., Shen, G. Q., Guo, H., Tang, X. L., &amp; Hamade, T. (2013). Roughness modelling based on human auditory perception for sound quality evaluation of vehicle interior noise. <em>Journal of Sound and Vibration</em>, <em>332</em>(16), 3893–3904. <a href="https://doi.org/10.1016/j.jsv.2013.02.030">https://doi.org/10.1016/j.jsv.2013.02.030</a></p>
</div>
<div>
<p>Watt, H. J. (1924). Functions of the size of interval in the songs of schubert and of the chippewa and teton sioux indians. <em>British Journal of Psychology</em>, <em>14</em>(4), 370–421.</p>
</div>
<div>
<p>Weij, B. van der, Pearce, M. T., &amp; Honing, H. (2017). A probabilistic model of meter perception: Simulating enculturation. <em>Frontiers in Psychology</em>, <em>8</em>. <a href="https://doi.org/10.3389/fpsyg.2017.00824">https://doi.org/10.3389/fpsyg.2017.00824</a></p>
</div>
<div>
<p>Williamon, A., Ginsborg, J., Perkins, R., &amp; Waddell, G. (2021). <em>Performing music research: Methods in music education, psychology, and performance science</em>. Oxford University Press.</p>
</div>
<div>
<p>Wysocki, A. C., Lawson, K. M., &amp; Rhemtulla, M. (2022). Statistical control requires causal justification. <em>Advances in Methods and Practices in Psychological Science</em>, <em>5</em>(2), 25152459221095823. <a href="https://doi.org/10.1177/25152459221095823">https://doi.org/10.1177/25152459221095823</a></p>
</div>
<div>
<p>Zentner, M., Grandjean, D., &amp; Scherer, K. R. (2008). Emotions evoked by the sound of music: Characterization, classification, and measurement. <em>Emotion</em>, <em>8</em>(4), 494–521. <a href="https://doi.org/10.1037/1528-3542.8.4.494">https://doi.org/10.1037/1528-3542.8.4.494</a></p>
</div>
</div>
</div>



























  <div class="chapter-nav">
<div class="prev"><a href="computational-music-psychology.html"><span class="header-section-number">27</span> Computational music psychology</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav"><li><a class="nav-link" href="#references">References</a></li></ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/pmcharrison/intro-to-music-and-science/blob/main/900-references.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/pmcharrison/intro-to-music-and-science/edit/main/900-references.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Introduction to Music and Science</strong>" was written by Peter M. C. Harrison. It was last built on 2026-01-28.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
