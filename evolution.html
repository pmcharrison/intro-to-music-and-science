<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 13 Evolution | Music and Science</title>
<meta name="author" content="Peter M. C. Harrison">
<meta name="description" content="This chapter explores the different biological ingredients that make humans predisposed to create and appreciate music, and why these biological ingredients developed in the first place. We are...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 13 Evolution | Music and Science">
<meta property="og:type" content="book">
<meta property="og:description" content="This chapter explores the different biological ingredients that make humans predisposed to create and appreciate music, and why these biological ingredients developed in the first place. We are...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 13 Evolution | Music and Science">
<meta name="twitter:description" content="This chapter explores the different biological ingredients that make humans predisposed to create and appreciate music, and why these biological ingredients developed in the first place. We are...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="libs/datatables-binding-0.20/datatables.js"></script><link href="libs/dt-core-1.11.3/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="libs/dt-core-1.11.3/js/jquery.dataTables.min.js"></script><link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script><!-- It makes little sense to put CSS in an HTML file instead of a 
  CSS file, but this seems to be the only way I could get BS4 book to
  recognise it !--><style>
    .csl-entry {
      margin-bottom: 15px;
      padding-left: 30px;
      text-indent: -30px;
    }
  </style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Music and Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Overview</a></li>
<li><a class="" href="undergraduate-courses.html"><span class="header-section-number">2</span> Undergraduate courses</a></li>
<li><a class="" href="how-to-approach-the-courses.html"><span class="header-section-number">3</span> How to approach the courses</a></li>
<li><a class="" href="advice-on-essay-writing.html"><span class="header-section-number">4</span> Advice on essay writing</a></li>
<li><a class="" href="copyright.html"><span class="header-section-number">5</span> Copyright</a></li>
<li class="book-part">What is science?</li>
<li><a class="" href="science.html"><span class="header-section-number">6</span> Science</a></li>
<li><a class="" href="science-and-music.html"><span class="header-section-number">7</span> Science and music</a></li>
<li class="book-part">The science of music</li>
<li><a class="" href="foundations-of-acoustics.html"><span class="header-section-number">8</span> Foundations of acoustics</a></li>
<li><a class="" href="timbre.html"><span class="header-section-number">9</span> Timbre</a></li>
<li><a class="" href="pitch.html"><span class="header-section-number">10</span> Pitch</a></li>
<li><a class="" href="consonance.html"><span class="header-section-number">11</span> Consonance</a></li>
<li><a class="" href="expectation.html"><span class="header-section-number">12</span> Expectation</a></li>
<li><a class="active" href="evolution.html"><span class="header-section-number">13</span> Evolution</a></li>
<li><a class="" href="music-across-the-world.html"><span class="header-section-number">14</span> Music across the world</a></li>
<li><a class="" href="emotion.html"><span class="header-section-number">15</span> Emotion</a></li>
<li class="book-part">Scientific methods</li>
<li><a class="" href="introduction-1.html"><span class="header-section-number">16</span> Introduction</a></li>
<li><a class="" href="research-topics.html"><span class="header-section-number">17</span> Research topics</a></li>
<li><a class="" href="research-questions.html"><span class="header-section-number">18</span> Research questions</a></li>
<li><a class="" href="quantitativequalitative.html"><span class="header-section-number">19</span> Quantitative/qualitative</a></li>
<li><a class="" href="ethics.html"><span class="header-section-number">20</span> Ethics</a></li>
<li class="book-part">Quantitative methods</li>
<li><a class="" href="variables.html"><span class="header-section-number">21</span> Variables</a></li>
<li><a class="" href="causality.html"><span class="header-section-number">22</span> Causality</a></li>
<li><a class="" href="generalisability.html"><span class="header-section-number">23</span> Generalisability</a></li>
<li><a class="" href="data-visualisation.html"><span class="header-section-number">24</span> Data visualisation</a></li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">25</span> Descriptive statistics</a></li>
<li><a class="" href="inferential-statistics.html"><span class="header-section-number">26</span> Inferential statistics</a></li>
<li class="book-part">Computational approaches</li>
<li><a class="" href="computational-music-psychology.html"><span class="header-section-number">27</span> Computational music psychology</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/pmcharrison/intro-to-music-and-science">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="evolution" class="section level1">
<h1>
<span class="header-section-number">13</span> Evolution<a class="anchor" aria-label="anchor" href="#evolution"><i class="fas fa-link"></i></a>
</h1>
<p>This chapter explores the different biological ingredients that make humans predisposed to create and appreciate music, and why these biological ingredients developed in the first place.</p>
<!-- When we talk about this problem, it's useful to make a distinction between two related words: **'music'** and **'musicality'**. We discussed the definition of 'music' in the previous section -- essentially, we define music as sound that we listen to in a specifically 'musical' way, where we attend to particular acoustic properties of the sound such as pitch and rhythm. We then define 'musicality' as the capacity to engage with music in a meaningful way. When studying the evolutionary origins of music, we are not so interested in the highly refined forms of musicality we might find in the conservatoire; we're more interested in broader aspects of musicality that are shared by musicians and nonmusicians alike, such as the ability to perceive the beat in a piece of music, or to sing along with a familiar tune. -->
<p>We are going to approach these topics from the perspective of <em>evolutionary biology</em>. Evolution describes the way in which inherited characteristics of a population of organisms change over time in response to <em>natural selection</em>. Natural selection describes how individuals with different inherited characteristics differ in their propensity to survive and reproduce. A beneficial characteristic may originally come about through a chance genetic mutation: if this beneficial characteristic helps the organism to survive and reproduce, then the characteristic will be spread to more organisms in the next generation, whose survival and reproduction chances can in turn be helped by this characteristic. The theory of evolution is essential for answering ‘why’ questions in biology: it helps us to understand the reason why particular biological traits developed in the first place.</p>
<p>We will structure our discussion around two particularly important research questions in the field, which are as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Where did our musical capacities (our ‘musicality’) come from?</p></li>
<li><p>What are music’s adaptive functions?</p></li>
</ol>
<div id="where-did-our-musicality-come-from" class="section level2">
<h2>
<span class="header-section-number">13.1</span> Where did our musicality come from?<a class="anchor" aria-label="anchor" href="#where-did-our-musicality-come-from"><i class="fas fa-link"></i></a>
</h2>
<p>Before we can begin to answer this question, we need a clear idea of what ‘musicality’ comprises. Reviewing the music psychology literature gives us many example traits that contribute to musicality, such as beat perception, pitch perception, consonance perception, emotion perception, grouping, and sensitivity to musical ‘syntax’. So, we can decompose the question of ‘why did musicality develop’ into many smaller questions: ‘why did beat perception develop’, ‘why did pitch perception develop’, why did ‘consonance perception develop’, and so on.</p>
<p>A common thread throughout all of these questions is the possibility of ‘exaptation’. A biological trait is called ‘exapted’ if it originally evolved for one purpose, but then later was adopted for another purpose. For example, it is now thought that feathers originally evolved for insulation purposes, and were only later exapted for supporting flight. In the context of music, we are particularly interested in understanding whether certain aspects of musicality (for example beat perception) evolved specifically for musical functions, or whether they instead evolved originally for another purpose, and were only later adopted for music.</p>
<p>How can we tell whether a particular musical trait was exapted? It’s always difficult to prove things in evolutionary biology, but nonetheless two kinds of evidence are particularly useful here.</p>
<p>One important piece of evidence comes when the trait has (or at least had, at some point in evolutionary history), an <strong>adaptive</strong> function that is <strong>non-musical</strong>. This is a necessary precondition for exaptation. However, it’s not sufficient, because perhaps the trait originally evolved for music and only subsequently achieved its non-musical function. </p>
<p>So, a second useful piece of evidence comes when we find that the trait evolved before music evolved. If this is the case, then the trait’s evolution cannot have been guided by musical functions. Unfortunately, it is quite difficult to know exactly when music evolved, because music does not leave much of a fossil record. However, scientists try and get a handle on this question by comparing human evolution to that of related species, for examples chimpanzees and apes, who do not produce or engage with music in the way that we understand it.</p>
<p>If we apply these principles, it turns out that many aspects of musicality may well have evolved for non-musical purposes, only later being exapted for musicality. We come to this conclusion after establishing that these musical traits in fact have clear non-musical functions, and are shared with species that do not produce music, implying that they evolved prior to music’s evolution.</p>
<p>Let’s go through a few examples.</p>
<div id="pitch-perception" class="section level3">
<h3>
<span class="header-section-number">13.1.1</span> Pitch perception<a class="anchor" aria-label="anchor" href="#pitch-perception"><i class="fas fa-link"></i></a>
</h3>
<p><em>Pitch perception</em> is essential to appreciating most forms of music – without it we can’t begin to appreciate the structure or form of a melody. One might therefore hypothesise that we evolved pitch perception for its musical function. However, it turns out that pitch perception is far from being unique to humans – we find it in many parts of the animal kingdom. In particular, pitch perception seems to be useful for animals that communicate with one another using vocalisations. The ability to control the pitch of one’s vocalisations and to identify the pitch of others’ vocalisations unlocks a whole range of expressive potential, allowing birds to produce complex competitive singing displays in order to attract mates, allowing chimpanzees to communicate danger using alarm calls, and so on.</p>
</div>
<div id="beat-perception" class="section level3">
<h3>
<span class="header-section-number">13.1.2</span> Beat perception<a class="anchor" aria-label="anchor" href="#beat-perception"><i class="fas fa-link"></i></a>
</h3>
<p><em>Beat perception</em> is a second skill that is fundamental to appreciating many kinds of music. This is the process by which we hear a musical extract and identify an underlying isochronous beat that we can entrain to. Most humans can do this easily, but it turns out that it is a non-trivial skill: many of our closest animal relatives are unable to entrain to a beat, and it turns out to be surprisingly hard to program a computer to do accurate beat extraction. So, we might again hypothesise that beat perception is a skill that evolved especially to support music making and listening. However, when we look more broadly over the animal kingdom, we surprisingly do find certain species capable of beat perception, just not very close to humans evolutionarily speaking.</p>
<p>The video below shows a well-known dancing cockatoo called Snowball <span class="citation">(Patel et al., <a href="#ref-patel2009" role="doc-biblioref">2009</a>)</span>. Snowball likes to dance to the musical beat, displaying abilities that strongly imply a sophisticated capacity for beat perception. Alongside cockatoos, beat perception abilities have also been demonstrated in budgerigars and sea lions, and there are ongoing research programmes seeking to identify more species capable of beat perception. Importantly, these species seem not to have evolved beat perception in one common evolutionary event; instead, beat perception seems to have convergently evolved multiple times in multiple species, not obviously in the context of music-making.</p>
<div class="figure">
<img src="images/1x1.png" alt=""><p class="caption"><video controls width="100%"><source src="https://s3-eu-west-1.amazonaws.com/media.pmcharrison.com/music/animals/snowball.mp4" type="video/mp4"></source></video><strong>Snowball the parrot dancing to music.</strong> Credit: <span class="citation">Patel et al. (<a href="#ref-patel2009" role="doc-biblioref">2009</a>)</span></p>
</div>

<p><span class="citation">Patel &amp; Iversen (<a href="#ref-patel2014" role="doc-biblioref">2014</a>)</span> proposed that beat perception abilities come as a consequence of evolving ‘vocal-learning’ abilities. Vocal learning means learning to produce complex vocal signals from auditory experience and sensory feedback. Vocal-learning abilities are only present in a small range of animal species (parrots, songbirds, hummingbirds, elephants, seals, and bats), and seems to require specialised neural circuitry coupling motor regions to auditory regions. Patel and Iversen’s hypothesis is that beat perception comes ‘for free’ as a consequence of developing this neural circuitry. In later work, <span class="citation">Patel (<a href="#ref-Patel2021-vu" role="doc-biblioref">2021</a>)</span> has nuanced this view, arguing that the human capacity for entrainment was further finessed through selection pressures specific to music (see Section <a href="evolution.html#what-are-musics-adaptive-functions">13.2</a>. Various scientists are currently trying to explore these hypotheses by investigating whether other vocal learners, for example seals and bats, possess latent beat perception abilities.</p>
</div>
<div id="emotion-perception" class="section level3">
<h3>
<span class="header-section-number">13.1.3</span> Emotion perception<a class="anchor" aria-label="anchor" href="#emotion-perception"><i class="fas fa-link"></i></a>
</h3>
<p><em>Emotion perception</em> is a third key characteristic of musicality. Music has a great capacity to elicit emotional responses, and one might think that the sensitivity to these emotions evolved specifically for this context. However, if we explore the cues that music uses to elicit emotional responses, it turns out that many of these cues are shared directly with language. We will discuss these mechanisms in detail in Chapter <a href="emotion.html#emotion">15</a>.</p>
</div>
<div id="auditory-scene-analysis" class="section level3">
<h3>
<span class="header-section-number">13.1.4</span> Auditory scene analysis<a class="anchor" aria-label="anchor" href="#auditory-scene-analysis"><i class="fas fa-link"></i></a>
</h3>
<p>A fourth key aspect of music perception is the ability to parse complex musical textures where many things are happening at the same time. This might involve for example distinguishing the melody from accompaniment in a pop song, hearing out the different subjects in a Bach fugue, and so on. These skills for parsing musical scenes seem directly linked to general processes of <em>auditory scene analysis</em> that help organisms to understand non-musical auditory environments. For example, in a cocktail party, auditory scene analysis is what allows us to separate the noisy sound signal into different perceptual streams corresponding to different conversations. Many aspects of human auditory scene analysis seem to be shared with non-human, non-musical species, implying that these traits evolved for non-musical rather than musical applications.</p>
</div>
<div id="musical-syntax" class="section level3">
<h3>
<span class="header-section-number">13.1.5</span> Musical syntax<a class="anchor" aria-label="anchor" href="#musical-syntax"><i class="fas fa-link"></i></a>
</h3>
<p><em>Musical syntax</em> is a fifth important aspect of music perception. By musical syntax, we mean music’s sequential and hierarchical structure: for example, the sense in which successive melody notes may be grouped into implied chords, how these chords may be grouped into chord progressions, and how chord progressions come together to produce higher-level tonal organisation. Understanding these musical syntactic structures requires fairly complex cognitive processing, and we might wonder why humans developed the cognitive skills to do this.</p>
<p>A prominent hypothesis is that our abilities to process musical syntax stems from our abilities to process linguistic syntax. This hypothesis is suggested by various structural similarities between linguistic and musical syntax, for example the way that both music and language can be conceptualised as atomic elements (such as notes, phonemes) that are hierarchically grouped into higher-level structures, such as chords and melodies or words and sentences <span class="citation">(Chomsky, <a href="#ref-Chomsky1957-om" role="doc-biblioref">1957</a>; Rohrmeier, <a href="#ref-Rohrmeier2011-ds" role="doc-biblioref">2011</a>)</span>. There is some tentative empirical evidence for this hypothesis, demonstrating for example certain similarities or overlaps between neural signatures of linguistic and musical processing. However, it is difficult to settle the question definitively, because music and language are not found in any other species, and because neither leave fossil records, making it difficult to know which came first in the evolutionary timeline. This connection between music and language is the subject of lots of ongoing research.﻿</p>
</div>
<div id="conclusion" class="section level3">
<h3>
<span class="header-section-number">13.1.6</span> Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"><i class="fas fa-link"></i></a>
</h3>
<p>So, returning to our original question of ‘why did our musical capacities develop in the first place?’, it seems clear that many of our musical capacities may in fact have originally evolved for non-musical purposes.</p>
<p>Does this mean that musicality has never shaped evolution in in its own way? Not necessarily. It is possible that musicality originally evolved for non-musical reasons, but subsequently became evolutionarily valuable in its own right, and hence was finessed by further evolutionary processes <span class="citation">(Patel, <a href="#ref-Patel2021-vu" role="doc-biblioref">2021</a>; Savage et al., <a href="#ref-Savage2020-mb" role="doc-biblioref">2020</a>)</span>. The question is then, why might musicality have become evolutionarily valuable? This is the topic of the next section.</p>
</div>
</div>
<div id="what-are-musics-adaptive-functions" class="section level2">
<h2>
<span class="header-section-number">13.2</span> What are music’s adaptive functions?<a class="anchor" aria-label="anchor" href="#what-are-musics-adaptive-functions"><i class="fas fa-link"></i></a>
</h2>
<div id="the-auditory-cheesecake-hypothesis" class="section level3">
<h3>
<span class="header-section-number">13.2.1</span> The ‘auditory cheesecake hypothesis’<a class="anchor" aria-label="anchor" href="#the-auditory-cheesecake-hypothesis"><i class="fas fa-link"></i></a>
</h3>
<p>One possibility is that music conveys no survival or reproductive benefits, but rather tickles pleasure centres in the brain that originally evolved for other reasons. An analogy would be various recreational drugs. This hypothesis was most famously articulated by Stephen Pinker, who wrote “I suspect that music is auditory cheesecake, an exquisite confection crafted to tickle the sensitive spots of at least six of our mental faculties” <span class="citation">(Pinker, <a href="#ref-Pinker1997-gh" role="doc-biblioref">1997</a>)</span>.</p>
<p>What pre-existing mental faculties could music be tickling, and why would tickling these faculties be pleasurable? We will consider a couple of possibilities now.</p>
<div id="information-processing" class="section level4">
<h4>
<span class="header-section-number">13.2.1.1</span> Information processing<a class="anchor" aria-label="anchor" href="#information-processing"><i class="fas fa-link"></i></a>
</h4>
<p>Music perception can be formulated as an information processing problem. Sound arrives in a very complex form, and the brain’s job is to process and understand this complex information. It needs to group different harmonics together into tones, and group multiple tones into melodies and chords; it needs to relate the pitches and rhythm it hears to prior cultural knowledge about tonality and metre; it needs to keep track of local thematic information, modulations, and emotional cues. One proposition is that music elicits pleasure precisely because of how it stimulates this complex information processing system.</p>
<p>How exactly would this information processing become rewarding? We don’t really know yet, though there are various hypotheses in the literature. One hypothesis is that rewards are released when the brain makes predictions for future events, and these predictions turn out to be correct. A second hypothesis is that rewards are released when the incoming information is initially complex, but the brain successfully compresses it into a small representation, perhaps by noticing certain repeating patterns or by relating the music to prior cultural knowledge. A third hypothesis is that rewards are released when the brain feels that is successfully learning new information. Many of these ideas have some kind of intuitive rationalisation in terms of evolutionary adaptation, but there has been little progress in demonstrating that these ideas explain much of musical pleasure in practice.</p>
</div>
<div id="emotion-processing" class="section level4">
<h4>
<span class="header-section-number">13.2.1.2</span> Emotion processing<a class="anchor" aria-label="anchor" href="#emotion-processing"><i class="fas fa-link"></i></a>
</h4>
<p>Another potential aspect of musical pleasure concerns music’s ability to communicate various emotions. It’s clear to all of us that music can indeed communicate a wide variety of emotions, ranging from ecstasy to tragedy. It’s not surprising that listening to happy music should elicit pleasure; what’s more surprising though is that listening to sad music can elicit just as much pleasure. Why is this? We will outline various possibilities here; see <span class="citation">Eerola et al. (<a href="#ref-Eerola2018-rk" role="doc-biblioref">2018</a>)</span> for an in-depth review.</p>
<p>One possibility suggested by recent work is that listening to emotional music is a bit like listening to someone tell us an emotional story about their lives. From a survival perspective, it makes a lot of sense to pay attention to other people’s emotional stories, even when these stories are sad: it provides an opportunity to learn from their experiences without having to go through the same negative life experiences, and it provides an opportunity to develop our ability to see from other people’s perspectives <span class="citation">(for relevant arguments in the context of literature, see Kidd &amp; Castano, <a href="#ref-Kidd2013-rr" role="doc-biblioref">2013</a>; Mar &amp; Oatley, <a href="#ref-Mar2008-vw" role="doc-biblioref">2008</a>)</span>. This hypothesis may be termed the <em>simulation</em> hypothesis. Moreover, if the music induces the listener to feel compassion towards the musical source, this feeling of compassion may itself be pleasurable; compassion is a direct precursor of altruism, and humans have evolved to experience pleasure upon performing altruistic acts, presumably in part due to the phenomenon of kin selection (helping genetically related individuals helps to propagate one’s shared genes) and in part due to the phenomenon of reciprocal altruism (if I help you, one day you will help me in return). This hypothesis has been termed <em>pleasurable compassion theory</em> <span class="citation">(Huron &amp; Vuoskoski, <a href="#ref-Huron2020-wm" role="doc-biblioref">2020</a>)</span>.</p>
<p>Other work has suggested that this imagined compassionate relationship may alternatively operate in the reverse direction. In particular, it is suggested that to sad listeners sad music will represent a virtual person with congruent emotions, and the existence of this virtual person will have a comforting and consoling effect <span class="citation">(Lee et al., <a href="#ref-Lee2013-cn" role="doc-biblioref">2013</a>)</span>. This may be termed the <em>social surrogacy</em> hypothesis. Another related possibility is that sad music distracts the sad listener from their own emotions, and this distraction ultimately improves the listener’s mood <span class="citation">(Drake &amp; Winner, <a href="#ref-Drake2012-gw" role="doc-biblioref">2012</a>)</span>.</p>
</div>
<div id="problems-with-the-cheesecake-hypothesis" class="section level4">
<h4>
<span class="header-section-number">13.2.1.3</span> Problems with the ‘cheesecake’ hypothesis<a class="anchor" aria-label="anchor" href="#problems-with-the-cheesecake-hypothesis"><i class="fas fa-link"></i></a>
</h4>
<p>Above we explored a couple of ways in which the auditory cheesecake hypothesis could work in practice, with music eliciting pleasure despite not having any intrinsic adaptive function. We should now acknowledge two limitations of the hypothesis.</p>
<p>The first is the fact that humans invest a lot of resources (such as time and money) into music. Evolution tends to prune away behaviours that bring costs without benefits, which makes it less likely that music would survive to become so widespread if it didn’t bring some kind of adaptive function.</p>
<p>A second limitation is explaining ‘groove’, the sense in which music often elicits a deep impulse to entrain body movement to its beat, with this entrainment often then feeling deeply pleasurable. Entrainment doesn’t seem to have an adaptive function in non-musical contexts, so it is difficult to explain why we would enjoy it so much.</p>
<p>These limitations suggest that we should entertain the possibility that music does after all have some kind of adaptive function. We’ll now discuss various ways in which this could work.</p>
</div>
</div>
<div id="sexual-selection" class="section level3">
<h3>
<span class="header-section-number">13.2.2</span> Sexual selection<a class="anchor" aria-label="anchor" href="#sexual-selection"><i class="fas fa-link"></i></a>
</h3>
<p><span class="citation">Darwin (<a href="#ref-Darwin1871-rg" role="doc-biblioref">1871</a>)</span> promoted the hypothesis that human musicality was shaped by <strong>sexual selection</strong>, similar to the evolution of birdsong. He claimed that early humans competed to attract mates by virtue of their musical performances, producing a selection bias towards improved musical skills, and hence promoting the evolution of musicality. This hypothesis has some surface plausibility, but is now considered to be problematic <span class="citation">(e.g. Mehr et al., <a href="#ref-Mehr2020-zk" role="doc-biblioref">2020</a>)</span>. The key issue is that sexual selection tends to create sexual dimorphism, where the relevant trait is amplified most in the sex that invests least in reproduction. This is why male birds tend to have more flamboyant plumage, for example. In contrast, we don’t see strong sexual dimorphism in human musicality.</p>
</div>
<div id="social-bonding" class="section level3">
<h3>
<span class="header-section-number">13.2.3</span> Social bonding<a class="anchor" aria-label="anchor" href="#social-bonding"><i class="fas fa-link"></i></a>
</h3>
<p>A second hypothesis is that music’s significant evolutionary function was <strong>inducing social bonding</strong> <span class="citation">(e.g. Savage et al., <a href="#ref-Savage2020-mb" role="doc-biblioref">2020</a>)</span>. Various scientific studies have confirmed that music-making seems to be an effective way of enhancing social bonding within a group. It’s obvious that social bonding has positive adaptive implications: it helps to form stable communities of individuals that can help each other to hunt for food and deter predators. Now, we should ask why we need music to promote social-bonding in the first place; if social bonding is so useful, why didn’t we simply evolve a propensity for social bonding that didn’t depend on time-consuming music-making?</p>
<p>The answer may be that music-making provides a particularly good way to develop social relationships. It allows you to practice complex collaborative behaviors without risk of dangerous consequences. It allows you to develop a relationship with many individuals at the same time in a way that language cannot. It has a ‘floating intentionality’ allowing many people to participate at the same time and feel like they are communicating something together, even if they don’t agree much on specific things <span class="citation">(Cross, <a href="#ref-Cross2001-nt" role="doc-biblioref">2001</a>)</span>. Put another way, a communal musical experience can support many people with diverse opinions, even if they wouldn’t ordinarily get on well in conversation.</p>
<p>Note that the social-bonding hypothesis provides a good explanation for musical ‘groove’, where people enjoy synchronising their physical movements to the musical beat: humans evolved to enjoy musical synchrony because it promoted group musical activities, and hence promoting social bonding.</p>
</div>
<div id="credible-signalling" class="section level3">
<h3>
<span class="header-section-number">13.2.4</span> Credible signalling<a class="anchor" aria-label="anchor" href="#credible-signalling"><i class="fas fa-link"></i></a>
</h3>
<p>A third hypothesis is that music-making evolved as a credible signal <span class="citation">(e.g. Mehr et al., <a href="#ref-Mehr2020-zk" role="doc-biblioref">2020</a>)</span>. A credible signal is a signal that is hard to fake, and therefore provides compelling evidence for a given state of affairs. For example, the building of massive architectural structures such as the pyramids historically provided a credible signal that a civilisation was technologically advanced and had the capacity to coordinate impressively large workforces.</p>
<p>Along these lines, we might suppose that performing a large-scale piece of collaborative music or dance acts as a credible signal of a group’s strength, size, and cooperation ability. A well-known example is the <a href="https://www.youtube.com/watch?v=BI851yJUQQw">Maori “Haka” dance</a>, which is traditionally associated with the battle preparations of Maori warriors, and is often performed by New Zealand sports teams before international matches. Note that, like the social-bonding hypothesis, the credible-signaling hypothesis also provides a reasonable explanation of musical ‘groove’.</p>
<div class="figure">
<img src="images/1x1.png" alt=""><p class="caption"><iframe width="560" height="315" src="https://www.youtube.com/embed/BI851yJUQQw?start=0" style="display: block; margin-bottom: 25px" title="A Maori 'Haka' dance." frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <strong>A Maori ‘Haka’ dance.</strong></p>
</div>

<p>A second potential form of credible signalling concerns parental attention. The idea is that singing to a child is a credible signal that you’re paying attention to them, because it’s guaranteeing that you’re somewhere in close proximity to the child, and you can’t be using your voice for other things (such as talking).</p>
</div>
<div id="conclusions" class="section level3">
<h3>
<span class="header-section-number">13.2.5</span> Conclusions<a class="anchor" aria-label="anchor" href="#conclusions"><i class="fas fa-link"></i></a>
</h3>
<p>We began this chapter by asking why our musical capacities developed in the first place. In all the cases we considered, the answer seemed to be exaptation: in other words, the musical capacities seem to derive directly from cognitive capacities that likely evolved for other reasons. However, it seems plausible that these same capacities may have subsequently been shaped by evolutionary functions of music-making.</p>
<p>We then asked a second question: what might these subsequent evolutionary functions be? We discussed three potential explanations to this question. The first was the auditory cheesecake hypothesis, which claims that music has no special evolutionary pressures, and that people pursue music because it tickles their information processing and emotion processing capacities. The second explanation claimed that humans evolved to produce music as a mechanism for inducing social bonding. The third explanation claimed that music humans evolved to produce music as a credible signalling mechanism.</p>
<p>It’s important to emphasise that many of these hypotheses are still rather speculative, and more work is needed to validate them as theories. There are also still lots of differences in opinion in the literature <span class="citation">(e.g. Savage et al., <a href="#ref-Savage2020-mb" role="doc-biblioref">2020</a>; Mehr et al., <a href="#ref-Mehr2020-zk" role="doc-biblioref">2020</a>)</span>. Unfortunately, the fact that music leaves essentially no fossil record makes it difficult to imagine ever achieving a conclusive end to this debate. Nonetheless, these evolutionary questions are very important to think about, because they constitute the foundations of almost all of music psychology.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Chomsky1957-om">
<p>Chomsky, N. (1957). <em>Syntactic structures</em>. Mouton Publishers.</p>
</div>
<div id="ref-Cross2001-nt">
<p>Cross, I. (2001). Music, cognition, culture, and evolution. <em>Annals of the New York Academy of Sciences</em>, <em>930</em>, 28–42. <a href="https://doi.org/10.1111/j.1749-6632.2001.tb05723.x">https://doi.org/10.1111/j.1749-6632.2001.tb05723.x</a></p>
</div>
<div id="ref-Darwin1871-rg">
<p>Darwin, C. (1871). <em>The descent of man and selection in relation to sex</em>. John Murray.</p>
</div>
<div id="ref-Drake2012-gw">
<p>Drake, J. E., &amp; Winner, E. (2012). Confronting sadness through art-making: Distraction is more beneficial than venting. <em>Psychology of Aesthetics, Creativity, and the Arts</em>, <em>6</em>(3), 255–261. <a href="https://doi.org/10.1037/a0026909">https://doi.org/10.1037/a0026909</a></p>
</div>
<div id="ref-Eerola2018-rk">
<p>Eerola, T., Vuoskoski, J. K., Peltola, H.-R., Putkinen, V., &amp; Schäfer, K. (2018). An integrative review of the enjoyment of sadness associated with music. <em>Physics of Life Reviews</em>, <em>25</em>, 100–121. <a href="https://doi.org/10.1016/j.plrev.2017.11.016">https://doi.org/10.1016/j.plrev.2017.11.016</a></p>
</div>
<div id="ref-Huron2020-wm">
<p>Huron, D., &amp; Vuoskoski, J. K. (2020). On the enjoyment of sad music: Pleasurable compassion theory and the role of trait empathy. <em>Frontiers in Psychology</em>, <em>11</em>, 1060. <a href="https://doi.org/10.3389/fpsyg.2020.01060">https://doi.org/10.3389/fpsyg.2020.01060</a></p>
</div>
<div id="ref-Kidd2013-rr">
<p>Kidd, D. C., &amp; Castano, E. (2013). Reading literary fiction improves theory of mind. <em>Science</em>, <em>342</em>(6156), 377–380. <a href="https://doi.org/10.1126/science.1239918">https://doi.org/10.1126/science.1239918</a></p>
</div>
<div id="ref-Lee2013-cn">
<p>Lee, C. J., Andrade, E. B., &amp; Palmer, S. E. (2013). Interpersonal relationships and preferences for Mood-Congruency in aesthetic experiences. <em>The Journal of Consumer Research</em>, <em>40</em>(2), 382–391. <a href="https://doi.org/10.1086/670609">https://doi.org/10.1086/670609</a></p>
</div>
<div id="ref-Mar2008-vw">
<p>Mar, R. A., &amp; Oatley, K. (2008). The function of fiction is the abstraction and simulation of social experience. <em>Perspectives on Psychological Science: A Journal of the Association for Psychological Science</em>, <em>3</em>(3), 173–192. <a href="https://doi.org/10.1111/j.1745-6924.2008.00073.x">https://doi.org/10.1111/j.1745-6924.2008.00073.x</a></p>
</div>
<div id="ref-Mehr2020-zk">
<p>Mehr, S. A., Krasnow, M. M., Bryant, G. A., &amp; Hagen, E. H. (2020). Origins of music in credible signaling. <em>Behavioral and Brain Sciences</em>, <em>44</em>, e60. <a href="https://doi.org/10.1017/S0140525X20000345">https://doi.org/10.1017/S0140525X20000345</a></p>
</div>
<div id="ref-Patel2021-vu">
<p>Patel, A. D. (2021). Vocal learning as a preadaptation for the evolution of human beat perception and synchronization. <em>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</em>, <em>376</em>(1835), 20200326. <a href="https://doi.org/10.1098/rstb.2020.0326">https://doi.org/10.1098/rstb.2020.0326</a></p>
</div>
<div id="ref-patel2014">
<p>Patel, A. D., &amp; Iversen, J. R. (2014). The evolutionary neuroscience of musical beat perception: The action simulation for auditory prediction (asap) hypothesis. <em>Frontiers in Systems Neuroscience</em>, <em>8</em>. <a href="https://doi.org/10.3389/fnsys.2014.00057">https://doi.org/10.3389/fnsys.2014.00057</a></p>
</div>
<div id="ref-patel2009">
<p>Patel, A. D., Iversen, J. R., Bregman, M. R., &amp; Schulz, I. (2009). Experimental evidence for synchronization to a musical beat in a nonhuman animal. <em>Current Biology</em>, <em>19</em>(10), 880. <a href="https://doi.org/10.1016/j.cub.2009.05.023">https://doi.org/10.1016/j.cub.2009.05.023</a></p>
</div>
<div id="ref-Pinker1997-gh">
<p>Pinker, S. (1997). <em>How the mind works</em>. W. W. Norton.</p>
</div>
<div id="ref-Rohrmeier2011-ds">
<p>Rohrmeier, M. (2011). Towards a generative syntax of tonal harmony. <em>Journal of Mathematics &amp; Music. Mathematical and Computational Approaches to Music Theory, Analysis, Composition and Performance</em>, <em>5</em>(1), 35–53.</p>
</div>
<div id="ref-Savage2020-mb">
<p>Savage, P. E., Loui, P., Tarr, B., Schachner, A., Glowacki, L., Mithen, S., &amp; Fitch, W. T. (2020). Music as a coevolved system for social bonding. <em>Behavioral and Brain Sciences</em>, <em>44</em>, e59. <a href="https://doi.org/10.1017/S0140525X20000333">https://doi.org/10.1017/S0140525X20000333</a></p>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="expectation.html"><span class="header-section-number">12</span> Expectation</a></div>
<div class="next"><a href="music-across-the-world.html"><span class="header-section-number">14</span> Music across the world</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#evolution"><span class="header-section-number">13</span> Evolution</a></li>
<li>
<a class="nav-link" href="#where-did-our-musicality-come-from"><span class="header-section-number">13.1</span> Where did our musicality come from?</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#pitch-perception"><span class="header-section-number">13.1.1</span> Pitch perception</a></li>
<li><a class="nav-link" href="#beat-perception"><span class="header-section-number">13.1.2</span> Beat perception</a></li>
<li><a class="nav-link" href="#emotion-perception"><span class="header-section-number">13.1.3</span> Emotion perception</a></li>
<li><a class="nav-link" href="#auditory-scene-analysis"><span class="header-section-number">13.1.4</span> Auditory scene analysis</a></li>
<li><a class="nav-link" href="#musical-syntax"><span class="header-section-number">13.1.5</span> Musical syntax</a></li>
<li><a class="nav-link" href="#conclusion"><span class="header-section-number">13.1.6</span> Conclusion</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#what-are-musics-adaptive-functions"><span class="header-section-number">13.2</span> What are music’s adaptive functions?</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#the-auditory-cheesecake-hypothesis"><span class="header-section-number">13.2.1</span> The ‘auditory cheesecake hypothesis’</a></li>
<li><a class="nav-link" href="#sexual-selection"><span class="header-section-number">13.2.2</span> Sexual selection</a></li>
<li><a class="nav-link" href="#social-bonding"><span class="header-section-number">13.2.3</span> Social bonding</a></li>
<li><a class="nav-link" href="#credible-signalling"><span class="header-section-number">13.2.4</span> Credible signalling</a></li>
<li><a class="nav-link" href="#conclusions"><span class="header-section-number">13.2.5</span> Conclusions</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/pmcharrison/intro-to-music-and-science/blob/main/050-evolution.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/pmcharrison/intro-to-music-and-science/edit/main/050-evolution.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Music and Science</strong>" was written by Peter M. C. Harrison. It was last built on 2023-01-14.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
